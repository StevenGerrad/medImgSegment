{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torchvision import transforms as tfs\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch), #添加了BN层\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Unet, self).__init__()\n",
    "        self.conv1 = DoubleConv(in_ch, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        # self.conv4 = DoubleConv(256, 512)\n",
    "        # self.pool4 = nn.MaxPool2d(2)\n",
    "        # self.conv5 = DoubleConv(512, 1024)\n",
    "\n",
    "        # 逆卷积，也可以使用上采样\n",
    "        # self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        # self.conv6 = DoubleConv(1024, 512)\n",
    "        # self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        # self.conv7 = DoubleConv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        # p3 = self.pool3(c3)\n",
    "        # c4 = self.conv4(p3)\n",
    "        # p4 = self.pool4(c4)\n",
    "        # c5 = self.conv5(p4)\n",
    "\n",
    "        # up_6 = self.up6(c5)\n",
    "        # merge6 = torch.cat([up_6, c4], dim=1)\n",
    "        # c6 = self.conv6(merge6)\n",
    "\n",
    "        # up_7 = self.up7(c6)\n",
    "        # merge7 = torch.cat([up_7, c3], dim=1)\n",
    "        # c7 = self.conv7(merge7)\n",
    "\n",
    "        up_8 = self.up8(c3)\n",
    "        merge8 = torch.cat([up_8, c2], dim=1)\n",
    "        c8 = self.conv8(merge8)\n",
    "\n",
    "        up_9 = self.up9(c8)\n",
    "        merge9 = torch.cat([up_9, c1], dim=1)\n",
    "        c9 = self.conv9(merge9)\n",
    "\n",
    "        c10 = self.conv10(c9)\n",
    "        out = nn.Sigmoid()(c10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData():\n",
    "    def __init__(self):\n",
    "        ''' 图像数据与标记数据路径 s1: 各为 150张 '''\n",
    "        self.image_dir = './imgData/train_data/s1/image/'\n",
    "        self.label_dir = './imgData/train_data/s1/label/'\n",
    "        self.image_data = None\n",
    "        self.label_data = None\n",
    "        \n",
    "    def get_image_file(self):\n",
    "        ''' 图像数据为 512 * 512, 为源数据值, 未作改动(范围在: -500左右 ~ 1000+ ) '''\n",
    "        file_dir = self.image_dir\n",
    "        image_data = []\n",
    "\n",
    "        files = os.listdir(file_dir)\n",
    "        files.sort(key= lambda x:int(x[:-4]))\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.npy':\n",
    "                img_item = np.load(file_dir + file)\n",
    "                image_data.append(img_item)\n",
    "        self.image_data = image_data\n",
    "        return image_data\n",
    "    \n",
    "    def decode(self, image, min=0.0, max=255.0):\n",
    "        image[image < min] = min\n",
    "        image[image > max] = max\n",
    "        image = image / max\n",
    "        return image\n",
    "\n",
    "    def get_label_file(self):\n",
    "        ''' 标签数据为 512 * 512, 为0/1 '''\n",
    "        file_dir = self.label_dir\n",
    "        label_data = []\n",
    "\n",
    "        files = os.listdir(file_dir)\n",
    "        files.sort(key= lambda x:int(x[:-4]))\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.npy':\n",
    "                img_item = np.load(file_dir + file)\n",
    "                label_data.append(img_item)\n",
    "        self.label_data = label_data\n",
    "        return label_data\n",
    "    \n",
    "    def test_show(self):\n",
    "        ''' 随机取九张展示 '''\n",
    "        if self.image_data == None or self.label_data == None:\n",
    "            self.get_image_file()\n",
    "            self.get_label_file()\n",
    "        \n",
    "        _, figs = plt.subplots(3, 3)\n",
    "        for i in range(3):\n",
    "            for j in range(3): \n",
    "                index = random.randint(0,len(self.image_data)-1)\n",
    "                img_item = self.image_data[index]\n",
    "                label_item = self.label_data[index]\n",
    "                # 标签处简单处理，显示浅红色\n",
    "                img_item[img_item < 0] = 0\n",
    "                img_item[img_item > 255] = 255\n",
    "                img_item = img_item.astype(np.uint8)\n",
    "                img_item = cv2.merge([img_item, img_item, img_item])\n",
    "                img_item[label_item > 0] = img_item[label_item > 0] * 0.6 + (80, 0, 0)\n",
    "\n",
    "                figs[i][j].imshow(img_item)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_train_data(self,number=50,batch_size=5,channel=1,im_size=(512,512)):\n",
    "        ''' \n",
    "        先试试使用未经处理的图像数据\n",
    "        注意：channel只能为奇数\n",
    "        '''\n",
    "        self.get_image_file()\n",
    "        self.get_label_file()\n",
    "\n",
    "        self.batch_size = 5\n",
    "        self.channel = channel\n",
    "        \n",
    "        # 此时数据范围较大, 对某范围内数值进行压缩处理, 其余直接取极值\n",
    "        l_temp = []\n",
    "        for i in self.image_data:\n",
    "            i = self.decode(i, 0.0, 300.0)\n",
    "            l_temp.append(i)\n",
    "        self.image_data = l_temp\n",
    "\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        while len(train_data) < number: \n",
    "            l1 = []\n",
    "            l2 = []\n",
    "            for i in range(batch_size):\n",
    "                # 随机从图片序列中选一个channel起始索引\n",
    "                ind = random.randint(0, len(self.image_data) - channel)\n",
    "                # channel压缩\n",
    "                temp = self.image_data[ind]\n",
    "                # temp = temp[:,:,np.newaxis,np.newaxis]\n",
    "                temp = temp[np.newaxis,np.newaxis,:,:]\n",
    "                for i in range(ind + 1, ind + channel):\n",
    "                    temp1 = self.image_data[i][np.newaxis, np.newaxis, :, :]\n",
    "                    # torch.cat([temp, temp1], dim=1)\n",
    "                    temp = np.concatenate((temp, temp1), axis=1)\n",
    "                l1.append(temp)\n",
    "\n",
    "                # label只能是三维，channel只能为奇数\n",
    "                temp = self.label_data[int((ind*2+channel-1)/2)]\n",
    "                temp = temp[np.newaxis,:,:]\n",
    "                l2.append(temp)\n",
    "            \n",
    "            t1 = l1[0]\n",
    "            t2 = l2[0]\n",
    "            for i in range(1,batch_size):\n",
    "                # torch.cat([t1, l1[i]], dim=3)\n",
    "                # torch.cat([t2, l2[i]], dim=3)\n",
    "                t1 = np.concatenate((t1, l1[i]), axis=0)\n",
    "                t2 = np.concatenate((t2, l2[i]), axis=0)\n",
    "            # 将numpy转化为torch.tensor\n",
    "            t1 = torch.from_numpy(t1)\n",
    "            t1 = torch.tensor(t1, dtype=torch.float32)\n",
    "            t2 = torch.from_numpy(t2)\n",
    "            t2 = torch.tensor(t2, dtype=torch.float32)\n",
    "\n",
    "            # 默认大小为(512,512)的不处理\n",
    "            if im_size != (512, 512):\n",
    "                ind_x = round(random.random() * (512 - im_size[0]))\n",
    "                ind_y = round(random.random() * (512 - im_size[1]))\n",
    "                ind_xx = torch.LongTensor(list(range(ind_x, ind_x + im_size[0])))\n",
    "                ind_yy = torch.LongTensor(list(range(ind_y, ind_y + im_size[1])))\n",
    "                t1 = torch.index_select(t1, 2, ind_xx)\n",
    "                t1 = torch.index_select(t1, 3, ind_yy)\n",
    "\n",
    "                t2 = torch.index_select(t2, 1, ind_xx)\n",
    "                t2 = torch.index_select(t2, 2, ind_yy)\n",
    "            \n",
    "            train_data.append(t1)\n",
    "            train_label.append(t2)\n",
    "        \n",
    "        return train_data,train_label\n",
    "        # return self.image_data, self.label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, xx, yy, EPOCH=100, learning_rate=0.05):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "\n",
    "    accuracy = 0\n",
    "    print('start train...')\n",
    "\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "    for epoch in range(EPOCH):\n",
    "        step = 0\n",
    "\n",
    "        # 取 80% 数据做训练集\n",
    "        ind_test = int(len(xx)*0.8)\n",
    "        for step, b_x in enumerate(xx[0:ind_test]):\n",
    "            output = net(b_x)  # cnn output\n",
    "\n",
    "            # reference: https://www.pytorchtutorial.com/pytorch-u-net/ 但不好用\n",
    "            # permute such that number of desired segments would be on 4th dimension\n",
    "            # TODO: 为什么专门把channel放到后面?\n",
    "            # output = output.permute(0, 2, 3, 1)\n",
    "            # m = output.shape[0]\n",
    "\n",
    "            # Resizing the outputs and label to caculate pixel wise softmax loss\n",
    "            # TODO: width_out = 128, height_out = 128, channel_out = 1\n",
    "            # output = output.resize(m*128*128, 1)\n",
    "            # label = yy[step].resize(m*128*128)\n",
    "\n",
    "            # loss = loss_func(output, yy[step])\n",
    "            loss = loss_func(torch.squeeze(output), torch.squeeze(yy[step]))\n",
    "            \n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 1 == 0:\n",
    "                pred = net(b_x)\n",
    "                # print(\"\\r\" + 'Epoch: ' + str(epoch) + ' step: ' + str(step) + '[' +\">>>\" * int(step / 10) + ']',end=' ')\n",
    "                print('Epoch:{} step:{}'.format(epoch, step),'loss: %.6f' % loss.data.numpy())\n",
    "                train_loss_history.append(loss.data.numpy())\n",
    "                # print('loss: %.4f' % loss.data.numpy(), '| accuracy: %.4f' % accuracy, end=' ')\n",
    "                # print('loss: %.4f' % loss.data.numpy(), end=' ')\n",
    "        \n",
    "        # test\n",
    "        for step, b_x in enumerate(xx[0:ind_test]):\n",
    "            output = net(b_x)  # cnn output\n",
    "            # loss = loss_func(output, yy[step])\n",
    "            loss = loss_func(torch.squeeze(output), torch.squeeze(yy[step]))\n",
    "            \n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  # backpropagation, compute gradients\n",
    "            optimizer.step()  # apply gradients\n",
    "\n",
    "            if step % 1 == 0:\n",
    "                # pred = net(b_x)\n",
    "                # print(\"\\r\" + 'Epoch: ' + str(epoch) + ' step: ' + str(step) + '[' +\">>>\" * int(step / 10) + ']',end=' ')\n",
    "                print('Test Epoch:{} step:{}'.format(epoch, step), 'loss: %.6f' % loss.data.numpy(), end='')\n",
    "                test_loss_history.append(loss.data.numpy())\n",
    "                print(iou(output, yy[step]))\n",
    "                # print('loss: %.4f' % loss.data.numpy(), '| accuracy: %.4f' % accuracy, end=' ')\n",
    "                # print('loss: %.4f' % loss.data.numpy(), end=' ')\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    img_true = torch.squeeze(img_true)\n",
    "    img_pred = torch.squeeze(img_pred) \n",
    "    img_pred = (img_pred > 0).float()\n",
    "    i = (img_true * img_pred).sum()\n",
    "    u = (img_true + img_pred).sum()\n",
    "    return i / u if u != 0 else uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwar\\academic\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "D:\\softwar\\academic\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (conv1): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (up8): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv8): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up9): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv9): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv10): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "start train...\n",
      "Epoch:0 step:0 loss: 0.829810\n",
      "Epoch:0 step:1 loss: 0.357183\n",
      "Epoch:0 step:2 loss: 0.121116\n",
      "Epoch:0 step:3 loss: 0.093400\n",
      "Epoch:0 step:4 loss: 0.074384\n",
      "Epoch:0 step:5 loss: 0.034295\n",
      "Epoch:0 step:6 loss: 0.006905\n",
      "Epoch:0 step:7 loss: 0.040167\n",
      "Epoch:0 step:8 loss: 0.010325\n",
      "Epoch:0 step:9 loss: 0.000895\n",
      "Epoch:0 step:10 loss: 0.000209\n",
      "Epoch:0 step:11 loss: 0.045445\n",
      "Epoch:0 step:12 loss: 0.132479\n",
      "Epoch:0 step:13 loss: 0.000117\n",
      "Epoch:0 step:14 loss: 0.000121\n",
      "Epoch:0 step:15 loss: 0.000075\n",
      "Epoch:0 step:16 loss: 0.000235\n",
      "Epoch:0 step:17 loss: 0.000269\n",
      "Epoch:0 step:18 loss: 0.029903\n",
      "Epoch:0 step:19 loss: 0.165065\n",
      "Epoch:0 step:20 loss: 0.001488\n",
      "Epoch:0 step:21 loss: 0.000450\n",
      "Epoch:0 step:22 loss: 0.382676\n",
      "Epoch:0 step:23 loss: 0.000173\n",
      "Epoch:0 step:24 loss: 0.054838\n",
      "Epoch:0 step:25 loss: 0.005168\n",
      "Epoch:0 step:26 loss: 0.096839\n",
      "Epoch:0 step:27 loss: 0.946017\n",
      "Epoch:0 step:28 loss: 0.002942\n",
      "Epoch:0 step:29 loss: 0.004510\n",
      "Epoch:0 step:30 loss: 0.006020\n",
      "Epoch:0 step:31 loss: 0.005061\n",
      "Epoch:0 step:32 loss: 0.005997\n",
      "Epoch:0 step:33 loss: 0.000955\n",
      "Epoch:0 step:34 loss: 0.024266\n",
      "Epoch:0 step:35 loss: 0.024162\n",
      "Epoch:0 step:36 loss: 0.000697\n",
      "Epoch:0 step:37 loss: 0.010224\n",
      "Epoch:0 step:38 loss: 0.001460\n",
      "Epoch:0 step:39 loss: 0.008313\n",
      "Epoch:0 step:40 loss: 0.195142\n",
      "Epoch:0 step:41 loss: 0.000950\n",
      "Epoch:0 step:42 loss: 0.003160\n",
      "Epoch:0 step:43 loss: 0.080452\n",
      "Epoch:0 step:44 loss: 0.019265\n",
      "Epoch:0 step:45 loss: 0.020344\n",
      "Epoch:0 step:46 loss: 0.011027\n",
      "Epoch:0 step:47 loss: 0.048555\n",
      "Epoch:0 step:48 loss: 0.013432\n",
      "Epoch:0 step:49 loss: 0.011257\n",
      "Epoch:0 step:50 loss: 0.023569\n",
      "Epoch:0 step:51 loss: 0.012892\n",
      "Epoch:0 step:52 loss: 0.005420\n",
      "Epoch:0 step:53 loss: 0.007705\n",
      "Epoch:0 step:54 loss: 0.104278\n",
      "Epoch:0 step:55 loss: 0.590806\n",
      "Epoch:0 step:56 loss: 0.073684\n",
      "Epoch:0 step:57 loss: 0.003124\n",
      "Epoch:0 step:58 loss: 0.045608\n",
      "Epoch:0 step:59 loss: 0.003981\n",
      "Epoch:0 step:60 loss: 0.280801\n",
      "Epoch:0 step:61 loss: 0.025299\n",
      "Epoch:0 step:62 loss: 0.001693\n",
      "Epoch:0 step:63 loss: 0.008715\n",
      "Epoch:0 step:64 loss: 0.007499\n",
      "Epoch:0 step:65 loss: 0.044160\n",
      "Epoch:0 step:66 loss: 0.008497\n",
      "Epoch:0 step:67 loss: 0.052014\n",
      "Epoch:0 step:68 loss: 0.002483\n",
      "Epoch:0 step:69 loss: 0.002357\n",
      "Epoch:0 step:70 loss: 0.016630\n",
      "Epoch:0 step:71 loss: 0.038356\n",
      "Epoch:0 step:72 loss: 0.023704\n",
      "Epoch:0 step:73 loss: 0.008021\n",
      "Epoch:0 step:74 loss: 0.039669\n",
      "Epoch:0 step:75 loss: 0.006960\n",
      "Epoch:0 step:76 loss: 0.006900\n",
      "Epoch:0 step:77 loss: 0.004264\n",
      "Epoch:0 step:78 loss: 0.162922\n",
      "Epoch:0 step:79 loss: 0.020334\n",
      "Test Epoch:0 step:0 loss: 0.018173tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:1 loss: 0.019790tensor(1.7701e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:2 loss: 0.003030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:3 loss: 0.002347tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:4 loss: 0.061319tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:5 loss: 0.045447tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:6 loss: 0.001660tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:7 loss: 0.036454tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:8 loss: 0.001757tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:9 loss: 0.001888tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:10 loss: 0.002533tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:11 loss: 0.028568tensor(0.0039, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:12 loss: 0.087979tensor(0.0062, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:13 loss: 0.003611tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:14 loss: 0.001482tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:15 loss: 0.005986tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:16 loss: 0.002473tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:17 loss: 0.005643tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:18 loss: 0.021079tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:19 loss: 0.072918tensor(0.0102, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:20 loss: 0.004142tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:21 loss: 0.002555tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:22 loss: 0.099983tensor(0.0131, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:23 loss: 0.006511tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:24 loss: 0.045982tensor(0.0120, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:25 loss: 0.003866tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:26 loss: 0.049768tensor(0.0152, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:27 loss: 0.153180tensor(0.0224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:28 loss: 0.011970tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:29 loss: 0.007213tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:30 loss: 0.013507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:31 loss: 0.010116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:32 loss: 0.011372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:33 loss: 0.003091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:34 loss: 0.017731tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:35 loss: 0.018644tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:36 loss: 0.001594tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:37 loss: 0.005142tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:38 loss: 0.001111tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:39 loss: 0.004394tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:40 loss: 0.182563tensor(0.0137, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:0 step:41 loss: 0.001074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:42 loss: 0.001347tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:43 loss: 0.070101tensor(0.0129, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:44 loss: 0.004789tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:45 loss: 0.010646tensor(0.0034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:46 loss: 0.003734tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:47 loss: 0.061195tensor(0.0147, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:48 loss: 0.007974tensor(0.0080, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:49 loss: 0.002263tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:50 loss: 0.008254tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:51 loss: 0.006719tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:52 loss: 0.002085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:53 loss: 0.006209tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:54 loss: 0.090105tensor(0.0184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:55 loss: 0.094875tensor(0.0179, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:56 loss: 0.062060tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:57 loss: 0.004667tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:58 loss: 0.046578tensor(1.4436e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:59 loss: 0.007243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:60 loss: 0.133914tensor(0.0260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:61 loss: 0.021764tensor(0.0130, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:62 loss: 0.003731tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:63 loss: 0.011887tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:64 loss: 0.010406tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:65 loss: 0.032549tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:66 loss: 0.010969tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:67 loss: 0.032781tensor(0.0118, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:68 loss: 0.001442tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:69 loss: 0.002242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:70 loss: 0.011633tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:71 loss: 0.041333tensor(0.0164, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:72 loss: 0.021139tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:73 loss: 0.002386tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:74 loss: 0.036479tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:75 loss: 0.003599tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:76 loss: 0.004133tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:77 loss: 0.002924tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:78 loss: 0.104541tensor(0.0058, grad_fn=<DivBackward0>)\n",
      "Test Epoch:0 step:79 loss: 0.017872tensor(0.0060, grad_fn=<DivBackward0>)\n",
      "Epoch:1 step:0 loss: 0.017615\n",
      "Epoch:1 step:1 loss: 0.017452\n",
      "Epoch:1 step:2 loss: 0.003378\n",
      "Epoch:1 step:3 loss: 0.001205\n",
      "Epoch:1 step:4 loss: 0.053905\n",
      "Epoch:1 step:5 loss: 0.028619\n",
      "Epoch:1 step:6 loss: 0.001228\n",
      "Epoch:1 step:7 loss: 0.027294\n",
      "Epoch:1 step:8 loss: 0.001307\n",
      "Epoch:1 step:9 loss: 0.002038\n",
      "Epoch:1 step:10 loss: 0.006016\n",
      "Epoch:1 step:11 loss: 0.025727\n",
      "Epoch:1 step:12 loss: 0.077245\n",
      "Epoch:1 step:13 loss: 0.005688\n",
      "Epoch:1 step:14 loss: 0.001552\n",
      "Epoch:1 step:15 loss: 0.006596\n",
      "Epoch:1 step:16 loss: 0.001077\n",
      "Epoch:1 step:17 loss: 0.005356\n",
      "Epoch:1 step:18 loss: 0.022489\n",
      "Epoch:1 step:19 loss: 0.067852\n",
      "Epoch:1 step:20 loss: 0.001395\n",
      "Epoch:1 step:21 loss: 0.000857\n",
      "Epoch:1 step:22 loss: 0.096844\n",
      "Epoch:1 step:23 loss: 0.005107\n",
      "Epoch:1 step:24 loss: 0.038769\n",
      "Epoch:1 step:25 loss: 0.003502\n",
      "Epoch:1 step:26 loss: 0.043743\n",
      "Epoch:1 step:27 loss: 0.139569\n",
      "Epoch:1 step:28 loss: 0.002901\n",
      "Epoch:1 step:29 loss: 0.007528\n",
      "Epoch:1 step:30 loss: 0.014460\n",
      "Epoch:1 step:31 loss: 0.002097\n",
      "Epoch:1 step:32 loss: 0.008284\n",
      "Epoch:1 step:33 loss: 0.003661\n",
      "Epoch:1 step:34 loss: 0.022234\n",
      "Epoch:1 step:35 loss: 0.030347\n",
      "Epoch:1 step:36 loss: 0.001560\n",
      "Epoch:1 step:37 loss: 0.011459\n",
      "Epoch:1 step:38 loss: 0.001938\n",
      "Epoch:1 step:39 loss: 0.001375\n",
      "Epoch:1 step:40 loss: 0.208993\n",
      "Epoch:1 step:41 loss: 0.002510\n",
      "Epoch:1 step:42 loss: 0.002890\n",
      "Epoch:1 step:43 loss: 0.076166\n",
      "Epoch:1 step:44 loss: 0.007098\n",
      "Epoch:1 step:45 loss: 0.013470\n",
      "Epoch:1 step:46 loss: 0.006196\n",
      "Epoch:1 step:47 loss: 0.062034\n",
      "Epoch:1 step:48 loss: 0.022341\n",
      "Epoch:1 step:49 loss: 0.005225\n",
      "Epoch:1 step:50 loss: 0.011350\n",
      "Epoch:1 step:51 loss: 0.006592\n",
      "Epoch:1 step:52 loss: 0.003153\n",
      "Epoch:1 step:53 loss: 0.005110\n",
      "Epoch:1 step:54 loss: 0.091198\n",
      "Epoch:1 step:55 loss: 0.095089\n",
      "Epoch:1 step:56 loss: 0.070758\n",
      "Epoch:1 step:57 loss: 0.002259\n",
      "Epoch:1 step:58 loss: 0.038007\n",
      "Epoch:1 step:59 loss: 0.005638\n",
      "Epoch:1 step:60 loss: 0.141829\n",
      "Epoch:1 step:61 loss: 0.023695\n",
      "Epoch:1 step:62 loss: 0.005172\n",
      "Epoch:1 step:63 loss: 0.011046\n",
      "Epoch:1 step:64 loss: 0.011652\n",
      "Epoch:1 step:65 loss: 0.033026\n",
      "Epoch:1 step:66 loss: 0.008704\n",
      "Epoch:1 step:67 loss: 0.033593\n",
      "Epoch:1 step:68 loss: 0.004098\n",
      "Epoch:1 step:69 loss: 0.006035\n",
      "Epoch:1 step:70 loss: 0.013491\n",
      "Epoch:1 step:71 loss: 0.040402\n",
      "Epoch:1 step:72 loss: 0.023313\n",
      "Epoch:1 step:73 loss: 0.002975\n",
      "Epoch:1 step:74 loss: 0.035987\n",
      "Epoch:1 step:75 loss: 0.004980\n",
      "Epoch:1 step:76 loss: 0.004563\n",
      "Epoch:1 step:77 loss: 0.004639\n",
      "Epoch:1 step:78 loss: 0.097583\n",
      "Epoch:1 step:79 loss: 0.021309\n",
      "Test Epoch:1 step:0 loss: 0.017631tensor(0.0084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:1 loss: 0.018147tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:2 loss: 0.003618tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:3 loss: 0.003059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:4 loss: 0.053070tensor(0.0142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:5 loss: 0.030935tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:6 loss: 0.001742tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:7 loss: 0.033262tensor(0.0055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:8 loss: 0.003675tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:9 loss: 0.004594tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:10 loss: 0.003655tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:11 loss: 0.026163tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:12 loss: 0.079551tensor(0.0101, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:13 loss: 0.004395tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:14 loss: 0.002075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:15 loss: 0.005810tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:16 loss: 0.002690tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:17 loss: 0.005223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:18 loss: 0.020623tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:19 loss: 0.074100tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:20 loss: 0.002649tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:21 loss: 0.001748tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:22 loss: 0.100750tensor(0.0126, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:23 loss: 0.004415tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:24 loss: 0.046206tensor(0.0109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:25 loss: 0.003318tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:26 loss: 0.048034tensor(0.0154, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:27 loss: 0.150598tensor(0.0230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:28 loss: 0.003247tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:29 loss: 0.006591tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:30 loss: 0.013129tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:31 loss: 0.006741tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:32 loss: 0.011003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:33 loss: 0.003469tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:34 loss: 0.019757tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:35 loss: 0.016257tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:36 loss: 0.001721tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:37 loss: 0.008969tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:38 loss: 0.003682tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:39 loss: 0.003227tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:1 step:40 loss: 0.229219tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:41 loss: 0.001861tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:42 loss: 0.001677tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:43 loss: 0.072361tensor(0.0133, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:44 loss: 0.003636tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:45 loss: 0.009201tensor(0.0068, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:46 loss: 0.003339tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:47 loss: 0.059455tensor(0.0216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:48 loss: 0.009120tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:49 loss: 0.003832tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:50 loss: 0.010971tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:51 loss: 0.005176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:52 loss: 0.002918tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:53 loss: 0.005754tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:54 loss: 0.081869tensor(0.0271, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:55 loss: 0.085230tensor(0.0275, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:56 loss: 0.052408tensor(0.0305, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:57 loss: 0.003945tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:58 loss: 0.045473tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:59 loss: 0.007310tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:60 loss: 0.140268tensor(0.0314, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:61 loss: 0.022543tensor(0.0193, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:62 loss: 0.002808tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:63 loss: 0.012003tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:64 loss: 0.012780tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:65 loss: 0.040218tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:66 loss: 0.005302tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:67 loss: 0.030184tensor(0.0147, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:68 loss: 0.001363tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:69 loss: 0.001463tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:70 loss: 0.012558tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:71 loss: 0.038042tensor(0.0237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:72 loss: 0.022611tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:73 loss: 0.002538tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:74 loss: 0.035835tensor(0.0100, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:75 loss: 0.002816tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:76 loss: 0.001931tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:77 loss: 0.003541tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:78 loss: 0.105418tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "Test Epoch:1 step:79 loss: 0.019334tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "Epoch:2 step:0 loss: 0.016931\n",
      "Epoch:2 step:1 loss: 0.021138\n",
      "Epoch:2 step:2 loss: 0.002154\n",
      "Epoch:2 step:3 loss: 0.001133\n",
      "Epoch:2 step:4 loss: 0.048732\n",
      "Epoch:2 step:5 loss: 0.028783\n",
      "Epoch:2 step:6 loss: 0.001137\n",
      "Epoch:2 step:7 loss: 0.027937\n",
      "Epoch:2 step:8 loss: 0.004319\n",
      "Epoch:2 step:9 loss: 0.001895\n",
      "Epoch:2 step:10 loss: 0.003146\n",
      "Epoch:2 step:11 loss: 0.022567\n",
      "Epoch:2 step:12 loss: 0.062148\n",
      "Epoch:2 step:13 loss: 0.003609\n",
      "Epoch:2 step:14 loss: 0.002044\n",
      "Epoch:2 step:15 loss: 0.004043\n",
      "Epoch:2 step:16 loss: 0.003810\n",
      "Epoch:2 step:17 loss: 0.004979\n",
      "Epoch:2 step:18 loss: 0.022004\n",
      "Epoch:2 step:19 loss: 0.058381\n",
      "Epoch:2 step:20 loss: 0.003590\n",
      "Epoch:2 step:21 loss: 0.003004\n",
      "Epoch:2 step:22 loss: 0.094141\n",
      "Epoch:2 step:23 loss: 0.003465\n",
      "Epoch:2 step:24 loss: 0.033479\n",
      "Epoch:2 step:25 loss: 0.004226\n",
      "Epoch:2 step:26 loss: 0.041734\n",
      "Epoch:2 step:27 loss: 0.114133\n",
      "Epoch:2 step:28 loss: 0.002821\n",
      "Epoch:2 step:29 loss: 0.011280\n",
      "Epoch:2 step:30 loss: 0.023149\n",
      "Epoch:2 step:31 loss: 0.004886\n",
      "Epoch:2 step:32 loss: 0.005429\n",
      "Epoch:2 step:33 loss: 0.003564\n",
      "Epoch:2 step:34 loss: 0.019180\n",
      "Epoch:2 step:35 loss: 0.012941\n",
      "Epoch:2 step:36 loss: 0.001065\n",
      "Epoch:2 step:37 loss: 0.003640\n",
      "Epoch:2 step:38 loss: 0.000749\n",
      "Epoch:2 step:39 loss: 0.001854\n",
      "Epoch:2 step:40 loss: 0.184604\n",
      "Epoch:2 step:41 loss: 0.000774\n",
      "Epoch:2 step:42 loss: 0.001813\n",
      "Epoch:2 step:43 loss: 0.069054\n",
      "Epoch:2 step:44 loss: 0.006605\n",
      "Epoch:2 step:45 loss: 0.008537\n",
      "Epoch:2 step:46 loss: 0.004331\n",
      "Epoch:2 step:47 loss: 0.058326\n",
      "Epoch:2 step:48 loss: 0.007673\n",
      "Epoch:2 step:49 loss: 0.003917\n",
      "Epoch:2 step:50 loss: 0.008111\n",
      "Epoch:2 step:51 loss: 0.005093\n",
      "Epoch:2 step:52 loss: 0.002170\n",
      "Epoch:2 step:53 loss: 0.004761\n",
      "Epoch:2 step:54 loss: 0.078707\n",
      "Epoch:2 step:55 loss: 0.080575\n",
      "Epoch:2 step:56 loss: 0.052416\n",
      "Epoch:2 step:57 loss: 0.001719\n",
      "Epoch:2 step:58 loss: 0.039593\n",
      "Epoch:2 step:59 loss: 0.005644\n",
      "Epoch:2 step:60 loss: 0.102597\n",
      "Epoch:2 step:61 loss: 0.019873\n",
      "Epoch:2 step:62 loss: 0.002630\n",
      "Epoch:2 step:63 loss: 0.015626\n",
      "Epoch:2 step:64 loss: 0.012310\n",
      "Epoch:2 step:65 loss: 0.023191\n",
      "Epoch:2 step:66 loss: 0.003115\n",
      "Epoch:2 step:67 loss: 0.027816\n",
      "Epoch:2 step:68 loss: 0.001685\n",
      "Epoch:2 step:69 loss: 0.001514\n",
      "Epoch:2 step:70 loss: 0.009789\n",
      "Epoch:2 step:71 loss: 0.031369\n",
      "Epoch:2 step:72 loss: 0.028404\n",
      "Epoch:2 step:73 loss: 0.009303\n",
      "Epoch:2 step:74 loss: 0.019721\n",
      "Epoch:2 step:75 loss: 0.004477\n",
      "Epoch:2 step:76 loss: 0.001833\n",
      "Epoch:2 step:77 loss: 0.002167\n",
      "Epoch:2 step:78 loss: 0.083446\n",
      "Epoch:2 step:79 loss: 0.024971\n",
      "Test Epoch:2 step:0 loss: 0.013740tensor(0.0298, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:1 loss: 0.015468tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:2 loss: 0.003775tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:3 loss: 0.001555tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:4 loss: 0.036670tensor(0.0622, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:5 loss: 0.019845tensor(0.0458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:6 loss: 0.001930tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:7 loss: 0.025368tensor(0.0412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:8 loss: 0.003441tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:9 loss: 0.003101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:10 loss: 0.003288tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:11 loss: 0.021748tensor(0.0415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:12 loss: 0.100646tensor(0.0404, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:13 loss: 0.001175tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:14 loss: 0.001030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:15 loss: 0.001997tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:16 loss: 0.002383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:17 loss: 0.006573tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:18 loss: 0.027764tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:19 loss: 0.068464tensor(0.0179, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:20 loss: 0.003509tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:21 loss: 0.002720tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:22 loss: 0.085252tensor(0.0332, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:23 loss: 0.007618tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:24 loss: 0.038736tensor(0.0331, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:25 loss: 0.006105tensor(0.0135, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:26 loss: 0.034740tensor(0.0641, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:27 loss: 0.108783tensor(0.0729, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:28 loss: 0.022439tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:29 loss: 0.011955tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:30 loss: 0.023494tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:31 loss: 0.008739tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:32 loss: 0.005107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:33 loss: 0.001850tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:34 loss: 0.018745tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:35 loss: 0.018877tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:36 loss: 0.000592tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:37 loss: 0.004056tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:38 loss: 0.000302tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:2 step:39 loss: 0.000496tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:40 loss: 0.233948tensor(0.0044, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:41 loss: 0.000419tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:42 loss: 0.000779tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:43 loss: 0.084482tensor(0.0061, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:44 loss: 0.001818tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:45 loss: 0.009031tensor(0.0030, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:46 loss: 0.004447tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:47 loss: 0.057399tensor(0.0194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:48 loss: 0.010413tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:49 loss: 0.014012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:50 loss: 0.008981tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:51 loss: 0.004285tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:52 loss: 0.005268tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:53 loss: 0.005880tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:54 loss: 0.083452tensor(0.0249, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:55 loss: 0.085484tensor(0.0266, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:56 loss: 0.066104tensor(0.0129, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:57 loss: 0.003430tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:58 loss: 0.039241tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:59 loss: 0.005846tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:60 loss: 0.116202tensor(0.0417, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:61 loss: 0.019570tensor(0.0223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:62 loss: 0.004414tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:63 loss: 0.016017tensor(5.9120e-07, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:64 loss: 0.013329tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:65 loss: 0.022406tensor(0.0543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:66 loss: 0.004237tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:67 loss: 0.029436tensor(0.0189, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:68 loss: 0.001086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:69 loss: 0.004536tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:70 loss: 0.009015tensor(0.0034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:71 loss: 0.037756tensor(0.0272, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:72 loss: 0.016804tensor(0.0251, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:73 loss: 0.002093tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:74 loss: 0.027885tensor(0.0323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:75 loss: 0.002217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:76 loss: 0.000931tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:77 loss: 0.003006tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:78 loss: 0.060266tensor(0.0564, grad_fn=<DivBackward0>)\n",
      "Test Epoch:2 step:79 loss: 0.015458tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "Epoch:3 step:0 loss: 0.017628\n",
      "Epoch:3 step:1 loss: 0.013531\n",
      "Epoch:3 step:2 loss: 0.008920\n",
      "Epoch:3 step:3 loss: 0.001487\n",
      "Epoch:3 step:4 loss: 0.040249\n",
      "Epoch:3 step:5 loss: 0.017349\n",
      "Epoch:3 step:6 loss: 0.000673\n",
      "Epoch:3 step:7 loss: 0.028748\n",
      "Epoch:3 step:8 loss: 0.001196\n",
      "Epoch:3 step:9 loss: 0.000528\n",
      "Epoch:3 step:10 loss: 0.002425\n",
      "Epoch:3 step:11 loss: 0.016862\n",
      "Epoch:3 step:12 loss: 0.047559\n",
      "Epoch:3 step:13 loss: 0.000675\n",
      "Epoch:3 step:14 loss: 0.000441\n",
      "Epoch:3 step:15 loss: 0.000744\n",
      "Epoch:3 step:16 loss: 0.000533\n",
      "Epoch:3 step:17 loss: 0.003120\n",
      "Epoch:3 step:18 loss: 0.024731\n",
      "Epoch:3 step:19 loss: 0.057128\n",
      "Epoch:3 step:20 loss: 0.000619\n",
      "Epoch:3 step:21 loss: 0.000541\n",
      "Epoch:3 step:22 loss: 0.129075\n",
      "Epoch:3 step:23 loss: 0.005357\n",
      "Epoch:3 step:24 loss: 0.026003\n",
      "Epoch:3 step:25 loss: 0.004175\n",
      "Epoch:3 step:26 loss: 0.038100\n",
      "Epoch:3 step:27 loss: 0.115486\n",
      "Epoch:3 step:28 loss: 0.022001\n",
      "Epoch:3 step:29 loss: 0.016518\n",
      "Epoch:3 step:30 loss: 0.016420\n",
      "Epoch:3 step:31 loss: 0.013222\n",
      "Epoch:3 step:32 loss: 0.011618\n",
      "Epoch:3 step:33 loss: 0.003328\n",
      "Epoch:3 step:34 loss: 0.016881\n",
      "Epoch:3 step:35 loss: 0.015467\n",
      "Epoch:3 step:36 loss: 0.001456\n",
      "Epoch:3 step:37 loss: 0.003818\n",
      "Epoch:3 step:38 loss: 0.000533\n",
      "Epoch:3 step:39 loss: 0.000950\n",
      "Epoch:3 step:40 loss: 0.193985\n",
      "Epoch:3 step:41 loss: 0.000571\n",
      "Epoch:3 step:42 loss: 0.000894\n",
      "Epoch:3 step:43 loss: 0.072114\n",
      "Epoch:3 step:44 loss: 0.002831\n",
      "Epoch:3 step:45 loss: 0.008078\n",
      "Epoch:3 step:46 loss: 0.003134\n",
      "Epoch:3 step:47 loss: 0.054375\n",
      "Epoch:3 step:48 loss: 0.008898\n",
      "Epoch:3 step:49 loss: 0.005708\n",
      "Epoch:3 step:50 loss: 0.008209\n",
      "Epoch:3 step:51 loss: 0.005339\n",
      "Epoch:3 step:52 loss: 0.004380\n",
      "Epoch:3 step:53 loss: 0.008059\n",
      "Epoch:3 step:54 loss: 0.071366\n",
      "Epoch:3 step:55 loss: 0.069896\n",
      "Epoch:3 step:56 loss: 0.057824\n",
      "Epoch:3 step:57 loss: 0.002886\n",
      "Epoch:3 step:58 loss: 0.038140\n",
      "Epoch:3 step:59 loss: 0.005588\n",
      "Epoch:3 step:60 loss: 0.086973\n",
      "Epoch:3 step:61 loss: 0.017198\n",
      "Epoch:3 step:62 loss: 0.001954\n",
      "Epoch:3 step:63 loss: 0.022680\n",
      "Epoch:3 step:64 loss: 0.012289\n",
      "Epoch:3 step:65 loss: 0.016129\n",
      "Epoch:3 step:66 loss: 0.004029\n",
      "Epoch:3 step:67 loss: 0.024758\n",
      "Epoch:3 step:68 loss: 0.000643\n",
      "Epoch:3 step:69 loss: 0.000712\n",
      "Epoch:3 step:70 loss: 0.014513\n",
      "Epoch:3 step:71 loss: 0.030242\n",
      "Epoch:3 step:72 loss: 0.014729\n",
      "Epoch:3 step:73 loss: 0.008710\n",
      "Epoch:3 step:74 loss: 0.022030\n",
      "Epoch:3 step:75 loss: 0.006524\n",
      "Epoch:3 step:76 loss: 0.002076\n",
      "Epoch:3 step:77 loss: 0.001930\n",
      "Epoch:3 step:78 loss: 0.056423\n",
      "Epoch:3 step:79 loss: 0.020150\n",
      "Test Epoch:3 step:0 loss: 0.017606tensor(0.0178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:1 loss: 0.013551tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:2 loss: 0.001114tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:3 loss: 0.000465tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:4 loss: 0.033048tensor(0.0927, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:5 loss: 0.015417tensor(0.1060, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:6 loss: 0.000455tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:7 loss: 0.029548tensor(0.0489, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:8 loss: 0.001187tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:9 loss: 0.002079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:10 loss: 0.027121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:11 loss: 0.028886tensor(0.0477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:12 loss: 0.033376tensor(0.1447, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:13 loss: 0.001081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:14 loss: 0.000496tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:15 loss: 0.000700tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:16 loss: 0.000510tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:17 loss: 0.000943tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:18 loss: 0.029871tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:19 loss: 0.084079tensor(0.0084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:20 loss: 0.000520tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:21 loss: 0.000613tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:22 loss: 0.146773tensor(0.0102, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:23 loss: 0.000866tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:24 loss: 0.039783tensor(0.0231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:25 loss: 0.003487tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:26 loss: 0.033810tensor(0.0568, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:27 loss: 0.124042tensor(0.0518, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:28 loss: 0.009291tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:29 loss: 0.013087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:30 loss: 0.023557tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:31 loss: 0.021476tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:32 loss: 0.021092tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:33 loss: 0.009053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:34 loss: 0.022099tensor(0.0116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:35 loss: 0.015397tensor(0.0196, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:36 loss: 0.003778tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:37 loss: 0.007841tensor(0.0019, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:3 step:38 loss: 0.002248tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:39 loss: 0.003993tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:40 loss: 0.138392tensor(0.0551, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:41 loss: 0.001144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:42 loss: 0.001545tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:43 loss: 0.066660tensor(0.0299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:44 loss: 0.004921tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:45 loss: 0.006506tensor(0.0198, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:46 loss: 0.003139tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:47 loss: 0.048759tensor(0.0503, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:48 loss: 0.008451tensor(0.0060, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:49 loss: 0.002018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:50 loss: 0.007698tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:51 loss: 0.008028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:52 loss: 0.002529tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:53 loss: 0.008083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:54 loss: 0.069954tensor(0.0587, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:55 loss: 0.088221tensor(0.0316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:56 loss: 0.050946tensor(0.0658, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:57 loss: 0.006447tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:58 loss: 0.039639tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:59 loss: 0.009814tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:60 loss: 0.082383tensor(0.1040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:61 loss: 0.018479tensor(0.0278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:62 loss: 0.005732tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:63 loss: 0.019901tensor(1.6916e-06, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:64 loss: 0.015235tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:65 loss: 0.018243tensor(0.0990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:66 loss: 0.005512tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:67 loss: 0.028413tensor(0.0333, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:68 loss: 0.001340tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:69 loss: 0.004571tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:70 loss: 0.012087tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:71 loss: 0.038275tensor(0.0292, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:72 loss: 0.019430tensor(0.0142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:73 loss: 0.002361tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:74 loss: 0.031028tensor(0.0333, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:75 loss: 0.003290tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:76 loss: 0.005254tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:77 loss: 0.001753tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:78 loss: 0.074163tensor(0.0347, grad_fn=<DivBackward0>)\n",
      "Test Epoch:3 step:79 loss: 0.023682tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "Epoch:4 step:0 loss: 0.018054\n",
      "Epoch:4 step:1 loss: 0.015798\n",
      "Epoch:4 step:2 loss: 0.002230\n",
      "Epoch:4 step:3 loss: 0.001123\n",
      "Epoch:4 step:4 loss: 0.045373\n",
      "Epoch:4 step:5 loss: 0.029162\n",
      "Epoch:4 step:6 loss: 0.001269\n",
      "Epoch:4 step:7 loss: 0.030842\n",
      "Epoch:4 step:8 loss: 0.001583\n",
      "Epoch:4 step:9 loss: 0.003007\n",
      "Epoch:4 step:10 loss: 0.007324\n",
      "Epoch:4 step:11 loss: 0.018579\n",
      "Epoch:4 step:12 loss: 0.050567\n",
      "Epoch:4 step:13 loss: 0.005846\n",
      "Epoch:4 step:14 loss: 0.002022\n",
      "Epoch:4 step:15 loss: 0.011771\n",
      "Epoch:4 step:16 loss: 0.001533\n",
      "Epoch:4 step:17 loss: 0.003722\n",
      "Epoch:4 step:18 loss: 0.022804\n",
      "Epoch:4 step:19 loss: 0.053668\n",
      "Epoch:4 step:20 loss: 0.001504\n",
      "Epoch:4 step:21 loss: 0.001158\n",
      "Epoch:4 step:22 loss: 0.087298\n",
      "Epoch:4 step:23 loss: 0.001943\n",
      "Epoch:4 step:24 loss: 0.032019\n",
      "Epoch:4 step:25 loss: 0.004390\n",
      "Epoch:4 step:26 loss: 0.033820\n",
      "Epoch:4 step:27 loss: 0.104996\n",
      "Epoch:4 step:28 loss: 0.001262\n",
      "Epoch:4 step:29 loss: 0.004954\n",
      "Epoch:4 step:30 loss: 0.008213\n",
      "Epoch:4 step:31 loss: 0.005323\n",
      "Epoch:4 step:32 loss: 0.008151\n",
      "Epoch:4 step:33 loss: 0.005616\n",
      "Epoch:4 step:34 loss: 0.032119\n",
      "Epoch:4 step:35 loss: 0.011582\n",
      "Epoch:4 step:36 loss: 0.002184\n",
      "Epoch:4 step:37 loss: 0.004195\n",
      "Epoch:4 step:38 loss: 0.001004\n",
      "Epoch:4 step:39 loss: 0.009177\n",
      "Epoch:4 step:40 loss: 0.095156\n",
      "Epoch:4 step:41 loss: 0.001754\n",
      "Epoch:4 step:42 loss: 0.002290\n",
      "Epoch:4 step:43 loss: 0.058693\n",
      "Epoch:4 step:44 loss: 0.010446\n",
      "Epoch:4 step:45 loss: 0.006161\n",
      "Epoch:4 step:46 loss: 0.002561\n",
      "Epoch:4 step:47 loss: 0.046422\n",
      "Epoch:4 step:48 loss: 0.007440\n",
      "Epoch:4 step:49 loss: 0.001085\n",
      "Epoch:4 step:50 loss: 0.002395\n",
      "Epoch:4 step:51 loss: 0.001646\n",
      "Epoch:4 step:52 loss: 0.000828\n",
      "Epoch:4 step:53 loss: 0.000773\n",
      "Epoch:4 step:54 loss: 0.066286\n",
      "Epoch:4 step:55 loss: 0.099778\n",
      "Epoch:4 step:56 loss: 0.057086\n",
      "Epoch:4 step:57 loss: 0.000970\n",
      "Epoch:4 step:58 loss: 0.040452\n",
      "Epoch:4 step:59 loss: 0.005249\n",
      "Epoch:4 step:60 loss: 0.084312\n",
      "Epoch:4 step:61 loss: 0.018167\n",
      "Epoch:4 step:62 loss: 0.002571\n",
      "Epoch:4 step:63 loss: 0.028261\n",
      "Epoch:4 step:64 loss: 0.018154\n",
      "Epoch:4 step:65 loss: 0.020227\n",
      "Epoch:4 step:66 loss: 0.005528\n",
      "Epoch:4 step:67 loss: 0.029708\n",
      "Epoch:4 step:68 loss: 0.001002\n",
      "Epoch:4 step:69 loss: 0.001380\n",
      "Epoch:4 step:70 loss: 0.009708\n",
      "Epoch:4 step:71 loss: 0.039509\n",
      "Epoch:4 step:72 loss: 0.029112\n",
      "Epoch:4 step:73 loss: 0.001842\n",
      "Epoch:4 step:74 loss: 0.035248\n",
      "Epoch:4 step:75 loss: 0.003241\n",
      "Epoch:4 step:76 loss: 0.003401\n",
      "Epoch:4 step:77 loss: 0.002515\n",
      "Epoch:4 step:78 loss: 0.071467\n",
      "Epoch:4 step:79 loss: 0.020501\n",
      "Test Epoch:4 step:0 loss: 0.017855tensor(0.0134, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:1 loss: 0.018218tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:2 loss: 0.002970tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:3 loss: 0.003783tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:4 loss: 0.042155tensor(0.0523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:5 loss: 0.020914tensor(0.0435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:6 loss: 0.002192tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:7 loss: 0.024600tensor(0.0435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:8 loss: 0.002212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:9 loss: 0.002764tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:10 loss: 0.009184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:11 loss: 0.017729tensor(0.0552, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:12 loss: 0.039930tensor(0.1323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:13 loss: 0.003337tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:14 loss: 0.002039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:15 loss: 0.003901tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:16 loss: 0.001135tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:17 loss: 0.003212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:18 loss: 0.017523tensor(0.0107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:19 loss: 0.066554tensor(0.0411, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:20 loss: 0.001026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:21 loss: 0.000714tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:22 loss: 0.104093tensor(0.0347, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:23 loss: 0.003923tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:24 loss: 0.028823tensor(0.0887, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:25 loss: 0.006654tensor(6.5496e-06, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:26 loss: 0.032862tensor(0.0901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:27 loss: 0.095766tensor(0.1236, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:28 loss: 0.009052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:29 loss: 0.003777tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:30 loss: 0.014364tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:31 loss: 0.004016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:32 loss: 0.006969tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:33 loss: 0.004081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:34 loss: 0.025319tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:35 loss: 0.012546tensor(0.0148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:36 loss: 0.001177tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:4 step:37 loss: 0.002846tensor(0.0046, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:38 loss: 0.000663tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:39 loss: 0.003552tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:40 loss: 0.134847tensor(0.0656, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:41 loss: 0.000993tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:42 loss: 0.001812tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:43 loss: 0.059620tensor(0.0427, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:44 loss: 0.004403tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:45 loss: 0.007223tensor(0.0168, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:46 loss: 0.002385tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:47 loss: 0.045443tensor(0.0612, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:48 loss: 0.006818tensor(0.0131, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:49 loss: 0.007537tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:50 loss: 0.009677tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:51 loss: 0.006999tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:52 loss: 0.006043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:53 loss: 0.011891tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:54 loss: 0.065407tensor(0.0770, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:55 loss: 0.061557tensor(0.0909, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:56 loss: 0.056017tensor(0.0464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:57 loss: 0.000484tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:58 loss: 0.028610tensor(0.0052, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:59 loss: 0.002064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:60 loss: 0.100339tensor(0.0940, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:61 loss: 0.027352tensor(0.0049, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:62 loss: 0.000542tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:63 loss: 0.016297tensor(5.6815e-06, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:64 loss: 0.008934tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:65 loss: 0.020747tensor(0.0966, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:66 loss: 0.004999tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:67 loss: 0.017876tensor(0.1007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:68 loss: 0.001257tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:69 loss: 0.000585tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:70 loss: 0.018836tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:71 loss: 0.037793tensor(0.0505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:72 loss: 0.017073tensor(0.0466, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:73 loss: 0.009440tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:74 loss: 0.018708tensor(0.1180, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:75 loss: 0.008191tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:76 loss: 0.006843tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:77 loss: 0.002309tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:78 loss: 0.052869tensor(0.0914, grad_fn=<DivBackward0>)\n",
      "Test Epoch:4 step:79 loss: 0.023468tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "Epoch:5 step:0 loss: 0.017341\n",
      "Epoch:5 step:1 loss: 0.015638\n",
      "Epoch:5 step:2 loss: 0.001183\n",
      "Epoch:5 step:3 loss: 0.000143\n",
      "Epoch:5 step:4 loss: 0.038359\n",
      "Epoch:5 step:5 loss: 0.021877\n",
      "Epoch:5 step:6 loss: 0.000121\n",
      "Epoch:5 step:7 loss: 0.028357\n",
      "Epoch:5 step:8 loss: 0.001040\n",
      "Epoch:5 step:9 loss: 0.000303\n",
      "Epoch:5 step:10 loss: 0.000810\n",
      "Epoch:5 step:11 loss: 0.018743\n",
      "Epoch:5 step:12 loss: 0.035349\n",
      "Epoch:5 step:13 loss: 0.003631\n",
      "Epoch:5 step:14 loss: 0.001118\n",
      "Epoch:5 step:15 loss: 0.005572\n",
      "Epoch:5 step:16 loss: 0.001315\n",
      "Epoch:5 step:17 loss: 0.008536\n",
      "Epoch:5 step:18 loss: 0.020693\n",
      "Epoch:5 step:19 loss: 0.041041\n",
      "Epoch:5 step:20 loss: 0.001065\n",
      "Epoch:5 step:21 loss: 0.000755\n",
      "Epoch:5 step:22 loss: 0.111837\n",
      "Epoch:5 step:23 loss: 0.003245\n",
      "Epoch:5 step:24 loss: 0.025291\n",
      "Epoch:5 step:25 loss: 0.005608\n",
      "Epoch:5 step:26 loss: 0.033052\n",
      "Epoch:5 step:27 loss: 0.082989\n",
      "Epoch:5 step:28 loss: 0.001548\n",
      "Epoch:5 step:29 loss: 0.001639\n",
      "Epoch:5 step:30 loss: 0.013273\n",
      "Epoch:5 step:31 loss: 0.005398\n",
      "Epoch:5 step:32 loss: 0.009904\n",
      "Epoch:5 step:33 loss: 0.002939\n",
      "Epoch:5 step:34 loss: 0.023513\n",
      "Epoch:5 step:35 loss: 0.011685\n",
      "Epoch:5 step:36 loss: 0.001729\n",
      "Epoch:5 step:37 loss: 0.002990\n",
      "Epoch:5 step:38 loss: 0.000227\n",
      "Epoch:5 step:39 loss: 0.004476\n",
      "Epoch:5 step:40 loss: 0.130984\n",
      "Epoch:5 step:41 loss: 0.000349\n",
      "Epoch:5 step:42 loss: 0.000491\n",
      "Epoch:5 step:43 loss: 0.055908\n",
      "Epoch:5 step:44 loss: 0.006711\n",
      "Epoch:5 step:45 loss: 0.006433\n",
      "Epoch:5 step:46 loss: 0.003147\n",
      "Epoch:5 step:47 loss: 0.043612\n",
      "Epoch:5 step:48 loss: 0.006302\n",
      "Epoch:5 step:49 loss: 0.005386\n",
      "Epoch:5 step:50 loss: 0.008830\n",
      "Epoch:5 step:51 loss: 0.005205\n",
      "Epoch:5 step:52 loss: 0.003473\n",
      "Epoch:5 step:53 loss: 0.011826\n",
      "Epoch:5 step:54 loss: 0.061186\n",
      "Epoch:5 step:55 loss: 0.053632\n",
      "Epoch:5 step:56 loss: 0.056267\n",
      "Epoch:5 step:57 loss: 0.000254\n",
      "Epoch:5 step:58 loss: 0.033471\n",
      "Epoch:5 step:59 loss: 0.001580\n",
      "Epoch:5 step:60 loss: 0.087834\n",
      "Epoch:5 step:61 loss: 0.026696\n",
      "Epoch:5 step:62 loss: 0.000233\n",
      "Epoch:5 step:63 loss: 0.012243\n",
      "Epoch:5 step:64 loss: 0.009314\n",
      "Epoch:5 step:65 loss: 0.025455\n",
      "Epoch:5 step:66 loss: 0.007390\n",
      "Epoch:5 step:67 loss: 0.015107\n",
      "Epoch:5 step:68 loss: 0.000274\n",
      "Epoch:5 step:69 loss: 0.001319\n",
      "Epoch:5 step:70 loss: 0.013256\n",
      "Epoch:5 step:71 loss: 0.031845\n",
      "Epoch:5 step:72 loss: 0.010839\n",
      "Epoch:5 step:73 loss: 0.003595\n",
      "Epoch:5 step:74 loss: 0.015212\n",
      "Epoch:5 step:75 loss: 0.007032\n",
      "Epoch:5 step:76 loss: 0.002379\n",
      "Epoch:5 step:77 loss: 0.002214\n",
      "Epoch:5 step:78 loss: 0.048908\n",
      "Epoch:5 step:79 loss: 0.022135\n",
      "Test Epoch:5 step:0 loss: 0.014140tensor(0.0376, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:1 loss: 0.013898tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:2 loss: 0.003647tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:3 loss: 0.000154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:4 loss: 0.032100tensor(0.1077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:5 loss: 0.021833tensor(0.0570, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:6 loss: 0.000717tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:7 loss: 0.029365tensor(0.0151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:8 loss: 0.001429tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:9 loss: 0.003053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:10 loss: 0.000512tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:11 loss: 0.016164tensor(0.0860, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:12 loss: 0.053817tensor(0.1133, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:13 loss: 0.001409tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:14 loss: 0.000963tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:15 loss: 0.002782tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:16 loss: 0.002030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:17 loss: 0.010281tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:18 loss: 0.022321tensor(0.0065, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:19 loss: 0.039872tensor(0.1325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:20 loss: 0.002873tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:21 loss: 0.001500tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:22 loss: 0.096316tensor(0.0627, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:23 loss: 0.004958tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:24 loss: 0.025455tensor(0.1200, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:25 loss: 0.005196tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:26 loss: 0.028136tensor(0.1287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:27 loss: 0.062627tensor(0.1966, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:28 loss: 0.003864tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:29 loss: 0.004297tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:30 loss: 0.011426tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:31 loss: 0.004066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:32 loss: 0.004771tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:33 loss: 0.003760tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:34 loss: 0.029739tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:35 loss: 0.015390tensor(0.0060, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:5 step:36 loss: 0.001654tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:37 loss: 0.003476tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:38 loss: 0.000135tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:39 loss: 0.001112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:40 loss: 0.155098tensor(0.0474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:41 loss: 0.000122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:42 loss: 0.000177tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:43 loss: 0.059552tensor(0.0362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:44 loss: 0.002859tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:45 loss: 0.006512tensor(0.0169, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:46 loss: 0.001785tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:47 loss: 0.046080tensor(0.0681, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:48 loss: 0.006668tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:49 loss: 0.000736tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:50 loss: 0.009611tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:51 loss: 0.005955tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:52 loss: 0.000692tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:53 loss: 0.014030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:54 loss: 0.057475tensor(0.1016, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:55 loss: 0.058448tensor(0.1053, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:56 loss: 0.047297tensor(0.0682, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:57 loss: 0.000824tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:58 loss: 0.039587tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:59 loss: 0.002507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:60 loss: 0.080015tensor(0.1333, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:61 loss: 0.023378tensor(0.0128, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:62 loss: 0.000341tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:63 loss: 0.017007tensor(1.0398e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:64 loss: 0.008848tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:65 loss: 0.015327tensor(0.1590, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:66 loss: 0.002146tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:67 loss: 0.020479tensor(0.0946, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:68 loss: 0.000107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:69 loss: 0.005770tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:70 loss: 0.016816tensor(0.0081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:71 loss: 0.034458tensor(0.0756, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:72 loss: 0.011564tensor(0.1095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:73 loss: 0.001964tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:74 loss: 0.015319tensor(0.1645, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:75 loss: 0.006069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:76 loss: 0.001407tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:77 loss: 0.003066tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:78 loss: 0.046260tensor(0.1453, grad_fn=<DivBackward0>)\n",
      "Test Epoch:5 step:79 loss: 0.020566tensor(0.0061, grad_fn=<DivBackward0>)\n",
      "Epoch:6 step:0 loss: 0.014883\n",
      "Epoch:6 step:1 loss: 0.013925\n",
      "Epoch:6 step:2 loss: 0.005579\n",
      "Epoch:6 step:3 loss: 0.000087\n",
      "Epoch:6 step:4 loss: 0.031885\n",
      "Epoch:6 step:5 loss: 0.014944\n",
      "Epoch:6 step:6 loss: 0.000128\n",
      "Epoch:6 step:7 loss: 0.022577\n",
      "Epoch:6 step:8 loss: 0.000114\n",
      "Epoch:6 step:9 loss: 0.000406\n",
      "Epoch:6 step:10 loss: 0.000879\n",
      "Epoch:6 step:11 loss: 0.031343\n",
      "Epoch:6 step:12 loss: 0.039438\n",
      "Epoch:6 step:13 loss: 0.001307\n",
      "Epoch:6 step:14 loss: 0.000084\n",
      "Epoch:6 step:15 loss: 0.001082\n",
      "Epoch:6 step:16 loss: 0.000089\n",
      "Epoch:6 step:17 loss: 0.003151\n",
      "Epoch:6 step:18 loss: 0.025875\n",
      "Epoch:6 step:19 loss: 0.049252\n",
      "Epoch:6 step:20 loss: 0.000254\n",
      "Epoch:6 step:21 loss: 0.000083\n",
      "Epoch:6 step:22 loss: 0.108902\n",
      "Epoch:6 step:23 loss: 0.002383\n",
      "Epoch:6 step:24 loss: 0.026332\n",
      "Epoch:6 step:25 loss: 0.005145\n",
      "Epoch:6 step:26 loss: 0.026649\n",
      "Epoch:6 step:27 loss: 0.066997\n",
      "Epoch:6 step:28 loss: 0.007882\n",
      "Epoch:6 step:29 loss: 0.009757\n",
      "Epoch:6 step:30 loss: 0.022804\n",
      "Epoch:6 step:31 loss: 0.007385\n",
      "Epoch:6 step:32 loss: 0.008341\n",
      "Epoch:6 step:33 loss: 0.001140\n",
      "Epoch:6 step:34 loss: 0.024473\n",
      "Epoch:6 step:35 loss: 0.012054\n",
      "Epoch:6 step:36 loss: 0.001828\n",
      "Epoch:6 step:37 loss: 0.003162\n",
      "Epoch:6 step:38 loss: 0.000084\n",
      "Epoch:6 step:39 loss: 0.002368\n",
      "Epoch:6 step:40 loss: 0.154008\n",
      "Epoch:6 step:41 loss: 0.000182\n",
      "Epoch:6 step:42 loss: 0.000218\n",
      "Epoch:6 step:43 loss: 0.055980\n",
      "Epoch:6 step:44 loss: 0.003153\n",
      "Epoch:6 step:45 loss: 0.006904\n",
      "Epoch:6 step:46 loss: 0.001703\n",
      "Epoch:6 step:47 loss: 0.043406\n",
      "Epoch:6 step:48 loss: 0.006622\n",
      "Epoch:6 step:49 loss: 0.000711\n",
      "Epoch:6 step:50 loss: 0.007501\n",
      "Epoch:6 step:51 loss: 0.004605\n",
      "Epoch:6 step:52 loss: 0.000645\n",
      "Epoch:6 step:53 loss: 0.010389\n",
      "Epoch:6 step:54 loss: 0.056695\n",
      "Epoch:6 step:55 loss: 0.050954\n",
      "Epoch:6 step:56 loss: 0.049665\n",
      "Epoch:6 step:57 loss: 0.000937\n",
      "Epoch:6 step:58 loss: 0.039078\n",
      "Epoch:6 step:59 loss: 0.002568\n",
      "Epoch:6 step:60 loss: 0.073510\n",
      "Epoch:6 step:61 loss: 0.022503\n",
      "Epoch:6 step:62 loss: 0.001635\n",
      "Epoch:6 step:63 loss: 0.018899\n",
      "Epoch:6 step:64 loss: 0.010089\n",
      "Epoch:6 step:65 loss: 0.012227\n",
      "Epoch:6 step:66 loss: 0.002466\n",
      "Epoch:6 step:67 loss: 0.019783\n",
      "Epoch:6 step:68 loss: 0.000692\n",
      "Epoch:6 step:69 loss: 0.000784\n",
      "Epoch:6 step:70 loss: 0.010517\n",
      "Epoch:6 step:71 loss: 0.026253\n",
      "Epoch:6 step:72 loss: 0.011072\n",
      "Epoch:6 step:73 loss: 0.002464\n",
      "Epoch:6 step:74 loss: 0.014663\n",
      "Epoch:6 step:75 loss: 0.006401\n",
      "Epoch:6 step:76 loss: 0.003027\n",
      "Epoch:6 step:77 loss: 0.002007\n",
      "Epoch:6 step:78 loss: 0.043412\n",
      "Epoch:6 step:79 loss: 0.022237\n",
      "Test Epoch:6 step:0 loss: 0.014472tensor(0.0393, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:1 loss: 0.017395tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:2 loss: 0.003480tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:3 loss: 0.000178tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:4 loss: 0.029899tensor(0.1227, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:5 loss: 0.018381tensor(0.0887, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:6 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:7 loss: 0.026077tensor(0.0850, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:8 loss: 0.000482tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:9 loss: 0.000335tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:10 loss: 0.000536tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:11 loss: 0.024076tensor(0.0736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:12 loss: 0.029470tensor(0.2015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:13 loss: 0.002171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:14 loss: 0.000260tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:15 loss: 0.001971tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:16 loss: 0.000151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:17 loss: 0.004106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:18 loss: 0.018712tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:19 loss: 0.048368tensor(0.1044, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:20 loss: 0.000365tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:21 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:22 loss: 0.100274tensor(0.0516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:23 loss: 0.002903tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:24 loss: 0.023128tensor(0.1360, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:25 loss: 0.005134tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:26 loss: 0.031554tensor(0.1038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:27 loss: 0.067798tensor(0.1962, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:28 loss: 0.001818tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:29 loss: 0.002343tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:30 loss: 0.017247tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:31 loss: 0.006346tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:32 loss: 0.008857tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:33 loss: 0.001676tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:34 loss: 0.024655tensor(0.0082, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:6 step:35 loss: 0.010642tensor(0.0330, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:36 loss: 0.003080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:37 loss: 0.003074tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:38 loss: 0.000146tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:39 loss: 0.004431tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:40 loss: 0.112993tensor(0.1273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:41 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:42 loss: 0.000320tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:43 loss: 0.054641tensor(0.0690, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:44 loss: 0.003696tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:45 loss: 0.005190tensor(0.0377, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:46 loss: 0.002032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:47 loss: 0.037458tensor(0.1100, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:48 loss: 0.005387tensor(0.0280, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:49 loss: 0.000358tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:50 loss: 0.006198tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:51 loss: 0.003588tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:52 loss: 0.000289tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:53 loss: 0.007057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:54 loss: 0.055509tensor(0.1205, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:55 loss: 0.050832tensor(0.1457, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:56 loss: 0.047064tensor(0.0901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:57 loss: 0.000359tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:58 loss: 0.038320tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:59 loss: 0.001897tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:60 loss: 0.071366tensor(0.1669, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:61 loss: 0.021962tensor(0.0227, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:62 loss: 0.005073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:63 loss: 0.003048tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:64 loss: 0.008292tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:65 loss: 0.027234tensor(0.0863, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:66 loss: 0.004729tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:67 loss: 0.015079tensor(0.1643, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:68 loss: 0.000149tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:69 loss: 0.000081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:70 loss: 0.021163tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:71 loss: 0.031657tensor(0.1144, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:72 loss: 0.008445tensor(0.1788, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:73 loss: 0.001027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:74 loss: 0.013683tensor(0.2002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:75 loss: 0.006685tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:76 loss: 0.001867tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:77 loss: 0.002071tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:78 loss: 0.050517tensor(0.1515, grad_fn=<DivBackward0>)\n",
      "Test Epoch:6 step:79 loss: 0.023887tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "Epoch:7 step:0 loss: 0.014683\n",
      "Epoch:7 step:1 loss: 0.015504\n",
      "Epoch:7 step:2 loss: 0.003051\n",
      "Epoch:7 step:3 loss: 0.000043\n",
      "Epoch:7 step:4 loss: 0.030290\n",
      "Epoch:7 step:5 loss: 0.020485\n",
      "Epoch:7 step:6 loss: 0.000051\n",
      "Epoch:7 step:7 loss: 0.021836\n",
      "Epoch:7 step:8 loss: 0.000080\n",
      "Epoch:7 step:9 loss: 0.000547\n",
      "Epoch:7 step:10 loss: 0.000444\n",
      "Epoch:7 step:11 loss: 0.022563\n",
      "Epoch:7 step:12 loss: 0.029360\n",
      "Epoch:7 step:13 loss: 0.002652\n",
      "Epoch:7 step:14 loss: 0.000129\n",
      "Epoch:7 step:15 loss: 0.002324\n",
      "Epoch:7 step:16 loss: 0.000081\n",
      "Epoch:7 step:17 loss: 0.005688\n",
      "Epoch:7 step:18 loss: 0.015963\n",
      "Epoch:7 step:19 loss: 0.050249\n",
      "Epoch:7 step:20 loss: 0.000317\n",
      "Epoch:7 step:21 loss: 0.000065\n",
      "Epoch:7 step:22 loss: 0.120855\n",
      "Epoch:7 step:23 loss: 0.003576\n",
      "Epoch:7 step:24 loss: 0.022250\n",
      "Epoch:7 step:25 loss: 0.004914\n",
      "Epoch:7 step:26 loss: 0.029069\n",
      "Epoch:7 step:27 loss: 0.125317\n",
      "Epoch:7 step:28 loss: 0.004811\n",
      "Epoch:7 step:29 loss: 0.006921\n",
      "Epoch:7 step:30 loss: 0.028668\n",
      "Epoch:7 step:31 loss: 0.019926\n",
      "Epoch:7 step:32 loss: 0.018774\n",
      "Epoch:7 step:33 loss: 0.006838\n",
      "Epoch:7 step:34 loss: 0.022563\n",
      "Epoch:7 step:35 loss: 0.014301\n",
      "Epoch:7 step:36 loss: 0.001179\n",
      "Epoch:7 step:37 loss: 0.003908\n",
      "Epoch:7 step:38 loss: 0.000170\n",
      "Epoch:7 step:39 loss: 0.003325\n",
      "Epoch:7 step:40 loss: 0.137110\n",
      "Epoch:7 step:41 loss: 0.000095\n",
      "Epoch:7 step:42 loss: 0.000106\n",
      "Epoch:7 step:43 loss: 0.061637\n",
      "Epoch:7 step:44 loss: 0.002560\n",
      "Epoch:7 step:45 loss: 0.005774\n",
      "Epoch:7 step:46 loss: 0.001249\n",
      "Epoch:7 step:47 loss: 0.038960\n",
      "Epoch:7 step:48 loss: 0.006288\n",
      "Epoch:7 step:49 loss: 0.000284\n",
      "Epoch:7 step:50 loss: 0.006631\n",
      "Epoch:7 step:51 loss: 0.004443\n",
      "Epoch:7 step:52 loss: 0.000258\n",
      "Epoch:7 step:53 loss: 0.014274\n",
      "Epoch:7 step:54 loss: 0.055330\n",
      "Epoch:7 step:55 loss: 0.048166\n",
      "Epoch:7 step:56 loss: 0.048111\n",
      "Epoch:7 step:57 loss: 0.000480\n",
      "Epoch:7 step:58 loss: 0.041994\n",
      "Epoch:7 step:59 loss: 0.002055\n",
      "Epoch:7 step:60 loss: 0.073305\n",
      "Epoch:7 step:61 loss: 0.024070\n",
      "Epoch:7 step:62 loss: 0.000538\n",
      "Epoch:7 step:63 loss: 0.010446\n",
      "Epoch:7 step:64 loss: 0.007919\n",
      "Epoch:7 step:65 loss: 0.012897\n",
      "Epoch:7 step:66 loss: 0.001865\n",
      "Epoch:7 step:67 loss: 0.017903\n",
      "Epoch:7 step:68 loss: 0.000282\n",
      "Epoch:7 step:69 loss: 0.000262\n",
      "Epoch:7 step:70 loss: 0.007315\n",
      "Epoch:7 step:71 loss: 0.025952\n",
      "Epoch:7 step:72 loss: 0.008783\n",
      "Epoch:7 step:73 loss: 0.000577\n",
      "Epoch:7 step:74 loss: 0.013099\n",
      "Epoch:7 step:75 loss: 0.004693\n",
      "Epoch:7 step:76 loss: 0.000398\n",
      "Epoch:7 step:77 loss: 0.002702\n",
      "Epoch:7 step:78 loss: 0.042342\n",
      "Epoch:7 step:79 loss: 0.017258\n",
      "Test Epoch:7 step:0 loss: 0.015161tensor(0.0671, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:1 loss: 0.014556tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:2 loss: 0.007791tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:3 loss: 0.000219tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:4 loss: 0.030046tensor(0.1379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:5 loss: 0.013940tensor(0.1545, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:6 loss: 0.000129tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:7 loss: 0.021759tensor(0.1218, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:8 loss: 0.000217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:9 loss: 0.000160tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:10 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:11 loss: 0.014990tensor(0.1070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:12 loss: 0.029155tensor(0.2202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:13 loss: 0.001689tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:14 loss: 0.000162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:15 loss: 0.001478tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:16 loss: 0.000169tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:17 loss: 0.005793tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:18 loss: 0.013507tensor(0.0375, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:19 loss: 0.041893tensor(0.1394, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:20 loss: 0.000308tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:21 loss: 0.000134tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:22 loss: 0.099411tensor(0.0763, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:23 loss: 0.005930tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:24 loss: 0.019353tensor(0.1825, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:25 loss: 0.005572tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:26 loss: 0.026821tensor(0.1527, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:27 loss: 0.053045tensor(0.2478, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:28 loss: 0.003160tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:29 loss: 0.001251tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:30 loss: 0.007052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:31 loss: 0.001745tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:32 loss: 0.004560tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:33 loss: 0.000351tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:7 step:34 loss: 0.029455tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:35 loss: 0.015800tensor(0.0064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:36 loss: 0.000408tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:37 loss: 0.003193tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:38 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:39 loss: 0.002540tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:40 loss: 0.120811tensor(0.1083, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:41 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:42 loss: 0.000371tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:43 loss: 0.054847tensor(0.0626, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:44 loss: 0.004306tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:45 loss: 0.007310tensor(0.0142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:46 loss: 0.002809tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:47 loss: 0.045699tensor(0.0842, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:48 loss: 0.005550tensor(0.0260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:49 loss: 0.000608tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:50 loss: 0.007371tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:51 loss: 0.002471tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:52 loss: 0.000316tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:53 loss: 0.003904tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:54 loss: 0.055242tensor(0.1184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:55 loss: 0.056309tensor(0.1232, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:56 loss: 0.050307tensor(0.0670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:57 loss: 0.000327tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:58 loss: 0.044365tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:59 loss: 0.001827tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:60 loss: 0.056295tensor(0.2375, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:61 loss: 0.024104tensor(0.0188, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:62 loss: 0.000586tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:63 loss: 0.005885tensor(1.3786e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:64 loss: 0.016538tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:65 loss: 0.009267tensor(0.3111, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:66 loss: 0.001713tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:67 loss: 0.017469tensor(0.1793, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:68 loss: 0.000529tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:69 loss: 0.000057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:70 loss: 0.008901tensor(0.0202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:71 loss: 0.028746tensor(0.1484, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:72 loss: 0.007610tensor(0.2419, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:73 loss: 0.000212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:74 loss: 0.023654tensor(0.1169, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:75 loss: 0.000864tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:76 loss: 0.000140tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:77 loss: 0.003424tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:78 loss: 0.040701tensor(0.2094, grad_fn=<DivBackward0>)\n",
      "Test Epoch:7 step:79 loss: 0.014457tensor(0.0735, grad_fn=<DivBackward0>)\n",
      "Epoch:8 step:0 loss: 0.012497\n",
      "Epoch:8 step:1 loss: 0.014669\n",
      "Epoch:8 step:2 loss: 0.011316\n",
      "Epoch:8 step:3 loss: 0.000195\n",
      "Epoch:8 step:4 loss: 0.026924\n",
      "Epoch:8 step:5 loss: 0.015320\n",
      "Epoch:8 step:6 loss: 0.000044\n",
      "Epoch:8 step:7 loss: 0.022645\n",
      "Epoch:8 step:8 loss: 0.000065\n",
      "Epoch:8 step:9 loss: 0.000092\n",
      "Epoch:8 step:10 loss: 0.000127\n",
      "Epoch:8 step:11 loss: 0.011352\n",
      "Epoch:8 step:12 loss: 0.024985\n",
      "Epoch:8 step:13 loss: 0.002159\n",
      "Epoch:8 step:14 loss: 0.000062\n",
      "Epoch:8 step:15 loss: 0.001386\n",
      "Epoch:8 step:16 loss: 0.000085\n",
      "Epoch:8 step:17 loss: 0.012408\n",
      "Epoch:8 step:18 loss: 0.011020\n",
      "Epoch:8 step:19 loss: 0.036154\n",
      "Epoch:8 step:20 loss: 0.000568\n",
      "Epoch:8 step:21 loss: 0.000064\n",
      "Epoch:8 step:22 loss: 0.102656\n",
      "Epoch:8 step:23 loss: 0.005352\n",
      "Epoch:8 step:24 loss: 0.019753\n",
      "Epoch:8 step:25 loss: 0.005348\n",
      "Epoch:8 step:26 loss: 0.022359\n",
      "Epoch:8 step:27 loss: 0.064063\n",
      "Epoch:8 step:28 loss: 0.001130\n",
      "Epoch:8 step:29 loss: 0.000754\n",
      "Epoch:8 step:30 loss: 0.008774\n",
      "Epoch:8 step:31 loss: 0.006317\n",
      "Epoch:8 step:32 loss: 0.011611\n",
      "Epoch:8 step:33 loss: 0.004246\n",
      "Epoch:8 step:34 loss: 0.025743\n",
      "Epoch:8 step:35 loss: 0.013658\n",
      "Epoch:8 step:36 loss: 0.003638\n",
      "Epoch:8 step:37 loss: 0.003066\n",
      "Epoch:8 step:38 loss: 0.000093\n",
      "Epoch:8 step:39 loss: 0.006701\n",
      "Epoch:8 step:40 loss: 0.105902\n",
      "Epoch:8 step:41 loss: 0.000089\n",
      "Epoch:8 step:42 loss: 0.000099\n",
      "Epoch:8 step:43 loss: 0.071553\n",
      "Epoch:8 step:44 loss: 0.002259\n",
      "Epoch:8 step:45 loss: 0.006992\n",
      "Epoch:8 step:46 loss: 0.000782\n",
      "Epoch:8 step:47 loss: 0.046453\n",
      "Epoch:8 step:48 loss: 0.006926\n",
      "Epoch:8 step:49 loss: 0.000344\n",
      "Epoch:8 step:50 loss: 0.005428\n",
      "Epoch:8 step:51 loss: 0.002094\n",
      "Epoch:8 step:52 loss: 0.000288\n",
      "Epoch:8 step:53 loss: 0.008673\n",
      "Epoch:8 step:54 loss: 0.051686\n",
      "Epoch:8 step:55 loss: 0.046536\n",
      "Epoch:8 step:56 loss: 0.046562\n",
      "Epoch:8 step:57 loss: 0.000406\n",
      "Epoch:8 step:58 loss: 0.040560\n",
      "Epoch:8 step:59 loss: 0.001921\n",
      "Epoch:8 step:60 loss: 0.068045\n",
      "Epoch:8 step:61 loss: 0.025876\n",
      "Epoch:8 step:62 loss: 0.000234\n",
      "Epoch:8 step:63 loss: 0.005165\n",
      "Epoch:8 step:64 loss: 0.008893\n",
      "Epoch:8 step:65 loss: 0.014788\n",
      "Epoch:8 step:66 loss: 0.001781\n",
      "Epoch:8 step:67 loss: 0.018009\n",
      "Epoch:8 step:68 loss: 0.000233\n",
      "Epoch:8 step:69 loss: 0.000119\n",
      "Epoch:8 step:70 loss: 0.013529\n",
      "Epoch:8 step:71 loss: 0.026673\n",
      "Epoch:8 step:72 loss: 0.007425\n",
      "Epoch:8 step:73 loss: 0.000677\n",
      "Epoch:8 step:74 loss: 0.011324\n",
      "Epoch:8 step:75 loss: 0.002472\n",
      "Epoch:8 step:76 loss: 0.000116\n",
      "Epoch:8 step:77 loss: 0.003953\n",
      "Epoch:8 step:78 loss: 0.040676\n",
      "Epoch:8 step:79 loss: 0.015928\n",
      "Test Epoch:8 step:0 loss: 0.012898tensor(0.0779, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:1 loss: 0.013075tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:2 loss: 0.009841tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:3 loss: 0.000525tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:4 loss: 0.029032tensor(0.1612, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:5 loss: 0.022370tensor(0.1694, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:6 loss: 0.000681tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:7 loss: 0.027073tensor(0.1014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:8 loss: 0.000276tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:9 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:10 loss: 0.000527tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:11 loss: 0.022126tensor(0.1244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:12 loss: 0.063235tensor(0.1926, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:13 loss: 0.002997tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:14 loss: 0.000170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:15 loss: 0.001007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:16 loss: 0.000801tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:17 loss: 0.008673tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:18 loss: 0.028203tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:19 loss: 0.065766tensor(0.0443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:20 loss: 0.000808tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:21 loss: 0.000313tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:22 loss: 0.071269tensor(0.0743, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:23 loss: 0.002184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:24 loss: 0.023844tensor(0.1361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:25 loss: 0.005454tensor(0.0108, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:26 loss: 0.027935tensor(0.1429, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:27 loss: 0.060949tensor(0.2193, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:28 loss: 0.007629tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:29 loss: 0.004023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:30 loss: 0.011184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:31 loss: 0.003760tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:32 loss: 0.004412tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:8 step:33 loss: 0.000647tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:34 loss: 0.031739tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:35 loss: 0.013018tensor(0.0181, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:36 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:37 loss: 0.003007tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:38 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:39 loss: 0.003240tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:40 loss: 0.159688tensor(0.0502, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:41 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:42 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:43 loss: 0.046989tensor(0.0948, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:44 loss: 0.008798tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:45 loss: 0.007267tensor(0.0135, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:46 loss: 0.008034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:47 loss: 0.057582tensor(0.0802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:48 loss: 0.004289tensor(0.0694, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:49 loss: 0.001105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:50 loss: 0.007373tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:51 loss: 0.002219tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:52 loss: 0.000309tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:53 loss: 0.008186tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:54 loss: 0.057848tensor(0.0889, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:55 loss: 0.055855tensor(0.1090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:56 loss: 0.058771tensor(0.0253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:57 loss: 0.000225tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:58 loss: 0.028845tensor(0.0052, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:59 loss: 0.001286tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:60 loss: 0.089184tensor(0.1063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:61 loss: 0.031572tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:62 loss: 0.000135tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:63 loss: 0.015454tensor(6.9811e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:64 loss: 0.006165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:65 loss: 0.030626tensor(0.0223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:66 loss: 0.001884tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:67 loss: 0.022583tensor(0.0531, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:68 loss: 0.000173tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:69 loss: 0.000253tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:70 loss: 0.012991tensor(0.0108, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:71 loss: 0.033391tensor(0.0864, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:72 loss: 0.013320tensor(0.0535, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:73 loss: 0.020300tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:74 loss: 0.017267tensor(0.1277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:75 loss: 0.009374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:76 loss: 0.009831tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:77 loss: 0.002480tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:78 loss: 0.058122tensor(0.0862, grad_fn=<DivBackward0>)\n",
      "Test Epoch:8 step:79 loss: 0.019666tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "Epoch:9 step:0 loss: 0.012805\n",
      "Epoch:9 step:1 loss: 0.014485\n",
      "Epoch:9 step:2 loss: 0.001195\n",
      "Epoch:9 step:3 loss: 0.000057\n",
      "Epoch:9 step:4 loss: 0.032967\n",
      "Epoch:9 step:5 loss: 0.019130\n",
      "Epoch:9 step:6 loss: 0.000088\n",
      "Epoch:9 step:7 loss: 0.033309\n",
      "Epoch:9 step:8 loss: 0.000231\n",
      "Epoch:9 step:9 loss: 0.000468\n",
      "Epoch:9 step:10 loss: 0.002383\n",
      "Epoch:9 step:11 loss: 0.017014\n",
      "Epoch:9 step:12 loss: 0.037911\n",
      "Epoch:9 step:13 loss: 0.002630\n",
      "Epoch:9 step:14 loss: 0.000664\n",
      "Epoch:9 step:15 loss: 0.004169\n",
      "Epoch:9 step:16 loss: 0.000390\n",
      "Epoch:9 step:17 loss: 0.011080\n",
      "Epoch:9 step:18 loss: 0.011299\n",
      "Epoch:9 step:19 loss: 0.045230\n",
      "Epoch:9 step:20 loss: 0.000489\n",
      "Epoch:9 step:21 loss: 0.000174\n",
      "Epoch:9 step:22 loss: 0.085454\n",
      "Epoch:9 step:23 loss: 0.002235\n",
      "Epoch:9 step:24 loss: 0.023268\n",
      "Epoch:9 step:25 loss: 0.004418\n",
      "Epoch:9 step:26 loss: 0.027664\n",
      "Epoch:9 step:27 loss: 0.050850\n",
      "Epoch:9 step:28 loss: 0.000996\n",
      "Epoch:9 step:29 loss: 0.001004\n",
      "Epoch:9 step:30 loss: 0.005843\n",
      "Epoch:9 step:31 loss: 0.001897\n",
      "Epoch:9 step:32 loss: 0.004170\n",
      "Epoch:9 step:33 loss: 0.000086\n",
      "Epoch:9 step:34 loss: 0.028683\n",
      "Epoch:9 step:35 loss: 0.012148\n",
      "Epoch:9 step:36 loss: 0.000074\n",
      "Epoch:9 step:37 loss: 0.002666\n",
      "Epoch:9 step:38 loss: 0.000120\n",
      "Epoch:9 step:39 loss: 0.008807\n",
      "Epoch:9 step:40 loss: 0.083060\n",
      "Epoch:9 step:41 loss: 0.000115\n",
      "Epoch:9 step:42 loss: 0.000466\n",
      "Epoch:9 step:43 loss: 0.049176\n",
      "Epoch:9 step:44 loss: 0.013935\n",
      "Epoch:9 step:45 loss: 0.004932\n",
      "Epoch:9 step:46 loss: 0.002578\n",
      "Epoch:9 step:47 loss: 0.034834\n",
      "Epoch:9 step:48 loss: 0.005930\n",
      "Epoch:9 step:49 loss: 0.000306\n",
      "Epoch:9 step:50 loss: 0.008115\n",
      "Epoch:9 step:51 loss: 0.001275\n",
      "Epoch:9 step:52 loss: 0.000154\n",
      "Epoch:9 step:53 loss: 0.008352\n",
      "Epoch:9 step:54 loss: 0.047399\n",
      "Epoch:9 step:55 loss: 0.066705\n",
      "Epoch:9 step:56 loss: 0.045684\n",
      "Epoch:9 step:57 loss: 0.000117\n",
      "Epoch:9 step:58 loss: 0.045412\n",
      "Epoch:9 step:59 loss: 0.001262\n",
      "Epoch:9 step:60 loss: 0.053887\n",
      "Epoch:9 step:61 loss: 0.029787\n",
      "Epoch:9 step:62 loss: 0.000105\n",
      "Epoch:9 step:63 loss: 0.014430\n",
      "Epoch:9 step:64 loss: 0.006252\n",
      "Epoch:9 step:65 loss: 0.037197\n",
      "Epoch:9 step:66 loss: 0.001199\n",
      "Epoch:9 step:67 loss: 0.027602\n",
      "Epoch:9 step:68 loss: 0.000437\n",
      "Epoch:9 step:69 loss: 0.000154\n",
      "Epoch:9 step:70 loss: 0.012642\n",
      "Epoch:9 step:71 loss: 0.041299\n",
      "Epoch:9 step:72 loss: 0.021029\n",
      "Epoch:9 step:73 loss: 0.002354\n",
      "Epoch:9 step:74 loss: 0.025268\n",
      "Epoch:9 step:75 loss: 0.003865\n",
      "Epoch:9 step:76 loss: 0.003093\n",
      "Epoch:9 step:77 loss: 0.002062\n",
      "Epoch:9 step:78 loss: 0.054247\n",
      "Epoch:9 step:79 loss: 0.021389\n",
      "Test Epoch:9 step:0 loss: 0.016160tensor(0.0154, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:1 loss: 0.017423tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:2 loss: 0.000993tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:3 loss: 0.000766tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:4 loss: 0.036110tensor(0.0786, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:5 loss: 0.028390tensor(0.0175, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:6 loss: 0.000137tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:7 loss: 0.030491tensor(0.0167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:8 loss: 0.000101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:9 loss: 0.000535tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:10 loss: 0.004564tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:11 loss: 0.015113tensor(0.0608, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:12 loss: 0.035688tensor(0.1603, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:13 loss: 0.005452tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:14 loss: 0.001657tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:15 loss: 0.007674tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:16 loss: 0.000119tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:17 loss: 0.008391tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:18 loss: 0.014525tensor(0.0303, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:19 loss: 0.041080tensor(0.1059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:20 loss: 0.000371tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:21 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:22 loss: 0.073228tensor(0.0857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:23 loss: 0.001506tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:24 loss: 0.022375tensor(0.1562, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:25 loss: 0.004146tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:26 loss: 0.027489tensor(0.1491, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:27 loss: 0.051223tensor(0.2597, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:28 loss: 0.001122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:29 loss: 0.000343tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:30 loss: 0.002774tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:31 loss: 0.004046tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:9 step:32 loss: 0.003574tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:33 loss: 0.000201tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:34 loss: 0.032096tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:35 loss: 0.010785tensor(0.0555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:36 loss: 0.000286tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:37 loss: 0.002388tensor(0.0113, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:38 loss: 0.000383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:39 loss: 0.007571tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:40 loss: 0.074271tensor(0.2474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:41 loss: 0.000226tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:42 loss: 0.001117tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:43 loss: 0.046359tensor(0.1382, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:44 loss: 0.008129tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:45 loss: 0.004623tensor(0.0626, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:46 loss: 0.003002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:47 loss: 0.059547tensor(0.1183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:48 loss: 0.005610tensor(0.0270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:49 loss: 0.000324tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:50 loss: 0.002714tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:51 loss: 0.000602tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:52 loss: 0.000130tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:53 loss: 0.000738tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:54 loss: 0.086068tensor(0.0359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:55 loss: 0.101910tensor(0.0231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:56 loss: 0.060147tensor(0.0276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:57 loss: 0.000852tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:58 loss: 0.030304tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:59 loss: 0.007620tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:60 loss: 0.089741tensor(0.0901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:61 loss: 0.021443tensor(0.0138, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:62 loss: 0.003962tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:63 loss: 0.018033tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:64 loss: 0.013482tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:65 loss: 0.025267tensor(0.0384, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:66 loss: 0.003558tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:67 loss: 0.022410tensor(0.0490, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:68 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:69 loss: 0.000255tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:70 loss: 0.007410tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:71 loss: 0.039145tensor(0.0410, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:72 loss: 0.026566tensor(0.0063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:73 loss: 0.004713tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:74 loss: 0.019178tensor(0.1107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:75 loss: 0.006065tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:76 loss: 0.007168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:77 loss: 0.001557tensor(0.0198, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:78 loss: 0.041922tensor(0.1391, grad_fn=<DivBackward0>)\n",
      "Test Epoch:9 step:79 loss: 0.023270tensor(0.0046, grad_fn=<DivBackward0>)\n",
      "Epoch:10 step:0 loss: 0.015077\n",
      "Epoch:10 step:1 loss: 0.022416\n",
      "Epoch:10 step:2 loss: 0.003379\n",
      "Epoch:10 step:3 loss: 0.001537\n",
      "Epoch:10 step:4 loss: 0.033561\n",
      "Epoch:10 step:5 loss: 0.026768\n",
      "Epoch:10 step:6 loss: 0.000132\n",
      "Epoch:10 step:7 loss: 0.028514\n",
      "Epoch:10 step:8 loss: 0.000091\n",
      "Epoch:10 step:9 loss: 0.000368\n",
      "Epoch:10 step:10 loss: 0.004542\n",
      "Epoch:10 step:11 loss: 0.015132\n",
      "Epoch:10 step:12 loss: 0.037788\n",
      "Epoch:10 step:13 loss: 0.003772\n",
      "Epoch:10 step:14 loss: 0.001173\n",
      "Epoch:10 step:15 loss: 0.004990\n",
      "Epoch:10 step:16 loss: 0.000102\n",
      "Epoch:10 step:17 loss: 0.006930\n",
      "Epoch:10 step:18 loss: 0.012067\n",
      "Epoch:10 step:19 loss: 0.042548\n",
      "Epoch:10 step:20 loss: 0.000229\n",
      "Epoch:10 step:21 loss: 0.000072\n",
      "Epoch:10 step:22 loss: 0.067203\n",
      "Epoch:10 step:23 loss: 0.002800\n",
      "Epoch:10 step:24 loss: 0.023828\n",
      "Epoch:10 step:25 loss: 0.004650\n",
      "Epoch:10 step:26 loss: 0.026704\n",
      "Epoch:10 step:27 loss: 0.064640\n",
      "Epoch:10 step:28 loss: 0.000763\n",
      "Epoch:10 step:29 loss: 0.000307\n",
      "Epoch:10 step:30 loss: 0.003719\n",
      "Epoch:10 step:31 loss: 0.005692\n",
      "Epoch:10 step:32 loss: 0.003724\n",
      "Epoch:10 step:33 loss: 0.000055\n",
      "Epoch:10 step:34 loss: 0.028968\n",
      "Epoch:10 step:35 loss: 0.008047\n",
      "Epoch:10 step:36 loss: 0.000137\n",
      "Epoch:10 step:37 loss: 0.001947\n",
      "Epoch:10 step:38 loss: 0.000398\n",
      "Epoch:10 step:39 loss: 0.009100\n",
      "Epoch:10 step:40 loss: 0.069547\n",
      "Epoch:10 step:41 loss: 0.000140\n",
      "Epoch:10 step:42 loss: 0.001369\n",
      "Epoch:10 step:43 loss: 0.042278\n",
      "Epoch:10 step:44 loss: 0.007010\n",
      "Epoch:10 step:45 loss: 0.004578\n",
      "Epoch:10 step:46 loss: 0.002265\n",
      "Epoch:10 step:47 loss: 0.031268\n",
      "Epoch:10 step:48 loss: 0.005163\n",
      "Epoch:10 step:49 loss: 0.000419\n",
      "Epoch:10 step:50 loss: 0.007310\n",
      "Epoch:10 step:51 loss: 0.003135\n",
      "Epoch:10 step:52 loss: 0.000162\n",
      "Epoch:10 step:53 loss: 0.005616\n",
      "Epoch:10 step:54 loss: 0.048686\n",
      "Epoch:10 step:55 loss: 0.048681\n",
      "Epoch:10 step:56 loss: 0.044295\n",
      "Epoch:10 step:57 loss: 0.000068\n",
      "Epoch:10 step:58 loss: 0.028787\n",
      "Epoch:10 step:59 loss: 0.000409\n",
      "Epoch:10 step:60 loss: 0.068965\n",
      "Epoch:10 step:61 loss: 0.038537\n",
      "Epoch:10 step:62 loss: 0.000091\n",
      "Epoch:10 step:63 loss: 0.006319\n",
      "Epoch:10 step:64 loss: 0.004538\n",
      "Epoch:10 step:65 loss: 0.034279\n",
      "Epoch:10 step:66 loss: 0.001305\n",
      "Epoch:10 step:67 loss: 0.015970\n",
      "Epoch:10 step:68 loss: 0.000547\n",
      "Epoch:10 step:69 loss: 0.000230\n",
      "Epoch:10 step:70 loss: 0.013759\n",
      "Epoch:10 step:71 loss: 0.032376\n",
      "Epoch:10 step:72 loss: 0.010843\n",
      "Epoch:10 step:73 loss: 0.013199\n",
      "Epoch:10 step:74 loss: 0.013402\n",
      "Epoch:10 step:75 loss: 0.003403\n",
      "Epoch:10 step:76 loss: 0.001501\n",
      "Epoch:10 step:77 loss: 0.001815\n",
      "Epoch:10 step:78 loss: 0.067507\n",
      "Epoch:10 step:79 loss: 0.020584\n",
      "Test Epoch:10 step:0 loss: 0.016528tensor(0.0125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:1 loss: 0.012578tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:2 loss: 0.001539tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:3 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:4 loss: 0.033504tensor(0.0854, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:5 loss: 0.022209tensor(0.0469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:6 loss: 0.000243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:7 loss: 0.020620tensor(0.0767, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:8 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:9 loss: 0.001998tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:10 loss: 0.005607tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:11 loss: 0.015823tensor(0.1129, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:12 loss: 0.026284tensor(0.2829, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:13 loss: 0.007698tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:14 loss: 0.001434tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:15 loss: 0.002492tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:16 loss: 0.000103tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:17 loss: 0.005291tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:18 loss: 0.014051tensor(0.0291, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:19 loss: 0.052244tensor(0.0764, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:20 loss: 0.000208tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:21 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:22 loss: 0.082206tensor(0.0762, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:23 loss: 0.001992tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:24 loss: 0.020924tensor(0.1901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:25 loss: 0.005117tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:26 loss: 0.022779tensor(0.1993, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:27 loss: 0.042471tensor(0.3107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:28 loss: 0.000882tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:29 loss: 0.000742tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:10 step:30 loss: 0.004158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:31 loss: 0.004993tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:32 loss: 0.004270tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:33 loss: 0.000184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:34 loss: 0.020939tensor(0.0115, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:35 loss: 0.008397tensor(0.0772, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:36 loss: 0.000111tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:37 loss: 0.002319tensor(0.0159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:38 loss: 0.000310tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:39 loss: 0.007565tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:40 loss: 0.069074tensor(0.2599, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:41 loss: 0.000213tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:42 loss: 0.001708tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:43 loss: 0.043226tensor(0.1700, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:44 loss: 0.008886tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:45 loss: 0.003904tensor(0.0828, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:46 loss: 0.004206tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:47 loss: 0.026906tensor(0.2203, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:48 loss: 0.005293tensor(0.0318, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:49 loss: 0.000235tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:50 loss: 0.006621tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:51 loss: 0.001465tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:52 loss: 0.000142tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:53 loss: 0.000692tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:54 loss: 0.053628tensor(0.2276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:55 loss: 0.044783tensor(0.2443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:56 loss: 0.053659tensor(0.0621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:57 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:58 loss: 0.023904tensor(0.0148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:59 loss: 0.000153tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:60 loss: 0.112703tensor(0.0654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:61 loss: 0.037115tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:62 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:63 loss: 0.002632tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:64 loss: 0.002309tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:65 loss: 0.034673tensor(0.0107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:66 loss: 0.001792tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:67 loss: 0.018147tensor(0.0779, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:68 loss: 0.000288tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:69 loss: 0.000964tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:70 loss: 0.015553tensor(0.0106, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:71 loss: 0.034763tensor(0.0809, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:72 loss: 0.013194tensor(0.0653, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:73 loss: 0.002506tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:74 loss: 0.014539tensor(0.1500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:75 loss: 0.004820tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:76 loss: 0.001214tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:77 loss: 0.003922tensor(0.0033, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:78 loss: 0.059614tensor(0.0866, grad_fn=<DivBackward0>)\n",
      "Test Epoch:10 step:79 loss: 0.015466tensor(0.0260, grad_fn=<DivBackward0>)\n",
      "Epoch:11 step:0 loss: 0.013641\n",
      "Epoch:11 step:1 loss: 0.014258\n",
      "Epoch:11 step:2 loss: 0.001164\n",
      "Epoch:11 step:3 loss: 0.001207\n",
      "Epoch:11 step:4 loss: 0.031068\n",
      "Epoch:11 step:5 loss: 0.018656\n",
      "Epoch:11 step:6 loss: 0.003696\n",
      "Epoch:11 step:7 loss: 0.020949\n",
      "Epoch:11 step:8 loss: 0.001294\n",
      "Epoch:11 step:9 loss: 0.007111\n",
      "Epoch:11 step:10 loss: 0.011668\n",
      "Epoch:11 step:11 loss: 0.015866\n",
      "Epoch:11 step:12 loss: 0.027718\n",
      "Epoch:11 step:13 loss: 0.007342\n",
      "Epoch:11 step:14 loss: 0.001395\n",
      "Epoch:11 step:15 loss: 0.000664\n",
      "Epoch:11 step:16 loss: 0.000192\n",
      "Epoch:11 step:17 loss: 0.001665\n",
      "Epoch:11 step:18 loss: 0.018414\n",
      "Epoch:11 step:19 loss: 0.060934\n",
      "Epoch:11 step:20 loss: 0.000110\n",
      "Epoch:11 step:21 loss: 0.000039\n",
      "Epoch:11 step:22 loss: 0.106252\n",
      "Epoch:11 step:23 loss: 0.005959\n",
      "Epoch:11 step:24 loss: 0.020117\n",
      "Epoch:11 step:25 loss: 0.005537\n",
      "Epoch:11 step:26 loss: 0.027453\n",
      "Epoch:11 step:27 loss: 0.055708\n",
      "Epoch:11 step:28 loss: 0.002389\n",
      "Epoch:11 step:29 loss: 0.001091\n",
      "Epoch:11 step:30 loss: 0.013604\n",
      "Epoch:11 step:31 loss: 0.011129\n",
      "Epoch:11 step:32 loss: 0.016935\n",
      "Epoch:11 step:33 loss: 0.000295\n",
      "Epoch:11 step:34 loss: 0.025669\n",
      "Epoch:11 step:35 loss: 0.009906\n",
      "Epoch:11 step:36 loss: 0.001263\n",
      "Epoch:11 step:37 loss: 0.003152\n",
      "Epoch:11 step:38 loss: 0.000385\n",
      "Epoch:11 step:39 loss: 0.003147\n",
      "Epoch:11 step:40 loss: 0.133385\n",
      "Epoch:11 step:41 loss: 0.000380\n",
      "Epoch:11 step:42 loss: 0.001856\n",
      "Epoch:11 step:43 loss: 0.051531\n",
      "Epoch:11 step:44 loss: 0.006662\n",
      "Epoch:11 step:45 loss: 0.005903\n",
      "Epoch:11 step:46 loss: 0.005480\n",
      "Epoch:11 step:47 loss: 0.032764\n",
      "Epoch:11 step:48 loss: 0.006566\n",
      "Epoch:11 step:49 loss: 0.001655\n",
      "Epoch:11 step:50 loss: 0.005352\n",
      "Epoch:11 step:51 loss: 0.002261\n",
      "Epoch:11 step:52 loss: 0.000878\n",
      "Epoch:11 step:53 loss: 0.001471\n",
      "Epoch:11 step:54 loss: 0.045788\n",
      "Epoch:11 step:55 loss: 0.042495\n",
      "Epoch:11 step:56 loss: 0.044047\n",
      "Epoch:11 step:57 loss: 0.000360\n",
      "Epoch:11 step:58 loss: 0.029532\n",
      "Epoch:11 step:59 loss: 0.001084\n",
      "Epoch:11 step:60 loss: 0.046993\n",
      "Epoch:11 step:61 loss: 0.034327\n",
      "Epoch:11 step:62 loss: 0.000574\n",
      "Epoch:11 step:63 loss: 0.002616\n",
      "Epoch:11 step:64 loss: 0.005611\n",
      "Epoch:11 step:65 loss: 0.024598\n",
      "Epoch:11 step:66 loss: 0.003341\n",
      "Epoch:11 step:67 loss: 0.013023\n",
      "Epoch:11 step:68 loss: 0.000940\n",
      "Epoch:11 step:69 loss: 0.000565\n",
      "Epoch:11 step:70 loss: 0.011358\n",
      "Epoch:11 step:71 loss: 0.029186\n",
      "Epoch:11 step:72 loss: 0.007133\n",
      "Epoch:11 step:73 loss: 0.001973\n",
      "Epoch:11 step:74 loss: 0.010356\n",
      "Epoch:11 step:75 loss: 0.004902\n",
      "Epoch:11 step:76 loss: 0.001030\n",
      "Epoch:11 step:77 loss: 0.001478\n",
      "Epoch:11 step:78 loss: 0.044469\n",
      "Epoch:11 step:79 loss: 0.019432\n",
      "Test Epoch:11 step:0 loss: 0.011758tensor(0.0603, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:1 loss: 0.010279tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:2 loss: 0.003708tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:3 loss: 0.000350tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:4 loss: 0.022315tensor(0.2044, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:5 loss: 0.016492tensor(0.1361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:6 loss: 0.000456tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:7 loss: 0.017408tensor(0.1479, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:8 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:9 loss: 0.003563tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:10 loss: 0.000493tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:11 loss: 0.012076tensor(0.1587, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:12 loss: 0.023253tensor(0.2826, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:13 loss: 0.003617tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:14 loss: 0.000249tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:15 loss: 0.000684tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:16 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:17 loss: 0.007314tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:18 loss: 0.012448tensor(0.0623, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:19 loss: 0.043247tensor(0.1461, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:20 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:21 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:22 loss: 0.058170tensor(0.1543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:23 loss: 0.001741tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:24 loss: 0.017738tensor(0.2359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:25 loss: 0.003941tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:26 loss: 0.025077tensor(0.2025, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:11 step:27 loss: 0.037148tensor(0.3380, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:28 loss: 0.000304tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:29 loss: 0.000181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:30 loss: 0.002261tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:31 loss: 0.005942tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:32 loss: 0.002266tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:33 loss: 0.021181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:34 loss: 0.021851tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:35 loss: 0.012343tensor(0.0374, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:36 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:37 loss: 0.002044tensor(0.0207, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:38 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:39 loss: 0.002691tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:40 loss: 0.132789tensor(0.0909, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:41 loss: 0.000225tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:42 loss: 0.002283tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:43 loss: 0.043824tensor(0.1138, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:44 loss: 0.012694tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:45 loss: 0.009634tensor(0.0337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:46 loss: 0.008270tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:47 loss: 0.051265tensor(0.0876, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:48 loss: 0.005532tensor(0.0457, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:49 loss: 0.000672tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:50 loss: 0.007567tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:51 loss: 0.003274tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:52 loss: 0.000119tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:53 loss: 0.006722tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:54 loss: 0.054753tensor(0.1028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:55 loss: 0.045142tensor(0.1472, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:56 loss: 0.045659tensor(0.0739, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:57 loss: 0.000180tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:58 loss: 0.036289tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:59 loss: 0.001184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:60 loss: 0.056769tensor(0.2269, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:61 loss: 0.027039tensor(0.0123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:62 loss: 0.000256tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:63 loss: 0.027453tensor(4.3937e-06, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:64 loss: 0.012959tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:65 loss: 0.017224tensor(0.1302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:66 loss: 0.001650tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:67 loss: 0.015451tensor(0.1419, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:68 loss: 0.000143tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:69 loss: 0.000193tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:70 loss: 0.010743tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:71 loss: 0.025385tensor(0.1337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:72 loss: 0.010160tensor(0.1195, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:73 loss: 0.002391tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:74 loss: 0.014199tensor(0.1814, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:75 loss: 0.005988tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:76 loss: 0.002396tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:77 loss: 0.001410tensor(0.0281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:78 loss: 0.053642tensor(0.1328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:11 step:79 loss: 0.014774tensor(0.0374, grad_fn=<DivBackward0>)\n",
      "Epoch:12 step:0 loss: 0.013405\n",
      "Epoch:12 step:1 loss: 0.011688\n",
      "Epoch:12 step:2 loss: 0.002303\n",
      "Epoch:12 step:3 loss: 0.000108\n",
      "Epoch:12 step:4 loss: 0.027433\n",
      "Epoch:12 step:5 loss: 0.014073\n",
      "Epoch:12 step:6 loss: 0.000092\n",
      "Epoch:12 step:7 loss: 0.016960\n",
      "Epoch:12 step:8 loss: 0.000236\n",
      "Epoch:12 step:9 loss: 0.000694\n",
      "Epoch:12 step:10 loss: 0.001619\n",
      "Epoch:12 step:11 loss: 0.013315\n",
      "Epoch:12 step:12 loss: 0.025199\n",
      "Epoch:12 step:13 loss: 0.003656\n",
      "Epoch:12 step:14 loss: 0.000157\n",
      "Epoch:12 step:15 loss: 0.000887\n",
      "Epoch:12 step:16 loss: 0.000094\n",
      "Epoch:12 step:17 loss: 0.004895\n",
      "Epoch:12 step:18 loss: 0.009827\n",
      "Epoch:12 step:19 loss: 0.040127\n",
      "Epoch:12 step:20 loss: 0.000086\n",
      "Epoch:12 step:21 loss: 0.000049\n",
      "Epoch:12 step:22 loss: 0.065954\n",
      "Epoch:12 step:23 loss: 0.003342\n",
      "Epoch:12 step:24 loss: 0.018136\n",
      "Epoch:12 step:25 loss: 0.004920\n",
      "Epoch:12 step:26 loss: 0.024780\n",
      "Epoch:12 step:27 loss: 0.045268\n",
      "Epoch:12 step:28 loss: 0.000090\n",
      "Epoch:12 step:29 loss: 0.000075\n",
      "Epoch:12 step:30 loss: 0.003890\n",
      "Epoch:12 step:31 loss: 0.007053\n",
      "Epoch:12 step:32 loss: 0.002958\n",
      "Epoch:12 step:33 loss: 0.002149\n",
      "Epoch:12 step:34 loss: 0.019405\n",
      "Epoch:12 step:35 loss: 0.009315\n",
      "Epoch:12 step:36 loss: 0.000099\n",
      "Epoch:12 step:37 loss: 0.001954\n",
      "Epoch:12 step:38 loss: 0.000160\n",
      "Epoch:12 step:39 loss: 0.007711\n",
      "Epoch:12 step:40 loss: 0.073771\n",
      "Epoch:12 step:41 loss: 0.000140\n",
      "Epoch:12 step:42 loss: 0.001949\n",
      "Epoch:12 step:43 loss: 0.041719\n",
      "Epoch:12 step:44 loss: 0.003279\n",
      "Epoch:12 step:45 loss: 0.003238\n",
      "Epoch:12 step:46 loss: 0.001587\n",
      "Epoch:12 step:47 loss: 0.023200\n",
      "Epoch:12 step:48 loss: 0.004729\n",
      "Epoch:12 step:49 loss: 0.000274\n",
      "Epoch:12 step:50 loss: 0.004966\n",
      "Epoch:12 step:51 loss: 0.002225\n",
      "Epoch:12 step:52 loss: 0.000206\n",
      "Epoch:12 step:53 loss: 0.000660\n",
      "Epoch:12 step:54 loss: 0.044955\n",
      "Epoch:12 step:55 loss: 0.046014\n",
      "Epoch:12 step:56 loss: 0.042298\n",
      "Epoch:12 step:57 loss: 0.000134\n",
      "Epoch:12 step:58 loss: 0.030191\n",
      "Epoch:12 step:59 loss: 0.000674\n",
      "Epoch:12 step:60 loss: 0.065258\n",
      "Epoch:12 step:61 loss: 0.027170\n",
      "Epoch:12 step:62 loss: 0.000115\n",
      "Epoch:12 step:63 loss: 0.002351\n",
      "Epoch:12 step:64 loss: 0.005971\n",
      "Epoch:12 step:65 loss: 0.016472\n",
      "Epoch:12 step:66 loss: 0.002985\n",
      "Epoch:12 step:67 loss: 0.012340\n",
      "Epoch:12 step:68 loss: 0.000195\n",
      "Epoch:12 step:69 loss: 0.000249\n",
      "Epoch:12 step:70 loss: 0.012732\n",
      "Epoch:12 step:71 loss: 0.048316\n",
      "Epoch:12 step:72 loss: 0.007471\n",
      "Epoch:12 step:73 loss: 0.000605\n",
      "Epoch:12 step:74 loss: 0.011254\n",
      "Epoch:12 step:75 loss: 0.002627\n",
      "Epoch:12 step:76 loss: 0.000512\n",
      "Epoch:12 step:77 loss: 0.001552\n",
      "Epoch:12 step:78 loss: 0.048706\n",
      "Epoch:12 step:79 loss: 0.016321\n",
      "Test Epoch:12 step:0 loss: 0.012425tensor(0.0453, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:1 loss: 0.009176tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:2 loss: 0.001669tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:3 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:4 loss: 0.025707tensor(0.1597, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:5 loss: 0.015767tensor(0.1304, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:6 loss: 0.000291tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:7 loss: 0.018571tensor(0.1364, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:8 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:9 loss: 0.001374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:10 loss: 0.000280tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:11 loss: 0.012732tensor(0.1417, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:12 loss: 0.024857tensor(0.2628, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:13 loss: 0.004720tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:14 loss: 0.000232tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:15 loss: 0.000768tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:16 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:17 loss: 0.008173tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:18 loss: 0.011694tensor(0.0801, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:19 loss: 0.026781tensor(0.2054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:20 loss: 0.000128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:21 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:22 loss: 0.056775tensor(0.1446, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:23 loss: 0.002205tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:12 step:24 loss: 0.018276tensor(0.2173, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:25 loss: 0.003924tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:26 loss: 0.020985tensor(0.2009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:27 loss: 0.041435tensor(0.3169, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:28 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:29 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:30 loss: 0.001624tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:31 loss: 0.003990tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:32 loss: 0.001217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:33 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:34 loss: 0.023974tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:35 loss: 0.007783tensor(0.1209, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:36 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:37 loss: 0.001689tensor(0.0475, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:38 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:39 loss: 0.006189tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:40 loss: 0.052897tensor(0.3054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:41 loss: 0.000184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:42 loss: 0.003122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:43 loss: 0.025270tensor(0.2595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:44 loss: 0.004321tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:45 loss: 0.003469tensor(0.1221, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:46 loss: 0.003571tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:47 loss: 0.018160tensor(0.2802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:48 loss: 0.004239tensor(0.0608, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:49 loss: 0.000154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:50 loss: 0.003372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:51 loss: 0.001658tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:52 loss: 0.000098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:53 loss: 0.000162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:54 loss: 0.045799tensor(0.2551, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:55 loss: 0.034742tensor(0.2846, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:56 loss: 0.043620tensor(0.1151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:57 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:58 loss: 0.027297tensor(0.0044, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:59 loss: 0.000416tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:60 loss: 0.068375tensor(0.2045, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:61 loss: 0.025851tensor(0.0084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:62 loss: 0.000195tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:63 loss: 0.002765tensor(9.6099e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:64 loss: 0.005718tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:65 loss: 0.013828tensor(0.1629, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:66 loss: 0.003199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:67 loss: 0.011689tensor(0.2047, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:68 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:69 loss: 0.002247tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:70 loss: 0.010183tensor(0.0267, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:71 loss: 0.024907tensor(0.1809, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:72 loss: 0.007561tensor(0.2125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:73 loss: 0.000727tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:74 loss: 0.008650tensor(0.2834, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:75 loss: 0.004867tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:76 loss: 0.000524tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:77 loss: 0.001332tensor(0.0408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:78 loss: 0.037802tensor(0.2298, grad_fn=<DivBackward0>)\n",
      "Test Epoch:12 step:79 loss: 0.010869tensor(0.1047, grad_fn=<DivBackward0>)\n",
      "Epoch:13 step:0 loss: 0.009554\n",
      "Epoch:13 step:1 loss: 0.009494\n",
      "Epoch:13 step:2 loss: 0.001411\n",
      "Epoch:13 step:3 loss: 0.000050\n",
      "Epoch:13 step:4 loss: 0.020658\n",
      "Epoch:13 step:5 loss: 0.014225\n",
      "Epoch:13 step:6 loss: 0.000080\n",
      "Epoch:13 step:7 loss: 0.020544\n",
      "Epoch:13 step:8 loss: 0.000056\n",
      "Epoch:13 step:9 loss: 0.000714\n",
      "Epoch:13 step:10 loss: 0.000123\n",
      "Epoch:13 step:11 loss: 0.011614\n",
      "Epoch:13 step:12 loss: 0.023682\n",
      "Epoch:13 step:13 loss: 0.005833\n",
      "Epoch:13 step:14 loss: 0.000181\n",
      "Epoch:13 step:15 loss: 0.000875\n",
      "Epoch:13 step:16 loss: 0.000042\n",
      "Epoch:13 step:17 loss: 0.009824\n",
      "Epoch:13 step:18 loss: 0.010756\n",
      "Epoch:13 step:19 loss: 0.030415\n",
      "Epoch:13 step:20 loss: 0.000107\n",
      "Epoch:13 step:21 loss: 0.000023\n",
      "Epoch:13 step:22 loss: 0.049646\n",
      "Epoch:13 step:23 loss: 0.001790\n",
      "Epoch:13 step:24 loss: 0.014466\n",
      "Epoch:13 step:25 loss: 0.002653\n",
      "Epoch:13 step:26 loss: 0.020549\n",
      "Epoch:13 step:27 loss: 0.031203\n",
      "Epoch:13 step:28 loss: 0.000198\n",
      "Epoch:13 step:29 loss: 0.000058\n",
      "Epoch:13 step:30 loss: 0.003585\n",
      "Epoch:13 step:31 loss: 0.006525\n",
      "Epoch:13 step:32 loss: 0.001500\n",
      "Epoch:13 step:33 loss: 0.000016\n",
      "Epoch:13 step:34 loss: 0.019055\n",
      "Epoch:13 step:35 loss: 0.008848\n",
      "Epoch:13 step:36 loss: 0.000012\n",
      "Epoch:13 step:37 loss: 0.001705\n",
      "Epoch:13 step:38 loss: 0.000079\n",
      "Epoch:13 step:39 loss: 0.001955\n",
      "Epoch:13 step:40 loss: 0.071480\n",
      "Epoch:13 step:41 loss: 0.000157\n",
      "Epoch:13 step:42 loss: 0.002813\n",
      "Epoch:13 step:43 loss: 0.036863\n",
      "Epoch:13 step:44 loss: 0.002327\n",
      "Epoch:13 step:45 loss: 0.003616\n",
      "Epoch:13 step:46 loss: 0.005794\n",
      "Epoch:13 step:47 loss: 0.017085\n",
      "Epoch:13 step:48 loss: 0.003962\n",
      "Epoch:13 step:49 loss: 0.000178\n",
      "Epoch:13 step:50 loss: 0.005483\n",
      "Epoch:13 step:51 loss: 0.002691\n",
      "Epoch:13 step:52 loss: 0.000131\n",
      "Epoch:13 step:53 loss: 0.000673\n",
      "Epoch:13 step:54 loss: 0.049751\n",
      "Epoch:13 step:55 loss: 0.039559\n",
      "Epoch:13 step:56 loss: 0.036063\n",
      "Epoch:13 step:57 loss: 0.000094\n",
      "Epoch:13 step:58 loss: 0.027992\n",
      "Epoch:13 step:59 loss: 0.000279\n",
      "Epoch:13 step:60 loss: 0.076798\n",
      "Epoch:13 step:61 loss: 0.030661\n",
      "Epoch:13 step:62 loss: 0.000036\n",
      "Epoch:13 step:63 loss: 0.002370\n",
      "Epoch:13 step:64 loss: 0.002229\n",
      "Epoch:13 step:65 loss: 0.022851\n",
      "Epoch:13 step:66 loss: 0.001519\n",
      "Epoch:13 step:67 loss: 0.013766\n",
      "Epoch:13 step:68 loss: 0.000140\n",
      "Epoch:13 step:69 loss: 0.000282\n",
      "Epoch:13 step:70 loss: 0.007849\n",
      "Epoch:13 step:71 loss: 0.025686\n",
      "Epoch:13 step:72 loss: 0.009869\n",
      "Epoch:13 step:73 loss: 0.001532\n",
      "Epoch:13 step:74 loss: 0.009994\n",
      "Epoch:13 step:75 loss: 0.007984\n",
      "Epoch:13 step:76 loss: 0.001367\n",
      "Epoch:13 step:77 loss: 0.002202\n",
      "Epoch:13 step:78 loss: 0.036991\n",
      "Epoch:13 step:79 loss: 0.009315\n",
      "Test Epoch:13 step:0 loss: 0.009485tensor(0.1140, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:1 loss: 0.009883tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:2 loss: 0.000900tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:3 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:4 loss: 0.021908tensor(0.2080, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:5 loss: 0.015914tensor(0.1630, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:6 loss: 0.000066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:7 loss: 0.024151tensor(0.1398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:8 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:9 loss: 0.000494tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:10 loss: 0.000138tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:11 loss: 0.008753tensor(0.2207, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:12 loss: 0.021496tensor(0.3235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:13 loss: 0.004584tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:14 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:15 loss: 0.001227tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:16 loss: 0.000113tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:17 loss: 0.014064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:18 loss: 0.010079tensor(0.1194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:19 loss: 0.023297tensor(0.2579, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:20 loss: 0.000165tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:13 step:21 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:22 loss: 0.053065tensor(0.1856, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:23 loss: 0.001596tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:24 loss: 0.014097tensor(0.2864, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:25 loss: 0.002561tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:26 loss: 0.020481tensor(0.2275, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:27 loss: 0.030293tensor(0.3782, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:28 loss: 0.000081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:29 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:30 loss: 0.002062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:31 loss: 0.005498tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:32 loss: 0.001040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:33 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:34 loss: 0.022856tensor(0.0197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:35 loss: 0.009846tensor(0.0823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:36 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:37 loss: 0.001437tensor(0.0803, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:38 loss: 0.000143tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:39 loss: 0.005393tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:40 loss: 0.056476tensor(0.3081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:41 loss: 0.000443tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:42 loss: 0.002520tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:43 loss: 0.024103tensor(0.2707, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:44 loss: 0.002650tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:45 loss: 0.003934tensor(0.0813, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:46 loss: 0.004204tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:47 loss: 0.017132tensor(0.2920, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:48 loss: 0.004524tensor(0.0574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:49 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:50 loss: 0.003019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:51 loss: 0.001661tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:52 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:53 loss: 0.000311tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:54 loss: 0.037718tensor(0.2755, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:55 loss: 0.053390tensor(0.2253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:56 loss: 0.037384tensor(0.1445, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:57 loss: 0.000195tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:58 loss: 0.031972tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:59 loss: 0.000892tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:60 loss: 0.036366tensor(0.3286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:61 loss: 0.025989tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:62 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:63 loss: 0.002705tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:64 loss: 0.003690tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:65 loss: 0.019060tensor(0.0890, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:66 loss: 0.001459tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:67 loss: 0.014296tensor(0.1624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:68 loss: 0.000208tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:69 loss: 0.000208tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:70 loss: 0.007990tensor(0.0308, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:71 loss: 0.029349tensor(0.1801, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:72 loss: 0.008459tensor(0.1669, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:73 loss: 0.000901tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:74 loss: 0.011830tensor(0.2229, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:75 loss: 0.003608tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:76 loss: 0.000681tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:77 loss: 0.001553tensor(0.0196, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:78 loss: 0.038327tensor(0.2118, grad_fn=<DivBackward0>)\n",
      "Test Epoch:13 step:79 loss: 0.010703tensor(0.0868, grad_fn=<DivBackward0>)\n",
      "Epoch:14 step:0 loss: 0.010896\n",
      "Epoch:14 step:1 loss: 0.008276\n",
      "Epoch:14 step:2 loss: 0.004329\n",
      "Epoch:14 step:3 loss: 0.000179\n",
      "Epoch:14 step:4 loss: 0.023331\n",
      "Epoch:14 step:5 loss: 0.009745\n",
      "Epoch:14 step:6 loss: 0.000105\n",
      "Epoch:14 step:7 loss: 0.015069\n",
      "Epoch:14 step:8 loss: 0.000028\n",
      "Epoch:14 step:9 loss: 0.000327\n",
      "Epoch:14 step:10 loss: 0.000121\n",
      "Epoch:14 step:11 loss: 0.008472\n",
      "Epoch:14 step:12 loss: 0.020272\n",
      "Epoch:14 step:13 loss: 0.004246\n",
      "Epoch:14 step:14 loss: 0.000154\n",
      "Epoch:14 step:15 loss: 0.000915\n",
      "Epoch:14 step:16 loss: 0.000027\n",
      "Epoch:14 step:17 loss: 0.010281\n",
      "Epoch:14 step:18 loss: 0.007978\n",
      "Epoch:14 step:19 loss: 0.026564\n",
      "Epoch:14 step:20 loss: 0.000121\n",
      "Epoch:14 step:21 loss: 0.000018\n",
      "Epoch:14 step:22 loss: 0.050647\n",
      "Epoch:14 step:23 loss: 0.003473\n",
      "Epoch:14 step:24 loss: 0.013617\n",
      "Epoch:14 step:25 loss: 0.002331\n",
      "Epoch:14 step:26 loss: 0.018167\n",
      "Epoch:14 step:27 loss: 0.031496\n",
      "Epoch:14 step:28 loss: 0.000089\n",
      "Epoch:14 step:29 loss: 0.000032\n",
      "Epoch:14 step:30 loss: 0.001754\n",
      "Epoch:14 step:31 loss: 0.001868\n",
      "Epoch:14 step:32 loss: 0.001204\n",
      "Epoch:14 step:33 loss: 0.000022\n",
      "Epoch:14 step:34 loss: 0.013348\n",
      "Epoch:14 step:35 loss: 0.007989\n",
      "Epoch:14 step:36 loss: 0.000016\n",
      "Epoch:14 step:37 loss: 0.001367\n",
      "Epoch:14 step:38 loss: 0.000471\n",
      "Epoch:14 step:39 loss: 0.004734\n",
      "Epoch:14 step:40 loss: 0.050724\n",
      "Epoch:14 step:41 loss: 0.000439\n",
      "Epoch:14 step:42 loss: 0.004081\n",
      "Epoch:14 step:43 loss: 0.035625\n",
      "Epoch:14 step:44 loss: 0.002341\n",
      "Epoch:14 step:45 loss: 0.003314\n",
      "Epoch:14 step:46 loss: 0.004639\n",
      "Epoch:14 step:47 loss: 0.016585\n",
      "Epoch:14 step:48 loss: 0.005572\n",
      "Epoch:14 step:49 loss: 0.000197\n",
      "Epoch:14 step:50 loss: 0.002466\n",
      "Epoch:14 step:51 loss: 0.002639\n",
      "Epoch:14 step:52 loss: 0.000127\n",
      "Epoch:14 step:53 loss: 0.004077\n",
      "Epoch:14 step:54 loss: 0.040811\n",
      "Epoch:14 step:55 loss: 0.031271\n",
      "Epoch:14 step:56 loss: 0.045072\n",
      "Epoch:14 step:57 loss: 0.000080\n",
      "Epoch:14 step:58 loss: 0.031564\n",
      "Epoch:14 step:59 loss: 0.000172\n",
      "Epoch:14 step:60 loss: 0.062343\n",
      "Epoch:14 step:61 loss: 0.035219\n",
      "Epoch:14 step:62 loss: 0.000098\n",
      "Epoch:14 step:63 loss: 0.002123\n",
      "Epoch:14 step:64 loss: 0.003823\n",
      "Epoch:14 step:65 loss: 0.022903\n",
      "Epoch:14 step:66 loss: 0.002482\n",
      "Epoch:14 step:67 loss: 0.011900\n",
      "Epoch:14 step:68 loss: 0.000342\n",
      "Epoch:14 step:69 loss: 0.000365\n",
      "Epoch:14 step:70 loss: 0.007162\n",
      "Epoch:14 step:71 loss: 0.026271\n",
      "Epoch:14 step:72 loss: 0.010742\n",
      "Epoch:14 step:73 loss: 0.002230\n",
      "Epoch:14 step:74 loss: 0.011119\n",
      "Epoch:14 step:75 loss: 0.005418\n",
      "Epoch:14 step:76 loss: 0.000682\n",
      "Epoch:14 step:77 loss: 0.001568\n",
      "Epoch:14 step:78 loss: 0.029527\n",
      "Epoch:14 step:79 loss: 0.010746\n",
      "Test Epoch:14 step:0 loss: 0.011627tensor(0.1296, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:1 loss: 0.008717tensor(0.0093, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:2 loss: 0.000809tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:3 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:4 loss: 0.016194tensor(0.2857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:5 loss: 0.015011tensor(0.1748, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:6 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:7 loss: 0.023339tensor(0.1547, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:8 loss: 0.000225tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:9 loss: 0.000397tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:10 loss: 0.000296tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:11 loss: 0.007818tensor(0.2584, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:12 loss: 0.020272tensor(0.3477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:13 loss: 0.004193tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:14 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:15 loss: 0.000664tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:16 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:17 loss: 0.017934tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:14 step:18 loss: 0.014282tensor(0.0745, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:19 loss: 0.024077tensor(0.2582, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:20 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:21 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:22 loss: 0.060110tensor(0.1732, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:23 loss: 0.001320tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:24 loss: 0.013324tensor(0.2849, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:25 loss: 0.002181tensor(0.0284, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:26 loss: 0.019641tensor(0.2371, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:27 loss: 0.026487tensor(0.3924, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:28 loss: 0.000189tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:29 loss: 0.000290tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:30 loss: 0.002996tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:31 loss: 0.005216tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:32 loss: 0.002161tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:33 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:34 loss: 0.017430tensor(0.0300, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:35 loss: 0.009131tensor(0.0697, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:36 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:37 loss: 0.001875tensor(0.0536, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:38 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:39 loss: 0.007196tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:40 loss: 0.070160tensor(0.2800, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:41 loss: 0.000151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:42 loss: 0.000955tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:43 loss: 0.030107tensor(0.2290, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:44 loss: 0.002780tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:45 loss: 0.003719tensor(0.0699, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:46 loss: 0.003805tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:47 loss: 0.015624tensor(0.3038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:48 loss: 0.003951tensor(0.0810, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:49 loss: 0.000162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:50 loss: 0.003311tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:51 loss: 0.001507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:52 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:53 loss: 0.000277tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:54 loss: 0.045832tensor(0.2705, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:55 loss: 0.035811tensor(0.2861, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:56 loss: 0.037754tensor(0.1291, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:57 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:58 loss: 0.026724tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:59 loss: 0.000563tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:60 loss: 0.084004tensor(0.1452, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:61 loss: 0.021913tensor(0.0172, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:62 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:63 loss: 0.003308tensor(9.7658e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:64 loss: 0.005226tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:65 loss: 0.014892tensor(0.1381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:66 loss: 0.003376tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:67 loss: 0.012394tensor(0.1825, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:68 loss: 0.000203tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:69 loss: 0.000493tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:70 loss: 0.012480tensor(0.0264, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:71 loss: 0.030729tensor(0.1477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:72 loss: 0.008281tensor(0.1901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:73 loss: 0.000959tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:74 loss: 0.010658tensor(0.2319, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:75 loss: 0.006520tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:76 loss: 0.000526tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:77 loss: 0.001482tensor(0.0317, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:78 loss: 0.039534tensor(0.1954, grad_fn=<DivBackward0>)\n",
      "Test Epoch:14 step:79 loss: 0.011084tensor(0.0860, grad_fn=<DivBackward0>)\n",
      "Epoch:15 step:0 loss: 0.009753\n",
      "Epoch:15 step:1 loss: 0.008158\n",
      "Epoch:15 step:2 loss: 0.001171\n",
      "Epoch:15 step:3 loss: 0.000053\n",
      "Epoch:15 step:4 loss: 0.020115\n",
      "Epoch:15 step:5 loss: 0.014243\n",
      "Epoch:15 step:6 loss: 0.000158\n",
      "Epoch:15 step:7 loss: 0.014377\n",
      "Epoch:15 step:8 loss: 0.000217\n",
      "Epoch:15 step:9 loss: 0.000986\n",
      "Epoch:15 step:10 loss: 0.002294\n",
      "Epoch:15 step:11 loss: 0.009009\n",
      "Epoch:15 step:12 loss: 0.021448\n",
      "Epoch:15 step:13 loss: 0.006895\n",
      "Epoch:15 step:14 loss: 0.000976\n",
      "Epoch:15 step:15 loss: 0.000499\n",
      "Epoch:15 step:16 loss: 0.000198\n",
      "Epoch:15 step:17 loss: 0.003638\n",
      "Epoch:15 step:18 loss: 0.009070\n",
      "Epoch:15 step:19 loss: 0.028832\n",
      "Epoch:15 step:20 loss: 0.000234\n",
      "Epoch:15 step:21 loss: 0.000162\n",
      "Epoch:15 step:22 loss: 0.047233\n",
      "Epoch:15 step:23 loss: 0.007376\n",
      "Epoch:15 step:24 loss: 0.011544\n",
      "Epoch:15 step:25 loss: 0.002637\n",
      "Epoch:15 step:26 loss: 0.021431\n",
      "Epoch:15 step:27 loss: 0.028637\n",
      "Epoch:15 step:28 loss: 0.000094\n",
      "Epoch:15 step:29 loss: 0.000056\n",
      "Epoch:15 step:30 loss: 0.002173\n",
      "Epoch:15 step:31 loss: 0.003974\n",
      "Epoch:15 step:32 loss: 0.001993\n",
      "Epoch:15 step:33 loss: 0.000011\n",
      "Epoch:15 step:34 loss: 0.015467\n",
      "Epoch:15 step:35 loss: 0.007974\n",
      "Epoch:15 step:36 loss: 0.000007\n",
      "Epoch:15 step:37 loss: 0.001041\n",
      "Epoch:15 step:38 loss: 0.000205\n",
      "Epoch:15 step:39 loss: 0.002552\n",
      "Epoch:15 step:40 loss: 0.065198\n",
      "Epoch:15 step:41 loss: 0.000059\n",
      "Epoch:15 step:42 loss: 0.002396\n",
      "Epoch:15 step:43 loss: 0.032441\n",
      "Epoch:15 step:44 loss: 0.001423\n",
      "Epoch:15 step:45 loss: 0.002559\n",
      "Epoch:15 step:46 loss: 0.005296\n",
      "Epoch:15 step:47 loss: 0.015784\n",
      "Epoch:15 step:48 loss: 0.006960\n",
      "Epoch:15 step:49 loss: 0.000107\n",
      "Epoch:15 step:50 loss: 0.004098\n",
      "Epoch:15 step:51 loss: 0.000354\n",
      "Epoch:15 step:52 loss: 0.000087\n",
      "Epoch:15 step:53 loss: 0.000146\n",
      "Epoch:15 step:54 loss: 0.059270\n",
      "Epoch:15 step:55 loss: 0.037373\n",
      "Epoch:15 step:56 loss: 0.033336\n",
      "Epoch:15 step:57 loss: 0.000027\n",
      "Epoch:15 step:58 loss: 0.029794\n",
      "Epoch:15 step:59 loss: 0.000089\n",
      "Epoch:15 step:60 loss: 0.089792\n",
      "Epoch:15 step:61 loss: 0.032956\n",
      "Epoch:15 step:62 loss: 0.000115\n",
      "Epoch:15 step:63 loss: 0.002297\n",
      "Epoch:15 step:64 loss: 0.002641\n",
      "Epoch:15 step:65 loss: 0.020493\n",
      "Epoch:15 step:66 loss: 0.003008\n",
      "Epoch:15 step:67 loss: 0.013675\n",
      "Epoch:15 step:68 loss: 0.001972\n",
      "Epoch:15 step:69 loss: 0.002019\n",
      "Epoch:15 step:70 loss: 0.007566\n",
      "Epoch:15 step:71 loss: 0.025274\n",
      "Epoch:15 step:72 loss: 0.090436\n",
      "Epoch:15 step:73 loss: 0.001930\n",
      "Epoch:15 step:74 loss: 0.017474\n",
      "Epoch:15 step:75 loss: 0.008832\n",
      "Epoch:15 step:76 loss: 0.004020\n",
      "Epoch:15 step:77 loss: 0.083898\n",
      "Epoch:15 step:78 loss: 0.033169\n",
      "Epoch:15 step:79 loss: 0.006980\n",
      "Test Epoch:15 step:0 loss: 0.010088tensor(0.0778, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:1 loss: 0.007925tensor(0.0118, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:2 loss: 0.001054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:3 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:4 loss: 0.038780tensor(0.0833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:5 loss: 0.020747tensor(0.0745, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:6 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:7 loss: 0.032755tensor(0.0624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:8 loss: 0.000543tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:9 loss: 0.000260tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:10 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:11 loss: 0.012869tensor(0.1167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:12 loss: 0.028987tensor(0.1858, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:13 loss: 0.003431tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:14 loss: 0.000432tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:15 step:15 loss: 0.001580tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:16 loss: 0.001652tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:17 loss: 0.007693tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:18 loss: 0.010189tensor(0.0716, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:19 loss: 0.036108tensor(0.1197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:20 loss: 0.002164tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:21 loss: 0.000771tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:22 loss: 0.078810tensor(0.1004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:23 loss: 0.002852tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:24 loss: 0.018586tensor(0.1707, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:25 loss: 0.002361tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:26 loss: 0.023141tensor(0.1493, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:27 loss: 0.062377tensor(0.2092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:28 loss: 0.000292tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:29 loss: 0.000256tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:30 loss: 0.002774tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:31 loss: 0.004782tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:32 loss: 0.002043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:33 loss: 0.001418tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:34 loss: 0.022188tensor(0.0247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:35 loss: 0.005818tensor(0.1559, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:36 loss: 0.000930tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:37 loss: 0.001578tensor(0.0531, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:38 loss: 0.000169tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:39 loss: 0.004997tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:40 loss: 0.067917tensor(0.2038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:41 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:42 loss: 0.001685tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:43 loss: 0.033505tensor(0.1834, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:44 loss: 0.002711tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:45 loss: 0.004375tensor(0.0919, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:46 loss: 0.002818tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:47 loss: 0.024152tensor(0.1837, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:48 loss: 0.004335tensor(0.0678, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:49 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:50 loss: 0.002599tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:51 loss: 0.001580tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:52 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:53 loss: 0.000270tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:54 loss: 0.037243tensor(0.1912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:55 loss: 0.044056tensor(0.1892, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:56 loss: 0.039268tensor(0.1313, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:57 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:58 loss: 0.030081tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:59 loss: 0.000446tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:60 loss: 0.048408tensor(0.2343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:61 loss: 0.027836tensor(0.0064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:62 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:63 loss: 0.003016tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:64 loss: 0.006715tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:65 loss: 0.013783tensor(0.1630, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:66 loss: 0.003864tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:67 loss: 0.010743tensor(0.2068, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:68 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:69 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:70 loss: 0.004554tensor(0.0814, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:71 loss: 0.023795tensor(0.1554, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:72 loss: 0.008292tensor(0.1791, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:73 loss: 0.000916tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:74 loss: 0.009983tensor(0.2373, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:75 loss: 0.001502tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:76 loss: 0.000266tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:77 loss: 0.002349tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:78 loss: 0.040149tensor(0.1880, grad_fn=<DivBackward0>)\n",
      "Test Epoch:15 step:79 loss: 0.012235tensor(0.0642, grad_fn=<DivBackward0>)\n",
      "Epoch:16 step:0 loss: 0.009559\n",
      "Epoch:16 step:1 loss: 0.007350\n",
      "Epoch:16 step:2 loss: 0.001514\n",
      "Epoch:16 step:3 loss: 0.000089\n",
      "Epoch:16 step:4 loss: 0.020944\n",
      "Epoch:16 step:5 loss: 0.010793\n",
      "Epoch:16 step:6 loss: 0.000204\n",
      "Epoch:16 step:7 loss: 0.012658\n",
      "Epoch:16 step:8 loss: 0.000057\n",
      "Epoch:16 step:9 loss: 0.000874\n",
      "Epoch:16 step:10 loss: 0.000072\n",
      "Epoch:16 step:11 loss: 0.009982\n",
      "Epoch:16 step:12 loss: 0.022150\n",
      "Epoch:16 step:13 loss: 0.002412\n",
      "Epoch:16 step:14 loss: 0.000046\n",
      "Epoch:16 step:15 loss: 0.000628\n",
      "Epoch:16 step:16 loss: 0.000044\n",
      "Epoch:16 step:17 loss: 0.006379\n",
      "Epoch:16 step:18 loss: 0.008855\n",
      "Epoch:16 step:19 loss: 0.029958\n",
      "Epoch:16 step:20 loss: 0.000734\n",
      "Epoch:16 step:21 loss: 0.000032\n",
      "Epoch:16 step:22 loss: 0.050300\n",
      "Epoch:16 step:23 loss: 0.001794\n",
      "Epoch:16 step:24 loss: 0.014531\n",
      "Epoch:16 step:25 loss: 0.002272\n",
      "Epoch:16 step:26 loss: 0.020350\n",
      "Epoch:16 step:27 loss: 0.043833\n",
      "Epoch:16 step:28 loss: 0.000057\n",
      "Epoch:16 step:29 loss: 0.000021\n",
      "Epoch:16 step:30 loss: 0.002648\n",
      "Epoch:16 step:31 loss: 0.003484\n",
      "Epoch:16 step:32 loss: 0.000509\n",
      "Epoch:16 step:33 loss: 0.000007\n",
      "Epoch:16 step:34 loss: 0.024067\n",
      "Epoch:16 step:35 loss: 0.008485\n",
      "Epoch:16 step:36 loss: 0.000008\n",
      "Epoch:16 step:37 loss: 0.001698\n",
      "Epoch:16 step:38 loss: 0.000088\n",
      "Epoch:16 step:39 loss: 0.004117\n",
      "Epoch:16 step:40 loss: 0.057886\n",
      "Epoch:16 step:41 loss: 0.000349\n",
      "Epoch:16 step:42 loss: 0.002475\n",
      "Epoch:16 step:43 loss: 0.025942\n",
      "Epoch:16 step:44 loss: 0.002681\n",
      "Epoch:16 step:45 loss: 0.003986\n",
      "Epoch:16 step:46 loss: 0.002984\n",
      "Epoch:16 step:47 loss: 0.018369\n",
      "Epoch:16 step:48 loss: 0.003899\n",
      "Epoch:16 step:49 loss: 0.000044\n",
      "Epoch:16 step:50 loss: 0.001994\n",
      "Epoch:16 step:51 loss: 0.000728\n",
      "Epoch:16 step:52 loss: 0.000027\n",
      "Epoch:16 step:53 loss: 0.000127\n",
      "Epoch:16 step:54 loss: 0.033251\n",
      "Epoch:16 step:55 loss: 0.038167\n",
      "Epoch:16 step:56 loss: 0.031344\n",
      "Epoch:16 step:57 loss: 0.000157\n",
      "Epoch:16 step:58 loss: 0.033234\n",
      "Epoch:16 step:59 loss: 0.001174\n",
      "Epoch:16 step:60 loss: 0.038348\n",
      "Epoch:16 step:61 loss: 0.022737\n",
      "Epoch:16 step:62 loss: 0.000034\n",
      "Epoch:16 step:63 loss: 0.003224\n",
      "Epoch:16 step:64 loss: 0.007132\n",
      "Epoch:16 step:65 loss: 0.012362\n",
      "Epoch:16 step:66 loss: 0.001896\n",
      "Epoch:16 step:67 loss: 0.010241\n",
      "Epoch:16 step:68 loss: 0.000029\n",
      "Epoch:16 step:69 loss: 0.000050\n",
      "Epoch:16 step:70 loss: 0.004864\n",
      "Epoch:16 step:71 loss: 0.017220\n",
      "Epoch:16 step:72 loss: 0.007263\n",
      "Epoch:16 step:73 loss: 0.000424\n",
      "Epoch:16 step:74 loss: 0.008596\n",
      "Epoch:16 step:75 loss: 0.001012\n",
      "Epoch:16 step:76 loss: 0.000154\n",
      "Epoch:16 step:77 loss: 0.001700\n",
      "Epoch:16 step:78 loss: 0.039277\n",
      "Epoch:16 step:79 loss: 0.008897\n",
      "Test Epoch:16 step:0 loss: 0.008459tensor(0.1290, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:1 loss: 0.008098tensor(0.0059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:2 loss: 0.004447tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:3 loss: 0.000147tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:4 loss: 0.019929tensor(0.2267, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:5 loss: 0.008800tensor(0.2421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:6 loss: 0.000163tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:7 loss: 0.012820tensor(0.1981, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:8 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:9 loss: 0.000346tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:10 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:11 loss: 0.008652tensor(0.2223, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:16 step:12 loss: 0.019246tensor(0.2981, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:13 loss: 0.001939tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:14 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:15 loss: 0.000664tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:16 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:17 loss: 0.007348tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:18 loss: 0.008556tensor(0.1360, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:19 loss: 0.025092tensor(0.2375, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:20 loss: 0.000863tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:21 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:22 loss: 0.044396tensor(0.2081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:23 loss: 0.002423tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:24 loss: 0.012983tensor(0.2799, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:25 loss: 0.002030tensor(0.0229, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:26 loss: 0.019317tensor(0.2175, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:27 loss: 0.036907tensor(0.3127, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:28 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:29 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:30 loss: 0.001911tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:31 loss: 0.002093tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:32 loss: 0.000501tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:33 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:34 loss: 0.017703tensor(0.0233, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:35 loss: 0.005808tensor(0.1822, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:36 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:37 loss: 0.001825tensor(0.1201, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:38 loss: 0.000599tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:39 loss: 0.004333tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:40 loss: 0.052120tensor(0.2829, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:41 loss: 0.000215tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:42 loss: 0.002165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:43 loss: 0.022926tensor(0.2762, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:44 loss: 0.001033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:45 loss: 0.003034tensor(0.1372, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:46 loss: 0.002429tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:47 loss: 0.016145tensor(0.2816, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:48 loss: 0.003468tensor(0.1294, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:49 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:50 loss: 0.001426tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:51 loss: 0.000852tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:52 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:53 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:54 loss: 0.031737tensor(0.2606, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:55 loss: 0.029807tensor(0.2735, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:56 loss: 0.038347tensor(0.1521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:57 loss: 0.000227tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:58 loss: 0.026094tensor(0.0090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:59 loss: 0.001215tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:60 loss: 0.047607tensor(0.2899, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:61 loss: 0.017057tensor(0.0595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:62 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:63 loss: 0.007732tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:64 loss: 0.018231tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:65 loss: 0.008148tensor(0.2794, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:66 loss: 0.002703tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:67 loss: 0.010313tensor(0.2336, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:68 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:69 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:70 loss: 0.010519tensor(0.0375, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:71 loss: 0.047854tensor(0.1158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:72 loss: 0.012896tensor(0.0771, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:73 loss: 0.000944tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:74 loss: 0.024538tensor(0.0843, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:75 loss: 0.002383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:76 loss: 0.000284tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:77 loss: 0.002082tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:78 loss: 0.044619tensor(0.1708, grad_fn=<DivBackward0>)\n",
      "Test Epoch:16 step:79 loss: 0.041581tensor(0.0455, grad_fn=<DivBackward0>)\n",
      "Epoch:17 step:0 loss: 0.011907\n",
      "Epoch:17 step:1 loss: 0.010338\n",
      "Epoch:17 step:2 loss: 0.000566\n",
      "Epoch:17 step:3 loss: 0.000125\n",
      "Epoch:17 step:4 loss: 0.025557\n",
      "Epoch:17 step:5 loss: 0.026113\n",
      "Epoch:17 step:6 loss: 0.000087\n",
      "Epoch:17 step:7 loss: 0.029627\n",
      "Epoch:17 step:8 loss: 0.000099\n",
      "Epoch:17 step:9 loss: 0.000751\n",
      "Epoch:17 step:10 loss: 0.002969\n",
      "Epoch:17 step:11 loss: 0.015019\n",
      "Epoch:17 step:12 loss: 0.029253\n",
      "Epoch:17 step:13 loss: 0.006508\n",
      "Epoch:17 step:14 loss: 0.001144\n",
      "Epoch:17 step:15 loss: 0.004521\n",
      "Epoch:17 step:16 loss: 0.000097\n",
      "Epoch:17 step:17 loss: 0.011673\n",
      "Epoch:17 step:18 loss: 0.011749\n",
      "Epoch:17 step:19 loss: 0.035058\n",
      "Epoch:17 step:20 loss: 0.001045\n",
      "Epoch:17 step:21 loss: 0.000051\n",
      "Epoch:17 step:22 loss: 0.058967\n",
      "Epoch:17 step:23 loss: 0.002406\n",
      "Epoch:17 step:24 loss: 0.019956\n",
      "Epoch:17 step:25 loss: 0.004241\n",
      "Epoch:17 step:26 loss: 0.024225\n",
      "Epoch:17 step:27 loss: 0.046049\n",
      "Epoch:17 step:28 loss: 0.000261\n",
      "Epoch:17 step:29 loss: 0.000091\n",
      "Epoch:17 step:30 loss: 0.001166\n",
      "Epoch:17 step:31 loss: 0.000474\n",
      "Epoch:17 step:32 loss: 0.000384\n",
      "Epoch:17 step:33 loss: 0.000064\n",
      "Epoch:17 step:34 loss: 0.023177\n",
      "Epoch:17 step:35 loss: 0.010159\n",
      "Epoch:17 step:36 loss: 0.000023\n",
      "Epoch:17 step:37 loss: 0.001758\n",
      "Epoch:17 step:38 loss: 0.000078\n",
      "Epoch:17 step:39 loss: 0.007551\n",
      "Epoch:17 step:40 loss: 0.046414\n",
      "Epoch:17 step:41 loss: 0.000071\n",
      "Epoch:17 step:42 loss: 0.001533\n",
      "Epoch:17 step:43 loss: 0.030579\n",
      "Epoch:17 step:44 loss: 0.004993\n",
      "Epoch:17 step:45 loss: 0.005627\n",
      "Epoch:17 step:46 loss: 0.007294\n",
      "Epoch:17 step:47 loss: 0.018438\n",
      "Epoch:17 step:48 loss: 0.003956\n",
      "Epoch:17 step:49 loss: 0.000116\n",
      "Epoch:17 step:50 loss: 0.003538\n",
      "Epoch:17 step:51 loss: 0.000957\n",
      "Epoch:17 step:52 loss: 0.000050\n",
      "Epoch:17 step:53 loss: 0.000244\n",
      "Epoch:17 step:54 loss: 0.034552\n",
      "Epoch:17 step:55 loss: 0.036328\n",
      "Epoch:17 step:56 loss: 0.035789\n",
      "Epoch:17 step:57 loss: 0.000100\n",
      "Epoch:17 step:58 loss: 0.030997\n",
      "Epoch:17 step:59 loss: 0.000349\n",
      "Epoch:17 step:60 loss: 0.036211\n",
      "Epoch:17 step:61 loss: 0.028092\n",
      "Epoch:17 step:62 loss: 0.000064\n",
      "Epoch:17 step:63 loss: 0.002325\n",
      "Epoch:17 step:64 loss: 0.008128\n",
      "Epoch:17 step:65 loss: 0.010568\n",
      "Epoch:17 step:66 loss: 0.002672\n",
      "Epoch:17 step:67 loss: 0.008737\n",
      "Epoch:17 step:68 loss: 0.000175\n",
      "Epoch:17 step:69 loss: 0.000345\n",
      "Epoch:17 step:70 loss: 0.010594\n",
      "Epoch:17 step:71 loss: 0.016195\n",
      "Epoch:17 step:72 loss: 0.006848\n",
      "Epoch:17 step:73 loss: 0.000445\n",
      "Epoch:17 step:74 loss: 0.008363\n",
      "Epoch:17 step:75 loss: 0.002260\n",
      "Epoch:17 step:76 loss: 0.000287\n",
      "Epoch:17 step:77 loss: 0.001454\n",
      "Epoch:17 step:78 loss: 0.039675\n",
      "Epoch:17 step:79 loss: 0.015374\n",
      "Test Epoch:17 step:0 loss: 0.010621tensor(0.0749, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:1 loss: 0.008445tensor(0.0050, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:2 loss: 0.001546tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:3 loss: 0.000313tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:4 loss: 0.017501tensor(0.2516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:5 loss: 0.010725tensor(0.2284, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:6 loss: 0.000331tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:7 loss: 0.012831tensor(0.2096, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:8 loss: 0.000483tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:17 step:9 loss: 0.002758tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:10 loss: 0.000857tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:11 loss: 0.011711tensor(0.1950, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:12 loss: 0.019730tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:13 loss: 0.002835tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:14 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:15 loss: 0.000374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:16 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:17 loss: 0.002600tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:18 loss: 0.010996tensor(0.0839, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:19 loss: 0.033752tensor(0.2063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:20 loss: 0.000103tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:21 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:22 loss: 0.053707tensor(0.1912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:23 loss: 0.002747tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:24 loss: 0.015816tensor(0.2499, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:25 loss: 0.002569tensor(0.0057, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:26 loss: 0.043833tensor(0.1572, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:27 loss: 0.033548tensor(0.3328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:28 loss: 0.000110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:29 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:30 loss: 0.001803tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:31 loss: 0.000520tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:32 loss: 0.000161tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:33 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:34 loss: 0.023803tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:35 loss: 0.012109tensor(0.0277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:36 loss: 0.001255tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:37 loss: 0.001813tensor(0.0263, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:38 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:39 loss: 0.001823tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:40 loss: 0.097285tensor(0.2018, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:41 loss: 0.000099tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:42 loss: 0.000864tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:43 loss: 0.040669tensor(0.1740, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:44 loss: 0.002564tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:45 loss: 0.007254tensor(0.0270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:46 loss: 0.004234tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:47 loss: 0.022861tensor(0.2282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:48 loss: 0.003930tensor(0.0915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:49 loss: 0.000174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:50 loss: 0.003578tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:51 loss: 0.000939tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:52 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:53 loss: 0.000274tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:54 loss: 0.036490tensor(0.2350, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:55 loss: 0.031082tensor(0.2700, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:56 loss: 0.036330tensor(0.1481, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:57 loss: 0.000127tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:58 loss: 0.047467tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:59 loss: 0.001009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:60 loss: 0.038172tensor(0.3136, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:61 loss: 0.020853tensor(0.0178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:62 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:63 loss: 0.002936tensor(3.7718e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:64 loss: 0.005518tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:65 loss: 0.012415tensor(0.1998, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:66 loss: 0.001822tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:67 loss: 0.009918tensor(0.2442, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:68 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:69 loss: 0.000082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:70 loss: 0.007378tensor(0.0212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:71 loss: 0.019264tensor(0.2123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:72 loss: 0.007348tensor(0.2381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:73 loss: 0.000789tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:74 loss: 0.007635tensor(0.3013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:75 loss: 0.002716tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:76 loss: 0.000151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:77 loss: 0.001279tensor(0.0612, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:78 loss: 0.047846tensor(0.1790, grad_fn=<DivBackward0>)\n",
      "Test Epoch:17 step:79 loss: 0.008943tensor(0.1420, grad_fn=<DivBackward0>)\n",
      "Epoch:18 step:0 loss: 0.008934\n",
      "Epoch:18 step:1 loss: 0.007998\n",
      "Epoch:18 step:2 loss: 0.001973\n",
      "Epoch:18 step:3 loss: 0.000251\n",
      "Epoch:18 step:4 loss: 0.018729\n",
      "Epoch:18 step:5 loss: 0.012608\n",
      "Epoch:18 step:6 loss: 0.000198\n",
      "Epoch:18 step:7 loss: 0.014500\n",
      "Epoch:18 step:8 loss: 0.000098\n",
      "Epoch:18 step:9 loss: 0.001413\n",
      "Epoch:18 step:10 loss: 0.000247\n",
      "Epoch:18 step:11 loss: 0.008109\n",
      "Epoch:18 step:12 loss: 0.019992\n",
      "Epoch:18 step:13 loss: 0.005868\n",
      "Epoch:18 step:14 loss: 0.000097\n",
      "Epoch:18 step:15 loss: 0.000916\n",
      "Epoch:18 step:16 loss: 0.000075\n",
      "Epoch:18 step:17 loss: 0.009630\n",
      "Epoch:18 step:18 loss: 0.008193\n",
      "Epoch:18 step:19 loss: 0.025293\n",
      "Epoch:18 step:20 loss: 0.000072\n",
      "Epoch:18 step:21 loss: 0.000032\n",
      "Epoch:18 step:22 loss: 0.046296\n",
      "Epoch:18 step:23 loss: 0.001553\n",
      "Epoch:18 step:24 loss: 0.014964\n",
      "Epoch:18 step:25 loss: 0.002080\n",
      "Epoch:18 step:26 loss: 0.017359\n",
      "Epoch:18 step:27 loss: 0.036188\n",
      "Epoch:18 step:28 loss: 0.000128\n",
      "Epoch:18 step:29 loss: 0.000042\n",
      "Epoch:18 step:30 loss: 0.002963\n",
      "Epoch:18 step:31 loss: 0.004141\n",
      "Epoch:18 step:32 loss: 0.000788\n",
      "Epoch:18 step:33 loss: 0.000092\n",
      "Epoch:18 step:34 loss: 0.013212\n",
      "Epoch:18 step:35 loss: 0.008021\n",
      "Epoch:18 step:36 loss: 0.000649\n",
      "Epoch:18 step:37 loss: 0.001519\n",
      "Epoch:18 step:38 loss: 0.000267\n",
      "Epoch:18 step:39 loss: 0.004051\n",
      "Epoch:18 step:40 loss: 0.051603\n",
      "Epoch:18 step:41 loss: 0.000028\n",
      "Epoch:18 step:42 loss: 0.002376\n",
      "Epoch:18 step:43 loss: 0.021508\n",
      "Epoch:18 step:44 loss: 0.000680\n",
      "Epoch:18 step:45 loss: 0.003000\n",
      "Epoch:18 step:46 loss: 0.001547\n",
      "Epoch:18 step:47 loss: 0.015536\n",
      "Epoch:18 step:48 loss: 0.003595\n",
      "Epoch:18 step:49 loss: 0.000032\n",
      "Epoch:18 step:50 loss: 0.001974\n",
      "Epoch:18 step:51 loss: 0.000536\n",
      "Epoch:18 step:52 loss: 0.000020\n",
      "Epoch:18 step:53 loss: 0.000058\n",
      "Epoch:18 step:54 loss: 0.034520\n",
      "Epoch:18 step:55 loss: 0.029939\n",
      "Epoch:18 step:56 loss: 0.027207\n",
      "Epoch:18 step:57 loss: 0.000114\n",
      "Epoch:18 step:58 loss: 0.030742\n",
      "Epoch:18 step:59 loss: 0.000875\n",
      "Epoch:18 step:60 loss: 0.038390\n",
      "Epoch:18 step:61 loss: 0.020120\n",
      "Epoch:18 step:62 loss: 0.000018\n",
      "Epoch:18 step:63 loss: 0.003295\n",
      "Epoch:18 step:64 loss: 0.008832\n",
      "Epoch:18 step:65 loss: 0.007170\n",
      "Epoch:18 step:66 loss: 0.003618\n",
      "Epoch:18 step:67 loss: 0.007357\n",
      "Epoch:18 step:68 loss: 0.000024\n",
      "Epoch:18 step:69 loss: 0.000029\n",
      "Epoch:18 step:70 loss: 0.003469\n",
      "Epoch:18 step:71 loss: 0.016563\n",
      "Epoch:18 step:72 loss: 0.005590\n",
      "Epoch:18 step:73 loss: 0.000454\n",
      "Epoch:18 step:74 loss: 0.011041\n",
      "Epoch:18 step:75 loss: 0.001210\n",
      "Epoch:18 step:76 loss: 0.000156\n",
      "Epoch:18 step:77 loss: 0.001124\n",
      "Epoch:18 step:78 loss: 0.031963\n",
      "Epoch:18 step:79 loss: 0.009568\n",
      "Test Epoch:18 step:0 loss: 0.007255tensor(0.1795, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:1 loss: 0.007468tensor(0.0145, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:2 loss: 0.002435tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:3 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:4 loss: 0.017184tensor(0.2705, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:5 loss: 0.011741tensor(0.2144, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:18 step:6 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:7 loss: 0.015278tensor(0.1883, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:8 loss: 0.000959tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:9 loss: 0.000211tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:10 loss: 0.000097tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:11 loss: 0.007479tensor(0.2563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:12 loss: 0.017368tensor(0.3324, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:13 loss: 0.001397tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:14 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:15 loss: 0.000813tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:16 loss: 0.001380tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:17 loss: 0.009620tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:18 loss: 0.009212tensor(0.1496, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:19 loss: 0.021456tensor(0.2812, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:20 loss: 0.000572tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:21 loss: 0.000997tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:22 loss: 0.037589tensor(0.2509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:23 loss: 0.001026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:24 loss: 0.015422tensor(0.2632, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:25 loss: 0.003872tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:26 loss: 0.026997tensor(0.1763, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:27 loss: 0.031014tensor(0.3541, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:28 loss: 0.000107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:29 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:30 loss: 0.002780tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:31 loss: 0.006354tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:32 loss: 0.001151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:33 loss: 0.002974tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:34 loss: 0.015158tensor(0.0706, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:35 loss: 0.005158tensor(0.1973, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:36 loss: 0.000853tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:37 loss: 0.001096tensor(0.1456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:38 loss: 0.000231tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:39 loss: 0.002318tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:40 loss: 0.047012tensor(0.3163, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:41 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:42 loss: 0.000565tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:43 loss: 0.029481tensor(0.2680, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:44 loss: 0.000618tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:45 loss: 0.002126tensor(0.2165, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:46 loss: 0.000920tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:47 loss: 0.017382tensor(0.2903, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:48 loss: 0.003606tensor(0.1444, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:49 loss: 0.000101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:50 loss: 0.002356tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:51 loss: 0.000760tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:52 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:53 loss: 0.000145tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:54 loss: 0.045132tensor(0.2543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:55 loss: 0.034840tensor(0.2834, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:56 loss: 0.025376tensor(0.2509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:57 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:58 loss: 0.024363tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:59 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:60 loss: 0.067353tensor(0.2494, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:61 loss: 0.031910tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:63 loss: 0.002250tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:64 loss: 0.004380tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:65 loss: 0.013735tensor(0.1690, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:66 loss: 0.004456tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:67 loss: 0.009615tensor(0.2725, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:68 loss: 0.000126tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:69 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:70 loss: 0.008299tensor(0.0676, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:71 loss: 0.030095tensor(0.1844, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:72 loss: 0.007970tensor(0.2464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:73 loss: 0.001113tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:74 loss: 0.007670tensor(0.3171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:75 loss: 0.000813tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:76 loss: 0.000107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:77 loss: 0.001539tensor(0.0548, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:78 loss: 0.042704tensor(0.2278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:18 step:79 loss: 0.011737tensor(0.1031, grad_fn=<DivBackward0>)\n",
      "Epoch:19 step:0 loss: 0.009079\n",
      "Epoch:19 step:1 loss: 0.006367\n",
      "Epoch:19 step:2 loss: 0.000506\n",
      "Epoch:19 step:3 loss: 0.000059\n",
      "Epoch:19 step:4 loss: 0.016655\n",
      "Epoch:19 step:5 loss: 0.010996\n",
      "Epoch:19 step:6 loss: 0.000064\n",
      "Epoch:19 step:7 loss: 0.012878\n",
      "Epoch:19 step:8 loss: 0.002015\n",
      "Epoch:19 step:9 loss: 0.001039\n",
      "Epoch:19 step:10 loss: 0.000272\n",
      "Epoch:19 step:11 loss: 0.009275\n",
      "Epoch:19 step:12 loss: 0.014259\n",
      "Epoch:19 step:13 loss: 0.002605\n",
      "Epoch:19 step:14 loss: 0.000266\n",
      "Epoch:19 step:15 loss: 0.001619\n",
      "Epoch:19 step:16 loss: 0.003246\n",
      "Epoch:19 step:17 loss: 0.006682\n",
      "Epoch:19 step:18 loss: 0.008846\n",
      "Epoch:19 step:19 loss: 0.026017\n",
      "Epoch:19 step:20 loss: 0.000349\n",
      "Epoch:19 step:21 loss: 0.000305\n",
      "Epoch:19 step:22 loss: 0.034913\n",
      "Epoch:19 step:23 loss: 0.002501\n",
      "Epoch:19 step:24 loss: 0.010456\n",
      "Epoch:19 step:25 loss: 0.002874\n",
      "Epoch:19 step:26 loss: 0.014792\n",
      "Epoch:19 step:27 loss: 0.033030\n",
      "Epoch:19 step:28 loss: 0.000026\n",
      "Epoch:19 step:29 loss: 0.000018\n",
      "Epoch:19 step:30 loss: 0.000701\n",
      "Epoch:19 step:31 loss: 0.001101\n",
      "Epoch:19 step:32 loss: 0.000189\n",
      "Epoch:19 step:33 loss: 0.000279\n",
      "Epoch:19 step:34 loss: 0.019965\n",
      "Epoch:19 step:35 loss: 0.006600\n",
      "Epoch:19 step:36 loss: 0.000881\n",
      "Epoch:19 step:37 loss: 0.002112\n",
      "Epoch:19 step:38 loss: 0.000061\n",
      "Epoch:19 step:39 loss: 0.001247\n",
      "Epoch:19 step:40 loss: 0.045730\n",
      "Epoch:19 step:41 loss: 0.000283\n",
      "Epoch:19 step:42 loss: 0.000430\n",
      "Epoch:19 step:43 loss: 0.019181\n",
      "Epoch:19 step:44 loss: 0.003610\n",
      "Epoch:19 step:45 loss: 0.004414\n",
      "Epoch:19 step:46 loss: 0.004300\n",
      "Epoch:19 step:47 loss: 0.020922\n",
      "Epoch:19 step:48 loss: 0.003274\n",
      "Epoch:19 step:49 loss: 0.000139\n",
      "Epoch:19 step:50 loss: 0.000801\n",
      "Epoch:19 step:51 loss: 0.000385\n",
      "Epoch:19 step:52 loss: 0.000069\n",
      "Epoch:19 step:53 loss: 0.000179\n",
      "Epoch:19 step:54 loss: 0.041526\n",
      "Epoch:19 step:55 loss: 0.031766\n",
      "Epoch:19 step:56 loss: 0.040011\n",
      "Epoch:19 step:57 loss: 0.000034\n",
      "Epoch:19 step:58 loss: 0.030885\n",
      "Epoch:19 step:59 loss: 0.000085\n",
      "Epoch:19 step:60 loss: 0.051273\n",
      "Epoch:19 step:61 loss: 0.024607\n",
      "Epoch:19 step:62 loss: 0.000020\n",
      "Epoch:19 step:63 loss: 0.002856\n",
      "Epoch:19 step:64 loss: 0.006733\n",
      "Epoch:19 step:65 loss: 0.011168\n",
      "Epoch:19 step:66 loss: 0.002421\n",
      "Epoch:19 step:67 loss: 0.008734\n",
      "Epoch:19 step:68 loss: 0.000069\n",
      "Epoch:19 step:69 loss: 0.000060\n",
      "Epoch:19 step:70 loss: 0.018913\n",
      "Epoch:19 step:71 loss: 0.031268\n",
      "Epoch:19 step:72 loss: 0.006527\n",
      "Epoch:19 step:73 loss: 0.000522\n",
      "Epoch:19 step:74 loss: 0.009038\n",
      "Epoch:19 step:75 loss: 0.003235\n",
      "Epoch:19 step:76 loss: 0.000069\n",
      "Epoch:19 step:77 loss: 0.001855\n",
      "Epoch:19 step:78 loss: 0.042049\n",
      "Epoch:19 step:79 loss: 0.011615\n",
      "Test Epoch:19 step:0 loss: 0.010603tensor(0.0755, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:1 loss: 0.007036tensor(0.0115, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:2 loss: 0.000712tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:19 step:3 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:4 loss: 0.018557tensor(0.2367, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:5 loss: 0.008665tensor(0.2586, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:6 loss: 0.000367tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:7 loss: 0.012666tensor(0.2081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:8 loss: 0.000782tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:9 loss: 0.002331tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:10 loss: 0.000196tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:11 loss: 0.007685tensor(0.2437, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:12 loss: 0.016019tensor(0.3376, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:13 loss: 0.004097tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:14 loss: 0.000185tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:15 loss: 0.001192tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:16 loss: 0.000521tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:17 loss: 0.010678tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:18 loss: 0.012551tensor(0.0783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:19 loss: 0.027866tensor(0.2398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:20 loss: 0.000599tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:21 loss: 0.000225tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:22 loss: 0.043183tensor(0.2335, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:23 loss: 0.002212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:24 loss: 0.011173tensor(0.3142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:25 loss: 0.003811tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:26 loss: 0.019327tensor(0.2372, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:27 loss: 0.031147tensor(0.3534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:28 loss: 0.000135tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:29 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:30 loss: 0.001984tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:31 loss: 0.000637tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:32 loss: 0.000267tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:33 loss: 0.000437tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:34 loss: 0.023399tensor(0.0148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:35 loss: 0.008204tensor(0.1156, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:36 loss: 0.000505tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:37 loss: 0.001507tensor(0.1399, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:38 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:39 loss: 0.005584tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:40 loss: 0.057055tensor(0.3000, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:41 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:42 loss: 0.000202tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:43 loss: 0.029305tensor(0.2398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:44 loss: 0.001583tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:45 loss: 0.004853tensor(0.0931, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:46 loss: 0.004551tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:47 loss: 0.028047tensor(0.2295, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:48 loss: 0.004007tensor(0.1369, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:49 loss: 0.000692tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:50 loss: 0.001849tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:51 loss: 0.000960tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:52 loss: 0.000786tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:53 loss: 0.000938tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:54 loss: 0.035617tensor(0.2595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:55 loss: 0.026640tensor(0.3009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:56 loss: 0.028133tensor(0.2158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:57 loss: 0.000205tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:58 loss: 0.035985tensor(0.0073, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:59 loss: 0.000199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:60 loss: 0.035707tensor(0.3394, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:61 loss: 0.023789tensor(0.0137, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:62 loss: 0.000550tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:63 loss: 0.002216tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:64 loss: 0.004236tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:65 loss: 0.010606tensor(0.2418, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:66 loss: 0.001491tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:67 loss: 0.007855tensor(0.3039, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:68 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:69 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:70 loss: 0.005033tensor(0.0414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:71 loss: 0.013637tensor(0.2727, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:72 loss: 0.008580tensor(0.2366, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:73 loss: 0.001522tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:74 loss: 0.006973tensor(0.3301, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:75 loss: 0.002913tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:76 loss: 0.000092tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:77 loss: 0.001117tensor(0.0573, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:78 loss: 0.029075tensor(0.2895, grad_fn=<DivBackward0>)\n",
      "Test Epoch:19 step:79 loss: 0.009369tensor(0.1566, grad_fn=<DivBackward0>)\n",
      "Epoch:20 step:0 loss: 0.007363\n",
      "Epoch:20 step:1 loss: 0.006423\n",
      "Epoch:20 step:2 loss: 0.000379\n",
      "Epoch:20 step:3 loss: 0.000046\n",
      "Epoch:20 step:4 loss: 0.017226\n",
      "Epoch:20 step:5 loss: 0.012836\n",
      "Epoch:20 step:6 loss: 0.000029\n",
      "Epoch:20 step:7 loss: 0.012878\n",
      "Epoch:20 step:8 loss: 0.000874\n",
      "Epoch:20 step:9 loss: 0.000361\n",
      "Epoch:20 step:10 loss: 0.000199\n",
      "Epoch:20 step:11 loss: 0.007529\n",
      "Epoch:20 step:12 loss: 0.015386\n",
      "Epoch:20 step:13 loss: 0.001527\n",
      "Epoch:20 step:14 loss: 0.000091\n",
      "Epoch:20 step:15 loss: 0.001693\n",
      "Epoch:20 step:16 loss: 0.000803\n",
      "Epoch:20 step:17 loss: 0.009166\n",
      "Epoch:20 step:18 loss: 0.014035\n",
      "Epoch:20 step:19 loss: 0.017762\n",
      "Epoch:20 step:20 loss: 0.000390\n",
      "Epoch:20 step:21 loss: 0.000327\n",
      "Epoch:20 step:22 loss: 0.037511\n",
      "Epoch:20 step:23 loss: 0.000771\n",
      "Epoch:20 step:24 loss: 0.010820\n",
      "Epoch:20 step:25 loss: 0.002153\n",
      "Epoch:20 step:26 loss: 0.014559\n",
      "Epoch:20 step:27 loss: 0.028368\n",
      "Epoch:20 step:28 loss: 0.000029\n",
      "Epoch:20 step:29 loss: 0.000008\n",
      "Epoch:20 step:30 loss: 0.000998\n",
      "Epoch:20 step:31 loss: 0.001225\n",
      "Epoch:20 step:32 loss: 0.000176\n",
      "Epoch:20 step:33 loss: 0.000098\n",
      "Epoch:20 step:34 loss: 0.017036\n",
      "Epoch:20 step:35 loss: 0.005818\n",
      "Epoch:20 step:36 loss: 0.000098\n",
      "Epoch:20 step:37 loss: 0.001696\n",
      "Epoch:20 step:38 loss: 0.000707\n",
      "Epoch:20 step:39 loss: 0.002314\n",
      "Epoch:20 step:40 loss: 0.038606\n",
      "Epoch:20 step:41 loss: 0.000041\n",
      "Epoch:20 step:42 loss: 0.002021\n",
      "Epoch:20 step:43 loss: 0.019344\n",
      "Epoch:20 step:44 loss: 0.000361\n",
      "Epoch:20 step:45 loss: 0.002743\n",
      "Epoch:20 step:46 loss: 0.002838\n",
      "Epoch:20 step:47 loss: 0.012860\n",
      "Epoch:20 step:48 loss: 0.003430\n",
      "Epoch:20 step:49 loss: 0.000048\n",
      "Epoch:20 step:50 loss: 0.002173\n",
      "Epoch:20 step:51 loss: 0.001163\n",
      "Epoch:20 step:52 loss: 0.000030\n",
      "Epoch:20 step:53 loss: 0.000427\n",
      "Epoch:20 step:54 loss: 0.043438\n",
      "Epoch:20 step:55 loss: 0.038577\n",
      "Epoch:20 step:56 loss: 0.027710\n",
      "Epoch:20 step:57 loss: 0.000061\n",
      "Epoch:20 step:58 loss: 0.028119\n",
      "Epoch:20 step:59 loss: 0.000030\n",
      "Epoch:20 step:60 loss: 0.077146\n",
      "Epoch:20 step:61 loss: 0.030573\n",
      "Epoch:20 step:62 loss: 0.000005\n",
      "Epoch:20 step:63 loss: 0.003076\n",
      "Epoch:20 step:64 loss: 0.003314\n",
      "Epoch:20 step:65 loss: 0.009431\n",
      "Epoch:20 step:66 loss: 0.001796\n",
      "Epoch:20 step:67 loss: 0.008028\n",
      "Epoch:20 step:68 loss: 0.000045\n",
      "Epoch:20 step:69 loss: 0.000067\n",
      "Epoch:20 step:70 loss: 0.011390\n",
      "Epoch:20 step:71 loss: 0.041695\n",
      "Epoch:20 step:72 loss: 0.008231\n",
      "Epoch:20 step:73 loss: 0.002028\n",
      "Epoch:20 step:74 loss: 0.007520\n",
      "Epoch:20 step:75 loss: 0.002761\n",
      "Epoch:20 step:76 loss: 0.000072\n",
      "Epoch:20 step:77 loss: 0.001308\n",
      "Epoch:20 step:78 loss: 0.026998\n",
      "Epoch:20 step:79 loss: 0.012064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:20 step:0 loss: 0.009834tensor(0.1034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:1 loss: 0.006790tensor(0.0095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:2 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:3 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:4 loss: 0.021638tensor(0.2307, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:5 loss: 0.014836tensor(0.1857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:6 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:7 loss: 0.014218tensor(0.2231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:8 loss: 0.000386tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:9 loss: 0.000528tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:10 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:11 loss: 0.009824tensor(0.2377, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:12 loss: 0.012221tensor(0.3785, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:13 loss: 0.000980tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:14 loss: 0.000936tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:15 loss: 0.000395tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:16 loss: 0.000357tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:17 loss: 0.003013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:18 loss: 0.009103tensor(0.1408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:19 loss: 0.021475tensor(0.2912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:20 loss: 0.000344tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:21 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:22 loss: 0.036117tensor(0.2602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:23 loss: 0.000762tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:24 loss: 0.010501tensor(0.3378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:25 loss: 0.002831tensor(0.0064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:26 loss: 0.014299tensor(0.2766, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:27 loss: 0.030939tensor(0.3656, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:28 loss: 0.000081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:29 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:30 loss: 0.001129tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:31 loss: 0.000713tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:32 loss: 0.000347tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:33 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:34 loss: 0.010366tensor(0.1106, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:35 loss: 0.009142tensor(0.1185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:36 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:37 loss: 0.002659tensor(0.1121, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:38 loss: 0.000389tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:39 loss: 0.003046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:40 loss: 0.041366tensor(0.3416, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:41 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:42 loss: 0.001290tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:43 loss: 0.019484tensor(0.3243, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:44 loss: 0.001032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:45 loss: 0.003882tensor(0.1505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:46 loss: 0.007431tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:47 loss: 0.015348tensor(0.3158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:48 loss: 0.003384tensor(0.1662, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:49 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:50 loss: 0.001008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:51 loss: 0.000508tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:52 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:53 loss: 0.000156tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:54 loss: 0.040404tensor(0.2706, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:55 loss: 0.035336tensor(0.2906, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:56 loss: 0.031766tensor(0.2220, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:57 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:58 loss: 0.024350tensor(0.0096, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:59 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:60 loss: 0.038469tensor(0.3267, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:61 loss: 0.029513tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:63 loss: 0.002075tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:64 loss: 0.001612tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:65 loss: 0.014001tensor(0.2019, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:66 loss: 0.000524tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:67 loss: 0.009505tensor(0.2670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:68 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:69 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:70 loss: 0.006299tensor(0.0762, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:71 loss: 0.014942tensor(0.2450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:72 loss: 0.012864tensor(0.1971, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:73 loss: 0.001423tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:74 loss: 0.007544tensor(0.3195, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:75 loss: 0.005619tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:76 loss: 0.000389tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:77 loss: 0.001513tensor(0.0247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:78 loss: 0.024009tensor(0.3116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:20 step:79 loss: 0.007277tensor(0.1981, grad_fn=<DivBackward0>)\n",
      "Epoch:21 step:0 loss: 0.007677\n",
      "Epoch:21 step:1 loss: 0.006280\n",
      "Epoch:21 step:2 loss: 0.000605\n",
      "Epoch:21 step:3 loss: 0.000048\n",
      "Epoch:21 step:4 loss: 0.015421\n",
      "Epoch:21 step:5 loss: 0.011196\n",
      "Epoch:21 step:6 loss: 0.000030\n",
      "Epoch:21 step:7 loss: 0.013975\n",
      "Epoch:21 step:8 loss: 0.000444\n",
      "Epoch:21 step:9 loss: 0.000466\n",
      "Epoch:21 step:10 loss: 0.000060\n",
      "Epoch:21 step:11 loss: 0.006783\n",
      "Epoch:21 step:12 loss: 0.010858\n",
      "Epoch:21 step:13 loss: 0.000773\n",
      "Epoch:21 step:14 loss: 0.000051\n",
      "Epoch:21 step:15 loss: 0.000411\n",
      "Epoch:21 step:16 loss: 0.000632\n",
      "Epoch:21 step:17 loss: 0.006471\n",
      "Epoch:21 step:18 loss: 0.009635\n",
      "Epoch:21 step:19 loss: 0.019047\n",
      "Epoch:21 step:20 loss: 0.000259\n",
      "Epoch:21 step:21 loss: 0.000241\n",
      "Epoch:21 step:22 loss: 0.032315\n",
      "Epoch:21 step:23 loss: 0.001117\n",
      "Epoch:21 step:24 loss: 0.010217\n",
      "Epoch:21 step:25 loss: 0.002286\n",
      "Epoch:21 step:26 loss: 0.013205\n",
      "Epoch:21 step:27 loss: 0.027472\n",
      "Epoch:21 step:28 loss: 0.000060\n",
      "Epoch:21 step:29 loss: 0.000014\n",
      "Epoch:21 step:30 loss: 0.001265\n",
      "Epoch:21 step:31 loss: 0.000423\n",
      "Epoch:21 step:32 loss: 0.000161\n",
      "Epoch:21 step:33 loss: 0.000058\n",
      "Epoch:21 step:34 loss: 0.011042\n",
      "Epoch:21 step:35 loss: 0.007827\n",
      "Epoch:21 step:36 loss: 0.000088\n",
      "Epoch:21 step:37 loss: 0.002307\n",
      "Epoch:21 step:38 loss: 0.000173\n",
      "Epoch:21 step:39 loss: 0.003293\n",
      "Epoch:21 step:40 loss: 0.038775\n",
      "Epoch:21 step:41 loss: 0.000013\n",
      "Epoch:21 step:42 loss: 0.000672\n",
      "Epoch:21 step:43 loss: 0.017760\n",
      "Epoch:21 step:44 loss: 0.000803\n",
      "Epoch:21 step:45 loss: 0.002658\n",
      "Epoch:21 step:46 loss: 0.003594\n",
      "Epoch:21 step:47 loss: 0.012725\n",
      "Epoch:21 step:48 loss: 0.003904\n",
      "Epoch:21 step:49 loss: 0.000060\n",
      "Epoch:21 step:50 loss: 0.003022\n",
      "Epoch:21 step:51 loss: 0.001173\n",
      "Epoch:21 step:52 loss: 0.000028\n",
      "Epoch:21 step:53 loss: 0.000128\n",
      "Epoch:21 step:54 loss: 0.031327\n",
      "Epoch:21 step:55 loss: 0.035828\n",
      "Epoch:21 step:56 loss: 0.021491\n",
      "Epoch:21 step:57 loss: 0.000109\n",
      "Epoch:21 step:58 loss: 0.024078\n",
      "Epoch:21 step:59 loss: 0.000024\n",
      "Epoch:21 step:60 loss: 0.025282\n",
      "Epoch:21 step:61 loss: 0.025770\n",
      "Epoch:21 step:62 loss: 0.000005\n",
      "Epoch:21 step:63 loss: 0.002230\n",
      "Epoch:21 step:64 loss: 0.001141\n",
      "Epoch:21 step:65 loss: 0.014117\n",
      "Epoch:21 step:66 loss: 0.000299\n",
      "Epoch:21 step:67 loss: 0.009174\n",
      "Epoch:21 step:68 loss: 0.000018\n",
      "Epoch:21 step:69 loss: 0.001902\n",
      "Epoch:21 step:70 loss: 0.003129\n",
      "Epoch:21 step:71 loss: 0.015711\n",
      "Epoch:21 step:72 loss: 0.009930\n",
      "Epoch:21 step:73 loss: 0.000543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21 step:74 loss: 0.006705\n",
      "Epoch:21 step:75 loss: 0.002037\n",
      "Epoch:21 step:76 loss: 0.000158\n",
      "Epoch:21 step:77 loss: 0.001607\n",
      "Epoch:21 step:78 loss: 0.021939\n",
      "Epoch:21 step:79 loss: 0.006661\n",
      "Test Epoch:21 step:0 loss: 0.006859tensor(0.1860, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:1 loss: 0.006290tensor(0.0162, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:2 loss: 0.000535tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:3 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:4 loss: 0.017309tensor(0.2740, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:5 loss: 0.009369tensor(0.2820, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:6 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:7 loss: 0.012344tensor(0.2488, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:8 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:9 loss: 0.000275tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:10 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:11 loss: 0.007190tensor(0.2831, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:12 loss: 0.011245tensor(0.3958, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:13 loss: 0.000547tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:14 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:15 loss: 0.000461tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:16 loss: 0.000099tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:17 loss: 0.003819tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:18 loss: 0.008010tensor(0.2099, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:19 loss: 0.016712tensor(0.3275, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:20 loss: 0.000171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:21 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:22 loss: 0.030186tensor(0.2902, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:23 loss: 0.002060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:24 loss: 0.008741tensor(0.3621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:25 loss: 0.002154tensor(0.0231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:26 loss: 0.012352tensor(0.3074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:27 loss: 0.026830tensor(0.3866, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:28 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:29 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:30 loss: 0.000766tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:31 loss: 0.000619tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:32 loss: 0.000258tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:34 loss: 0.009671tensor(0.1312, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:35 loss: 0.006639tensor(0.1738, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:36 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:37 loss: 0.002459tensor(0.1318, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:38 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:39 loss: 0.001239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:40 loss: 0.033173tensor(0.3721, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:41 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:42 loss: 0.000273tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:43 loss: 0.015338tensor(0.3596, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:44 loss: 0.001197tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:45 loss: 0.002969tensor(0.2258, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:46 loss: 0.004544tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:47 loss: 0.012313tensor(0.3452, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:48 loss: 0.003601tensor(0.1864, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:49 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:50 loss: 0.001921tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:51 loss: 0.001041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:52 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:53 loss: 0.000203tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:54 loss: 0.048725tensor(0.2722, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:55 loss: 0.030466tensor(0.3182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:56 loss: 0.024008tensor(0.2977, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:57 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:58 loss: 0.024011tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:59 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:60 loss: 0.055285tensor(0.2968, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:61 loss: 0.035190tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:62 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:63 loss: 0.001879tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:64 loss: 0.001117tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:65 loss: 0.015305tensor(0.1843, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:66 loss: 0.000615tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:67 loss: 0.007648tensor(0.3076, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:68 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:69 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:70 loss: 0.003446tensor(0.1501, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:71 loss: 0.019752tensor(0.2241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:72 loss: 0.013503tensor(0.1928, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:73 loss: 0.002226tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:74 loss: 0.006269tensor(0.3432, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:75 loss: 0.003525tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:76 loss: 0.000285tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:77 loss: 0.001270tensor(0.0446, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:78 loss: 0.026852tensor(0.3237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:21 step:79 loss: 0.008340tensor(0.1989, grad_fn=<DivBackward0>)\n",
      "Epoch:22 step:0 loss: 0.006351\n",
      "Epoch:22 step:1 loss: 0.007247\n",
      "Epoch:22 step:2 loss: 0.000512\n",
      "Epoch:22 step:3 loss: 0.000065\n",
      "Epoch:22 step:4 loss: 0.014502\n",
      "Epoch:22 step:5 loss: 0.012340\n",
      "Epoch:22 step:6 loss: 0.000023\n",
      "Epoch:22 step:7 loss: 0.012444\n",
      "Epoch:22 step:8 loss: 0.000247\n",
      "Epoch:22 step:9 loss: 0.000497\n",
      "Epoch:22 step:10 loss: 0.000065\n",
      "Epoch:22 step:11 loss: 0.006595\n",
      "Epoch:22 step:12 loss: 0.010166\n",
      "Epoch:22 step:13 loss: 0.000902\n",
      "Epoch:22 step:14 loss: 0.000029\n",
      "Epoch:22 step:15 loss: 0.000300\n",
      "Epoch:22 step:16 loss: 0.000050\n",
      "Epoch:22 step:17 loss: 0.001608\n",
      "Epoch:22 step:18 loss: 0.007507\n",
      "Epoch:22 step:19 loss: 0.018468\n",
      "Epoch:22 step:20 loss: 0.000428\n",
      "Epoch:22 step:21 loss: 0.000018\n",
      "Epoch:22 step:22 loss: 0.027713\n",
      "Epoch:22 step:23 loss: 0.002671\n",
      "Epoch:22 step:24 loss: 0.008377\n",
      "Epoch:22 step:25 loss: 0.002103\n",
      "Epoch:22 step:26 loss: 0.012160\n",
      "Epoch:22 step:27 loss: 0.024976\n",
      "Epoch:22 step:28 loss: 0.000044\n",
      "Epoch:22 step:29 loss: 0.000008\n",
      "Epoch:22 step:30 loss: 0.000951\n",
      "Epoch:22 step:31 loss: 0.000366\n",
      "Epoch:22 step:32 loss: 0.000171\n",
      "Epoch:22 step:33 loss: 0.000003\n",
      "Epoch:22 step:34 loss: 0.014392\n",
      "Epoch:22 step:35 loss: 0.009376\n",
      "Epoch:22 step:36 loss: 0.000085\n",
      "Epoch:22 step:37 loss: 0.003934\n",
      "Epoch:22 step:38 loss: 0.000096\n",
      "Epoch:22 step:39 loss: 0.001661\n",
      "Epoch:22 step:40 loss: 0.044344\n",
      "Epoch:22 step:41 loss: 0.000032\n",
      "Epoch:22 step:42 loss: 0.000251\n",
      "Epoch:22 step:43 loss: 0.014362\n",
      "Epoch:22 step:44 loss: 0.001167\n",
      "Epoch:22 step:45 loss: 0.003511\n",
      "Epoch:22 step:46 loss: 0.007019\n",
      "Epoch:22 step:47 loss: 0.012054\n",
      "Epoch:22 step:48 loss: 0.003687\n",
      "Epoch:22 step:49 loss: 0.000039\n",
      "Epoch:22 step:50 loss: 0.001897\n",
      "Epoch:22 step:51 loss: 0.000893\n",
      "Epoch:22 step:52 loss: 0.000018\n",
      "Epoch:22 step:53 loss: 0.000056\n",
      "Epoch:22 step:54 loss: 0.031733\n",
      "Epoch:22 step:55 loss: 0.028445\n",
      "Epoch:22 step:56 loss: 0.024953\n",
      "Epoch:22 step:57 loss: 0.000048\n",
      "Epoch:22 step:58 loss: 0.021533\n",
      "Epoch:22 step:59 loss: 0.000032\n",
      "Epoch:22 step:60 loss: 0.029275\n",
      "Epoch:22 step:61 loss: 0.024885\n",
      "Epoch:22 step:62 loss: 0.000009\n",
      "Epoch:22 step:63 loss: 0.002813\n",
      "Epoch:22 step:64 loss: 0.003413\n",
      "Epoch:22 step:65 loss: 0.009681\n",
      "Epoch:22 step:66 loss: 0.000536\n",
      "Epoch:22 step:67 loss: 0.008466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22 step:68 loss: 0.000028\n",
      "Epoch:22 step:69 loss: 0.000019\n",
      "Epoch:22 step:70 loss: 0.006428\n",
      "Epoch:22 step:71 loss: 0.016429\n",
      "Epoch:22 step:72 loss: 0.007894\n",
      "Epoch:22 step:73 loss: 0.001107\n",
      "Epoch:22 step:74 loss: 0.006077\n",
      "Epoch:22 step:75 loss: 0.002437\n",
      "Epoch:22 step:76 loss: 0.000112\n",
      "Epoch:22 step:77 loss: 0.001780\n",
      "Epoch:22 step:78 loss: 0.018174\n",
      "Epoch:22 step:79 loss: 0.008354\n",
      "Test Epoch:22 step:0 loss: 0.006277tensor(0.2183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:1 loss: 0.004963tensor(0.0328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:2 loss: 0.000768tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:3 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:4 loss: 0.014574tensor(0.3051, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:5 loss: 0.011815tensor(0.2277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:6 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:7 loss: 0.011742tensor(0.2422, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:8 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:9 loss: 0.000578tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:10 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:11 loss: 0.006295tensor(0.2991, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:12 loss: 0.009723tensor(0.4085, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:13 loss: 0.000572tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:14 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:15 loss: 0.000390tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:16 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:17 loss: 0.002715tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:18 loss: 0.009108tensor(0.1823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:19 loss: 0.015189tensor(0.3411, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:20 loss: 0.000207tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:21 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:22 loss: 0.024652tensor(0.3237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:23 loss: 0.001553tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:24 loss: 0.008065tensor(0.3730, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:25 loss: 0.002381tensor(0.0189, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:26 loss: 0.011714tensor(0.3185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:27 loss: 0.024610tensor(0.3966, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:28 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:29 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:30 loss: 0.000473tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:31 loss: 0.000118tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:32 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:34 loss: 0.011627tensor(0.0773, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:35 loss: 0.007832tensor(0.1556, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:36 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:37 loss: 0.001734tensor(0.1644, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:38 loss: 0.000115tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:39 loss: 0.001694tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:40 loss: 0.033622tensor(0.3741, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:41 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:42 loss: 0.000475tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:43 loss: 0.013332tensor(0.3738, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:44 loss: 0.001138tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:45 loss: 0.003542tensor(0.2161, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:46 loss: 0.002240tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:47 loss: 0.011589tensor(0.3564, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:48 loss: 0.004719tensor(0.1790, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:49 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:50 loss: 0.002517tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:51 loss: 0.001480tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:52 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:53 loss: 0.000152tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:54 loss: 0.041263tensor(0.2960, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:55 loss: 0.027231tensor(0.3351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:56 loss: 0.022148tensor(0.3165, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:57 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:58 loss: 0.024608tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:59 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:60 loss: 0.039450tensor(0.3495, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:61 loss: 0.032069tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:62 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:63 loss: 0.001863tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:64 loss: 0.000546tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:65 loss: 0.009520tensor(0.2910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:66 loss: 0.000280tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:67 loss: 0.007641tensor(0.3141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:68 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:69 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:70 loss: 0.003731tensor(0.1344, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:71 loss: 0.017998tensor(0.2443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:72 loss: 0.011061tensor(0.2160, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:73 loss: 0.000475tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:74 loss: 0.005857tensor(0.3557, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:75 loss: 0.003584tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:76 loss: 0.000235tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:77 loss: 0.001764tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:78 loss: 0.019003tensor(0.3423, grad_fn=<DivBackward0>)\n",
      "Test Epoch:22 step:79 loss: 0.007861tensor(0.1923, grad_fn=<DivBackward0>)\n",
      "Epoch:23 step:0 loss: 0.006549\n",
      "Epoch:23 step:1 loss: 0.004950\n",
      "Epoch:23 step:2 loss: 0.000749\n",
      "Epoch:23 step:3 loss: 0.000088\n",
      "Epoch:23 step:4 loss: 0.014559\n",
      "Epoch:23 step:5 loss: 0.010749\n",
      "Epoch:23 step:6 loss: 0.000020\n",
      "Epoch:23 step:7 loss: 0.011756\n",
      "Epoch:23 step:8 loss: 0.000005\n",
      "Epoch:23 step:9 loss: 0.000533\n",
      "Epoch:23 step:10 loss: 0.000067\n",
      "Epoch:23 step:11 loss: 0.006215\n",
      "Epoch:23 step:12 loss: 0.010066\n",
      "Epoch:23 step:13 loss: 0.000294\n",
      "Epoch:23 step:14 loss: 0.000030\n",
      "Epoch:23 step:15 loss: 0.000383\n",
      "Epoch:23 step:16 loss: 0.000005\n",
      "Epoch:23 step:17 loss: 0.001557\n",
      "Epoch:23 step:18 loss: 0.007051\n",
      "Epoch:23 step:19 loss: 0.016984\n",
      "Epoch:23 step:20 loss: 0.000349\n",
      "Epoch:23 step:21 loss: 0.000004\n",
      "Epoch:23 step:22 loss: 0.026307\n",
      "Epoch:23 step:23 loss: 0.005154\n",
      "Epoch:23 step:24 loss: 0.007599\n",
      "Epoch:23 step:25 loss: 0.005644\n",
      "Epoch:23 step:26 loss: 0.011460\n",
      "Epoch:23 step:27 loss: 0.024456\n",
      "Epoch:23 step:28 loss: 0.000035\n",
      "Epoch:23 step:29 loss: 0.000016\n",
      "Epoch:23 step:30 loss: 0.000348\n",
      "Epoch:23 step:31 loss: 0.000349\n",
      "Epoch:23 step:32 loss: 0.000114\n",
      "Epoch:23 step:33 loss: 0.000002\n",
      "Epoch:23 step:34 loss: 0.017624\n",
      "Epoch:23 step:35 loss: 0.009927\n",
      "Epoch:23 step:36 loss: 0.000079\n",
      "Epoch:23 step:37 loss: 0.001841\n",
      "Epoch:23 step:38 loss: 0.000060\n",
      "Epoch:23 step:39 loss: 0.000901\n",
      "Epoch:23 step:40 loss: 0.046801\n",
      "Epoch:23 step:41 loss: 0.000015\n",
      "Epoch:23 step:42 loss: 0.000340\n",
      "Epoch:23 step:43 loss: 0.014942\n",
      "Epoch:23 step:44 loss: 0.001485\n",
      "Epoch:23 step:45 loss: 0.003374\n",
      "Epoch:23 step:46 loss: 0.006624\n",
      "Epoch:23 step:47 loss: 0.012502\n",
      "Epoch:23 step:48 loss: 0.004026\n",
      "Epoch:23 step:49 loss: 0.000072\n",
      "Epoch:23 step:50 loss: 0.001912\n",
      "Epoch:23 step:51 loss: 0.002304\n",
      "Epoch:23 step:52 loss: 0.000021\n",
      "Epoch:23 step:53 loss: 0.000052\n",
      "Epoch:23 step:54 loss: 0.030847\n",
      "Epoch:23 step:55 loss: 0.034968\n",
      "Epoch:23 step:56 loss: 0.021704\n",
      "Epoch:23 step:57 loss: 0.000149\n",
      "Epoch:23 step:58 loss: 0.030548\n",
      "Epoch:23 step:59 loss: 0.000034\n",
      "Epoch:23 step:60 loss: 0.021073\n",
      "Epoch:23 step:61 loss: 0.026113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23 step:62 loss: 0.000003\n",
      "Epoch:23 step:63 loss: 0.003565\n",
      "Epoch:23 step:64 loss: 0.000606\n",
      "Epoch:23 step:65 loss: 0.023478\n",
      "Epoch:23 step:66 loss: 0.000093\n",
      "Epoch:23 step:67 loss: 0.019293\n",
      "Epoch:23 step:68 loss: 0.000016\n",
      "Epoch:23 step:69 loss: 0.000010\n",
      "Epoch:23 step:70 loss: 0.009506\n",
      "Epoch:23 step:71 loss: 0.019225\n",
      "Epoch:23 step:72 loss: 0.006426\n",
      "Epoch:23 step:73 loss: 0.001894\n",
      "Epoch:23 step:74 loss: 0.007142\n",
      "Epoch:23 step:75 loss: 0.005976\n",
      "Epoch:23 step:76 loss: 0.001101\n",
      "Epoch:23 step:77 loss: 0.001775\n",
      "Epoch:23 step:78 loss: 0.032274\n",
      "Epoch:23 step:79 loss: 0.008266\n",
      "Test Epoch:23 step:0 loss: 0.010746tensor(0.1480, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:1 loss: 0.005386tensor(0.0336, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:2 loss: 0.003543tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:3 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:4 loss: 0.019116tensor(0.2550, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:5 loss: 0.007610tensor(0.3054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:7 loss: 0.013969tensor(0.2337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:8 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:9 loss: 0.000569tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:10 loss: 0.000115tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:11 loss: 0.006616tensor(0.2923, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:12 loss: 0.011275tensor(0.3946, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:13 loss: 0.001058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:14 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:15 loss: 0.000217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:16 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:17 loss: 0.000903tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:18 loss: 0.007418tensor(0.1903, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:19 loss: 0.016143tensor(0.3286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:20 loss: 0.000887tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:21 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:22 loss: 0.036386tensor(0.2667, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:23 loss: 0.006651tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:24 loss: 0.008056tensor(0.3696, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:25 loss: 0.003043tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:26 loss: 0.013422tensor(0.3062, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:27 loss: 0.031836tensor(0.3816, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:28 loss: 0.000543tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:29 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:30 loss: 0.000660tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:31 loss: 0.000950tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:32 loss: 0.000230tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:33 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:34 loss: 0.012935tensor(0.0562, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:35 loss: 0.014508tensor(0.0565, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:36 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:37 loss: 0.001467tensor(0.0916, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:38 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:39 loss: 0.002331tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:40 loss: 0.036035tensor(0.3660, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:41 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:42 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:43 loss: 0.036851tensor(0.2353, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:44 loss: 0.000381tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:45 loss: 0.003999tensor(0.1891, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:46 loss: 0.004524tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:47 loss: 0.023591tensor(0.2880, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:48 loss: 0.005333tensor(0.0501, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:49 loss: 0.000453tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:50 loss: 0.010495tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:51 loss: 0.007375tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:52 loss: 0.000744tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:53 loss: 0.005059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:54 loss: 0.042962tensor(0.2550, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:55 loss: 0.032080tensor(0.2945, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:56 loss: 0.046555tensor(0.1511, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:57 loss: 0.000370tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:58 loss: 0.036643tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:59 loss: 0.007701tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:60 loss: 0.024927tensor(0.3772, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:61 loss: 0.025291tensor(0.0060, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:62 loss: 0.001407tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:63 loss: 0.002552tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:64 loss: 0.003179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:65 loss: 0.034187tensor(0.0175, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:66 loss: 0.000761tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:67 loss: 0.016482tensor(0.1255, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:68 loss: 0.000328tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:69 loss: 0.001286tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:70 loss: 0.008311tensor(0.0167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:71 loss: 0.018670tensor(0.2111, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:72 loss: 0.007919tensor(0.1695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:73 loss: 0.001994tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:74 loss: 0.013456tensor(0.1826, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:75 loss: 0.005528tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:76 loss: 0.000392tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:77 loss: 0.001835tensor(0.0080, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:78 loss: 0.031360tensor(0.2810, grad_fn=<DivBackward0>)\n",
      "Test Epoch:23 step:79 loss: 0.007071tensor(0.1874, grad_fn=<DivBackward0>)\n",
      "Epoch:24 step:0 loss: 0.009043\n",
      "Epoch:24 step:1 loss: 0.008935\n",
      "Epoch:24 step:2 loss: 0.002312\n",
      "Epoch:24 step:3 loss: 0.000113\n",
      "Epoch:24 step:4 loss: 0.015411\n",
      "Epoch:24 step:5 loss: 0.007612\n",
      "Epoch:24 step:6 loss: 0.000055\n",
      "Epoch:24 step:7 loss: 0.017761\n",
      "Epoch:24 step:8 loss: 0.000106\n",
      "Epoch:24 step:9 loss: 0.000596\n",
      "Epoch:24 step:10 loss: 0.000016\n",
      "Epoch:24 step:11 loss: 0.009428\n",
      "Epoch:24 step:12 loss: 0.018981\n",
      "Epoch:24 step:13 loss: 0.001955\n",
      "Epoch:24 step:14 loss: 0.000061\n",
      "Epoch:24 step:15 loss: 0.000525\n",
      "Epoch:24 step:16 loss: 0.000004\n",
      "Epoch:24 step:17 loss: 0.014116\n",
      "Epoch:24 step:18 loss: 0.009197\n",
      "Epoch:24 step:19 loss: 0.021970\n",
      "Epoch:24 step:20 loss: 0.000496\n",
      "Epoch:24 step:21 loss: 0.000011\n",
      "Epoch:24 step:22 loss: 0.063179\n",
      "Epoch:24 step:23 loss: 0.003266\n",
      "Epoch:24 step:24 loss: 0.014711\n",
      "Epoch:24 step:25 loss: 0.006926\n",
      "Epoch:24 step:26 loss: 0.034362\n",
      "Epoch:24 step:27 loss: 0.029500\n",
      "Epoch:24 step:28 loss: 0.000677\n",
      "Epoch:24 step:29 loss: 0.000540\n",
      "Epoch:24 step:30 loss: 0.002534\n",
      "Epoch:24 step:31 loss: 0.001405\n",
      "Epoch:24 step:32 loss: 0.001198\n",
      "Epoch:24 step:33 loss: 0.000391\n",
      "Epoch:24 step:34 loss: 0.014974\n",
      "Epoch:24 step:35 loss: 0.018738\n",
      "Epoch:24 step:36 loss: 0.000259\n",
      "Epoch:24 step:37 loss: 0.002077\n",
      "Epoch:24 step:38 loss: 0.000091\n",
      "Epoch:24 step:39 loss: 0.003909\n",
      "Epoch:24 step:40 loss: 0.104924\n",
      "Epoch:24 step:41 loss: 0.000288\n",
      "Epoch:24 step:42 loss: 0.001183\n",
      "Epoch:24 step:43 loss: 0.026427\n",
      "Epoch:24 step:44 loss: 0.007113\n",
      "Epoch:24 step:45 loss: 0.006049\n",
      "Epoch:24 step:46 loss: 0.005915\n",
      "Epoch:24 step:47 loss: 0.017496\n",
      "Epoch:24 step:48 loss: 0.004203\n",
      "Epoch:24 step:49 loss: 0.000327\n",
      "Epoch:24 step:50 loss: 0.005784\n",
      "Epoch:24 step:51 loss: 0.001550\n",
      "Epoch:24 step:52 loss: 0.000043\n",
      "Epoch:24 step:53 loss: 0.000135\n",
      "Epoch:24 step:54 loss: 0.029130\n",
      "Epoch:24 step:55 loss: 0.024811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24 step:56 loss: 0.032804\n",
      "Epoch:24 step:57 loss: 0.000022\n",
      "Epoch:24 step:58 loss: 0.020846\n",
      "Epoch:24 step:59 loss: 0.000540\n",
      "Epoch:24 step:60 loss: 0.025755\n",
      "Epoch:24 step:61 loss: 0.024886\n",
      "Epoch:24 step:62 loss: 0.000058\n",
      "Epoch:24 step:63 loss: 0.005855\n",
      "Epoch:24 step:64 loss: 0.007639\n",
      "Epoch:24 step:65 loss: 0.005874\n",
      "Epoch:24 step:66 loss: 0.001298\n",
      "Epoch:24 step:67 loss: 0.010696\n",
      "Epoch:24 step:68 loss: 0.000312\n",
      "Epoch:24 step:69 loss: 0.001809\n",
      "Epoch:24 step:70 loss: 0.006041\n",
      "Epoch:24 step:71 loss: 0.021780\n",
      "Epoch:24 step:72 loss: 0.006572\n",
      "Epoch:24 step:73 loss: 0.000102\n",
      "Epoch:24 step:74 loss: 0.011491\n",
      "Epoch:24 step:75 loss: 0.001424\n",
      "Epoch:24 step:76 loss: 0.000078\n",
      "Epoch:24 step:77 loss: 0.002989\n",
      "Epoch:24 step:78 loss: 0.027137\n",
      "Epoch:24 step:79 loss: 0.008741\n",
      "Test Epoch:24 step:0 loss: 0.008540tensor(0.1374, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:1 loss: 0.005556tensor(0.0273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:2 loss: 0.002292tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:3 loss: 0.000107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:4 loss: 0.016925tensor(0.2900, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:5 loss: 0.006733tensor(0.2981, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:6 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:7 loss: 0.011850tensor(0.2307, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:8 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:9 loss: 0.000703tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:10 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:11 loss: 0.008435tensor(0.2366, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:12 loss: 0.015818tensor(0.3585, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:13 loss: 0.001251tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:14 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:15 loss: 0.000610tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:17 loss: 0.004254tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:18 loss: 0.008165tensor(0.1420, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:19 loss: 0.021551tensor(0.2830, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:20 loss: 0.000345tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:22 loss: 0.038714tensor(0.2658, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:23 loss: 0.004110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:24 loss: 0.009661tensor(0.3407, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:25 loss: 0.002445tensor(0.0396, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:26 loss: 0.019718tensor(0.2504, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:27 loss: 0.032312tensor(0.3654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:28 loss: 0.000141tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:29 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:30 loss: 0.001931tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:31 loss: 0.001466tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:32 loss: 0.000374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:34 loss: 0.012546tensor(0.0654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:35 loss: 0.012966tensor(0.0476, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:36 loss: 0.000189tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:37 loss: 0.001458tensor(0.0715, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:38 loss: 0.000242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:39 loss: 0.011240tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:40 loss: 0.037149tensor(0.3575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:41 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:42 loss: 0.000397tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:43 loss: 0.026357tensor(0.2650, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:44 loss: 0.001258tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:45 loss: 0.002475tensor(0.1840, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:46 loss: 0.000479tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:47 loss: 0.016609tensor(0.3172, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:48 loss: 0.003569tensor(0.1599, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:49 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:50 loss: 0.000971tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:51 loss: 0.002034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:52 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:53 loss: 0.000180tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:54 loss: 0.028730tensor(0.3117, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:55 loss: 0.022716tensor(0.3364, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:56 loss: 0.036377tensor(0.2325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:57 loss: 0.001668tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:58 loss: 0.032168tensor(0.0039, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:59 loss: 0.001523tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:60 loss: 0.034795tensor(0.3563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:61 loss: 0.012094tensor(0.1667, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:62 loss: 0.000112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:63 loss: 0.011726tensor(8.4320e-07, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:64 loss: 0.015730tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:65 loss: 0.005997tensor(0.3575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:66 loss: 0.000606tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:67 loss: 0.016700tensor(0.1817, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:68 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:69 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:70 loss: 0.006025tensor(0.0225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:71 loss: 0.025536tensor(0.1881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:72 loss: 0.007992tensor(0.1972, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:73 loss: 0.000214tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:74 loss: 0.019319tensor(0.1463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:75 loss: 0.001962tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:76 loss: 0.000239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:77 loss: 0.002414tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:78 loss: 0.025994tensor(0.2951, grad_fn=<DivBackward0>)\n",
      "Test Epoch:24 step:79 loss: 0.010630tensor(0.0980, grad_fn=<DivBackward0>)\n",
      "Epoch:25 step:0 loss: 0.010464\n",
      "Epoch:25 step:1 loss: 0.008895\n",
      "Epoch:25 step:2 loss: 0.001285\n",
      "Epoch:25 step:3 loss: 0.000205\n",
      "Epoch:25 step:4 loss: 0.016947\n",
      "Epoch:25 step:5 loss: 0.008268\n",
      "Epoch:25 step:6 loss: 0.000018\n",
      "Epoch:25 step:7 loss: 0.016348\n",
      "Epoch:25 step:8 loss: 0.000032\n",
      "Epoch:25 step:9 loss: 0.000338\n",
      "Epoch:25 step:10 loss: 0.000704\n",
      "Epoch:25 step:11 loss: 0.007401\n",
      "Epoch:25 step:12 loss: 0.012779\n",
      "Epoch:25 step:13 loss: 0.004863\n",
      "Epoch:25 step:14 loss: 0.000096\n",
      "Epoch:25 step:15 loss: 0.000591\n",
      "Epoch:25 step:16 loss: 0.000008\n",
      "Epoch:25 step:17 loss: 0.001728\n",
      "Epoch:25 step:18 loss: 0.008623\n",
      "Epoch:25 step:19 loss: 0.022955\n",
      "Epoch:25 step:20 loss: 0.000279\n",
      "Epoch:25 step:21 loss: 0.000004\n",
      "Epoch:25 step:22 loss: 0.033433\n",
      "Epoch:25 step:23 loss: 0.003634\n",
      "Epoch:25 step:24 loss: 0.010140\n",
      "Epoch:25 step:25 loss: 0.004851\n",
      "Epoch:25 step:26 loss: 0.014276\n",
      "Epoch:25 step:27 loss: 0.032924\n",
      "Epoch:25 step:28 loss: 0.000039\n",
      "Epoch:25 step:29 loss: 0.000007\n",
      "Epoch:25 step:30 loss: 0.001537\n",
      "Epoch:25 step:31 loss: 0.000881\n",
      "Epoch:25 step:32 loss: 0.000162\n",
      "Epoch:25 step:33 loss: 0.000002\n",
      "Epoch:25 step:34 loss: 0.016775\n",
      "Epoch:25 step:35 loss: 0.014074\n",
      "Epoch:25 step:36 loss: 0.000017\n",
      "Epoch:25 step:37 loss: 0.001201\n",
      "Epoch:25 step:38 loss: 0.000019\n",
      "Epoch:25 step:39 loss: 0.010706\n",
      "Epoch:25 step:40 loss: 0.037291\n",
      "Epoch:25 step:41 loss: 0.000108\n",
      "Epoch:25 step:42 loss: 0.000176\n",
      "Epoch:25 step:43 loss: 0.020630\n",
      "Epoch:25 step:44 loss: 0.002534\n",
      "Epoch:25 step:45 loss: 0.002598\n",
      "Epoch:25 step:46 loss: 0.006448\n",
      "Epoch:25 step:47 loss: 0.015634\n",
      "Epoch:25 step:48 loss: 0.004813\n",
      "Epoch:25 step:49 loss: 0.000234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25 step:50 loss: 0.004440\n",
      "Epoch:25 step:51 loss: 0.002771\n",
      "Epoch:25 step:52 loss: 0.000058\n",
      "Epoch:25 step:53 loss: 0.000136\n",
      "Epoch:25 step:54 loss: 0.046809\n",
      "Epoch:25 step:55 loss: 0.027360\n",
      "Epoch:25 step:56 loss: 0.027858\n",
      "Epoch:25 step:57 loss: 0.000022\n",
      "Epoch:25 step:58 loss: 0.025836\n",
      "Epoch:25 step:59 loss: 0.000035\n",
      "Epoch:25 step:60 loss: 0.057996\n",
      "Epoch:25 step:61 loss: 0.026738\n",
      "Epoch:25 step:62 loss: 0.000007\n",
      "Epoch:25 step:63 loss: 0.001867\n",
      "Epoch:25 step:64 loss: 0.002061\n",
      "Epoch:25 step:65 loss: 0.008723\n",
      "Epoch:25 step:66 loss: 0.002794\n",
      "Epoch:25 step:67 loss: 0.007064\n",
      "Epoch:25 step:68 loss: 0.000221\n",
      "Epoch:25 step:69 loss: 0.000093\n",
      "Epoch:25 step:70 loss: 0.006259\n",
      "Epoch:25 step:71 loss: 0.020700\n",
      "Epoch:25 step:72 loss: 0.019254\n",
      "Epoch:25 step:73 loss: 0.003184\n",
      "Epoch:25 step:74 loss: 0.006659\n",
      "Epoch:25 step:75 loss: 0.005667\n",
      "Epoch:25 step:76 loss: 0.000073\n",
      "Epoch:25 step:77 loss: 0.001405\n",
      "Epoch:25 step:78 loss: 0.042981\n",
      "Epoch:25 step:79 loss: 0.010625\n",
      "Test Epoch:25 step:0 loss: 0.010965tensor(0.0793, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:1 loss: 0.006138tensor(0.0157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:2 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:3 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:4 loss: 0.015479tensor(0.2956, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:5 loss: 0.013550tensor(0.1796, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:6 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:7 loss: 0.014926tensor(0.2273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:8 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:9 loss: 0.002678tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:10 loss: 0.000160tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:11 loss: 0.009206tensor(0.2415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:12 loss: 0.011239tensor(0.3867, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:13 loss: 0.001482tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:14 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:15 loss: 0.000712tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:16 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:17 loss: 0.002395tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:18 loss: 0.009877tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:19 loss: 0.020832tensor(0.2941, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:20 loss: 0.001001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:21 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:22 loss: 0.030378tensor(0.2979, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:23 loss: 0.001158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:24 loss: 0.009592tensor(0.3428, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:25 loss: 0.002674tensor(0.0168, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:26 loss: 0.014847tensor(0.2954, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:27 loss: 0.026849tensor(0.3884, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:28 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:29 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:30 loss: 0.000672tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:31 loss: 0.000439tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:32 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:34 loss: 0.014471tensor(0.0342, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:35 loss: 0.009699tensor(0.0765, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:36 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:37 loss: 0.001682tensor(0.1182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:38 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:39 loss: 0.000795tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:40 loss: 0.044139tensor(0.3474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:41 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:42 loss: 0.001021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:43 loss: 0.016820tensor(0.3463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:44 loss: 0.001154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:45 loss: 0.002673tensor(0.2283, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:46 loss: 0.006746tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:47 loss: 0.018227tensor(0.3155, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:48 loss: 0.005287tensor(0.1440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:49 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:50 loss: 0.002232tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:51 loss: 0.001081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:52 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:53 loss: 0.000187tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:54 loss: 0.046342tensor(0.2812, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:55 loss: 0.031071tensor(0.3177, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:56 loss: 0.018435tensor(0.3230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:57 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:58 loss: 0.025303tensor(0.0093, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:59 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:60 loss: 0.047964tensor(0.3110, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:61 loss: 0.033395tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:63 loss: 0.002147tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:64 loss: 0.000512tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:65 loss: 0.017125tensor(0.1747, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:66 loss: 0.000222tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:67 loss: 0.008912tensor(0.2920, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:68 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:69 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:70 loss: 0.003379tensor(0.1341, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:71 loss: 0.013448tensor(0.2922, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:72 loss: 0.008663tensor(0.2456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:73 loss: 0.001119tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:74 loss: 0.007227tensor(0.3299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:75 loss: 0.006219tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:76 loss: 0.000401tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:77 loss: 0.001593tensor(0.0352, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:78 loss: 0.024272tensor(0.3107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:25 step:79 loss: 0.008082tensor(0.1727, grad_fn=<DivBackward0>)\n",
      "Epoch:26 step:0 loss: 0.006885\n",
      "Epoch:26 step:1 loss: 0.005957\n",
      "Epoch:26 step:2 loss: 0.000931\n",
      "Epoch:26 step:3 loss: 0.000067\n",
      "Epoch:26 step:4 loss: 0.014526\n",
      "Epoch:26 step:5 loss: 0.013241\n",
      "Epoch:26 step:6 loss: 0.000011\n",
      "Epoch:26 step:7 loss: 0.014828\n",
      "Epoch:26 step:8 loss: 0.000012\n",
      "Epoch:26 step:9 loss: 0.000431\n",
      "Epoch:26 step:10 loss: 0.000131\n",
      "Epoch:26 step:11 loss: 0.007236\n",
      "Epoch:26 step:12 loss: 0.013458\n",
      "Epoch:26 step:13 loss: 0.000571\n",
      "Epoch:26 step:14 loss: 0.000015\n",
      "Epoch:26 step:15 loss: 0.000345\n",
      "Epoch:26 step:16 loss: 0.000007\n",
      "Epoch:26 step:17 loss: 0.002044\n",
      "Epoch:26 step:18 loss: 0.008084\n",
      "Epoch:26 step:19 loss: 0.017277\n",
      "Epoch:26 step:20 loss: 0.000455\n",
      "Epoch:26 step:21 loss: 0.000004\n",
      "Epoch:26 step:22 loss: 0.023464\n",
      "Epoch:26 step:23 loss: 0.001981\n",
      "Epoch:26 step:24 loss: 0.008703\n",
      "Epoch:26 step:25 loss: 0.003537\n",
      "Epoch:26 step:26 loss: 0.014168\n",
      "Epoch:26 step:27 loss: 0.024900\n",
      "Epoch:26 step:28 loss: 0.000196\n",
      "Epoch:26 step:29 loss: 0.000012\n",
      "Epoch:26 step:30 loss: 0.000615\n",
      "Epoch:26 step:31 loss: 0.000602\n",
      "Epoch:26 step:32 loss: 0.000227\n",
      "Epoch:26 step:33 loss: 0.000002\n",
      "Epoch:26 step:34 loss: 0.011347\n",
      "Epoch:26 step:35 loss: 0.008148\n",
      "Epoch:26 step:36 loss: 0.000014\n",
      "Epoch:26 step:37 loss: 0.001382\n",
      "Epoch:26 step:38 loss: 0.000051\n",
      "Epoch:26 step:39 loss: 0.004503\n",
      "Epoch:26 step:40 loss: 0.038024\n",
      "Epoch:26 step:41 loss: 0.000027\n",
      "Epoch:26 step:42 loss: 0.000272\n",
      "Epoch:26 step:43 loss: 0.015232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26 step:44 loss: 0.001330\n",
      "Epoch:26 step:45 loss: 0.002446\n",
      "Epoch:26 step:46 loss: 0.001730\n",
      "Epoch:26 step:47 loss: 0.012444\n",
      "Epoch:26 step:48 loss: 0.004462\n",
      "Epoch:26 step:49 loss: 0.000073\n",
      "Epoch:26 step:50 loss: 0.005642\n",
      "Epoch:26 step:51 loss: 0.007100\n",
      "Epoch:26 step:52 loss: 0.000032\n",
      "Epoch:26 step:53 loss: 0.000164\n",
      "Epoch:26 step:54 loss: 0.046804\n",
      "Epoch:26 step:55 loss: 0.028784\n",
      "Epoch:26 step:56 loss: 0.014885\n",
      "Epoch:26 step:57 loss: 0.000144\n",
      "Epoch:26 step:58 loss: 0.022206\n",
      "Epoch:26 step:59 loss: 0.000011\n",
      "Epoch:26 step:60 loss: 0.038150\n",
      "Epoch:26 step:61 loss: 0.027046\n",
      "Epoch:26 step:62 loss: 0.000001\n",
      "Epoch:26 step:63 loss: 0.002531\n",
      "Epoch:26 step:64 loss: 0.000197\n",
      "Epoch:26 step:65 loss: 0.022891\n",
      "Epoch:26 step:66 loss: 0.000084\n",
      "Epoch:26 step:67 loss: 0.011025\n",
      "Epoch:26 step:68 loss: 0.000003\n",
      "Epoch:26 step:69 loss: 0.000003\n",
      "Epoch:26 step:70 loss: 0.003050\n",
      "Epoch:26 step:71 loss: 0.013647\n",
      "Epoch:26 step:72 loss: 0.010434\n",
      "Epoch:26 step:73 loss: 0.000517\n",
      "Epoch:26 step:74 loss: 0.008011\n",
      "Epoch:26 step:75 loss: 0.003478\n",
      "Epoch:26 step:76 loss: 0.000239\n",
      "Epoch:26 step:77 loss: 0.003213\n",
      "Epoch:26 step:78 loss: 0.019963\n",
      "Epoch:26 step:79 loss: 0.004083\n",
      "Test Epoch:26 step:0 loss: 0.006336tensor(0.2125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:1 loss: 0.005195tensor(0.0363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:2 loss: 0.001313tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:3 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:4 loss: 0.014312tensor(0.3113, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:5 loss: 0.009135tensor(0.2798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:6 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:7 loss: 0.014233tensor(0.2124, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:9 loss: 0.000152tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:10 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:11 loss: 0.007171tensor(0.2782, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:12 loss: 0.009613tensor(0.4095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:13 loss: 0.000315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:14 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:15 loss: 0.000201tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:16 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:17 loss: 0.001489tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:18 loss: 0.007395tensor(0.1775, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:19 loss: 0.017103tensor(0.3278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:20 loss: 0.000130tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:21 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:22 loss: 0.024734tensor(0.3223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:23 loss: 0.002660tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:24 loss: 0.008065tensor(0.3653, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:25 loss: 0.002879tensor(0.0139, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:26 loss: 0.012620tensor(0.3070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:27 loss: 0.024613tensor(0.3940, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:28 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:29 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:30 loss: 0.001097tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:31 loss: 0.000453tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:32 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:34 loss: 0.014808tensor(0.0334, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:35 loss: 0.006918tensor(0.1597, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:36 loss: 0.000135tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:37 loss: 0.002237tensor(0.1247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:38 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:39 loss: 0.002580tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:40 loss: 0.040270tensor(0.3658, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:41 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:42 loss: 0.000159tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:43 loss: 0.015318tensor(0.3583, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:44 loss: 0.001375tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:45 loss: 0.002130tensor(0.2585, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:46 loss: 0.001604tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:47 loss: 0.011332tensor(0.3559, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:48 loss: 0.005079tensor(0.1580, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:49 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:50 loss: 0.004956tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:51 loss: 0.006110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:52 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:53 loss: 0.000217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:54 loss: 0.048613tensor(0.2830, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:55 loss: 0.034088tensor(0.3157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:56 loss: 0.014023tensor(0.3679, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:57 loss: 0.000376tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:58 loss: 0.018039tensor(0.0171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:59 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:60 loss: 0.034024tensor(0.3692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:61 loss: 0.027196tensor(0.0115, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:63 loss: 0.002502tensor(3.8456e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:64 loss: 0.000195tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:65 loss: 0.012171tensor(0.2671, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:66 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:67 loss: 0.010699tensor(0.2776, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:69 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:70 loss: 0.002670tensor(0.1712, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:71 loss: 0.016383tensor(0.2800, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:72 loss: 0.006580tensor(0.2893, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:73 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:74 loss: 0.009694tensor(0.3088, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:75 loss: 0.001469tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:76 loss: 0.000147tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:77 loss: 0.002852tensor(0.0779, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:78 loss: 0.015442tensor(0.3675, grad_fn=<DivBackward0>)\n",
      "Test Epoch:26 step:79 loss: 0.003952tensor(0.3046, grad_fn=<DivBackward0>)\n",
      "Epoch:27 step:0 loss: 0.008251\n",
      "Epoch:27 step:1 loss: 0.005097\n",
      "Epoch:27 step:2 loss: 0.007390\n",
      "Epoch:27 step:3 loss: 0.000046\n",
      "Epoch:27 step:4 loss: 0.012489\n",
      "Epoch:27 step:5 loss: 0.008461\n",
      "Epoch:27 step:6 loss: 0.000003\n",
      "Epoch:27 step:7 loss: 0.014721\n",
      "Epoch:27 step:8 loss: 0.000003\n",
      "Epoch:27 step:9 loss: 0.000097\n",
      "Epoch:27 step:10 loss: 0.000025\n",
      "Epoch:27 step:11 loss: 0.009816\n",
      "Epoch:27 step:12 loss: 0.012832\n",
      "Epoch:27 step:13 loss: 0.000164\n",
      "Epoch:27 step:14 loss: 0.000006\n",
      "Epoch:27 step:15 loss: 0.000221\n",
      "Epoch:27 step:16 loss: 0.000002\n",
      "Epoch:27 step:17 loss: 0.001018\n",
      "Epoch:27 step:18 loss: 0.006781\n",
      "Epoch:27 step:19 loss: 0.014793\n",
      "Epoch:27 step:20 loss: 0.000131\n",
      "Epoch:27 step:21 loss: 0.000003\n",
      "Epoch:27 step:22 loss: 0.022668\n",
      "Epoch:27 step:23 loss: 0.004725\n",
      "Epoch:27 step:24 loss: 0.009986\n",
      "Epoch:27 step:25 loss: 0.003682\n",
      "Epoch:27 step:26 loss: 0.010994\n",
      "Epoch:27 step:27 loss: 0.025235\n",
      "Epoch:27 step:28 loss: 0.000045\n",
      "Epoch:27 step:29 loss: 0.000005\n",
      "Epoch:27 step:30 loss: 0.001112\n",
      "Epoch:27 step:31 loss: 0.000216\n",
      "Epoch:27 step:32 loss: 0.000076\n",
      "Epoch:27 step:33 loss: 0.000004\n",
      "Epoch:27 step:34 loss: 0.019864\n",
      "Epoch:27 step:35 loss: 0.006816\n",
      "Epoch:27 step:36 loss: 0.000134\n",
      "Epoch:27 step:37 loss: 0.001291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27 step:38 loss: 0.000021\n",
      "Epoch:27 step:39 loss: 0.001860\n",
      "Epoch:27 step:40 loss: 0.049250\n",
      "Epoch:27 step:41 loss: 0.000025\n",
      "Epoch:27 step:42 loss: 0.000281\n",
      "Epoch:27 step:43 loss: 0.015078\n",
      "Epoch:27 step:44 loss: 0.000995\n",
      "Epoch:27 step:45 loss: 0.003025\n",
      "Epoch:27 step:46 loss: 0.001732\n",
      "Epoch:27 step:47 loss: 0.012670\n",
      "Epoch:27 step:48 loss: 0.006257\n",
      "Epoch:27 step:49 loss: 0.000149\n",
      "Epoch:27 step:50 loss: 0.006487\n",
      "Epoch:27 step:51 loss: 0.004837\n",
      "Epoch:27 step:52 loss: 0.000056\n",
      "Epoch:27 step:53 loss: 0.000289\n",
      "Epoch:27 step:54 loss: 0.041904\n",
      "Epoch:27 step:55 loss: 0.031486\n",
      "Epoch:27 step:56 loss: 0.011244\n",
      "Epoch:27 step:57 loss: 0.000418\n",
      "Epoch:27 step:58 loss: 0.015867\n",
      "Epoch:27 step:59 loss: 0.000008\n",
      "Epoch:27 step:60 loss: 0.028474\n",
      "Epoch:27 step:61 loss: 0.023434\n",
      "Epoch:27 step:62 loss: 0.000004\n",
      "Epoch:27 step:63 loss: 0.002646\n",
      "Epoch:27 step:64 loss: 0.000339\n",
      "Epoch:27 step:65 loss: 0.009705\n",
      "Epoch:27 step:66 loss: 0.000072\n",
      "Epoch:27 step:67 loss: 0.011875\n",
      "Epoch:27 step:68 loss: 0.000001\n",
      "Epoch:27 step:69 loss: 0.000001\n",
      "Epoch:27 step:70 loss: 0.002503\n",
      "Epoch:27 step:71 loss: 0.013959\n",
      "Epoch:27 step:72 loss: 0.006250\n",
      "Epoch:27 step:73 loss: 0.000224\n",
      "Epoch:27 step:74 loss: 0.006464\n",
      "Epoch:27 step:75 loss: 0.001177\n",
      "Epoch:27 step:76 loss: 0.000142\n",
      "Epoch:27 step:77 loss: 0.001292\n",
      "Epoch:27 step:78 loss: 0.014367\n",
      "Epoch:27 step:79 loss: 0.004398\n",
      "Test Epoch:27 step:0 loss: 0.008370tensor(0.2134, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:1 loss: 0.005673tensor(0.0620, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:2 loss: 0.006385tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:3 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:4 loss: 0.012625tensor(0.3295, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:5 loss: 0.008573tensor(0.2921, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:6 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:7 loss: 0.013496tensor(0.2343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:8 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:9 loss: 0.000455tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:10 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:11 loss: 0.008661tensor(0.2474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:12 loss: 0.014269tensor(0.3788, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:13 loss: 0.000120tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:14 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:15 loss: 0.000268tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:16 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:17 loss: 0.003524tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:18 loss: 0.009049tensor(0.1946, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:19 loss: 0.016960tensor(0.3351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:20 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:21 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:22 loss: 0.025265tensor(0.3279, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:23 loss: 0.003910tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:24 loss: 0.007207tensor(0.3739, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:25 loss: 0.002627tensor(0.0057, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:26 loss: 0.013595tensor(0.3081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:27 loss: 0.024669tensor(0.3983, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:28 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:29 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:30 loss: 0.001507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:31 loss: 0.000736tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:32 loss: 0.000180tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:34 loss: 0.009814tensor(0.1602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:35 loss: 0.005617tensor(0.2000, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:36 loss: 0.000171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:37 loss: 0.001486tensor(0.1324, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:38 loss: 0.000082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:39 loss: 0.002457tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:40 loss: 0.032251tensor(0.3821, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:41 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:42 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:43 loss: 0.017935tensor(0.3579, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:44 loss: 0.000125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:45 loss: 0.001438tensor(0.3025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:46 loss: 0.000296tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:47 loss: 0.011038tensor(0.3692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:48 loss: 0.003479tensor(0.1918, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:49 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:50 loss: 0.001077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:51 loss: 0.001956tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:52 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:53 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:54 loss: 0.035324tensor(0.3144, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:55 loss: 0.027683tensor(0.3368, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:56 loss: 0.010416tensor(0.3853, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:57 loss: 0.002141tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:58 loss: 0.019169tensor(0.0286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:59 loss: 0.000152tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:60 loss: 0.027654tensor(0.3820, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:61 loss: 0.014593tensor(0.1000, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:63 loss: 0.002065tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:64 loss: 0.001528tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:65 loss: 0.006773tensor(0.3529, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:66 loss: 0.000174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:67 loss: 0.009097tensor(0.3110, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:70 loss: 0.002661tensor(0.2002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:71 loss: 0.012630tensor(0.3284, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:72 loss: 0.004822tensor(0.3185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:73 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:74 loss: 0.006395tensor(0.3463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:75 loss: 0.001003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:76 loss: 0.000098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:77 loss: 0.001542tensor(0.0176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:78 loss: 0.016821tensor(0.3648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:27 step:79 loss: 0.005055tensor(0.2779, grad_fn=<DivBackward0>)\n",
      "Epoch:28 step:0 loss: 0.009006\n",
      "Epoch:28 step:1 loss: 0.004267\n",
      "Epoch:28 step:2 loss: 0.006547\n",
      "Epoch:28 step:3 loss: 0.000068\n",
      "Epoch:28 step:4 loss: 0.012142\n",
      "Epoch:28 step:5 loss: 0.010514\n",
      "Epoch:28 step:6 loss: 0.000015\n",
      "Epoch:28 step:7 loss: 0.010548\n",
      "Epoch:28 step:8 loss: 0.000003\n",
      "Epoch:28 step:9 loss: 0.000203\n",
      "Epoch:28 step:10 loss: 0.000021\n",
      "Epoch:28 step:11 loss: 0.009104\n",
      "Epoch:28 step:12 loss: 0.012957\n",
      "Epoch:28 step:13 loss: 0.000166\n",
      "Epoch:28 step:14 loss: 0.000003\n",
      "Epoch:28 step:15 loss: 0.000158\n",
      "Epoch:28 step:16 loss: 0.000001\n",
      "Epoch:28 step:17 loss: 0.000548\n",
      "Epoch:28 step:18 loss: 0.007757\n",
      "Epoch:28 step:19 loss: 0.015012\n",
      "Epoch:28 step:20 loss: 0.000087\n",
      "Epoch:28 step:21 loss: 0.000001\n",
      "Epoch:28 step:22 loss: 0.029037\n",
      "Epoch:28 step:23 loss: 0.005182\n",
      "Epoch:28 step:24 loss: 0.009974\n",
      "Epoch:28 step:25 loss: 0.004119\n",
      "Epoch:28 step:26 loss: 0.012025\n",
      "Epoch:28 step:27 loss: 0.022318\n",
      "Epoch:28 step:28 loss: 0.000083\n",
      "Epoch:28 step:29 loss: 0.000003\n",
      "Epoch:28 step:30 loss: 0.001038\n",
      "Epoch:28 step:31 loss: 0.000235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28 step:32 loss: 0.000056\n",
      "Epoch:28 step:33 loss: 0.000001\n",
      "Epoch:28 step:34 loss: 0.010035\n",
      "Epoch:28 step:35 loss: 0.007710\n",
      "Epoch:28 step:36 loss: 0.000184\n",
      "Epoch:28 step:37 loss: 0.001737\n",
      "Epoch:28 step:38 loss: 0.000014\n",
      "Epoch:28 step:39 loss: 0.001920\n",
      "Epoch:28 step:40 loss: 0.033433\n",
      "Epoch:28 step:41 loss: 0.000002\n",
      "Epoch:28 step:42 loss: 0.000066\n",
      "Epoch:28 step:43 loss: 0.014360\n",
      "Epoch:28 step:44 loss: 0.000151\n",
      "Epoch:28 step:45 loss: 0.001797\n",
      "Epoch:28 step:46 loss: 0.000671\n",
      "Epoch:28 step:47 loss: 0.010885\n",
      "Epoch:28 step:48 loss: 0.005446\n",
      "Epoch:28 step:49 loss: 0.000045\n",
      "Epoch:28 step:50 loss: 0.002418\n",
      "Epoch:28 step:51 loss: 0.002442\n",
      "Epoch:28 step:52 loss: 0.000031\n",
      "Epoch:28 step:53 loss: 0.000120\n",
      "Epoch:28 step:54 loss: 0.045667\n",
      "Epoch:28 step:55 loss: 0.028688\n",
      "Epoch:28 step:56 loss: 0.011166\n",
      "Epoch:28 step:57 loss: 0.001648\n",
      "Epoch:28 step:58 loss: 0.020196\n",
      "Epoch:28 step:59 loss: 0.000027\n",
      "Epoch:28 step:60 loss: 0.034444\n",
      "Epoch:28 step:61 loss: 0.017265\n",
      "Epoch:28 step:62 loss: 0.000007\n",
      "Epoch:28 step:63 loss: 0.002378\n",
      "Epoch:28 step:64 loss: 0.000387\n",
      "Epoch:28 step:65 loss: 0.007848\n",
      "Epoch:28 step:66 loss: 0.000062\n",
      "Epoch:28 step:67 loss: 0.011433\n",
      "Epoch:28 step:68 loss: 0.000009\n",
      "Epoch:28 step:69 loss: 0.000001\n",
      "Epoch:28 step:70 loss: 0.003504\n",
      "Epoch:28 step:71 loss: 0.021006\n",
      "Epoch:28 step:72 loss: 0.004964\n",
      "Epoch:28 step:73 loss: 0.000142\n",
      "Epoch:28 step:74 loss: 0.005391\n",
      "Epoch:28 step:75 loss: 0.001256\n",
      "Epoch:28 step:76 loss: 0.000217\n",
      "Epoch:28 step:77 loss: 0.001537\n",
      "Epoch:28 step:78 loss: 0.015745\n",
      "Epoch:28 step:79 loss: 0.006576\n",
      "Test Epoch:28 step:0 loss: 0.009495tensor(0.2023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:1 loss: 0.004151tensor(0.0908, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:2 loss: 0.012239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:3 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:4 loss: 0.013391tensor(0.3305, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:5 loss: 0.007126tensor(0.3023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:7 loss: 0.011416tensor(0.2245, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:8 loss: 0.001097tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:9 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:11 loss: 0.010677tensor(0.2021, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:12 loss: 0.013783tensor(0.3855, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:13 loss: 0.000150tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:14 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:15 loss: 0.000396tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:16 loss: 0.000870tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:17 loss: 0.001222tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:18 loss: 0.006796tensor(0.1920, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:19 loss: 0.014250tensor(0.3450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:20 loss: 0.000181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:21 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:22 loss: 0.024793tensor(0.3321, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:23 loss: 0.005823tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:24 loss: 0.011357tensor(0.3389, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:25 loss: 0.002724tensor(0.0123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:26 loss: 0.013553tensor(0.3124, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:27 loss: 0.022922tensor(0.4029, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:28 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:30 loss: 0.000479tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:31 loss: 0.000110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:32 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:33 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:34 loss: 0.010737tensor(0.0837, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:35 loss: 0.007162tensor(0.1875, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:36 loss: 0.000288tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:37 loss: 0.001640tensor(0.0358, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:38 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:39 loss: 0.001031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:40 loss: 0.040474tensor(0.3776, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:41 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:42 loss: 0.000139tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:43 loss: 0.015128tensor(0.3648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:44 loss: 0.000282tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:45 loss: 0.003119tensor(0.2303, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:46 loss: 0.001114tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:47 loss: 0.010452tensor(0.3701, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:48 loss: 0.005102tensor(0.1802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:49 loss: 0.000154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:50 loss: 0.004181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:51 loss: 0.003048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:52 loss: 0.000078tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:53 loss: 0.000460tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:54 loss: 0.041227tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:55 loss: 0.031565tensor(0.3260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:56 loss: 0.010922tensor(0.3900, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:57 loss: 0.000839tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:58 loss: 0.018721tensor(0.0208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:59 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:60 loss: 0.024916tensor(0.3923, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:61 loss: 0.025957tensor(0.0104, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:63 loss: 0.002677tensor(2.9487e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:64 loss: 0.000423tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:65 loss: 0.011636tensor(0.2762, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:66 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:67 loss: 0.013539tensor(0.2523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:69 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:70 loss: 0.002866tensor(0.1773, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:71 loss: 0.010491tensor(0.3313, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:72 loss: 0.004580tensor(0.3235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:73 loss: 0.001095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:74 loss: 0.005850tensor(0.3509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:75 loss: 0.000910tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:76 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:77 loss: 0.001998tensor(0.0934, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:78 loss: 0.015360tensor(0.3761, grad_fn=<DivBackward0>)\n",
      "Test Epoch:28 step:79 loss: 0.003532tensor(0.3171, grad_fn=<DivBackward0>)\n",
      "Epoch:29 step:0 loss: 0.006227\n",
      "Epoch:29 step:1 loss: 0.005437\n",
      "Epoch:29 step:2 loss: 0.004593\n",
      "Epoch:29 step:3 loss: 0.000029\n",
      "Epoch:29 step:4 loss: 0.012531\n",
      "Epoch:29 step:5 loss: 0.006892\n",
      "Epoch:29 step:6 loss: 0.000002\n",
      "Epoch:29 step:7 loss: 0.013630\n",
      "Epoch:29 step:8 loss: 0.000070\n",
      "Epoch:29 step:9 loss: 0.000342\n",
      "Epoch:29 step:10 loss: 0.000197\n",
      "Epoch:29 step:11 loss: 0.006048\n",
      "Epoch:29 step:12 loss: 0.012517\n",
      "Epoch:29 step:13 loss: 0.000194\n",
      "Epoch:29 step:14 loss: 0.000008\n",
      "Epoch:29 step:15 loss: 0.000234\n",
      "Epoch:29 step:16 loss: 0.000056\n",
      "Epoch:29 step:17 loss: 0.002394\n",
      "Epoch:29 step:18 loss: 0.008323\n",
      "Epoch:29 step:19 loss: 0.013820\n",
      "Epoch:29 step:20 loss: 0.000182\n",
      "Epoch:29 step:21 loss: 0.000818\n",
      "Epoch:29 step:22 loss: 0.025342\n",
      "Epoch:29 step:23 loss: 0.002484\n",
      "Epoch:29 step:24 loss: 0.012972\n",
      "Epoch:29 step:25 loss: 0.002322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29 step:26 loss: 0.013479\n",
      "Epoch:29 step:27 loss: 0.024526\n",
      "Epoch:29 step:28 loss: 0.000087\n",
      "Epoch:29 step:29 loss: 0.000008\n",
      "Epoch:29 step:30 loss: 0.001236\n",
      "Epoch:29 step:31 loss: 0.000670\n",
      "Epoch:29 step:32 loss: 0.000276\n",
      "Epoch:29 step:33 loss: 0.000012\n",
      "Epoch:29 step:34 loss: 0.009288\n",
      "Epoch:29 step:35 loss: 0.006080\n",
      "Epoch:29 step:36 loss: 0.000041\n",
      "Epoch:29 step:37 loss: 0.001290\n",
      "Epoch:29 step:38 loss: 0.000015\n",
      "Epoch:29 step:39 loss: 0.011903\n",
      "Epoch:29 step:40 loss: 0.031611\n",
      "Epoch:29 step:41 loss: 0.000033\n",
      "Epoch:29 step:42 loss: 0.000050\n",
      "Epoch:29 step:43 loss: 0.019293\n",
      "Epoch:29 step:44 loss: 0.000134\n",
      "Epoch:29 step:45 loss: 0.001761\n",
      "Epoch:29 step:46 loss: 0.000471\n",
      "Epoch:29 step:47 loss: 0.011793\n",
      "Epoch:29 step:48 loss: 0.004267\n",
      "Epoch:29 step:49 loss: 0.000048\n",
      "Epoch:29 step:50 loss: 0.003461\n",
      "Epoch:29 step:51 loss: 0.003048\n",
      "Epoch:29 step:52 loss: 0.000036\n",
      "Epoch:29 step:53 loss: 0.000375\n",
      "Epoch:29 step:54 loss: 0.032763\n",
      "Epoch:29 step:55 loss: 0.025010\n",
      "Epoch:29 step:56 loss: 0.013370\n",
      "Epoch:29 step:57 loss: 0.000652\n",
      "Epoch:29 step:58 loss: 0.011217\n",
      "Epoch:29 step:59 loss: 0.000054\n",
      "Epoch:29 step:60 loss: 0.032864\n",
      "Epoch:29 step:61 loss: 0.017074\n",
      "Epoch:29 step:62 loss: 0.000004\n",
      "Epoch:29 step:63 loss: 0.002196\n",
      "Epoch:29 step:64 loss: 0.001648\n",
      "Epoch:29 step:65 loss: 0.005664\n",
      "Epoch:29 step:66 loss: 0.000191\n",
      "Epoch:29 step:67 loss: 0.008123\n",
      "Epoch:29 step:68 loss: 0.000002\n",
      "Epoch:29 step:69 loss: 0.000011\n",
      "Epoch:29 step:70 loss: 0.004408\n",
      "Epoch:29 step:71 loss: 0.027412\n",
      "Epoch:29 step:72 loss: 0.004336\n",
      "Epoch:29 step:73 loss: 0.000017\n",
      "Epoch:29 step:74 loss: 0.012398\n",
      "Epoch:29 step:75 loss: 0.000094\n",
      "Epoch:29 step:76 loss: 0.000056\n",
      "Epoch:29 step:77 loss: 0.003061\n",
      "Epoch:29 step:78 loss: 0.026413\n",
      "Epoch:29 step:79 loss: 0.005000\n",
      "Test Epoch:29 step:0 loss: 0.008893tensor(0.1056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:1 loss: 0.007643tensor(0.0633, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:2 loss: 0.003465tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:3 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:4 loss: 0.015212tensor(0.2818, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:5 loss: 0.006399tensor(0.3199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:6 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:7 loss: 0.015397tensor(0.2565, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:8 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:9 loss: 0.001864tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:10 loss: 0.000179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:11 loss: 0.006254tensor(0.2855, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:12 loss: 0.011986tensor(0.3881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:13 loss: 0.000965tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:14 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:15 loss: 0.000372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:16 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:17 loss: 0.001151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:18 loss: 0.008059tensor(0.1607, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:19 loss: 0.017943tensor(0.3126, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:20 loss: 0.000146tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:21 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:22 loss: 0.043533tensor(0.2230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:23 loss: 0.004796tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:24 loss: 0.011120tensor(0.3225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:25 loss: 0.002139tensor(0.0144, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:26 loss: 0.030232tensor(0.2454, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:27 loss: 0.027888tensor(0.3786, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:28 loss: 0.000166tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:29 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:30 loss: 0.002572tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:31 loss: 0.000282tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:32 loss: 0.000224tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:33 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:34 loss: 0.010561tensor(0.0961, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:35 loss: 0.011480tensor(0.0928, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:36 loss: 0.000123tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:37 loss: 0.001460tensor(0.0849, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:38 loss: 0.000150tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:39 loss: 0.002113tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:40 loss: 0.038219tensor(0.3753, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:41 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:42 loss: 0.000430tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:43 loss: 0.013443tensor(0.3814, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:44 loss: 0.000474tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:45 loss: 0.003520tensor(0.1787, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:46 loss: 0.003333tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:47 loss: 0.014668tensor(0.3392, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:48 loss: 0.003631tensor(0.1821, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:49 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:50 loss: 0.001603tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:51 loss: 0.001181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:52 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:53 loss: 0.000365tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:54 loss: 0.033117tensor(0.3182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:55 loss: 0.022568tensor(0.3459, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:56 loss: 0.011066tensor(0.3889, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:57 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:58 loss: 0.011063tensor(0.0877, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:59 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:60 loss: 0.023899tensor(0.3972, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:61 loss: 0.019691tensor(0.0505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:62 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:63 loss: 0.002926tensor(2.0178e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:64 loss: 0.002959tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:65 loss: 0.008324tensor(0.3313, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:66 loss: 0.000515tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:67 loss: 0.009534tensor(0.3168, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:69 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:70 loss: 0.002578tensor(0.1906, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:71 loss: 0.010015tensor(0.3298, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:72 loss: 0.007829tensor(0.2871, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:73 loss: 0.000512tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:74 loss: 0.004921tensor(0.3794, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:75 loss: 0.001098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:76 loss: 0.000065tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:77 loss: 0.001528tensor(0.0243, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:78 loss: 0.018487tensor(0.3594, grad_fn=<DivBackward0>)\n",
      "Test Epoch:29 step:79 loss: 0.004317tensor(0.2887, grad_fn=<DivBackward0>)\n",
      "Epoch:30 step:0 loss: 0.005308\n",
      "Epoch:30 step:1 loss: 0.004294\n",
      "Epoch:30 step:2 loss: 0.001576\n",
      "Epoch:30 step:3 loss: 0.000041\n",
      "Epoch:30 step:4 loss: 0.014380\n",
      "Epoch:30 step:5 loss: 0.006442\n",
      "Epoch:30 step:6 loss: 0.000006\n",
      "Epoch:30 step:7 loss: 0.009709\n",
      "Epoch:30 step:8 loss: 0.000059\n",
      "Epoch:30 step:9 loss: 0.000119\n",
      "Epoch:30 step:10 loss: 0.000163\n",
      "Epoch:30 step:11 loss: 0.006914\n",
      "Epoch:30 step:12 loss: 0.010130\n",
      "Epoch:30 step:13 loss: 0.002111\n",
      "Epoch:30 step:14 loss: 0.000004\n",
      "Epoch:30 step:15 loss: 0.000583\n",
      "Epoch:30 step:16 loss: 0.000062\n",
      "Epoch:30 step:17 loss: 0.000610\n",
      "Epoch:30 step:18 loss: 0.006471\n",
      "Epoch:30 step:19 loss: 0.012788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30 step:20 loss: 0.000114\n",
      "Epoch:30 step:21 loss: 0.000020\n",
      "Epoch:30 step:22 loss: 0.024596\n",
      "Epoch:30 step:23 loss: 0.001846\n",
      "Epoch:30 step:24 loss: 0.007433\n",
      "Epoch:30 step:25 loss: 0.001520\n",
      "Epoch:30 step:26 loss: 0.013048\n",
      "Epoch:30 step:27 loss: 0.019855\n",
      "Epoch:30 step:28 loss: 0.000218\n",
      "Epoch:30 step:29 loss: 0.000028\n",
      "Epoch:30 step:30 loss: 0.000733\n",
      "Epoch:30 step:31 loss: 0.000748\n",
      "Epoch:30 step:32 loss: 0.000118\n",
      "Epoch:30 step:33 loss: 0.000005\n",
      "Epoch:30 step:34 loss: 0.007119\n",
      "Epoch:30 step:35 loss: 0.005426\n",
      "Epoch:30 step:36 loss: 0.000105\n",
      "Epoch:30 step:37 loss: 0.001352\n",
      "Epoch:30 step:38 loss: 0.000225\n",
      "Epoch:30 step:39 loss: 0.000449\n",
      "Epoch:30 step:40 loss: 0.036861\n",
      "Epoch:30 step:41 loss: 0.000006\n",
      "Epoch:30 step:42 loss: 0.000133\n",
      "Epoch:30 step:43 loss: 0.015143\n",
      "Epoch:30 step:44 loss: 0.000085\n",
      "Epoch:30 step:45 loss: 0.002163\n",
      "Epoch:30 step:46 loss: 0.000838\n",
      "Epoch:30 step:47 loss: 0.009308\n",
      "Epoch:30 step:48 loss: 0.005893\n",
      "Epoch:30 step:49 loss: 0.000046\n",
      "Epoch:30 step:50 loss: 0.001788\n",
      "Epoch:30 step:51 loss: 0.002079\n",
      "Epoch:30 step:52 loss: 0.000040\n",
      "Epoch:30 step:53 loss: 0.000115\n",
      "Epoch:30 step:54 loss: 0.042363\n",
      "Epoch:30 step:55 loss: 0.033290\n",
      "Epoch:30 step:56 loss: 0.010741\n",
      "Epoch:30 step:57 loss: 0.000169\n",
      "Epoch:30 step:58 loss: 0.007166\n",
      "Epoch:30 step:59 loss: 0.000003\n",
      "Epoch:30 step:60 loss: 0.047111\n",
      "Epoch:30 step:61 loss: 0.025473\n",
      "Epoch:30 step:62 loss: 0.000005\n",
      "Epoch:30 step:63 loss: 0.002476\n",
      "Epoch:30 step:64 loss: 0.000735\n",
      "Epoch:30 step:65 loss: 0.008762\n",
      "Epoch:30 step:66 loss: 0.000111\n",
      "Epoch:30 step:67 loss: 0.008873\n",
      "Epoch:30 step:68 loss: 0.000001\n",
      "Epoch:30 step:69 loss: 0.000003\n",
      "Epoch:30 step:70 loss: 0.002362\n",
      "Epoch:30 step:71 loss: 0.010044\n",
      "Epoch:30 step:72 loss: 0.007151\n",
      "Epoch:30 step:73 loss: 0.000573\n",
      "Epoch:30 step:74 loss: 0.005419\n",
      "Epoch:30 step:75 loss: 0.000699\n",
      "Epoch:30 step:76 loss: 0.000079\n",
      "Epoch:30 step:77 loss: 0.002582\n",
      "Epoch:30 step:78 loss: 0.016445\n",
      "Epoch:30 step:79 loss: 0.003840\n",
      "Test Epoch:30 step:0 loss: 0.005813tensor(0.2387, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:1 loss: 0.004076tensor(0.0718, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:2 loss: 0.001511tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:3 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:4 loss: 0.014914tensor(0.3192, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:5 loss: 0.010805tensor(0.2385, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:7 loss: 0.009150tensor(0.2718, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:8 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:9 loss: 0.000151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:10 loss: 0.000140tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:11 loss: 0.006474tensor(0.2915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:12 loss: 0.008892tensor(0.4186, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:13 loss: 0.001162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:14 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:15 loss: 0.000424tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:16 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:17 loss: 0.000503tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:18 loss: 0.007583tensor(0.2212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:19 loss: 0.018240tensor(0.3208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:20 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:21 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:22 loss: 0.023438tensor(0.3344, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:23 loss: 0.003782tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:24 loss: 0.009490tensor(0.3593, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:25 loss: 0.001909tensor(0.0540, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:26 loss: 0.013035tensor(0.3143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:27 loss: 0.020554tensor(0.4100, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:28 loss: 0.000099tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:29 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:30 loss: 0.001019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:31 loss: 0.002501tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:32 loss: 0.000166tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:33 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:34 loss: 0.009794tensor(0.1194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:35 loss: 0.004610tensor(0.2408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:36 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:37 loss: 0.001339tensor(0.1558, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:38 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:39 loss: 0.001105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:40 loss: 0.033330tensor(0.3900, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:41 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:42 loss: 0.000103tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:43 loss: 0.015475tensor(0.3833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:44 loss: 0.000583tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:45 loss: 0.002300tensor(0.2715, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:46 loss: 0.001418tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:47 loss: 0.009745tensor(0.3858, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:48 loss: 0.004349tensor(0.1817, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:49 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:50 loss: 0.003126tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:51 loss: 0.004529tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:52 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:53 loss: 0.000730tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:54 loss: 0.031590tensor(0.3266, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:55 loss: 0.025766tensor(0.3446, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:56 loss: 0.008991tensor(0.4064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:57 loss: 0.000596tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:58 loss: 0.007605tensor(0.1519, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:59 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:60 loss: 0.021356tensor(0.4119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:61 loss: 0.019587tensor(0.0646, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:62 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:63 loss: 0.003037tensor(9.9442e-06, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:64 loss: 0.000628tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:65 loss: 0.005092tensor(0.3914, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:66 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:67 loss: 0.012564tensor(0.2881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:70 loss: 0.003099tensor(0.1749, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:71 loss: 0.017558tensor(0.2611, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:72 loss: 0.004968tensor(0.3346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:73 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:74 loss: 0.004989tensor(0.3814, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:75 loss: 0.000344tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:76 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:77 loss: 0.001200tensor(0.0653, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:78 loss: 0.013123tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:30 step:79 loss: 0.003053tensor(0.3314, grad_fn=<DivBackward0>)\n",
      "Epoch:31 step:0 loss: 0.006102\n",
      "Epoch:31 step:1 loss: 0.003388\n",
      "Epoch:31 step:2 loss: 0.007195\n",
      "Epoch:31 step:3 loss: 0.000017\n",
      "Epoch:31 step:4 loss: 0.013042\n",
      "Epoch:31 step:5 loss: 0.008386\n",
      "Epoch:31 step:6 loss: 0.000005\n",
      "Epoch:31 step:7 loss: 0.011088\n",
      "Epoch:31 step:8 loss: 0.000015\n",
      "Epoch:31 step:9 loss: 0.000060\n",
      "Epoch:31 step:10 loss: 0.000050\n",
      "Epoch:31 step:11 loss: 0.007596\n",
      "Epoch:31 step:12 loss: 0.010478\n",
      "Epoch:31 step:13 loss: 0.000221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31 step:14 loss: 0.000008\n",
      "Epoch:31 step:15 loss: 0.000557\n",
      "Epoch:31 step:16 loss: 0.000025\n",
      "Epoch:31 step:17 loss: 0.000616\n",
      "Epoch:31 step:18 loss: 0.005987\n",
      "Epoch:31 step:19 loss: 0.015057\n",
      "Epoch:31 step:20 loss: 0.000055\n",
      "Epoch:31 step:21 loss: 0.000016\n",
      "Epoch:31 step:22 loss: 0.023346\n",
      "Epoch:31 step:23 loss: 0.000856\n",
      "Epoch:31 step:24 loss: 0.007216\n",
      "Epoch:31 step:25 loss: 0.001958\n",
      "Epoch:31 step:26 loss: 0.010427\n",
      "Epoch:31 step:27 loss: 0.021097\n",
      "Epoch:31 step:28 loss: 0.000065\n",
      "Epoch:31 step:29 loss: 0.000005\n",
      "Epoch:31 step:30 loss: 0.000221\n",
      "Epoch:31 step:31 loss: 0.000339\n",
      "Epoch:31 step:32 loss: 0.000127\n",
      "Epoch:31 step:33 loss: 0.000011\n",
      "Epoch:31 step:34 loss: 0.007853\n",
      "Epoch:31 step:35 loss: 0.004628\n",
      "Epoch:31 step:36 loss: 0.000208\n",
      "Epoch:31 step:37 loss: 0.002608\n",
      "Epoch:31 step:38 loss: 0.000017\n",
      "Epoch:31 step:39 loss: 0.000554\n",
      "Epoch:31 step:40 loss: 0.024740\n",
      "Epoch:31 step:41 loss: 0.000072\n",
      "Epoch:31 step:42 loss: 0.000024\n",
      "Epoch:31 step:43 loss: 0.012874\n",
      "Epoch:31 step:44 loss: 0.000059\n",
      "Epoch:31 step:45 loss: 0.001427\n",
      "Epoch:31 step:46 loss: 0.000139\n",
      "Epoch:31 step:47 loss: 0.010097\n",
      "Epoch:31 step:48 loss: 0.003570\n",
      "Epoch:31 step:49 loss: 0.000008\n",
      "Epoch:31 step:50 loss: 0.001149\n",
      "Epoch:31 step:51 loss: 0.001897\n",
      "Epoch:31 step:52 loss: 0.000007\n",
      "Epoch:31 step:53 loss: 0.000083\n",
      "Epoch:31 step:54 loss: 0.025587\n",
      "Epoch:31 step:55 loss: 0.021004\n",
      "Epoch:31 step:56 loss: 0.009614\n",
      "Epoch:31 step:57 loss: 0.003855\n",
      "Epoch:31 step:58 loss: 0.010639\n",
      "Epoch:31 step:59 loss: 0.000307\n",
      "Epoch:31 step:60 loss: 0.018248\n",
      "Epoch:31 step:61 loss: 0.009856\n",
      "Epoch:31 step:62 loss: 0.000013\n",
      "Epoch:31 step:63 loss: 0.002664\n",
      "Epoch:31 step:64 loss: 0.003657\n",
      "Epoch:31 step:65 loss: 0.004921\n",
      "Epoch:31 step:66 loss: 0.000228\n",
      "Epoch:31 step:67 loss: 0.010494\n",
      "Epoch:31 step:68 loss: 0.000000\n",
      "Epoch:31 step:69 loss: 0.000001\n",
      "Epoch:31 step:70 loss: 0.003500\n",
      "Epoch:31 step:71 loss: 0.010104\n",
      "Epoch:31 step:72 loss: 0.003202\n",
      "Epoch:31 step:73 loss: 0.000223\n",
      "Epoch:31 step:74 loss: 0.007365\n",
      "Epoch:31 step:75 loss: 0.000283\n",
      "Epoch:31 step:76 loss: 0.000053\n",
      "Epoch:31 step:77 loss: 0.001315\n",
      "Epoch:31 step:78 loss: 0.013147\n",
      "Epoch:31 step:79 loss: 0.003673\n",
      "Test Epoch:31 step:0 loss: 0.005639tensor(0.2176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:1 loss: 0.006187tensor(0.0867, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:2 loss: 0.002910tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:3 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:4 loss: 0.014303tensor(0.3299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:5 loss: 0.007232tensor(0.3281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:6 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:7 loss: 0.009003tensor(0.2932, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:8 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:9 loss: 0.000588tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:10 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:11 loss: 0.004894tensor(0.3318, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:12 loss: 0.008384tensor(0.4287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:13 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:14 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:15 loss: 0.000230tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:16 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:17 loss: 0.000230tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:18 loss: 0.005769tensor(0.2455, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:19 loss: 0.011547tensor(0.3749, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:20 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:22 loss: 0.029573tensor(0.3164, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:23 loss: 0.006787tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:24 loss: 0.015562tensor(0.3240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:25 loss: 0.001468tensor(0.0650, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:26 loss: 0.012086tensor(0.3418, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:27 loss: 0.019706tensor(0.4150, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:28 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:29 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:30 loss: 0.000493tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:31 loss: 0.000226tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:32 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:33 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:34 loss: 0.011853tensor(0.0799, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:35 loss: 0.012439tensor(0.0924, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:36 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:37 loss: 0.002395tensor(0.0090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:38 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:39 loss: 0.000712tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:40 loss: 0.032094tensor(0.3952, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:41 loss: 0.000164tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:42 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:43 loss: 0.025529tensor(0.3258, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:44 loss: 0.000245tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:45 loss: 0.003112tensor(0.1874, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:46 loss: 0.001487tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:47 loss: 0.009676tensor(0.3839, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:48 loss: 0.005750tensor(0.1638, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:49 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:50 loss: 0.004753tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:51 loss: 0.001199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:52 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:53 loss: 0.000172tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:54 loss: 0.026786tensor(0.3324, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:55 loss: 0.027272tensor(0.3276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:56 loss: 0.010878tensor(0.3914, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:57 loss: 0.000243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:58 loss: 0.021616tensor(0.0287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:59 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:60 loss: 0.018888tensor(0.4167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:61 loss: 0.027347tensor(0.0378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:63 loss: 0.002495tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:64 loss: 0.002445tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:65 loss: 0.005885tensor(0.3765, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:66 loss: 0.000359tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:67 loss: 0.007854tensor(0.3398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:68 loss: 0.000057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:69 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:70 loss: 0.003130tensor(0.1476, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:71 loss: 0.010562tensor(0.3381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:72 loss: 0.015384tensor(0.2174, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:73 loss: 0.000323tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:74 loss: 0.005513tensor(0.3741, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:75 loss: 0.000595tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:76 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:77 loss: 0.003326tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:78 loss: 0.023056tensor(0.3489, grad_fn=<DivBackward0>)\n",
      "Test Epoch:31 step:79 loss: 0.007259tensor(0.2237, grad_fn=<DivBackward0>)\n",
      "Epoch:32 step:0 loss: 0.006733\n",
      "Epoch:32 step:1 loss: 0.006171\n",
      "Epoch:32 step:2 loss: 0.000890\n",
      "Epoch:32 step:3 loss: 0.000017\n",
      "Epoch:32 step:4 loss: 0.013473\n",
      "Epoch:32 step:5 loss: 0.005804\n",
      "Epoch:32 step:6 loss: 0.000006\n",
      "Epoch:32 step:7 loss: 0.008316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:32 step:8 loss: 0.000051\n",
      "Epoch:32 step:9 loss: 0.000908\n",
      "Epoch:32 step:10 loss: 0.000012\n",
      "Epoch:32 step:11 loss: 0.006500\n",
      "Epoch:32 step:12 loss: 0.008271\n",
      "Epoch:32 step:13 loss: 0.000435\n",
      "Epoch:32 step:14 loss: 0.000012\n",
      "Epoch:32 step:15 loss: 0.000786\n",
      "Epoch:32 step:16 loss: 0.000055\n",
      "Epoch:32 step:17 loss: 0.000556\n",
      "Epoch:32 step:18 loss: 0.008854\n",
      "Epoch:32 step:19 loss: 0.015645\n",
      "Epoch:32 step:20 loss: 0.000024\n",
      "Epoch:32 step:21 loss: 0.000004\n",
      "Epoch:32 step:22 loss: 0.018305\n",
      "Epoch:32 step:23 loss: 0.004451\n",
      "Epoch:32 step:24 loss: 0.006290\n",
      "Epoch:32 step:25 loss: 0.003986\n",
      "Epoch:32 step:26 loss: 0.010009\n",
      "Epoch:32 step:27 loss: 0.020818\n",
      "Epoch:32 step:28 loss: 0.000065\n",
      "Epoch:32 step:29 loss: 0.000001\n",
      "Epoch:32 step:30 loss: 0.002796\n",
      "Epoch:32 step:31 loss: 0.000649\n",
      "Epoch:32 step:32 loss: 0.000083\n",
      "Epoch:32 step:33 loss: 0.000142\n",
      "Epoch:32 step:34 loss: 0.010165\n",
      "Epoch:32 step:35 loss: 0.006535\n",
      "Epoch:32 step:36 loss: 0.000029\n",
      "Epoch:32 step:37 loss: 0.001258\n",
      "Epoch:32 step:38 loss: 0.000017\n",
      "Epoch:32 step:39 loss: 0.001527\n",
      "Epoch:32 step:40 loss: 0.025444\n",
      "Epoch:32 step:41 loss: 0.000022\n",
      "Epoch:32 step:42 loss: 0.000195\n",
      "Epoch:32 step:43 loss: 0.013434\n",
      "Epoch:32 step:44 loss: 0.000171\n",
      "Epoch:32 step:45 loss: 0.001630\n",
      "Epoch:32 step:46 loss: 0.000351\n",
      "Epoch:32 step:47 loss: 0.010536\n",
      "Epoch:32 step:48 loss: 0.004756\n",
      "Epoch:32 step:49 loss: 0.000032\n",
      "Epoch:32 step:50 loss: 0.001129\n",
      "Epoch:32 step:51 loss: 0.002734\n",
      "Epoch:32 step:52 loss: 0.000023\n",
      "Epoch:32 step:53 loss: 0.000137\n",
      "Epoch:32 step:54 loss: 0.028444\n",
      "Epoch:32 step:55 loss: 0.020290\n",
      "Epoch:32 step:56 loss: 0.008876\n",
      "Epoch:32 step:57 loss: 0.003439\n",
      "Epoch:32 step:58 loss: 0.024804\n",
      "Epoch:32 step:59 loss: 0.000057\n",
      "Epoch:32 step:60 loss: 0.025036\n",
      "Epoch:32 step:61 loss: 0.015071\n",
      "Epoch:32 step:62 loss: 0.000005\n",
      "Epoch:32 step:63 loss: 0.002784\n",
      "Epoch:32 step:64 loss: 0.001670\n",
      "Epoch:32 step:65 loss: 0.009317\n",
      "Epoch:32 step:66 loss: 0.000044\n",
      "Epoch:32 step:67 loss: 0.015015\n",
      "Epoch:32 step:68 loss: 0.000001\n",
      "Epoch:32 step:69 loss: 0.000003\n",
      "Epoch:32 step:70 loss: 0.004195\n",
      "Epoch:32 step:71 loss: 0.011098\n",
      "Epoch:32 step:72 loss: 0.004497\n",
      "Epoch:32 step:73 loss: 0.000060\n",
      "Epoch:32 step:74 loss: 0.004747\n",
      "Epoch:32 step:75 loss: 0.000923\n",
      "Epoch:32 step:76 loss: 0.000121\n",
      "Epoch:32 step:77 loss: 0.001143\n",
      "Epoch:32 step:78 loss: 0.014407\n",
      "Epoch:32 step:79 loss: 0.004023\n",
      "Test Epoch:32 step:0 loss: 0.005798tensor(0.2240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:1 loss: 0.004505tensor(0.0950, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:2 loss: 0.004444tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:3 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:4 loss: 0.011414tensor(0.3466, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:5 loss: 0.005711tensor(0.3471, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:6 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:7 loss: 0.013753tensor(0.2657, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:8 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:9 loss: 0.001120tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:10 loss: 0.000477tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:11 loss: 0.005596tensor(0.3148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:12 loss: 0.027257tensor(0.3158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:13 loss: 0.000324tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:14 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:15 loss: 0.001822tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:16 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:17 loss: 0.016977tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:18 loss: 0.014115tensor(0.1514, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:19 loss: 0.017725tensor(0.3346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:20 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:21 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:22 loss: 0.030947tensor(0.3045, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:23 loss: 0.002904tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:24 loss: 0.011363tensor(0.3509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:25 loss: 0.003240tensor(0.0101, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:26 loss: 0.012947tensor(0.2989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:27 loss: 0.023163tensor(0.4033, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:28 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:29 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:30 loss: 0.000584tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:31 loss: 0.003932tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:32 loss: 0.000917tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:33 loss: 0.012590tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:34 loss: 0.020412tensor(0.0261, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:35 loss: 0.005533tensor(0.1815, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:36 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:37 loss: 0.001543tensor(0.0485, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:38 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:39 loss: 0.001818tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:40 loss: 0.034982tensor(0.3730, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:41 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:42 loss: 0.000694tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:43 loss: 0.016913tensor(0.3478, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:44 loss: 0.000841tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:45 loss: 0.002090tensor(0.1941, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:46 loss: 0.003526tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:47 loss: 0.013796tensor(0.3450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:48 loss: 0.005193tensor(0.0338, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:49 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:50 loss: 0.005513tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:51 loss: 0.004933tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:52 loss: 0.000057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:53 loss: 0.000365tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:54 loss: 0.020347tensor(0.3408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:55 loss: 0.025796tensor(0.3209, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:56 loss: 0.015756tensor(0.3474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:57 loss: 0.000410tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:58 loss: 0.012627tensor(0.0790, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:59 loss: 0.000212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:60 loss: 0.017587tensor(0.4178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:61 loss: 0.020714tensor(0.0247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:63 loss: 0.002350tensor(7.0084e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:64 loss: 0.001093tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:65 loss: 0.013992tensor(0.2156, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:66 loss: 0.000239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:67 loss: 0.012310tensor(0.2803, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:69 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:70 loss: 0.003437tensor(0.1600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:71 loss: 0.010989tensor(0.3368, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:72 loss: 0.010156tensor(0.2596, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:73 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:74 loss: 0.004676tensor(0.3852, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:75 loss: 0.002607tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:76 loss: 0.000383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:77 loss: 0.001619tensor(0.0194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:78 loss: 0.023717tensor(0.3553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:32 step:79 loss: 0.004954tensor(0.2761, grad_fn=<DivBackward0>)\n",
      "Epoch:33 step:0 loss: 0.009475\n",
      "Epoch:33 step:1 loss: 0.005192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33 step:2 loss: 0.001232\n",
      "Epoch:33 step:3 loss: 0.000026\n",
      "Epoch:33 step:4 loss: 0.013251\n",
      "Epoch:33 step:5 loss: 0.006583\n",
      "Epoch:33 step:6 loss: 0.000007\n",
      "Epoch:33 step:7 loss: 0.013025\n",
      "Epoch:33 step:8 loss: 0.000058\n",
      "Epoch:33 step:9 loss: 0.000249\n",
      "Epoch:33 step:10 loss: 0.000533\n",
      "Epoch:33 step:11 loss: 0.007273\n",
      "Epoch:33 step:12 loss: 0.012905\n",
      "Epoch:33 step:13 loss: 0.001541\n",
      "Epoch:33 step:14 loss: 0.000019\n",
      "Epoch:33 step:15 loss: 0.000797\n",
      "Epoch:33 step:16 loss: 0.000034\n",
      "Epoch:33 step:17 loss: 0.000441\n",
      "Epoch:33 step:18 loss: 0.007169\n",
      "Epoch:33 step:19 loss: 0.021519\n",
      "Epoch:33 step:20 loss: 0.000071\n",
      "Epoch:33 step:21 loss: 0.000034\n",
      "Epoch:33 step:22 loss: 0.019412\n",
      "Epoch:33 step:23 loss: 0.001628\n",
      "Epoch:33 step:24 loss: 0.008297\n",
      "Epoch:33 step:25 loss: 0.001584\n",
      "Epoch:33 step:26 loss: 0.010551\n",
      "Epoch:33 step:27 loss: 0.020716\n",
      "Epoch:33 step:28 loss: 0.000037\n",
      "Epoch:33 step:29 loss: 0.000010\n",
      "Epoch:33 step:30 loss: 0.000436\n",
      "Epoch:33 step:31 loss: 0.000389\n",
      "Epoch:33 step:32 loss: 0.000190\n",
      "Epoch:33 step:33 loss: 0.000005\n",
      "Epoch:33 step:34 loss: 0.011880\n",
      "Epoch:33 step:35 loss: 0.006641\n",
      "Epoch:33 step:36 loss: 0.000025\n",
      "Epoch:33 step:37 loss: 0.002888\n",
      "Epoch:33 step:38 loss: 0.000117\n",
      "Epoch:33 step:39 loss: 0.007701\n",
      "Epoch:33 step:40 loss: 0.032193\n",
      "Epoch:33 step:41 loss: 0.000014\n",
      "Epoch:33 step:42 loss: 0.000603\n",
      "Epoch:33 step:43 loss: 0.015304\n",
      "Epoch:33 step:44 loss: 0.000566\n",
      "Epoch:33 step:45 loss: 0.002338\n",
      "Epoch:33 step:46 loss: 0.002001\n",
      "Epoch:33 step:47 loss: 0.010986\n",
      "Epoch:33 step:48 loss: 0.003895\n",
      "Epoch:33 step:49 loss: 0.000071\n",
      "Epoch:33 step:50 loss: 0.001838\n",
      "Epoch:33 step:51 loss: 0.001720\n",
      "Epoch:33 step:52 loss: 0.000041\n",
      "Epoch:33 step:53 loss: 0.000349\n",
      "Epoch:33 step:54 loss: 0.019934\n",
      "Epoch:33 step:55 loss: 0.022683\n",
      "Epoch:33 step:56 loss: 0.010932\n",
      "Epoch:33 step:57 loss: 0.000632\n",
      "Epoch:33 step:58 loss: 0.009718\n",
      "Epoch:33 step:59 loss: 0.000427\n",
      "Epoch:33 step:60 loss: 0.016330\n",
      "Epoch:33 step:61 loss: 0.011266\n",
      "Epoch:33 step:62 loss: 0.000002\n",
      "Epoch:33 step:63 loss: 0.002790\n",
      "Epoch:33 step:64 loss: 0.001678\n",
      "Epoch:33 step:65 loss: 0.005144\n",
      "Epoch:33 step:66 loss: 0.000218\n",
      "Epoch:33 step:67 loss: 0.013658\n",
      "Epoch:33 step:68 loss: 0.000000\n",
      "Epoch:33 step:69 loss: 0.000000\n",
      "Epoch:33 step:70 loss: 0.003162\n",
      "Epoch:33 step:71 loss: 0.008119\n",
      "Epoch:33 step:72 loss: 0.004230\n",
      "Epoch:33 step:73 loss: 0.000009\n",
      "Epoch:33 step:74 loss: 0.005524\n",
      "Epoch:33 step:75 loss: 0.000090\n",
      "Epoch:33 step:76 loss: 0.000031\n",
      "Epoch:33 step:77 loss: 0.002542\n",
      "Epoch:33 step:78 loss: 0.014509\n",
      "Epoch:33 step:79 loss: 0.003152\n",
      "Test Epoch:33 step:0 loss: 0.007757tensor(0.2412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:1 loss: 0.004065tensor(0.0925, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:2 loss: 0.005778tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:3 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:4 loss: 0.013144tensor(0.3390, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:5 loss: 0.006574tensor(0.3343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:7 loss: 0.011724tensor(0.2282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:8 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:9 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:10 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:11 loss: 0.006621tensor(0.2884, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:12 loss: 0.009917tensor(0.4198, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:13 loss: 0.000834tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:14 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:15 loss: 0.000317tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:16 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:17 loss: 0.000391tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:18 loss: 0.006820tensor(0.2543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:19 loss: 0.021482tensor(0.3286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:20 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:21 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:22 loss: 0.035270tensor(0.2910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:23 loss: 0.000379tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:24 loss: 0.007153tensor(0.3922, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:25 loss: 0.003000tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:26 loss: 0.010273tensor(0.3484, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:27 loss: 0.019302tensor(0.4204, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:28 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:29 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:30 loss: 0.000426tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:31 loss: 0.000542tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:32 loss: 0.000410tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:33 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:34 loss: 0.007642tensor(0.1730, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:35 loss: 0.005459tensor(0.2021, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:36 loss: 0.000259tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:37 loss: 0.002408tensor(0.1204, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:38 loss: 0.000125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:39 loss: 0.001241tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:40 loss: 0.025103tensor(0.4046, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:41 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:42 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:43 loss: 0.012342tensor(0.3924, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:44 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:45 loss: 0.001926tensor(0.2750, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:46 loss: 0.000146tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:47 loss: 0.010816tensor(0.3796, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:48 loss: 0.002505tensor(0.2248, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:50 loss: 0.000425tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:51 loss: 0.002002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:52 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:53 loss: 0.000098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:54 loss: 0.020895tensor(0.3559, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:55 loss: 0.027691tensor(0.3378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:56 loss: 0.008531tensor(0.4059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:57 loss: 0.008436tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:58 loss: 0.048988tensor(0.0056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:59 loss: 0.000507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:60 loss: 0.015856tensor(0.4248, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:61 loss: 0.010836tensor(0.1987, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:63 loss: 0.002975tensor(3.3233e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:64 loss: 0.008419tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:65 loss: 0.006893tensor(0.3451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:66 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:67 loss: 0.039164tensor(0.0438, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:70 loss: 0.013632tensor(5.5368e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:71 loss: 0.015624tensor(0.2587, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:72 loss: 0.012120tensor(0.1477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:73 loss: 0.000212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:74 loss: 0.020103tensor(0.1017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:75 loss: 0.002602tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:76 loss: 0.000733tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:77 loss: 0.001429tensor(0.0549, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:33 step:78 loss: 0.025674tensor(0.2797, grad_fn=<DivBackward0>)\n",
      "Test Epoch:33 step:79 loss: 0.005907tensor(0.2158, grad_fn=<DivBackward0>)\n",
      "Epoch:34 step:0 loss: 0.024153\n",
      "Epoch:34 step:1 loss: 0.016131\n",
      "Epoch:34 step:2 loss: 0.003332\n",
      "Epoch:34 step:3 loss: 0.000135\n",
      "Epoch:34 step:4 loss: 0.024205\n",
      "Epoch:34 step:5 loss: 0.016696\n",
      "Epoch:34 step:6 loss: 0.000026\n",
      "Epoch:34 step:7 loss: 0.024787\n",
      "Epoch:34 step:8 loss: 0.000041\n",
      "Epoch:34 step:9 loss: 0.000180\n",
      "Epoch:34 step:10 loss: 0.000306\n",
      "Epoch:34 step:11 loss: 0.006796\n",
      "Epoch:34 step:12 loss: 0.012818\n",
      "Epoch:34 step:13 loss: 0.000964\n",
      "Epoch:34 step:14 loss: 0.000027\n",
      "Epoch:34 step:15 loss: 0.001711\n",
      "Epoch:34 step:16 loss: 0.000132\n",
      "Epoch:34 step:17 loss: 0.000973\n",
      "Epoch:34 step:18 loss: 0.005774\n",
      "Epoch:34 step:19 loss: 0.019941\n",
      "Epoch:34 step:20 loss: 0.000057\n",
      "Epoch:34 step:21 loss: 0.000012\n",
      "Epoch:34 step:22 loss: 0.048417\n",
      "Epoch:34 step:23 loss: 0.002069\n",
      "Epoch:34 step:24 loss: 0.007186\n",
      "Epoch:34 step:25 loss: 0.003387\n",
      "Epoch:34 step:26 loss: 0.015125\n",
      "Epoch:34 step:27 loss: 0.027256\n",
      "Epoch:34 step:28 loss: 0.000149\n",
      "Epoch:34 step:29 loss: 0.000009\n",
      "Epoch:34 step:30 loss: 0.001565\n",
      "Epoch:34 step:31 loss: 0.000407\n",
      "Epoch:34 step:32 loss: 0.000226\n",
      "Epoch:34 step:33 loss: 0.000098\n",
      "Epoch:34 step:34 loss: 0.013414\n",
      "Epoch:34 step:35 loss: 0.006836\n",
      "Epoch:34 step:36 loss: 0.000102\n",
      "Epoch:34 step:37 loss: 0.002366\n",
      "Epoch:34 step:38 loss: 0.000492\n",
      "Epoch:34 step:39 loss: 0.001273\n",
      "Epoch:34 step:40 loss: 0.045337\n",
      "Epoch:34 step:41 loss: 0.000017\n",
      "Epoch:34 step:42 loss: 0.000334\n",
      "Epoch:34 step:43 loss: 0.066788\n",
      "Epoch:34 step:44 loss: 0.000412\n",
      "Epoch:34 step:45 loss: 0.001815\n",
      "Epoch:34 step:46 loss: 0.005580\n",
      "Epoch:34 step:47 loss: 0.012845\n",
      "Epoch:34 step:48 loss: 0.003342\n",
      "Epoch:34 step:49 loss: 0.010597\n",
      "Epoch:34 step:50 loss: 0.002990\n",
      "Epoch:34 step:51 loss: 0.002458\n",
      "Epoch:34 step:52 loss: 0.000060\n",
      "Epoch:34 step:53 loss: 0.000896\n",
      "Epoch:34 step:54 loss: 0.034363\n",
      "Epoch:34 step:55 loss: 0.029454\n",
      "Epoch:34 step:56 loss: 0.024909\n",
      "Epoch:34 step:57 loss: 0.002312\n",
      "Epoch:34 step:58 loss: 0.013771\n",
      "Epoch:34 step:59 loss: 0.001525\n",
      "Epoch:34 step:60 loss: 0.036316\n",
      "Epoch:34 step:61 loss: 0.014757\n",
      "Epoch:34 step:62 loss: 0.000189\n",
      "Epoch:34 step:63 loss: 0.004411\n",
      "Epoch:34 step:64 loss: 0.003943\n",
      "Epoch:34 step:65 loss: 0.009923\n",
      "Epoch:34 step:66 loss: 0.001053\n",
      "Epoch:34 step:67 loss: 0.008643\n",
      "Epoch:34 step:68 loss: 0.000035\n",
      "Epoch:34 step:69 loss: 0.000036\n",
      "Epoch:34 step:70 loss: 0.006534\n",
      "Epoch:34 step:71 loss: 0.013073\n",
      "Epoch:34 step:72 loss: 0.003714\n",
      "Epoch:34 step:73 loss: 0.008201\n",
      "Epoch:34 step:74 loss: 0.009373\n",
      "Epoch:34 step:75 loss: 0.000878\n",
      "Epoch:34 step:76 loss: 0.000018\n",
      "Epoch:34 step:77 loss: 0.002272\n",
      "Epoch:34 step:78 loss: 0.032255\n",
      "Epoch:34 step:79 loss: 0.006450\n",
      "Test Epoch:34 step:0 loss: 0.008263tensor(0.1728, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:1 loss: 0.007850tensor(0.0836, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:2 loss: 0.006406tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:3 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:4 loss: 0.016455tensor(0.3146, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:5 loss: 0.006122tensor(0.3499, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:6 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:7 loss: 0.011358tensor(0.2626, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:8 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:9 loss: 0.000290tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:10 loss: 0.000213tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:11 loss: 0.006343tensor(0.2966, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:12 loss: 0.012621tensor(0.3988, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:13 loss: 0.000550tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:14 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:15 loss: 0.000181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:16 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:17 loss: 0.001205tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:18 loss: 0.008056tensor(0.1378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:19 loss: 0.020051tensor(0.3054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:20 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:21 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:22 loss: 0.060452tensor(0.2320, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:23 loss: 0.009236tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:24 loss: 0.015884tensor(0.3050, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:25 loss: 0.001633tensor(0.0761, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:26 loss: 0.051023tensor(0.1758, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:27 loss: 0.021896tensor(0.4132, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:28 loss: 0.000169tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:29 loss: 0.000259tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:30 loss: 0.001750tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:31 loss: 0.001475tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:32 loss: 0.000575tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:33 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:34 loss: 0.015963tensor(0.0216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:35 loss: 0.012245tensor(0.0378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:36 loss: 0.001596tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:37 loss: 0.001800tensor(0.0297, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:38 loss: 0.000199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:39 loss: 0.003136tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:40 loss: 0.123704tensor(0.1934, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:41 loss: 0.000321tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:42 loss: 0.001839tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:43 loss: 0.029451tensor(0.2139, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:44 loss: 0.004907tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:45 loss: 0.010816tensor(0.0320, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:46 loss: 0.005206tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:47 loss: 0.027153tensor(0.2195, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:48 loss: 0.004555tensor(0.0632, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:49 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:50 loss: 0.009401tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:51 loss: 0.000707tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:53 loss: 0.000404tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:54 loss: 0.037484tensor(0.2538, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:55 loss: 0.036292tensor(0.2652, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:56 loss: 0.033586tensor(0.2111, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:57 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:58 loss: 0.026347tensor(0.0191, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:59 loss: 0.003203tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:60 loss: 0.024035tensor(0.3919, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:61 loss: 0.013811tensor(0.1437, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:62 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:63 loss: 0.007579tensor(4.7677e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:64 loss: 0.010217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:65 loss: 0.008398tensor(0.3302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:66 loss: 0.000265tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:67 loss: 0.019327tensor(0.1877, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:68 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:69 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:70 loss: 0.006589tensor(0.0473, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:71 loss: 0.013550tensor(0.3013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:72 loss: 0.005365tensor(0.3116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:73 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:74 loss: 0.009531tensor(0.2903, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:34 step:75 loss: 0.000610tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:76 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:77 loss: 0.001281tensor(0.0639, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:78 loss: 0.029291tensor(0.3010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:34 step:79 loss: 0.007741tensor(0.1872, grad_fn=<DivBackward0>)\n",
      "Epoch:35 step:0 loss: 0.008099\n",
      "Epoch:35 step:1 loss: 0.005962\n",
      "Epoch:35 step:2 loss: 0.006052\n",
      "Epoch:35 step:3 loss: 0.000149\n",
      "Epoch:35 step:4 loss: 0.015196\n",
      "Epoch:35 step:5 loss: 0.009075\n",
      "Epoch:35 step:6 loss: 0.000034\n",
      "Epoch:35 step:7 loss: 0.011100\n",
      "Epoch:35 step:8 loss: 0.000094\n",
      "Epoch:35 step:9 loss: 0.000976\n",
      "Epoch:35 step:10 loss: 0.000147\n",
      "Epoch:35 step:11 loss: 0.007372\n",
      "Epoch:35 step:12 loss: 0.013563\n",
      "Epoch:35 step:13 loss: 0.000912\n",
      "Epoch:35 step:14 loss: 0.000008\n",
      "Epoch:35 step:15 loss: 0.000726\n",
      "Epoch:35 step:16 loss: 0.000060\n",
      "Epoch:35 step:17 loss: 0.001139\n",
      "Epoch:35 step:18 loss: 0.009259\n",
      "Epoch:35 step:19 loss: 0.016931\n",
      "Epoch:35 step:20 loss: 0.000092\n",
      "Epoch:35 step:21 loss: 0.000040\n",
      "Epoch:35 step:22 loss: 0.027200\n",
      "Epoch:35 step:23 loss: 0.004196\n",
      "Epoch:35 step:24 loss: 0.007498\n",
      "Epoch:35 step:25 loss: 0.003009\n",
      "Epoch:35 step:26 loss: 0.013286\n",
      "Epoch:35 step:27 loss: 0.032305\n",
      "Epoch:35 step:28 loss: 0.000079\n",
      "Epoch:35 step:29 loss: 0.000005\n",
      "Epoch:35 step:30 loss: 0.001920\n",
      "Epoch:35 step:31 loss: 0.001154\n",
      "Epoch:35 step:32 loss: 0.000207\n",
      "Epoch:35 step:33 loss: 0.000029\n",
      "Epoch:35 step:34 loss: 0.011432\n",
      "Epoch:35 step:35 loss: 0.007448\n",
      "Epoch:35 step:36 loss: 0.000332\n",
      "Epoch:35 step:37 loss: 0.001759\n",
      "Epoch:35 step:38 loss: 0.000193\n",
      "Epoch:35 step:39 loss: 0.009606\n",
      "Epoch:35 step:40 loss: 0.047973\n",
      "Epoch:35 step:41 loss: 0.000025\n",
      "Epoch:35 step:42 loss: 0.000170\n",
      "Epoch:35 step:43 loss: 0.019481\n",
      "Epoch:35 step:44 loss: 0.000147\n",
      "Epoch:35 step:45 loss: 0.001605\n",
      "Epoch:35 step:46 loss: 0.000219\n",
      "Epoch:35 step:47 loss: 0.010515\n",
      "Epoch:35 step:48 loss: 0.003071\n",
      "Epoch:35 step:49 loss: 0.000072\n",
      "Epoch:35 step:50 loss: 0.000956\n",
      "Epoch:35 step:51 loss: 0.001150\n",
      "Epoch:35 step:52 loss: 0.000042\n",
      "Epoch:35 step:53 loss: 0.000209\n",
      "Epoch:35 step:54 loss: 0.025471\n",
      "Epoch:35 step:55 loss: 0.022450\n",
      "Epoch:35 step:56 loss: 0.014822\n",
      "Epoch:35 step:57 loss: 0.002170\n",
      "Epoch:35 step:58 loss: 0.011441\n",
      "Epoch:35 step:59 loss: 0.001272\n",
      "Epoch:35 step:60 loss: 0.034660\n",
      "Epoch:35 step:61 loss: 0.009205\n",
      "Epoch:35 step:62 loss: 0.000006\n",
      "Epoch:35 step:63 loss: 0.002150\n",
      "Epoch:35 step:64 loss: 0.006126\n",
      "Epoch:35 step:65 loss: 0.005398\n",
      "Epoch:35 step:66 loss: 0.000674\n",
      "Epoch:35 step:67 loss: 0.006417\n",
      "Epoch:35 step:68 loss: 0.000001\n",
      "Epoch:35 step:69 loss: 0.000001\n",
      "Epoch:35 step:70 loss: 0.002507\n",
      "Epoch:35 step:71 loss: 0.011056\n",
      "Epoch:35 step:72 loss: 0.003180\n",
      "Epoch:35 step:73 loss: 0.000233\n",
      "Epoch:35 step:74 loss: 0.006920\n",
      "Epoch:35 step:75 loss: 0.000353\n",
      "Epoch:35 step:76 loss: 0.000017\n",
      "Epoch:35 step:77 loss: 0.002420\n",
      "Epoch:35 step:78 loss: 0.015654\n",
      "Epoch:35 step:79 loss: 0.012513\n",
      "Test Epoch:35 step:0 loss: 0.005821tensor(0.2434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:1 loss: 0.003615tensor(0.0848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:2 loss: 0.001191tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:3 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:4 loss: 0.020268tensor(0.3028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:5 loss: 0.007436tensor(0.3195, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:6 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:7 loss: 0.010185tensor(0.2665, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:8 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:9 loss: 0.000354tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:10 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:11 loss: 0.006481tensor(0.2856, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:12 loss: 0.009137tensor(0.4176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:13 loss: 0.000152tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:14 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:15 loss: 0.000389tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:16 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:17 loss: 0.000663tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:18 loss: 0.007769tensor(0.1822, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:19 loss: 0.013710tensor(0.3549, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:20 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:21 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:22 loss: 0.018946tensor(0.3596, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:23 loss: 0.004491tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:24 loss: 0.008032tensor(0.3656, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:25 loss: 0.002295tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:26 loss: 0.012558tensor(0.3136, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:27 loss: 0.020227tensor(0.4180, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:28 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:30 loss: 0.000945tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:31 loss: 0.001067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:32 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:34 loss: 0.009509tensor(0.1222, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:35 loss: 0.005124tensor(0.2254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:36 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:37 loss: 0.002260tensor(0.1275, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:38 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:39 loss: 0.000874tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:40 loss: 0.049199tensor(0.3552, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:41 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:42 loss: 0.000207tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:43 loss: 0.010755tensor(0.3937, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:44 loss: 0.000444tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:45 loss: 0.004596tensor(0.2107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:46 loss: 0.001758tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:47 loss: 0.011571tensor(0.3705, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:48 loss: 0.005386tensor(0.1861, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:49 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:50 loss: 0.003169tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:51 loss: 0.001899tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:52 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:53 loss: 0.000918tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:54 loss: 0.049383tensor(0.2989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:55 loss: 0.028539tensor(0.3508, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:56 loss: 0.012863tensor(0.3824, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:57 loss: 0.000313tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:58 loss: 0.009643tensor(0.0783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:59 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:60 loss: 0.047529tensor(0.3340, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:61 loss: 0.022220tensor(0.0224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:62 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:63 loss: 0.002274tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:64 loss: 0.000193tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:65 loss: 0.010438tensor(0.2946, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:66 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:67 loss: 0.007026tensor(0.3414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:69 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:70 loss: 0.001855tensor(0.2624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:71 loss: 0.009972tensor(0.3405, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:35 step:72 loss: 0.014312tensor(0.2440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:73 loss: 0.000183tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:74 loss: 0.005744tensor(0.3792, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:75 loss: 0.000725tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:76 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:77 loss: 0.004168tensor(0.0957, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:78 loss: 0.019593tensor(0.3770, grad_fn=<DivBackward0>)\n",
      "Test Epoch:35 step:79 loss: 0.003173tensor(0.3250, grad_fn=<DivBackward0>)\n",
      "Epoch:36 step:0 loss: 0.006238\n",
      "Epoch:36 step:1 loss: 0.003647\n",
      "Epoch:36 step:2 loss: 0.000757\n",
      "Epoch:36 step:3 loss: 0.000006\n",
      "Epoch:36 step:4 loss: 0.011568\n",
      "Epoch:36 step:5 loss: 0.006681\n",
      "Epoch:36 step:6 loss: 0.000001\n",
      "Epoch:36 step:7 loss: 0.011732\n",
      "Epoch:36 step:8 loss: 0.000272\n",
      "Epoch:36 step:9 loss: 0.000178\n",
      "Epoch:36 step:10 loss: 0.000669\n",
      "Epoch:36 step:11 loss: 0.005922\n",
      "Epoch:36 step:12 loss: 0.007985\n",
      "Epoch:36 step:13 loss: 0.007464\n",
      "Epoch:36 step:14 loss: 0.000003\n",
      "Epoch:36 step:15 loss: 0.000834\n",
      "Epoch:36 step:16 loss: 0.000071\n",
      "Epoch:36 step:17 loss: 0.000176\n",
      "Epoch:36 step:18 loss: 0.007192\n",
      "Epoch:36 step:19 loss: 0.022700\n",
      "Epoch:36 step:20 loss: 0.000029\n",
      "Epoch:36 step:21 loss: 0.000028\n",
      "Epoch:36 step:22 loss: 0.020952\n",
      "Epoch:36 step:23 loss: 0.001012\n",
      "Epoch:36 step:24 loss: 0.006433\n",
      "Epoch:36 step:25 loss: 0.001923\n",
      "Epoch:36 step:26 loss: 0.013624\n",
      "Epoch:36 step:27 loss: 0.022208\n",
      "Epoch:36 step:28 loss: 0.000077\n",
      "Epoch:36 step:29 loss: 0.000002\n",
      "Epoch:36 step:30 loss: 0.000548\n",
      "Epoch:36 step:31 loss: 0.000246\n",
      "Epoch:36 step:32 loss: 0.000068\n",
      "Epoch:36 step:33 loss: 0.000003\n",
      "Epoch:36 step:34 loss: 0.011533\n",
      "Epoch:36 step:35 loss: 0.005340\n",
      "Epoch:36 step:36 loss: 0.000045\n",
      "Epoch:36 step:37 loss: 0.002227\n",
      "Epoch:36 step:38 loss: 0.000026\n",
      "Epoch:36 step:39 loss: 0.000205\n",
      "Epoch:36 step:40 loss: 0.036423\n",
      "Epoch:36 step:41 loss: 0.000057\n",
      "Epoch:36 step:42 loss: 0.000143\n",
      "Epoch:36 step:43 loss: 0.010589\n",
      "Epoch:36 step:44 loss: 0.000317\n",
      "Epoch:36 step:45 loss: 0.002405\n",
      "Epoch:36 step:46 loss: 0.000727\n",
      "Epoch:36 step:47 loss: 0.008735\n",
      "Epoch:36 step:48 loss: 0.004027\n",
      "Epoch:36 step:49 loss: 0.000018\n",
      "Epoch:36 step:50 loss: 0.001885\n",
      "Epoch:36 step:51 loss: 0.005631\n",
      "Epoch:36 step:52 loss: 0.000012\n",
      "Epoch:36 step:53 loss: 0.000800\n",
      "Epoch:36 step:54 loss: 0.024855\n",
      "Epoch:36 step:55 loss: 0.020880\n",
      "Epoch:36 step:56 loss: 0.007849\n",
      "Epoch:36 step:57 loss: 0.001867\n",
      "Epoch:36 step:58 loss: 0.006947\n",
      "Epoch:36 step:59 loss: 0.000037\n",
      "Epoch:36 step:60 loss: 0.021023\n",
      "Epoch:36 step:61 loss: 0.015849\n",
      "Epoch:36 step:62 loss: 0.000002\n",
      "Epoch:36 step:63 loss: 0.002603\n",
      "Epoch:36 step:64 loss: 0.002382\n",
      "Epoch:36 step:65 loss: 0.004231\n",
      "Epoch:36 step:66 loss: 0.000104\n",
      "Epoch:36 step:67 loss: 0.008545\n",
      "Epoch:36 step:68 loss: 0.000000\n",
      "Epoch:36 step:69 loss: 0.000000\n",
      "Epoch:36 step:70 loss: 0.002699\n",
      "Epoch:36 step:71 loss: 0.010588\n",
      "Epoch:36 step:72 loss: 0.003088\n",
      "Epoch:36 step:73 loss: 0.000031\n",
      "Epoch:36 step:74 loss: 0.005423\n",
      "Epoch:36 step:75 loss: 0.000223\n",
      "Epoch:36 step:76 loss: 0.000050\n",
      "Epoch:36 step:77 loss: 0.002877\n",
      "Epoch:36 step:78 loss: 0.011459\n",
      "Epoch:36 step:79 loss: 0.004053\n",
      "Test Epoch:36 step:0 loss: 0.005869tensor(0.2559, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:1 loss: 0.002733tensor(0.1510, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:2 loss: 0.002586tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:3 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:4 loss: 0.011988tensor(0.3523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:5 loss: 0.004887tensor(0.3714, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:7 loss: 0.009969tensor(0.2967, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:8 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:9 loss: 0.000171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:10 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:11 loss: 0.005527tensor(0.3209, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:12 loss: 0.007455tensor(0.4321, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:13 loss: 0.000201tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:15 loss: 0.000269tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:16 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:17 loss: 0.000114tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:18 loss: 0.007531tensor(0.2102, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:19 loss: 0.014525tensor(0.3500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:20 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:21 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:22 loss: 0.017263tensor(0.3768, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:23 loss: 0.002083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:24 loss: 0.009770tensor(0.3582, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:25 loss: 0.002094tensor(0.0197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:26 loss: 0.010529tensor(0.3389, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:27 loss: 0.021143tensor(0.4120, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:28 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:30 loss: 0.001859tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:31 loss: 0.000478tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:32 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:34 loss: 0.006288tensor(0.2199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:35 loss: 0.003898tensor(0.2774, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:36 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:37 loss: 0.001482tensor(0.1694, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:38 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:39 loss: 0.000437tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:40 loss: 0.021750tensor(0.4205, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:41 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:42 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:43 loss: 0.012449tensor(0.3939, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:44 loss: 0.000097tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:45 loss: 0.002021tensor(0.2865, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:46 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:47 loss: 0.008447tensor(0.4007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:48 loss: 0.003165tensor(0.2049, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:49 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:50 loss: 0.000473tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:51 loss: 0.000384tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:52 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:53 loss: 0.000201tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:54 loss: 0.029949tensor(0.3492, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:55 loss: 0.023251tensor(0.3707, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:56 loss: 0.007652tensor(0.4112, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:57 loss: 0.002560tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:58 loss: 0.007741tensor(0.2028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:59 loss: 0.000157tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:60 loss: 0.037056tensor(0.3775, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:61 loss: 0.010989tensor(0.1736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:62 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:63 loss: 0.002702tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:64 loss: 0.004402tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:65 loss: 0.004305tensor(0.4028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:66 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:67 loss: 0.007994tensor(0.3366, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:36 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:70 loss: 0.003050tensor(0.1700, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:71 loss: 0.008405tensor(0.3692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:72 loss: 0.002833tensor(0.3849, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:73 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:74 loss: 0.004817tensor(0.3882, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:75 loss: 0.000143tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:76 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:77 loss: 0.001960tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:78 loss: 0.012474tensor(0.4021, grad_fn=<DivBackward0>)\n",
      "Test Epoch:36 step:79 loss: 0.003279tensor(0.3392, grad_fn=<DivBackward0>)\n",
      "Epoch:37 step:0 loss: 0.005872\n",
      "Epoch:37 step:1 loss: 0.002894\n",
      "Epoch:37 step:2 loss: 0.000362\n",
      "Epoch:37 step:3 loss: 0.000002\n",
      "Epoch:37 step:4 loss: 0.010912\n",
      "Epoch:37 step:5 loss: 0.005190\n",
      "Epoch:37 step:6 loss: 0.000004\n",
      "Epoch:37 step:7 loss: 0.008990\n",
      "Epoch:37 step:8 loss: 0.000044\n",
      "Epoch:37 step:9 loss: 0.000591\n",
      "Epoch:37 step:10 loss: 0.000016\n",
      "Epoch:37 step:11 loss: 0.012131\n",
      "Epoch:37 step:12 loss: 0.007063\n",
      "Epoch:37 step:13 loss: 0.000087\n",
      "Epoch:37 step:14 loss: 0.000001\n",
      "Epoch:37 step:15 loss: 0.000094\n",
      "Epoch:37 step:16 loss: 0.000027\n",
      "Epoch:37 step:17 loss: 0.000072\n",
      "Epoch:37 step:18 loss: 0.007470\n",
      "Epoch:37 step:19 loss: 0.020593\n",
      "Epoch:37 step:20 loss: 0.000017\n",
      "Epoch:37 step:21 loss: 0.000016\n",
      "Epoch:37 step:22 loss: 0.015860\n",
      "Epoch:37 step:23 loss: 0.000927\n",
      "Epoch:37 step:24 loss: 0.005871\n",
      "Epoch:37 step:25 loss: 0.001215\n",
      "Epoch:37 step:26 loss: 0.010881\n",
      "Epoch:37 step:27 loss: 0.024963\n",
      "Epoch:37 step:28 loss: 0.000078\n",
      "Epoch:37 step:29 loss: 0.000003\n",
      "Epoch:37 step:30 loss: 0.001950\n",
      "Epoch:37 step:31 loss: 0.000318\n",
      "Epoch:37 step:32 loss: 0.000079\n",
      "Epoch:37 step:33 loss: 0.000006\n",
      "Epoch:37 step:34 loss: 0.007068\n",
      "Epoch:37 step:35 loss: 0.003713\n",
      "Epoch:37 step:36 loss: 0.000055\n",
      "Epoch:37 step:37 loss: 0.001598\n",
      "Epoch:37 step:38 loss: 0.000039\n",
      "Epoch:37 step:39 loss: 0.000436\n",
      "Epoch:37 step:40 loss: 0.025986\n",
      "Epoch:37 step:41 loss: 0.000002\n",
      "Epoch:37 step:42 loss: 0.000007\n",
      "Epoch:37 step:43 loss: 0.011332\n",
      "Epoch:37 step:44 loss: 0.000030\n",
      "Epoch:37 step:45 loss: 0.001745\n",
      "Epoch:37 step:46 loss: 0.000023\n",
      "Epoch:37 step:47 loss: 0.008220\n",
      "Epoch:37 step:48 loss: 0.002594\n",
      "Epoch:37 step:49 loss: 0.000003\n",
      "Epoch:37 step:50 loss: 0.000133\n",
      "Epoch:37 step:51 loss: 0.000188\n",
      "Epoch:37 step:52 loss: 0.000003\n",
      "Epoch:37 step:53 loss: 0.000085\n",
      "Epoch:37 step:54 loss: 0.026872\n",
      "Epoch:37 step:55 loss: 0.025300\n",
      "Epoch:37 step:56 loss: 0.007211\n",
      "Epoch:37 step:57 loss: 0.001897\n",
      "Epoch:37 step:58 loss: 0.010035\n",
      "Epoch:37 step:59 loss: 0.000144\n",
      "Epoch:37 step:60 loss: 0.020587\n",
      "Epoch:37 step:61 loss: 0.009851\n",
      "Epoch:37 step:62 loss: 0.000008\n",
      "Epoch:37 step:63 loss: 0.001724\n",
      "Epoch:37 step:64 loss: 0.005138\n",
      "Epoch:37 step:65 loss: 0.003924\n",
      "Epoch:37 step:66 loss: 0.000220\n",
      "Epoch:37 step:67 loss: 0.006586\n",
      "Epoch:37 step:68 loss: 0.000000\n",
      "Epoch:37 step:69 loss: 0.000000\n",
      "Epoch:37 step:70 loss: 0.002164\n",
      "Epoch:37 step:71 loss: 0.008418\n",
      "Epoch:37 step:72 loss: 0.003241\n",
      "Epoch:37 step:73 loss: 0.000043\n",
      "Epoch:37 step:74 loss: 0.004491\n",
      "Epoch:37 step:75 loss: 0.000144\n",
      "Epoch:37 step:76 loss: 0.000033\n",
      "Epoch:37 step:77 loss: 0.001986\n",
      "Epoch:37 step:78 loss: 0.011804\n",
      "Epoch:37 step:79 loss: 0.003287\n",
      "Test Epoch:37 step:0 loss: 0.005288tensor(0.2434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:1 loss: 0.003128tensor(0.1574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:2 loss: 0.000584tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:3 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:4 loss: 0.010421tensor(0.3570, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:5 loss: 0.004299tensor(0.3838, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:6 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:7 loss: 0.007106tensor(0.3224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:8 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:9 loss: 0.000360tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:11 loss: 0.007787tensor(0.3084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:12 loss: 0.007181tensor(0.4346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:13 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:15 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:16 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:17 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:18 loss: 0.007249tensor(0.2138, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:19 loss: 0.016742tensor(0.3471, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:20 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:21 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:22 loss: 0.015760tensor(0.3812, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:23 loss: 0.000664tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:24 loss: 0.008015tensor(0.3753, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:25 loss: 0.001219tensor(0.1023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:26 loss: 0.011774tensor(0.3311, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:27 loss: 0.022198tensor(0.4103, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:28 loss: 0.000494tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:29 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:30 loss: 0.002233tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:31 loss: 0.000304tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:32 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:34 loss: 0.004972tensor(0.2886, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:35 loss: 0.003431tensor(0.3057, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:36 loss: 0.000395tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:37 loss: 0.001503tensor(0.1617, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:38 loss: 0.000304tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:39 loss: 0.000182tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:40 loss: 0.021955tensor(0.4245, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:41 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:42 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:43 loss: 0.011612tensor(0.4077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:44 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:45 loss: 0.001620tensor(0.3123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:46 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:47 loss: 0.008105tensor(0.4037, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:48 loss: 0.002846tensor(0.2140, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:50 loss: 0.000358tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:51 loss: 0.000454tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:52 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:53 loss: 0.000505tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:54 loss: 0.026623tensor(0.3598, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:55 loss: 0.017900tensor(0.3889, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:56 loss: 0.007489tensor(0.4163, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:57 loss: 0.003484tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:58 loss: 0.009029tensor(0.1854, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:59 loss: 0.000186tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:60 loss: 0.019204tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:61 loss: 0.009112tensor(0.2240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:62 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:63 loss: 0.002389tensor(8.9672e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:64 loss: 0.006242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:65 loss: 0.003922tensor(0.4120, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:37 step:66 loss: 0.000132tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:67 loss: 0.012245tensor(0.2973, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:70 loss: 0.002550tensor(0.2550, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:71 loss: 0.007029tensor(0.3833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:72 loss: 0.002780tensor(0.3848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:73 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:74 loss: 0.003894tensor(0.4078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:75 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:76 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:77 loss: 0.001240tensor(0.0670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:78 loss: 0.015774tensor(0.4049, grad_fn=<DivBackward0>)\n",
      "Test Epoch:37 step:79 loss: 0.002532tensor(0.3651, grad_fn=<DivBackward0>)\n",
      "Epoch:38 step:0 loss: 0.004953\n",
      "Epoch:38 step:1 loss: 0.003890\n",
      "Epoch:38 step:2 loss: 0.000160\n",
      "Epoch:38 step:3 loss: 0.000001\n",
      "Epoch:38 step:4 loss: 0.012879\n",
      "Epoch:38 step:5 loss: 0.005304\n",
      "Epoch:38 step:6 loss: 0.000005\n",
      "Epoch:38 step:7 loss: 0.008168\n",
      "Epoch:38 step:8 loss: 0.000016\n",
      "Epoch:38 step:9 loss: 0.000167\n",
      "Epoch:38 step:10 loss: 0.000009\n",
      "Epoch:38 step:11 loss: 0.009341\n",
      "Epoch:38 step:12 loss: 0.007780\n",
      "Epoch:38 step:13 loss: 0.000259\n",
      "Epoch:38 step:14 loss: 0.000001\n",
      "Epoch:38 step:15 loss: 0.000120\n",
      "Epoch:38 step:16 loss: 0.000008\n",
      "Epoch:38 step:17 loss: 0.000062\n",
      "Epoch:38 step:18 loss: 0.005427\n",
      "Epoch:38 step:19 loss: 0.019853\n",
      "Epoch:38 step:20 loss: 0.000008\n",
      "Epoch:38 step:21 loss: 0.000009\n",
      "Epoch:38 step:22 loss: 0.021943\n",
      "Epoch:38 step:23 loss: 0.001568\n",
      "Epoch:38 step:24 loss: 0.007421\n",
      "Epoch:38 step:25 loss: 0.001178\n",
      "Epoch:38 step:26 loss: 0.009948\n",
      "Epoch:38 step:27 loss: 0.022567\n",
      "Epoch:38 step:28 loss: 0.000063\n",
      "Epoch:38 step:29 loss: 0.000001\n",
      "Epoch:38 step:30 loss: 0.000398\n",
      "Epoch:38 step:31 loss: 0.000477\n",
      "Epoch:38 step:32 loss: 0.000062\n",
      "Epoch:38 step:33 loss: 0.000006\n",
      "Epoch:38 step:34 loss: 0.007135\n",
      "Epoch:38 step:35 loss: 0.004344\n",
      "Epoch:38 step:36 loss: 0.000024\n",
      "Epoch:38 step:37 loss: 0.006377\n",
      "Epoch:38 step:38 loss: 0.000039\n",
      "Epoch:38 step:39 loss: 0.000418\n",
      "Epoch:38 step:40 loss: 0.022515\n",
      "Epoch:38 step:41 loss: 0.000160\n",
      "Epoch:38 step:42 loss: 0.000320\n",
      "Epoch:38 step:43 loss: 0.012380\n",
      "Epoch:38 step:44 loss: 0.000003\n",
      "Epoch:38 step:45 loss: 0.001202\n",
      "Epoch:38 step:46 loss: 0.000034\n",
      "Epoch:38 step:47 loss: 0.009160\n",
      "Epoch:38 step:48 loss: 0.002380\n",
      "Epoch:38 step:49 loss: 0.000005\n",
      "Epoch:38 step:50 loss: 0.000133\n",
      "Epoch:38 step:51 loss: 0.000555\n",
      "Epoch:38 step:52 loss: 0.000005\n",
      "Epoch:38 step:53 loss: 0.000049\n",
      "Epoch:38 step:54 loss: 0.016688\n",
      "Epoch:38 step:55 loss: 0.017984\n",
      "Epoch:38 step:56 loss: 0.009412\n",
      "Epoch:38 step:57 loss: 0.001810\n",
      "Epoch:38 step:58 loss: 0.020043\n",
      "Epoch:38 step:59 loss: 0.000198\n",
      "Epoch:38 step:60 loss: 0.016505\n",
      "Epoch:38 step:61 loss: 0.009414\n",
      "Epoch:38 step:62 loss: 0.000041\n",
      "Epoch:38 step:63 loss: 0.001598\n",
      "Epoch:38 step:64 loss: 0.005127\n",
      "Epoch:38 step:65 loss: 0.005360\n",
      "Epoch:38 step:66 loss: 0.000561\n",
      "Epoch:38 step:67 loss: 0.005337\n",
      "Epoch:38 step:68 loss: 0.000001\n",
      "Epoch:38 step:69 loss: 0.000002\n",
      "Epoch:38 step:70 loss: 0.002507\n",
      "Epoch:38 step:71 loss: 0.012032\n",
      "Epoch:38 step:72 loss: 0.003066\n",
      "Epoch:38 step:73 loss: 0.000055\n",
      "Epoch:38 step:74 loss: 0.004459\n",
      "Epoch:38 step:75 loss: 0.000099\n",
      "Epoch:38 step:76 loss: 0.000011\n",
      "Epoch:38 step:77 loss: 0.000495\n",
      "Epoch:38 step:78 loss: 0.011684\n",
      "Epoch:38 step:79 loss: 0.004128\n",
      "Test Epoch:38 step:0 loss: 0.004893tensor(0.2598, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:1 loss: 0.003306tensor(0.1416, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:2 loss: 0.001480tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:4 loss: 0.011611tensor(0.3450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:5 loss: 0.006113tensor(0.3589, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:6 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:7 loss: 0.008721tensor(0.3120, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:8 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:9 loss: 0.001356tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:10 loss: 0.000409tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:11 loss: 0.010465tensor(0.2800, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:12 loss: 0.008404tensor(0.4250, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:13 loss: 0.000251tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:15 loss: 0.000340tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:16 loss: 0.000198tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:17 loss: 0.000138tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:18 loss: 0.004030tensor(0.3010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:19 loss: 0.017416tensor(0.3462, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:20 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:21 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:22 loss: 0.014351tensor(0.3878, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:23 loss: 0.000312tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:24 loss: 0.006711tensor(0.3890, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:25 loss: 0.002359tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:26 loss: 0.009111tensor(0.3613, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:27 loss: 0.022716tensor(0.4078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:28 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:30 loss: 0.001195tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:31 loss: 0.000358tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:32 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:34 loss: 0.005982tensor(0.2734, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:35 loss: 0.003534tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:36 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:37 loss: 0.003041tensor(0.1380, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:38 loss: 0.000437tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:39 loss: 0.000497tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:40 loss: 0.026442tensor(0.4128, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:42 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:43 loss: 0.010354tensor(0.4076, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:44 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:45 loss: 0.001449tensor(0.3223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:46 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:47 loss: 0.007718tensor(0.4076, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:48 loss: 0.002638tensor(0.2281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:50 loss: 0.000184tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:51 loss: 0.000282tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:52 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:53 loss: 0.000561tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:54 loss: 0.024191tensor(0.3686, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:55 loss: 0.025704tensor(0.3645, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:56 loss: 0.007195tensor(0.4225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:57 loss: 0.002315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:58 loss: 0.009460tensor(0.1276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:59 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:60 loss: 0.028401tensor(0.3967, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:61 loss: 0.012351tensor(0.1819, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:38 step:63 loss: 0.002015tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:64 loss: 0.005350tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:65 loss: 0.004512tensor(0.4075, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:66 loss: 0.000125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:67 loss: 0.007083tensor(0.3500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:70 loss: 0.001592tensor(0.2922, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:71 loss: 0.007503tensor(0.3787, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:72 loss: 0.002956tensor(0.3786, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:73 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:74 loss: 0.006773tensor(0.3465, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:75 loss: 0.000226tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:76 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:77 loss: 0.001046tensor(0.0899, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:78 loss: 0.010179tensor(0.4164, grad_fn=<DivBackward0>)\n",
      "Test Epoch:38 step:79 loss: 0.002661tensor(0.3589, grad_fn=<DivBackward0>)\n",
      "Epoch:39 step:0 loss: 0.004853\n",
      "Epoch:39 step:1 loss: 0.003740\n",
      "Epoch:39 step:2 loss: 0.000724\n",
      "Epoch:39 step:3 loss: 0.000007\n",
      "Epoch:39 step:4 loss: 0.010566\n",
      "Epoch:39 step:5 loss: 0.004938\n",
      "Epoch:39 step:6 loss: 0.000040\n",
      "Epoch:39 step:7 loss: 0.007458\n",
      "Epoch:39 step:8 loss: 0.000009\n",
      "Epoch:39 step:9 loss: 0.001095\n",
      "Epoch:39 step:10 loss: 0.000008\n",
      "Epoch:39 step:11 loss: 0.004641\n",
      "Epoch:39 step:12 loss: 0.006095\n",
      "Epoch:39 step:13 loss: 0.000052\n",
      "Epoch:39 step:14 loss: 0.000001\n",
      "Epoch:39 step:15 loss: 0.000051\n",
      "Epoch:39 step:16 loss: 0.000015\n",
      "Epoch:39 step:17 loss: 0.000272\n",
      "Epoch:39 step:18 loss: 0.005678\n",
      "Epoch:39 step:19 loss: 0.010596\n",
      "Epoch:39 step:20 loss: 0.000031\n",
      "Epoch:39 step:21 loss: 0.000004\n",
      "Epoch:39 step:22 loss: 0.016659\n",
      "Epoch:39 step:23 loss: 0.000756\n",
      "Epoch:39 step:24 loss: 0.005827\n",
      "Epoch:39 step:25 loss: 0.001447\n",
      "Epoch:39 step:26 loss: 0.008531\n",
      "Epoch:39 step:27 loss: 0.017418\n",
      "Epoch:39 step:28 loss: 0.000002\n",
      "Epoch:39 step:29 loss: 0.000003\n",
      "Epoch:39 step:30 loss: 0.001358\n",
      "Epoch:39 step:31 loss: 0.000508\n",
      "Epoch:39 step:32 loss: 0.000176\n",
      "Epoch:39 step:33 loss: 0.000002\n",
      "Epoch:39 step:34 loss: 0.004609\n",
      "Epoch:39 step:35 loss: 0.003065\n",
      "Epoch:39 step:36 loss: 0.000037\n",
      "Epoch:39 step:37 loss: 0.001413\n",
      "Epoch:39 step:38 loss: 0.000454\n",
      "Epoch:39 step:39 loss: 0.000170\n",
      "Epoch:39 step:40 loss: 0.022198\n",
      "Epoch:39 step:41 loss: 0.000001\n",
      "Epoch:39 step:42 loss: 0.000009\n",
      "Epoch:39 step:43 loss: 0.011001\n",
      "Epoch:39 step:44 loss: 0.000050\n",
      "Epoch:39 step:45 loss: 0.001700\n",
      "Epoch:39 step:46 loss: 0.000005\n",
      "Epoch:39 step:47 loss: 0.007388\n",
      "Epoch:39 step:48 loss: 0.002350\n",
      "Epoch:39 step:49 loss: 0.000001\n",
      "Epoch:39 step:50 loss: 0.000046\n",
      "Epoch:39 step:51 loss: 0.000047\n",
      "Epoch:39 step:52 loss: 0.000001\n",
      "Epoch:39 step:53 loss: 0.000039\n",
      "Epoch:39 step:54 loss: 0.015992\n",
      "Epoch:39 step:55 loss: 0.020315\n",
      "Epoch:39 step:56 loss: 0.006355\n",
      "Epoch:39 step:57 loss: 0.000744\n",
      "Epoch:39 step:58 loss: 0.007441\n",
      "Epoch:39 step:59 loss: 0.000058\n",
      "Epoch:39 step:60 loss: 0.016151\n",
      "Epoch:39 step:61 loss: 0.010956\n",
      "Epoch:39 step:62 loss: 0.000007\n",
      "Epoch:39 step:63 loss: 0.001821\n",
      "Epoch:39 step:64 loss: 0.007197\n",
      "Epoch:39 step:65 loss: 0.004801\n",
      "Epoch:39 step:66 loss: 0.000235\n",
      "Epoch:39 step:67 loss: 0.005913\n",
      "Epoch:39 step:68 loss: 0.000000\n",
      "Epoch:39 step:69 loss: 0.000000\n",
      "Epoch:39 step:70 loss: 0.001540\n",
      "Epoch:39 step:71 loss: 0.006203\n",
      "Epoch:39 step:72 loss: 0.001956\n",
      "Epoch:39 step:73 loss: 0.000010\n",
      "Epoch:39 step:74 loss: 0.004249\n",
      "Epoch:39 step:75 loss: 0.000126\n",
      "Epoch:39 step:76 loss: 0.000016\n",
      "Epoch:39 step:77 loss: 0.001135\n",
      "Epoch:39 step:78 loss: 0.022313\n",
      "Epoch:39 step:79 loss: 0.003463\n",
      "Test Epoch:39 step:0 loss: 0.004300tensor(0.2880, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:1 loss: 0.003270tensor(0.1574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:2 loss: 0.000259tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:3 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:4 loss: 0.014649tensor(0.3451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:5 loss: 0.005133tensor(0.3797, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:6 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:7 loss: 0.007170tensor(0.2986, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:8 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:9 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:10 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:11 loss: 0.007464tensor(0.3084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:12 loss: 0.010595tensor(0.4017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:13 loss: 0.000128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:15 loss: 0.000204tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:16 loss: 0.000162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:17 loss: 0.000078tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:18 loss: 0.006225tensor(0.2569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:19 loss: 0.017248tensor(0.3376, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:20 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:21 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:22 loss: 0.030766tensor(0.3252, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:23 loss: 0.000967tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:24 loss: 0.018959tensor(0.3034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:25 loss: 0.000864tensor(0.1831, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:26 loss: 0.010560tensor(0.3545, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:27 loss: 0.018485tensor(0.4288, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:28 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:30 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:31 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:32 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:33 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:34 loss: 0.010610tensor(0.0850, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:35 loss: 0.011358tensor(0.0549, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:36 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:37 loss: 0.005438tensor(0.0105, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:38 loss: 0.000164tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:39 loss: 0.000236tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:40 loss: 0.021034tensor(0.4293, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:41 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:42 loss: 0.000562tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:43 loss: 0.010278tensor(0.4048, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:44 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:45 loss: 0.001488tensor(0.3155, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:46 loss: 0.001559tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:47 loss: 0.009901tensor(0.3871, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:48 loss: 0.003716tensor(0.2323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:49 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:50 loss: 0.000634tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:51 loss: 0.001570tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:53 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:54 loss: 0.012969tensor(0.4022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:55 loss: 0.017082tensor(0.3793, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:56 loss: 0.008626tensor(0.4196, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:57 loss: 0.001170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:58 loss: 0.008619tensor(0.1358, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:59 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:39 step:60 loss: 0.013880tensor(0.4336, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:61 loss: 0.016605tensor(0.1396, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:63 loss: 0.002024tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:64 loss: 0.005565tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:65 loss: 0.003944tensor(0.4196, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:66 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:67 loss: 0.007896tensor(0.3384, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:69 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:70 loss: 0.002404tensor(0.2398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:71 loss: 0.007682tensor(0.3766, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:72 loss: 0.004067tensor(0.3553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:73 loss: 0.000300tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:74 loss: 0.005740tensor(0.3800, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:75 loss: 0.000309tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:76 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:77 loss: 0.000522tensor(0.2695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:78 loss: 0.010474tensor(0.4153, grad_fn=<DivBackward0>)\n",
      "Test Epoch:39 step:79 loss: 0.003986tensor(0.3302, grad_fn=<DivBackward0>)\n",
      "Epoch:40 step:0 loss: 0.004752\n",
      "Epoch:40 step:1 loss: 0.003376\n",
      "Epoch:40 step:2 loss: 0.000643\n",
      "Epoch:40 step:3 loss: 0.000016\n",
      "Epoch:40 step:4 loss: 0.013787\n",
      "Epoch:40 step:5 loss: 0.006870\n",
      "Epoch:40 step:6 loss: 0.000038\n",
      "Epoch:40 step:7 loss: 0.008054\n",
      "Epoch:40 step:8 loss: 0.000011\n",
      "Epoch:40 step:9 loss: 0.002844\n",
      "Epoch:40 step:10 loss: 0.000411\n",
      "Epoch:40 step:11 loss: 0.006797\n",
      "Epoch:40 step:12 loss: 0.006948\n",
      "Epoch:40 step:13 loss: 0.000491\n",
      "Epoch:40 step:14 loss: 0.000000\n",
      "Epoch:40 step:15 loss: 0.000093\n",
      "Epoch:40 step:16 loss: 0.000002\n",
      "Epoch:40 step:17 loss: 0.000219\n",
      "Epoch:40 step:18 loss: 0.006100\n",
      "Epoch:40 step:19 loss: 0.012296\n",
      "Epoch:40 step:20 loss: 0.000003\n",
      "Epoch:40 step:21 loss: 0.000006\n",
      "Epoch:40 step:22 loss: 0.017366\n",
      "Epoch:40 step:23 loss: 0.000979\n",
      "Epoch:40 step:24 loss: 0.006783\n",
      "Epoch:40 step:25 loss: 0.003056\n",
      "Epoch:40 step:26 loss: 0.012851\n",
      "Epoch:40 step:27 loss: 0.016128\n",
      "Epoch:40 step:28 loss: 0.000009\n",
      "Epoch:40 step:29 loss: 0.000004\n",
      "Epoch:40 step:30 loss: 0.001112\n",
      "Epoch:40 step:31 loss: 0.001197\n",
      "Epoch:40 step:32 loss: 0.000042\n",
      "Epoch:40 step:33 loss: 0.000002\n",
      "Epoch:40 step:34 loss: 0.005205\n",
      "Epoch:40 step:35 loss: 0.004309\n",
      "Epoch:40 step:36 loss: 0.000028\n",
      "Epoch:40 step:37 loss: 0.001943\n",
      "Epoch:40 step:38 loss: 0.000204\n",
      "Epoch:40 step:39 loss: 0.003852\n",
      "Epoch:40 step:40 loss: 0.018245\n",
      "Epoch:40 step:41 loss: 0.000002\n",
      "Epoch:40 step:42 loss: 0.000035\n",
      "Epoch:40 step:43 loss: 0.009006\n",
      "Epoch:40 step:44 loss: 0.000016\n",
      "Epoch:40 step:45 loss: 0.001820\n",
      "Epoch:40 step:46 loss: 0.000003\n",
      "Epoch:40 step:47 loss: 0.007834\n",
      "Epoch:40 step:48 loss: 0.003302\n",
      "Epoch:40 step:49 loss: 0.000002\n",
      "Epoch:40 step:50 loss: 0.000094\n",
      "Epoch:40 step:51 loss: 0.000528\n",
      "Epoch:40 step:52 loss: 0.000003\n",
      "Epoch:40 step:53 loss: 0.000026\n",
      "Epoch:40 step:54 loss: 0.011839\n",
      "Epoch:40 step:55 loss: 0.013427\n",
      "Epoch:40 step:56 loss: 0.007453\n",
      "Epoch:40 step:57 loss: 0.004051\n",
      "Epoch:40 step:58 loss: 0.005759\n",
      "Epoch:40 step:59 loss: 0.000259\n",
      "Epoch:40 step:60 loss: 0.012671\n",
      "Epoch:40 step:61 loss: 0.008919\n",
      "Epoch:40 step:62 loss: 0.000011\n",
      "Epoch:40 step:63 loss: 0.002763\n",
      "Epoch:40 step:64 loss: 0.003855\n",
      "Epoch:40 step:65 loss: 0.003704\n",
      "Epoch:40 step:66 loss: 0.000094\n",
      "Epoch:40 step:67 loss: 0.010217\n",
      "Epoch:40 step:68 loss: 0.000000\n",
      "Epoch:40 step:69 loss: 0.000000\n",
      "Epoch:40 step:70 loss: 0.002399\n",
      "Epoch:40 step:71 loss: 0.006250\n",
      "Epoch:40 step:72 loss: 0.002778\n",
      "Epoch:40 step:73 loss: 0.000011\n",
      "Epoch:40 step:74 loss: 0.003749\n",
      "Epoch:40 step:75 loss: 0.000046\n",
      "Epoch:40 step:76 loss: 0.000013\n",
      "Epoch:40 step:77 loss: 0.001030\n",
      "Epoch:40 step:78 loss: 0.011400\n",
      "Epoch:40 step:79 loss: 0.002292\n",
      "Test Epoch:40 step:0 loss: 0.004207tensor(0.2933, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:1 loss: 0.002785tensor(0.1649, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:2 loss: 0.000341tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:3 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:4 loss: 0.013416tensor(0.3686, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:5 loss: 0.005516tensor(0.3805, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:7 loss: 0.006422tensor(0.3351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:8 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:9 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:10 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:11 loss: 0.006737tensor(0.3156, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:12 loss: 0.005786tensor(0.4456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:13 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:15 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:16 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:17 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:18 loss: 0.004479tensor(0.2835, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:19 loss: 0.017954tensor(0.3349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:20 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:21 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:22 loss: 0.017650tensor(0.3822, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:23 loss: 0.001427tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:24 loss: 0.010267tensor(0.3634, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:25 loss: 0.001700tensor(0.0308, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:26 loss: 0.010697tensor(0.3607, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:27 loss: 0.016471tensor(0.4316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:28 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:30 loss: 0.000443tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:31 loss: 0.000112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:32 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:34 loss: 0.005575tensor(0.2513, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:35 loss: 0.004748tensor(0.2617, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:36 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:37 loss: 0.002384tensor(0.1489, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:38 loss: 0.000081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:39 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:40 loss: 0.020302tensor(0.4350, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:42 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:43 loss: 0.008408tensor(0.4202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:44 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:45 loss: 0.001565tensor(0.3339, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:46 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:47 loss: 0.007061tensor(0.4177, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:48 loss: 0.003875tensor(0.2388, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:49 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:50 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:51 loss: 0.000164tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:52 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:53 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:54 loss: 0.010616tensor(0.4227, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:55 loss: 0.015023tensor(0.4074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:56 loss: 0.007526tensor(0.4242, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:40 step:57 loss: 0.001377tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:58 loss: 0.009316tensor(0.1455, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:59 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:60 loss: 0.013035tensor(0.4435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:61 loss: 0.011044tensor(0.2199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:62 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:63 loss: 0.002344tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:64 loss: 0.006507tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:65 loss: 0.007297tensor(0.3788, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:66 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:67 loss: 0.006537tensor(0.3798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:70 loss: 0.001547tensor(0.2917, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:71 loss: 0.006018tensor(0.4062, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:72 loss: 0.005217tensor(0.3293, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:73 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:74 loss: 0.022224tensor(0.1053, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:75 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:76 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:77 loss: 0.000836tensor(0.1162, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:78 loss: 0.009213tensor(0.4220, grad_fn=<DivBackward0>)\n",
      "Test Epoch:40 step:79 loss: 0.003344tensor(0.3349, grad_fn=<DivBackward0>)\n",
      "Epoch:41 step:0 loss: 0.004520\n",
      "Epoch:41 step:1 loss: 0.003933\n",
      "Epoch:41 step:2 loss: 0.005856\n",
      "Epoch:41 step:3 loss: 0.000049\n",
      "Epoch:41 step:4 loss: 0.015498\n",
      "Epoch:41 step:5 loss: 0.006057\n",
      "Epoch:41 step:6 loss: 0.000355\n",
      "Epoch:41 step:7 loss: 0.008261\n",
      "Epoch:41 step:8 loss: 0.000008\n",
      "Epoch:41 step:9 loss: 0.000939\n",
      "Epoch:41 step:10 loss: 0.000164\n",
      "Epoch:41 step:11 loss: 0.004396\n",
      "Epoch:41 step:12 loss: 0.007445\n",
      "Epoch:41 step:13 loss: 0.000083\n",
      "Epoch:41 step:14 loss: 0.000010\n",
      "Epoch:41 step:15 loss: 0.000240\n",
      "Epoch:41 step:16 loss: 0.000006\n",
      "Epoch:41 step:17 loss: 0.001216\n",
      "Epoch:41 step:18 loss: 0.004185\n",
      "Epoch:41 step:19 loss: 0.009906\n",
      "Epoch:41 step:20 loss: 0.004877\n",
      "Epoch:41 step:21 loss: 0.000002\n",
      "Epoch:41 step:22 loss: 0.025048\n",
      "Epoch:41 step:23 loss: 0.001597\n",
      "Epoch:41 step:24 loss: 0.006119\n",
      "Epoch:41 step:25 loss: 0.002996\n",
      "Epoch:41 step:26 loss: 0.007775\n",
      "Epoch:41 step:27 loss: 0.019014\n",
      "Epoch:41 step:28 loss: 0.000019\n",
      "Epoch:41 step:29 loss: 0.000006\n",
      "Epoch:41 step:30 loss: 0.000813\n",
      "Epoch:41 step:31 loss: 0.001725\n",
      "Epoch:41 step:32 loss: 0.000095\n",
      "Epoch:41 step:33 loss: 0.000001\n",
      "Epoch:41 step:34 loss: 0.010182\n",
      "Epoch:41 step:35 loss: 0.006183\n",
      "Epoch:41 step:36 loss: 0.000016\n",
      "Epoch:41 step:37 loss: 0.002082\n",
      "Epoch:41 step:38 loss: 0.000066\n",
      "Epoch:41 step:39 loss: 0.001664\n",
      "Epoch:41 step:40 loss: 0.024320\n",
      "Epoch:41 step:41 loss: 0.000011\n",
      "Epoch:41 step:42 loss: 0.001184\n",
      "Epoch:41 step:43 loss: 0.011260\n",
      "Epoch:41 step:44 loss: 0.000084\n",
      "Epoch:41 step:45 loss: 0.002075\n",
      "Epoch:41 step:46 loss: 0.000411\n",
      "Epoch:41 step:47 loss: 0.009172\n",
      "Epoch:41 step:48 loss: 0.002836\n",
      "Epoch:41 step:49 loss: 0.000009\n",
      "Epoch:41 step:50 loss: 0.000447\n",
      "Epoch:41 step:51 loss: 0.002952\n",
      "Epoch:41 step:52 loss: 0.000011\n",
      "Epoch:41 step:53 loss: 0.000100\n",
      "Epoch:41 step:54 loss: 0.013491\n",
      "Epoch:41 step:55 loss: 0.014439\n",
      "Epoch:41 step:56 loss: 0.006754\n",
      "Epoch:41 step:57 loss: 0.000825\n",
      "Epoch:41 step:58 loss: 0.007220\n",
      "Epoch:41 step:59 loss: 0.000086\n",
      "Epoch:41 step:60 loss: 0.012418\n",
      "Epoch:41 step:61 loss: 0.012370\n",
      "Epoch:41 step:62 loss: 0.000014\n",
      "Epoch:41 step:63 loss: 0.001961\n",
      "Epoch:41 step:64 loss: 0.002797\n",
      "Epoch:41 step:65 loss: 0.006196\n",
      "Epoch:41 step:66 loss: 0.000304\n",
      "Epoch:41 step:67 loss: 0.006555\n",
      "Epoch:41 step:68 loss: 0.000005\n",
      "Epoch:41 step:69 loss: 0.000001\n",
      "Epoch:41 step:70 loss: 0.002652\n",
      "Epoch:41 step:71 loss: 0.008190\n",
      "Epoch:41 step:72 loss: 0.003627\n",
      "Epoch:41 step:73 loss: 0.000024\n",
      "Epoch:41 step:74 loss: 0.003860\n",
      "Epoch:41 step:75 loss: 0.000144\n",
      "Epoch:41 step:76 loss: 0.000019\n",
      "Epoch:41 step:77 loss: 0.000875\n",
      "Epoch:41 step:78 loss: 0.018449\n",
      "Epoch:41 step:79 loss: 0.002994\n",
      "Test Epoch:41 step:0 loss: 0.005183tensor(0.2600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:1 loss: 0.002598tensor(0.1692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:2 loss: 0.000777tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:3 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:4 loss: 0.010823tensor(0.3696, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:5 loss: 0.005725tensor(0.3760, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:6 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:7 loss: 0.006512tensor(0.3318, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:8 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:9 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:10 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:11 loss: 0.007195tensor(0.3152, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:12 loss: 0.006679tensor(0.4379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:13 loss: 0.000223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:14 loss: 0.031253tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:15 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:17 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:18 loss: 0.016131tensor(0.0343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:19 loss: 0.030300tensor(0.2519, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:22 loss: 0.048329tensor(0.2427, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:23 loss: 0.000856tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:24 loss: 0.012353tensor(0.3378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:25 loss: 0.002899tensor(0.0090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:26 loss: 0.033123tensor(0.2444, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:27 loss: 0.032473tensor(0.3813, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:28 loss: 0.001113tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:29 loss: 0.000066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:30 loss: 0.013017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:31 loss: 0.000219tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:32 loss: 0.000133tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:34 loss: 0.022804tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:35 loss: 0.020167tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:36 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:37 loss: 0.003894tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:38 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:39 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:40 loss: 0.267584tensor(0.0359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:41 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:42 loss: 0.000607tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:43 loss: 0.045373tensor(0.1477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:44 loss: 0.005175tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:45 loss: 0.027839tensor(0.0115, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:46 loss: 0.006176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:47 loss: 0.023798tensor(0.2301, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:48 loss: 0.005209tensor(0.0335, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:49 loss: 0.000458tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:50 loss: 0.005243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:51 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:52 loss: 0.001354tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:53 loss: 0.000511tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:41 step:54 loss: 0.032322tensor(0.3072, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:55 loss: 0.039388tensor(0.2609, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:56 loss: 0.045242tensor(0.2364, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:57 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:58 loss: 0.036555tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:59 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:60 loss: 0.023887tensor(0.3841, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:61 loss: 0.027729tensor(0.0173, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:62 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:63 loss: 0.004147tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:64 loss: 0.014675tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:65 loss: 0.008383tensor(0.3075, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:66 loss: 0.001892tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:67 loss: 0.012429tensor(0.2233, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:68 loss: 0.000376tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:69 loss: 0.000578tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:70 loss: 0.005469tensor(0.0251, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:71 loss: 0.016117tensor(0.2363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:72 loss: 0.007499tensor(0.2302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:73 loss: 0.000262tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:74 loss: 0.010630tensor(0.2659, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:75 loss: 0.000659tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:76 loss: 0.000284tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:77 loss: 0.001403tensor(0.0537, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:78 loss: 0.033385tensor(0.2692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:41 step:79 loss: 0.008341tensor(0.1219, grad_fn=<DivBackward0>)\n",
      "Epoch:42 step:0 loss: 0.009558\n",
      "Epoch:42 step:1 loss: 0.007479\n",
      "Epoch:42 step:2 loss: 0.003657\n",
      "Epoch:42 step:3 loss: 0.000072\n",
      "Epoch:42 step:4 loss: 0.018523\n",
      "Epoch:42 step:5 loss: 0.010722\n",
      "Epoch:42 step:6 loss: 0.000013\n",
      "Epoch:42 step:7 loss: 0.014642\n",
      "Epoch:42 step:8 loss: 0.000071\n",
      "Epoch:42 step:9 loss: 0.000625\n",
      "Epoch:42 step:10 loss: 0.000212\n",
      "Epoch:42 step:11 loss: 0.007463\n",
      "Epoch:42 step:12 loss: 0.017598\n",
      "Epoch:42 step:13 loss: 0.001220\n",
      "Epoch:42 step:14 loss: 0.000141\n",
      "Epoch:42 step:15 loss: 0.000554\n",
      "Epoch:42 step:16 loss: 0.000008\n",
      "Epoch:42 step:17 loss: 0.013730\n",
      "Epoch:42 step:18 loss: 0.009238\n",
      "Epoch:42 step:19 loss: 0.015924\n",
      "Epoch:42 step:20 loss: 0.000005\n",
      "Epoch:42 step:21 loss: 0.000007\n",
      "Epoch:42 step:22 loss: 0.032187\n",
      "Epoch:42 step:23 loss: 0.002077\n",
      "Epoch:42 step:24 loss: 0.008946\n",
      "Epoch:42 step:25 loss: 0.002782\n",
      "Epoch:42 step:26 loss: 0.013735\n",
      "Epoch:42 step:27 loss: 0.021706\n",
      "Epoch:42 step:28 loss: 0.000157\n",
      "Epoch:42 step:29 loss: 0.000015\n",
      "Epoch:42 step:30 loss: 0.000791\n",
      "Epoch:42 step:31 loss: 0.000599\n",
      "Epoch:42 step:32 loss: 0.000077\n",
      "Epoch:42 step:33 loss: 0.000003\n",
      "Epoch:42 step:34 loss: 0.010800\n",
      "Epoch:42 step:35 loss: 0.006819\n",
      "Epoch:42 step:36 loss: 0.000328\n",
      "Epoch:42 step:37 loss: 0.001427\n",
      "Epoch:42 step:38 loss: 0.000011\n",
      "Epoch:42 step:39 loss: 0.002544\n",
      "Epoch:42 step:40 loss: 0.035277\n",
      "Epoch:42 step:41 loss: 0.000004\n",
      "Epoch:42 step:42 loss: 0.000061\n",
      "Epoch:42 step:43 loss: 0.011355\n",
      "Epoch:42 step:44 loss: 0.000420\n",
      "Epoch:42 step:45 loss: 0.005893\n",
      "Epoch:42 step:46 loss: 0.002854\n",
      "Epoch:42 step:47 loss: 0.029507\n",
      "Epoch:42 step:48 loss: 0.003360\n",
      "Epoch:42 step:49 loss: 0.000061\n",
      "Epoch:42 step:50 loss: 0.000372\n",
      "Epoch:42 step:51 loss: 0.000156\n",
      "Epoch:42 step:52 loss: 0.000019\n",
      "Epoch:42 step:53 loss: 0.000064\n",
      "Epoch:42 step:54 loss: 0.030649\n",
      "Epoch:42 step:55 loss: 0.032809\n",
      "Epoch:42 step:56 loss: 0.025497\n",
      "Epoch:42 step:57 loss: 0.000821\n",
      "Epoch:42 step:58 loss: 0.024723\n",
      "Epoch:42 step:59 loss: 0.000627\n",
      "Epoch:42 step:60 loss: 0.032644\n",
      "Epoch:42 step:61 loss: 0.008974\n",
      "Epoch:42 step:62 loss: 0.000009\n",
      "Epoch:42 step:63 loss: 0.012415\n",
      "Epoch:42 step:64 loss: 0.009039\n",
      "Epoch:42 step:65 loss: 0.008244\n",
      "Epoch:42 step:66 loss: 0.000093\n",
      "Epoch:42 step:67 loss: 0.012689\n",
      "Epoch:42 step:68 loss: 0.000003\n",
      "Epoch:42 step:69 loss: 0.000005\n",
      "Epoch:42 step:70 loss: 0.006001\n",
      "Epoch:42 step:71 loss: 0.025018\n",
      "Epoch:42 step:72 loss: 0.004804\n",
      "Epoch:42 step:73 loss: 0.000022\n",
      "Epoch:42 step:74 loss: 0.010840\n",
      "Epoch:42 step:75 loss: 0.000072\n",
      "Epoch:42 step:76 loss: 0.000033\n",
      "Epoch:42 step:77 loss: 0.001364\n",
      "Epoch:42 step:78 loss: 0.031680\n",
      "Epoch:42 step:79 loss: 0.008304\n",
      "Test Epoch:42 step:0 loss: 0.009331tensor(0.0971, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:1 loss: 0.006063tensor(0.0325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:2 loss: 0.008504tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:3 loss: 0.000101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:4 loss: 0.018989tensor(0.2515, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:5 loss: 0.008051tensor(0.2716, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:6 loss: 0.000808tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:7 loss: 0.011866tensor(0.2120, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:8 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:9 loss: 0.001179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:10 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:11 loss: 0.008564tensor(0.2333, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:12 loss: 0.013266tensor(0.3720, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:13 loss: 0.000717tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:14 loss: 0.000078tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:15 loss: 0.000314tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:16 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:17 loss: 0.001013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:18 loss: 0.007666tensor(0.1420, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:19 loss: 0.021137tensor(0.2920, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:20 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:21 loss: 0.000286tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:22 loss: 0.042019tensor(0.2413, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:23 loss: 0.002014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:24 loss: 0.009028tensor(0.3487, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:25 loss: 0.004506tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:26 loss: 0.017934tensor(0.2860, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:27 loss: 0.027401tensor(0.3916, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:28 loss: 0.000118tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:29 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:30 loss: 0.001884tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:31 loss: 0.000285tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:32 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:33 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:34 loss: 0.010504tensor(0.1131, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:35 loss: 0.004423tensor(0.2523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:36 loss: 0.001165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:37 loss: 0.001545tensor(0.1122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:38 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:39 loss: 0.001559tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:40 loss: 0.024043tensor(0.4042, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:41 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:42 loss: 0.000261tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:43 loss: 0.014616tensor(0.3659, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:44 loss: 0.000174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:45 loss: 0.002923tensor(0.2422, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:46 loss: 0.000177tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:47 loss: 0.010266tensor(0.3729, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:48 loss: 0.003011tensor(0.2139, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:49 loss: 0.000122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:50 loss: 0.001148tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:42 step:51 loss: 0.000787tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:52 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:53 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:54 loss: 0.030664tensor(0.3366, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:55 loss: 0.019654tensor(0.3648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:56 loss: 0.010732tensor(0.3974, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:57 loss: 0.001037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:58 loss: 0.011145tensor(0.0856, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:59 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:60 loss: 0.032319tensor(0.3705, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:61 loss: 0.012281tensor(0.1727, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:63 loss: 0.002680tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:64 loss: 0.002815tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:65 loss: 0.005130tensor(0.3844, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:66 loss: 0.000888tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:67 loss: 0.006207tensor(0.3464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:69 loss: 0.000215tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:70 loss: 0.002055tensor(0.2338, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:71 loss: 0.009446tensor(0.3537, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:72 loss: 0.004070tensor(0.3513, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:73 loss: 0.000239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:74 loss: 0.004484tensor(0.3902, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:75 loss: 0.001277tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:76 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:77 loss: 0.002675tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:78 loss: 0.012716tensor(0.3912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:42 step:79 loss: 0.003580tensor(0.3364, grad_fn=<DivBackward0>)\n",
      "Epoch:43 step:0 loss: 0.006395\n",
      "Epoch:43 step:1 loss: 0.003447\n",
      "Epoch:43 step:2 loss: 0.000176\n",
      "Epoch:43 step:3 loss: 0.000006\n",
      "Epoch:43 step:4 loss: 0.015682\n",
      "Epoch:43 step:5 loss: 0.008420\n",
      "Epoch:43 step:6 loss: 0.000001\n",
      "Epoch:43 step:7 loss: 0.008938\n",
      "Epoch:43 step:8 loss: 0.000001\n",
      "Epoch:43 step:9 loss: 0.000104\n",
      "Epoch:43 step:10 loss: 0.000010\n",
      "Epoch:43 step:11 loss: 0.006561\n",
      "Epoch:43 step:12 loss: 0.007395\n",
      "Epoch:43 step:13 loss: 0.001000\n",
      "Epoch:43 step:14 loss: 0.000008\n",
      "Epoch:43 step:15 loss: 0.000341\n",
      "Epoch:43 step:16 loss: 0.000001\n",
      "Epoch:43 step:17 loss: 0.000256\n",
      "Epoch:43 step:18 loss: 0.006416\n",
      "Epoch:43 step:19 loss: 0.013472\n",
      "Epoch:43 step:20 loss: 0.000000\n",
      "Epoch:43 step:21 loss: 0.000000\n",
      "Epoch:43 step:22 loss: 0.017729\n",
      "Epoch:43 step:23 loss: 0.001430\n",
      "Epoch:43 step:24 loss: 0.007376\n",
      "Epoch:43 step:25 loss: 0.003625\n",
      "Epoch:43 step:26 loss: 0.012800\n",
      "Epoch:43 step:27 loss: 0.019021\n",
      "Epoch:43 step:28 loss: 0.000043\n",
      "Epoch:43 step:29 loss: 0.000003\n",
      "Epoch:43 step:30 loss: 0.000346\n",
      "Epoch:43 step:31 loss: 0.000315\n",
      "Epoch:43 step:32 loss: 0.000054\n",
      "Epoch:43 step:33 loss: 0.000000\n",
      "Epoch:43 step:34 loss: 0.007043\n",
      "Epoch:43 step:35 loss: 0.004175\n",
      "Epoch:43 step:36 loss: 0.000146\n",
      "Epoch:43 step:37 loss: 0.002969\n",
      "Epoch:43 step:38 loss: 0.000022\n",
      "Epoch:43 step:39 loss: 0.000278\n",
      "Epoch:43 step:40 loss: 0.039331\n",
      "Epoch:43 step:41 loss: 0.000001\n",
      "Epoch:43 step:42 loss: 0.000026\n",
      "Epoch:43 step:43 loss: 0.011973\n",
      "Epoch:43 step:44 loss: 0.000086\n",
      "Epoch:43 step:45 loss: 0.001671\n",
      "Epoch:43 step:46 loss: 0.000053\n",
      "Epoch:43 step:47 loss: 0.008624\n",
      "Epoch:43 step:48 loss: 0.003509\n",
      "Epoch:43 step:49 loss: 0.000020\n",
      "Epoch:43 step:50 loss: 0.000389\n",
      "Epoch:43 step:51 loss: 0.000411\n",
      "Epoch:43 step:52 loss: 0.000016\n",
      "Epoch:43 step:53 loss: 0.000163\n",
      "Epoch:43 step:54 loss: 0.041150\n",
      "Epoch:43 step:55 loss: 0.039416\n",
      "Epoch:43 step:56 loss: 0.008549\n",
      "Epoch:43 step:57 loss: 0.001596\n",
      "Epoch:43 step:58 loss: 0.007158\n",
      "Epoch:43 step:59 loss: 0.000014\n",
      "Epoch:43 step:60 loss: 0.055247\n",
      "Epoch:43 step:61 loss: 0.018063\n",
      "Epoch:43 step:62 loss: 0.000000\n",
      "Epoch:43 step:63 loss: 0.002355\n",
      "Epoch:43 step:64 loss: 0.000457\n",
      "Epoch:43 step:65 loss: 0.007016\n",
      "Epoch:43 step:66 loss: 0.000126\n",
      "Epoch:43 step:67 loss: 0.007186\n",
      "Epoch:43 step:68 loss: 0.000001\n",
      "Epoch:43 step:69 loss: 0.000001\n",
      "Epoch:43 step:70 loss: 0.001621\n",
      "Epoch:43 step:71 loss: 0.011132\n",
      "Epoch:43 step:72 loss: 0.008755\n",
      "Epoch:43 step:73 loss: 0.000215\n",
      "Epoch:43 step:74 loss: 0.004944\n",
      "Epoch:43 step:75 loss: 0.000974\n",
      "Epoch:43 step:76 loss: 0.000039\n",
      "Epoch:43 step:77 loss: 0.001052\n",
      "Epoch:43 step:78 loss: 0.014611\n",
      "Epoch:43 step:79 loss: 0.003580\n",
      "Test Epoch:43 step:0 loss: 0.005966tensor(0.2025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:1 loss: 0.004106tensor(0.0663, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:2 loss: 0.000803tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:3 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:4 loss: 0.012111tensor(0.3355, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:5 loss: 0.007159tensor(0.3302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:6 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:7 loss: 0.008496tensor(0.2932, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:9 loss: 0.000384tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:10 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:11 loss: 0.008455tensor(0.2773, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:12 loss: 0.007250tensor(0.4297, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:13 loss: 0.001472tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:14 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:15 loss: 0.000400tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:17 loss: 0.000126tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:18 loss: 0.005282tensor(0.2417, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:19 loss: 0.015956tensor(0.3425, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:22 loss: 0.019275tensor(0.3538, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:23 loss: 0.000673tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:24 loss: 0.006124tensor(0.3965, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:25 loss: 0.002408tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:26 loss: 0.009976tensor(0.3520, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:27 loss: 0.017848tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:28 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:30 loss: 0.001333tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:31 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:32 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:34 loss: 0.005926tensor(0.2435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:35 loss: 0.004296tensor(0.2826, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:36 loss: 0.000181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:37 loss: 0.002680tensor(0.1181, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:38 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:39 loss: 0.000220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:40 loss: 0.027228tensor(0.4087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:42 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:43 loss: 0.011115tensor(0.3989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:44 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:45 loss: 0.001876tensor(0.2864, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:46 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:47 loss: 0.007748tensor(0.4030, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:43 step:48 loss: 0.003879tensor(0.2112, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:49 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:50 loss: 0.000643tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:51 loss: 0.000776tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:52 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:53 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:54 loss: 0.026861tensor(0.3575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:55 loss: 0.023461tensor(0.3647, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:56 loss: 0.007218tensor(0.4211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:57 loss: 0.004437tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:58 loss: 0.008616tensor(0.1752, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:59 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:60 loss: 0.020946tensor(0.4159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:61 loss: 0.012417tensor(0.1844, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:63 loss: 0.003323tensor(1.5973e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:64 loss: 0.001213tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:65 loss: 0.005344tensor(0.3914, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:66 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:67 loss: 0.009935tensor(0.3143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:70 loss: 0.002671tensor(0.2273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:71 loss: 0.008121tensor(0.3832, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:72 loss: 0.002769tensor(0.3843, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:73 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:74 loss: 0.004041tensor(0.4059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:75 loss: 0.000110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:76 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:77 loss: 0.000923tensor(0.0910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:78 loss: 0.011511tensor(0.4089, grad_fn=<DivBackward0>)\n",
      "Test Epoch:43 step:79 loss: 0.002319tensor(0.3725, grad_fn=<DivBackward0>)\n",
      "Epoch:44 step:0 loss: 0.004743\n",
      "Epoch:44 step:1 loss: 0.002766\n",
      "Epoch:44 step:2 loss: 0.000646\n",
      "Epoch:44 step:3 loss: 0.000001\n",
      "Epoch:44 step:4 loss: 0.010873\n",
      "Epoch:44 step:5 loss: 0.005178\n",
      "Epoch:44 step:6 loss: 0.000043\n",
      "Epoch:44 step:7 loss: 0.007272\n",
      "Epoch:44 step:8 loss: 0.000002\n",
      "Epoch:44 step:9 loss: 0.000238\n",
      "Epoch:44 step:10 loss: 0.000002\n",
      "Epoch:44 step:11 loss: 0.007442\n",
      "Epoch:44 step:12 loss: 0.005981\n",
      "Epoch:44 step:13 loss: 0.000078\n",
      "Epoch:44 step:14 loss: 0.000002\n",
      "Epoch:44 step:15 loss: 0.000069\n",
      "Epoch:44 step:16 loss: 0.000001\n",
      "Epoch:44 step:17 loss: 0.000041\n",
      "Epoch:44 step:18 loss: 0.006429\n",
      "Epoch:44 step:19 loss: 0.012461\n",
      "Epoch:44 step:20 loss: 0.000020\n",
      "Epoch:44 step:21 loss: 0.000001\n",
      "Epoch:44 step:22 loss: 0.015198\n",
      "Epoch:44 step:23 loss: 0.000410\n",
      "Epoch:44 step:24 loss: 0.005010\n",
      "Epoch:44 step:25 loss: 0.002140\n",
      "Epoch:44 step:26 loss: 0.011028\n",
      "Epoch:44 step:27 loss: 0.017371\n",
      "Epoch:44 step:28 loss: 0.000038\n",
      "Epoch:44 step:29 loss: 0.000004\n",
      "Epoch:44 step:30 loss: 0.001634\n",
      "Epoch:44 step:31 loss: 0.000354\n",
      "Epoch:44 step:32 loss: 0.000090\n",
      "Epoch:44 step:33 loss: 0.000001\n",
      "Epoch:44 step:34 loss: 0.007253\n",
      "Epoch:44 step:35 loss: 0.004728\n",
      "Epoch:44 step:36 loss: 0.000248\n",
      "Epoch:44 step:37 loss: 0.002651\n",
      "Epoch:44 step:38 loss: 0.000045\n",
      "Epoch:44 step:39 loss: 0.000453\n",
      "Epoch:44 step:40 loss: 0.032232\n",
      "Epoch:44 step:41 loss: 0.000001\n",
      "Epoch:44 step:42 loss: 0.000031\n",
      "Epoch:44 step:43 loss: 0.013945\n",
      "Epoch:44 step:44 loss: 0.000019\n",
      "Epoch:44 step:45 loss: 0.001961\n",
      "Epoch:44 step:46 loss: 0.000003\n",
      "Epoch:44 step:47 loss: 0.007951\n",
      "Epoch:44 step:48 loss: 0.003889\n",
      "Epoch:44 step:49 loss: 0.000007\n",
      "Epoch:44 step:50 loss: 0.000175\n",
      "Epoch:44 step:51 loss: 0.000033\n",
      "Epoch:44 step:52 loss: 0.000008\n",
      "Epoch:44 step:53 loss: 0.000089\n",
      "Epoch:44 step:54 loss: 0.016690\n",
      "Epoch:44 step:55 loss: 0.025952\n",
      "Epoch:44 step:56 loss: 0.008764\n",
      "Epoch:44 step:57 loss: 0.000165\n",
      "Epoch:44 step:58 loss: 0.005839\n",
      "Epoch:44 step:59 loss: 0.000123\n",
      "Epoch:44 step:60 loss: 0.018264\n",
      "Epoch:44 step:61 loss: 0.011163\n",
      "Epoch:44 step:62 loss: 0.000004\n",
      "Epoch:44 step:63 loss: 0.002010\n",
      "Epoch:44 step:64 loss: 0.001882\n",
      "Epoch:44 step:65 loss: 0.003988\n",
      "Epoch:44 step:66 loss: 0.000143\n",
      "Epoch:44 step:67 loss: 0.006282\n",
      "Epoch:44 step:68 loss: 0.000000\n",
      "Epoch:44 step:69 loss: 0.000000\n",
      "Epoch:44 step:70 loss: 0.002380\n",
      "Epoch:44 step:71 loss: 0.007617\n",
      "Epoch:44 step:72 loss: 0.003183\n",
      "Epoch:44 step:73 loss: 0.000012\n",
      "Epoch:44 step:74 loss: 0.004291\n",
      "Epoch:44 step:75 loss: 0.000099\n",
      "Epoch:44 step:76 loss: 0.000016\n",
      "Epoch:44 step:77 loss: 0.000981\n",
      "Epoch:44 step:78 loss: 0.015036\n",
      "Epoch:44 step:79 loss: 0.002953\n",
      "Test Epoch:44 step:0 loss: 0.004045tensor(0.2924, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:1 loss: 0.002833tensor(0.1509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:2 loss: 0.001320tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:3 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:4 loss: 0.012005tensor(0.3570, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:5 loss: 0.004366tensor(0.3938, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:6 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:7 loss: 0.006403tensor(0.3488, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:9 loss: 0.000510tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:10 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:11 loss: 0.007613tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:12 loss: 0.005555tensor(0.4475, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:13 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:14 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:15 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:17 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:18 loss: 0.007487tensor(0.2231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:19 loss: 0.016148tensor(0.3458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:22 loss: 0.015049tensor(0.3885, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:23 loss: 0.000219tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:24 loss: 0.005411tensor(0.4067, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:25 loss: 0.001514tensor(0.0895, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:26 loss: 0.009932tensor(0.3623, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:27 loss: 0.017723tensor(0.4278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:28 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:30 loss: 0.001968tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:31 loss: 0.000957tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:32 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:34 loss: 0.007080tensor(0.2703, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:35 loss: 0.004499tensor(0.2823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:36 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:37 loss: 0.004477tensor(0.1224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:38 loss: 0.000170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:39 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:40 loss: 0.022047tensor(0.4300, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:42 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:43 loss: 0.012975tensor(0.3912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:44 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:44 step:45 loss: 0.001649tensor(0.3013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:46 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:47 loss: 0.007632tensor(0.4064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:48 loss: 0.002434tensor(0.2458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:49 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:50 loss: 0.000130tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:51 loss: 0.000414tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:52 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:53 loss: 0.000160tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:54 loss: 0.013278tensor(0.4027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:55 loss: 0.018831tensor(0.3842, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:56 loss: 0.009664tensor(0.4057, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:57 loss: 0.002413tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:58 loss: 0.006205tensor(0.2134, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:59 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:60 loss: 0.014876tensor(0.4357, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:61 loss: 0.009486tensor(0.2131, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:62 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:63 loss: 0.001989tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:64 loss: 0.005710tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:65 loss: 0.004051tensor(0.4154, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:66 loss: 0.000123tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:67 loss: 0.005037tensor(0.3803, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:70 loss: 0.001980tensor(0.2703, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:71 loss: 0.006472tensor(0.4046, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:72 loss: 0.002635tensor(0.3925, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:73 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:74 loss: 0.003975tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:75 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:76 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:77 loss: 0.002831tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:78 loss: 0.010240tensor(0.4217, grad_fn=<DivBackward0>)\n",
      "Test Epoch:44 step:79 loss: 0.003155tensor(0.3566, grad_fn=<DivBackward0>)\n",
      "Epoch:45 step:0 loss: 0.004819\n",
      "Epoch:45 step:1 loss: 0.002479\n",
      "Epoch:45 step:2 loss: 0.000065\n",
      "Epoch:45 step:3 loss: 0.000001\n",
      "Epoch:45 step:4 loss: 0.012770\n",
      "Epoch:45 step:5 loss: 0.006768\n",
      "Epoch:45 step:6 loss: 0.000001\n",
      "Epoch:45 step:7 loss: 0.010836\n",
      "Epoch:45 step:8 loss: 0.000003\n",
      "Epoch:45 step:9 loss: 0.000223\n",
      "Epoch:45 step:10 loss: 0.000002\n",
      "Epoch:45 step:11 loss: 0.006847\n",
      "Epoch:45 step:12 loss: 0.007514\n",
      "Epoch:45 step:13 loss: 0.000414\n",
      "Epoch:45 step:14 loss: 0.000002\n",
      "Epoch:45 step:15 loss: 0.000324\n",
      "Epoch:45 step:16 loss: 0.000000\n",
      "Epoch:45 step:17 loss: 0.000228\n",
      "Epoch:45 step:18 loss: 0.006998\n",
      "Epoch:45 step:19 loss: 0.010412\n",
      "Epoch:45 step:20 loss: 0.000006\n",
      "Epoch:45 step:21 loss: 0.000000\n",
      "Epoch:45 step:22 loss: 0.016995\n",
      "Epoch:45 step:23 loss: 0.001054\n",
      "Epoch:45 step:24 loss: 0.004825\n",
      "Epoch:45 step:25 loss: 0.002487\n",
      "Epoch:45 step:26 loss: 0.012179\n",
      "Epoch:45 step:27 loss: 0.017563\n",
      "Epoch:45 step:28 loss: 0.000197\n",
      "Epoch:45 step:29 loss: 0.000003\n",
      "Epoch:45 step:30 loss: 0.000274\n",
      "Epoch:45 step:31 loss: 0.002627\n",
      "Epoch:45 step:32 loss: 0.000813\n",
      "Epoch:45 step:33 loss: 0.000002\n",
      "Epoch:45 step:34 loss: 0.010430\n",
      "Epoch:45 step:35 loss: 0.003895\n",
      "Epoch:45 step:36 loss: 0.000280\n",
      "Epoch:45 step:37 loss: 0.003220\n",
      "Epoch:45 step:38 loss: 0.000215\n",
      "Epoch:45 step:39 loss: 0.000161\n",
      "Epoch:45 step:40 loss: 0.023258\n",
      "Epoch:45 step:41 loss: 0.000000\n",
      "Epoch:45 step:42 loss: 0.000034\n",
      "Epoch:45 step:43 loss: 0.014682\n",
      "Epoch:45 step:44 loss: 0.000013\n",
      "Epoch:45 step:45 loss: 0.002066\n",
      "Epoch:45 step:46 loss: 0.000001\n",
      "Epoch:45 step:47 loss: 0.011734\n",
      "Epoch:45 step:48 loss: 0.002360\n",
      "Epoch:45 step:49 loss: 0.000003\n",
      "Epoch:45 step:50 loss: 0.000533\n",
      "Epoch:45 step:51 loss: 0.000030\n",
      "Epoch:45 step:52 loss: 0.000007\n",
      "Epoch:45 step:53 loss: 0.000031\n",
      "Epoch:45 step:54 loss: 0.022078\n",
      "Epoch:45 step:55 loss: 0.018532\n",
      "Epoch:45 step:56 loss: 0.008748\n",
      "Epoch:45 step:57 loss: 0.000065\n",
      "Epoch:45 step:58 loss: 0.006454\n",
      "Epoch:45 step:59 loss: 0.000163\n",
      "Epoch:45 step:60 loss: 0.014545\n",
      "Epoch:45 step:61 loss: 0.009658\n",
      "Epoch:45 step:62 loss: 0.000001\n",
      "Epoch:45 step:63 loss: 0.002001\n",
      "Epoch:45 step:64 loss: 0.001627\n",
      "Epoch:45 step:65 loss: 0.004175\n",
      "Epoch:45 step:66 loss: 0.000256\n",
      "Epoch:45 step:67 loss: 0.006159\n",
      "Epoch:45 step:68 loss: 0.000000\n",
      "Epoch:45 step:69 loss: 0.000000\n",
      "Epoch:45 step:70 loss: 0.002246\n",
      "Epoch:45 step:71 loss: 0.008598\n",
      "Epoch:45 step:72 loss: 0.003034\n",
      "Epoch:45 step:73 loss: 0.000040\n",
      "Epoch:45 step:74 loss: 0.004616\n",
      "Epoch:45 step:75 loss: 0.000181\n",
      "Epoch:45 step:76 loss: 0.000023\n",
      "Epoch:45 step:77 loss: 0.004429\n",
      "Epoch:45 step:78 loss: 0.011974\n",
      "Epoch:45 step:79 loss: 0.002082\n",
      "Test Epoch:45 step:0 loss: 0.005240tensor(0.2426, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:1 loss: 0.004285tensor(0.0713, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:2 loss: 0.001535tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:3 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:4 loss: 0.009468tensor(0.3668, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:5 loss: 0.006021tensor(0.3579, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:7 loss: 0.007052tensor(0.3383, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:8 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:9 loss: 0.000253tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:11 loss: 0.008280tensor(0.2972, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:12 loss: 0.005962tensor(0.4433, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:13 loss: 0.000112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:15 loss: 0.000145tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:17 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:18 loss: 0.007364tensor(0.2247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:19 loss: 0.016517tensor(0.3452, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:20 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:21 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:22 loss: 0.015173tensor(0.3899, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:23 loss: 0.000153tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:24 loss: 0.005792tensor(0.4017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:25 loss: 0.001583tensor(0.0421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:26 loss: 0.008140tensor(0.3744, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:27 loss: 0.030078tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:30 loss: 0.003262tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:31 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:32 loss: 0.000139tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:33 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:34 loss: 0.005132tensor(0.2833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:35 loss: 0.004089tensor(0.2813, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:36 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:37 loss: 0.003992tensor(0.1190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:38 loss: 0.000727tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:39 loss: 0.001657tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:40 loss: 0.052877tensor(0.3477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:41 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:45 step:42 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:43 loss: 0.016066tensor(0.3621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:44 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:45 loss: 0.002434tensor(0.2121, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:46 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:47 loss: 0.011398tensor(0.3840, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:48 loss: 0.003456tensor(0.1281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:50 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:51 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:53 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:54 loss: 0.057775tensor(0.2049, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:55 loss: 0.051802tensor(0.2563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:56 loss: 0.009307tensor(0.4026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:57 loss: 0.002835tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:58 loss: 0.018839tensor(0.1098, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:59 loss: 0.003630tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:60 loss: 0.034121tensor(0.3736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:61 loss: 0.007397tensor(0.2682, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:62 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:63 loss: 0.001203tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:64 loss: 0.004808tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:65 loss: 0.008748tensor(0.3665, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:66 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:67 loss: 0.014921tensor(0.2553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:70 loss: 0.005480tensor(0.0658, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:71 loss: 0.034040tensor(0.2357, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:72 loss: 0.008400tensor(0.2605, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:73 loss: 0.000220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:74 loss: 0.012229tensor(0.2714, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:75 loss: 0.000144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:76 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:77 loss: 0.001725tensor(0.0095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:78 loss: 0.021112tensor(0.3451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:45 step:79 loss: 0.019271tensor(0.0496, grad_fn=<DivBackward0>)\n",
      "Epoch:46 step:0 loss: 0.007236\n",
      "Epoch:46 step:1 loss: 0.005247\n",
      "Epoch:46 step:2 loss: 0.001112\n",
      "Epoch:46 step:3 loss: 0.000245\n",
      "Epoch:46 step:4 loss: 0.014282\n",
      "Epoch:46 step:5 loss: 0.009064\n",
      "Epoch:46 step:6 loss: 0.000149\n",
      "Epoch:46 step:7 loss: 0.014380\n",
      "Epoch:46 step:8 loss: 0.000146\n",
      "Epoch:46 step:9 loss: 0.002519\n",
      "Epoch:46 step:10 loss: 0.006088\n",
      "Epoch:46 step:11 loss: 0.008623\n",
      "Epoch:46 step:12 loss: 0.009428\n",
      "Epoch:46 step:13 loss: 0.001429\n",
      "Epoch:46 step:14 loss: 0.000024\n",
      "Epoch:46 step:15 loss: 0.001062\n",
      "Epoch:46 step:16 loss: 0.000015\n",
      "Epoch:46 step:17 loss: 0.000557\n",
      "Epoch:46 step:18 loss: 0.006468\n",
      "Epoch:46 step:19 loss: 0.021597\n",
      "Epoch:46 step:20 loss: 0.000004\n",
      "Epoch:46 step:21 loss: 0.000004\n",
      "Epoch:46 step:22 loss: 0.024777\n",
      "Epoch:46 step:23 loss: 0.001121\n",
      "Epoch:46 step:24 loss: 0.010753\n",
      "Epoch:46 step:25 loss: 0.002509\n",
      "Epoch:46 step:26 loss: 0.010727\n",
      "Epoch:46 step:27 loss: 0.022292\n",
      "Epoch:46 step:28 loss: 0.000022\n",
      "Epoch:46 step:29 loss: 0.000004\n",
      "Epoch:46 step:30 loss: 0.002951\n",
      "Epoch:46 step:31 loss: 0.002385\n",
      "Epoch:46 step:32 loss: 0.000287\n",
      "Epoch:46 step:33 loss: 0.000002\n",
      "Epoch:46 step:34 loss: 0.011487\n",
      "Epoch:46 step:35 loss: 0.004497\n",
      "Epoch:46 step:36 loss: 0.000296\n",
      "Epoch:46 step:37 loss: 0.005746\n",
      "Epoch:46 step:38 loss: 0.000021\n",
      "Epoch:46 step:39 loss: 0.000293\n",
      "Epoch:46 step:40 loss: 0.021824\n",
      "Epoch:46 step:41 loss: 0.000001\n",
      "Epoch:46 step:42 loss: 0.000029\n",
      "Epoch:46 step:43 loss: 0.010796\n",
      "Epoch:46 step:44 loss: 0.000065\n",
      "Epoch:46 step:45 loss: 0.001620\n",
      "Epoch:46 step:46 loss: 0.000023\n",
      "Epoch:46 step:47 loss: 0.009352\n",
      "Epoch:46 step:48 loss: 0.003082\n",
      "Epoch:46 step:49 loss: 0.000006\n",
      "Epoch:46 step:50 loss: 0.000727\n",
      "Epoch:46 step:51 loss: 0.000211\n",
      "Epoch:46 step:52 loss: 0.000007\n",
      "Epoch:46 step:53 loss: 0.000281\n",
      "Epoch:46 step:54 loss: 0.041500\n",
      "Epoch:46 step:55 loss: 0.022330\n",
      "Epoch:46 step:56 loss: 0.007291\n",
      "Epoch:46 step:57 loss: 0.000207\n",
      "Epoch:46 step:58 loss: 0.010687\n",
      "Epoch:46 step:59 loss: 0.000131\n",
      "Epoch:46 step:60 loss: 0.029667\n",
      "Epoch:46 step:61 loss: 0.013632\n",
      "Epoch:46 step:62 loss: 0.000001\n",
      "Epoch:46 step:63 loss: 0.001921\n",
      "Epoch:46 step:64 loss: 0.005718\n",
      "Epoch:46 step:65 loss: 0.005124\n",
      "Epoch:46 step:66 loss: 0.000575\n",
      "Epoch:46 step:67 loss: 0.006613\n",
      "Epoch:46 step:68 loss: 0.000000\n",
      "Epoch:46 step:69 loss: 0.000001\n",
      "Epoch:46 step:70 loss: 0.001989\n",
      "Epoch:46 step:71 loss: 0.006850\n",
      "Epoch:46 step:72 loss: 0.002525\n",
      "Epoch:46 step:73 loss: 0.000139\n",
      "Epoch:46 step:74 loss: 0.004082\n",
      "Epoch:46 step:75 loss: 0.000186\n",
      "Epoch:46 step:76 loss: 0.000011\n",
      "Epoch:46 step:77 loss: 0.001333\n",
      "Epoch:46 step:78 loss: 0.014731\n",
      "Epoch:46 step:79 loss: 0.007493\n",
      "Test Epoch:46 step:0 loss: 0.004391tensor(0.2859, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:1 loss: 0.004263tensor(0.0575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:2 loss: 0.000669tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:3 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:4 loss: 0.010992tensor(0.3613, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:5 loss: 0.006860tensor(0.3481, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:7 loss: 0.006716tensor(0.3176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:8 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:9 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:10 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:11 loss: 0.009435tensor(0.2827, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:12 loss: 0.008369tensor(0.4269, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:13 loss: 0.001821tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:15 loss: 0.000300tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:16 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:17 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:18 loss: 0.007036tensor(0.2228, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:19 loss: 0.017827tensor(0.3398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:20 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:21 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:22 loss: 0.015772tensor(0.3802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:23 loss: 0.000372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:24 loss: 0.006682tensor(0.3944, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:25 loss: 0.001208tensor(0.1276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:26 loss: 0.008989tensor(0.3636, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:27 loss: 0.017063tensor(0.4279, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:28 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:30 loss: 0.002790tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:31 loss: 0.000470tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:32 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:33 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:34 loss: 0.004822tensor(0.2798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:35 loss: 0.004362tensor(0.2796, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:36 loss: 0.000123tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:37 loss: 0.003068tensor(0.1400, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:38 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:46 step:39 loss: 0.000223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:40 loss: 0.023152tensor(0.4191, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:41 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:42 loss: 0.000082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:43 loss: 0.009609tensor(0.4070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:44 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:45 loss: 0.001296tensor(0.3216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:46 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:47 loss: 0.008489tensor(0.4002, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:48 loss: 0.002923tensor(0.2385, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:49 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:50 loss: 0.000332tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:51 loss: 0.000205tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:53 loss: 0.000132tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:54 loss: 0.023066tensor(0.3670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:55 loss: 0.016306tensor(0.3875, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:56 loss: 0.006973tensor(0.4237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:57 loss: 0.001692tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:58 loss: 0.005763tensor(0.2482, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:59 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:60 loss: 0.015002tensor(0.4308, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:61 loss: 0.009371tensor(0.2244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:63 loss: 0.001959tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:64 loss: 0.003462tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:65 loss: 0.003664tensor(0.4154, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:66 loss: 0.000293tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:67 loss: 0.005397tensor(0.3776, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:70 loss: 0.002202tensor(0.2833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:71 loss: 0.005546tensor(0.4046, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:72 loss: 0.002065tensor(0.4116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:73 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:74 loss: 0.003582tensor(0.4178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:75 loss: 0.000504tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:76 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:77 loss: 0.001182tensor(0.0416, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:78 loss: 0.011428tensor(0.4158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:46 step:79 loss: 0.002099tensor(0.3864, grad_fn=<DivBackward0>)\n",
      "Epoch:47 step:0 loss: 0.004132\n",
      "Epoch:47 step:1 loss: 0.002652\n",
      "Epoch:47 step:2 loss: 0.000162\n",
      "Epoch:47 step:3 loss: 0.000001\n",
      "Epoch:47 step:4 loss: 0.008686\n",
      "Epoch:47 step:5 loss: 0.004451\n",
      "Epoch:47 step:6 loss: 0.000004\n",
      "Epoch:47 step:7 loss: 0.006425\n",
      "Epoch:47 step:8 loss: 0.000002\n",
      "Epoch:47 step:9 loss: 0.000026\n",
      "Epoch:47 step:10 loss: 0.000001\n",
      "Epoch:47 step:11 loss: 0.004544\n",
      "Epoch:47 step:12 loss: 0.006289\n",
      "Epoch:47 step:13 loss: 0.000114\n",
      "Epoch:47 step:14 loss: 0.000000\n",
      "Epoch:47 step:15 loss: 0.000086\n",
      "Epoch:47 step:16 loss: 0.000001\n",
      "Epoch:47 step:17 loss: 0.000028\n",
      "Epoch:47 step:18 loss: 0.003380\n",
      "Epoch:47 step:19 loss: 0.010496\n",
      "Epoch:47 step:20 loss: 0.000001\n",
      "Epoch:47 step:21 loss: 0.000001\n",
      "Epoch:47 step:22 loss: 0.014225\n",
      "Epoch:47 step:23 loss: 0.000069\n",
      "Epoch:47 step:24 loss: 0.007724\n",
      "Epoch:47 step:25 loss: 0.001970\n",
      "Epoch:47 step:26 loss: 0.007138\n",
      "Epoch:47 step:27 loss: 0.015799\n",
      "Epoch:47 step:28 loss: 0.000003\n",
      "Epoch:47 step:29 loss: 0.000001\n",
      "Epoch:47 step:30 loss: 0.000378\n",
      "Epoch:47 step:31 loss: 0.000350\n",
      "Epoch:47 step:32 loss: 0.000055\n",
      "Epoch:47 step:33 loss: 0.000002\n",
      "Epoch:47 step:34 loss: 0.005408\n",
      "Epoch:47 step:35 loss: 0.003382\n",
      "Epoch:47 step:36 loss: 0.000191\n",
      "Epoch:47 step:37 loss: 0.006320\n",
      "Epoch:47 step:38 loss: 0.000028\n",
      "Epoch:47 step:39 loss: 0.000350\n",
      "Epoch:47 step:40 loss: 0.016174\n",
      "Epoch:47 step:41 loss: 0.000002\n",
      "Epoch:47 step:42 loss: 0.000040\n",
      "Epoch:47 step:43 loss: 0.008525\n",
      "Epoch:47 step:44 loss: 0.000018\n",
      "Epoch:47 step:45 loss: 0.001529\n",
      "Epoch:47 step:46 loss: 0.000003\n",
      "Epoch:47 step:47 loss: 0.008180\n",
      "Epoch:47 step:48 loss: 0.002755\n",
      "Epoch:47 step:49 loss: 0.000001\n",
      "Epoch:47 step:50 loss: 0.000090\n",
      "Epoch:47 step:51 loss: 0.000123\n",
      "Epoch:47 step:52 loss: 0.000001\n",
      "Epoch:47 step:53 loss: 0.000048\n",
      "Epoch:47 step:54 loss: 0.013483\n",
      "Epoch:47 step:55 loss: 0.013868\n",
      "Epoch:47 step:56 loss: 0.007366\n",
      "Epoch:47 step:57 loss: 0.002107\n",
      "Epoch:47 step:58 loss: 0.007339\n",
      "Epoch:47 step:59 loss: 0.000381\n",
      "Epoch:47 step:60 loss: 0.012466\n",
      "Epoch:47 step:61 loss: 0.007083\n",
      "Epoch:47 step:62 loss: 0.000068\n",
      "Epoch:47 step:63 loss: 0.001401\n",
      "Epoch:47 step:64 loss: 0.005179\n",
      "Epoch:47 step:65 loss: 0.003695\n",
      "Epoch:47 step:66 loss: 0.000341\n",
      "Epoch:47 step:67 loss: 0.004891\n",
      "Epoch:47 step:68 loss: 0.000000\n",
      "Epoch:47 step:69 loss: 0.000000\n",
      "Epoch:47 step:70 loss: 0.002380\n",
      "Epoch:47 step:71 loss: 0.005330\n",
      "Epoch:47 step:72 loss: 0.002357\n",
      "Epoch:47 step:73 loss: 0.000005\n",
      "Epoch:47 step:74 loss: 0.004417\n",
      "Epoch:47 step:75 loss: 0.000021\n",
      "Epoch:47 step:76 loss: 0.000004\n",
      "Epoch:47 step:77 loss: 0.000582\n",
      "Epoch:47 step:78 loss: 0.010976\n",
      "Epoch:47 step:79 loss: 0.006423\n",
      "Test Epoch:47 step:0 loss: 0.004073tensor(0.3208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:1 loss: 0.002537tensor(0.1910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:2 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:4 loss: 0.009367tensor(0.3853, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:5 loss: 0.006388tensor(0.3728, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:6 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:7 loss: 0.006176tensor(0.3506, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:8 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:9 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:11 loss: 0.006017tensor(0.3415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:12 loss: 0.006463tensor(0.4449, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:13 loss: 0.000203tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:15 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:17 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:18 loss: 0.002927tensor(0.3536, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:19 loss: 0.009424tensor(0.3986, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:20 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:22 loss: 0.012967tensor(0.4053, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:23 loss: 0.000243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:24 loss: 0.005767tensor(0.4143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:25 loss: 0.001038tensor(0.1763, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:26 loss: 0.007869tensor(0.3862, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:27 loss: 0.016009tensor(0.4363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:28 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:30 loss: 0.000811tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:31 loss: 0.000289tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:32 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:34 loss: 0.003891tensor(0.3153, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:35 loss: 0.003591tensor(0.3132, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:47 step:36 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:37 loss: 0.004713tensor(0.1138, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:38 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:39 loss: 0.000224tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:40 loss: 0.017044tensor(0.4395, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:41 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:42 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:43 loss: 0.007297tensor(0.4230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:44 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:45 loss: 0.001315tensor(0.3462, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:46 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:47 loss: 0.007152tensor(0.4136, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:48 loss: 0.002576tensor(0.2363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:50 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:51 loss: 0.000179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:53 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:54 loss: 0.011178tensor(0.4218, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:55 loss: 0.012190tensor(0.4132, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:56 loss: 0.006457tensor(0.4291, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:57 loss: 0.001012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:58 loss: 0.005124tensor(0.2618, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:59 loss: 0.000192tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:60 loss: 0.011377tensor(0.4458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:61 loss: 0.007079tensor(0.2661, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:62 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:63 loss: 0.001352tensor(0.0048, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:64 loss: 0.004021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:65 loss: 0.003457tensor(0.4220, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:66 loss: 0.000249tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:67 loss: 0.004826tensor(0.3988, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:70 loss: 0.001794tensor(0.3171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:71 loss: 0.004441tensor(0.4211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:72 loss: 0.001609tensor(0.4305, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:73 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:74 loss: 0.004051tensor(0.4165, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:75 loss: 0.000191tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:76 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:77 loss: 0.000557tensor(0.2230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:78 loss: 0.011185tensor(0.4211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:47 step:79 loss: 0.003081tensor(0.3688, grad_fn=<DivBackward0>)\n",
      "Epoch:48 step:0 loss: 0.003755\n",
      "Epoch:48 step:1 loss: 0.003498\n",
      "Epoch:48 step:2 loss: 0.000042\n",
      "Epoch:48 step:3 loss: 0.000001\n",
      "Epoch:48 step:4 loss: 0.012541\n",
      "Epoch:48 step:5 loss: 0.005644\n",
      "Epoch:48 step:6 loss: 0.000003\n",
      "Epoch:48 step:7 loss: 0.005618\n",
      "Epoch:48 step:8 loss: 0.000013\n",
      "Epoch:48 step:9 loss: 0.000017\n",
      "Epoch:48 step:10 loss: 0.000001\n",
      "Epoch:48 step:11 loss: 0.004698\n",
      "Epoch:48 step:12 loss: 0.005032\n",
      "Epoch:48 step:13 loss: 0.000042\n",
      "Epoch:48 step:14 loss: 0.000001\n",
      "Epoch:48 step:15 loss: 0.000074\n",
      "Epoch:48 step:16 loss: 0.000002\n",
      "Epoch:48 step:17 loss: 0.000029\n",
      "Epoch:48 step:18 loss: 0.003630\n",
      "Epoch:48 step:19 loss: 0.008799\n",
      "Epoch:48 step:20 loss: 0.000003\n",
      "Epoch:48 step:21 loss: 0.000001\n",
      "Epoch:48 step:22 loss: 0.020852\n",
      "Epoch:48 step:23 loss: 0.000594\n",
      "Epoch:48 step:24 loss: 0.006143\n",
      "Epoch:48 step:25 loss: 0.000912\n",
      "Epoch:48 step:26 loss: 0.009071\n",
      "Epoch:48 step:27 loss: 0.013880\n",
      "Epoch:48 step:28 loss: 0.000000\n",
      "Epoch:48 step:29 loss: 0.000000\n",
      "Epoch:48 step:30 loss: 0.000945\n",
      "Epoch:48 step:31 loss: 0.000317\n",
      "Epoch:48 step:32 loss: 0.000030\n",
      "Epoch:48 step:33 loss: 0.000003\n",
      "Epoch:48 step:34 loss: 0.007011\n",
      "Epoch:48 step:35 loss: 0.003448\n",
      "Epoch:48 step:36 loss: 0.000031\n",
      "Epoch:48 step:37 loss: 0.002962\n",
      "Epoch:48 step:38 loss: 0.000045\n",
      "Epoch:48 step:39 loss: 0.000091\n",
      "Epoch:48 step:40 loss: 0.016388\n",
      "Epoch:48 step:41 loss: 0.000003\n",
      "Epoch:48 step:42 loss: 0.000023\n",
      "Epoch:48 step:43 loss: 0.008140\n",
      "Epoch:48 step:44 loss: 0.000012\n",
      "Epoch:48 step:45 loss: 0.001340\n",
      "Epoch:48 step:46 loss: 0.000005\n",
      "Epoch:48 step:47 loss: 0.007094\n",
      "Epoch:48 step:48 loss: 0.001928\n",
      "Epoch:48 step:49 loss: 0.000001\n",
      "Epoch:48 step:50 loss: 0.000319\n",
      "Epoch:48 step:51 loss: 0.000462\n",
      "Epoch:48 step:52 loss: 0.000001\n",
      "Epoch:48 step:53 loss: 0.000399\n",
      "Epoch:48 step:54 loss: 0.011698\n",
      "Epoch:48 step:55 loss: 0.012791\n",
      "Epoch:48 step:56 loss: 0.006436\n",
      "Epoch:48 step:57 loss: 0.002292\n",
      "Epoch:48 step:58 loss: 0.005949\n",
      "Epoch:48 step:59 loss: 0.000120\n",
      "Epoch:48 step:60 loss: 0.010694\n",
      "Epoch:48 step:61 loss: 0.007573\n",
      "Epoch:48 step:62 loss: 0.000006\n",
      "Epoch:48 step:63 loss: 0.001124\n",
      "Epoch:48 step:64 loss: 0.004126\n",
      "Epoch:48 step:65 loss: 0.004030\n",
      "Epoch:48 step:66 loss: 0.000176\n",
      "Epoch:48 step:67 loss: 0.006097\n",
      "Epoch:48 step:68 loss: 0.000000\n",
      "Epoch:48 step:69 loss: 0.000001\n",
      "Epoch:48 step:70 loss: 0.002611\n",
      "Epoch:48 step:71 loss: 0.004111\n",
      "Epoch:48 step:72 loss: 0.003792\n",
      "Epoch:48 step:73 loss: 0.000409\n",
      "Epoch:48 step:74 loss: 0.009991\n",
      "Epoch:48 step:75 loss: 0.000259\n",
      "Epoch:48 step:76 loss: 0.000001\n",
      "Epoch:48 step:77 loss: 0.000942\n",
      "Epoch:48 step:78 loss: 0.008487\n",
      "Epoch:48 step:79 loss: 0.004131\n",
      "Test Epoch:48 step:0 loss: 0.003880tensor(0.3203, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:1 loss: 0.002609tensor(0.2184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:2 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:4 loss: 0.009520tensor(0.3806, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:5 loss: 0.006956tensor(0.3505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:6 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:7 loss: 0.006633tensor(0.3496, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:9 loss: 0.000532tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:10 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:11 loss: 0.005662tensor(0.3513, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:12 loss: 0.007737tensor(0.4378, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:13 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:15 loss: 0.000555tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:16 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:17 loss: 0.002481tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:18 loss: 0.004946tensor(0.2935, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:19 loss: 0.009226tensor(0.4096, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:20 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:22 loss: 0.011772tensor(0.4130, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:23 loss: 0.000642tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:24 loss: 0.004956tensor(0.4210, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:25 loss: 0.001911tensor(0.0267, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:26 loss: 0.005934tensor(0.4063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:27 loss: 0.016742tensor(0.4401, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:28 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:30 loss: 0.000451tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:31 loss: 0.000885tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:32 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:48 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:34 loss: 0.005835tensor(0.2753, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:35 loss: 0.005664tensor(0.2540, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:36 loss: 0.000206tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:37 loss: 0.001442tensor(0.1150, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:38 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:39 loss: 0.000088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:40 loss: 0.016986tensor(0.4474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:41 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:42 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:43 loss: 0.009539tensor(0.4219, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:44 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:45 loss: 0.001107tensor(0.3612, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:46 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:47 loss: 0.008327tensor(0.4098, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:48 loss: 0.002568tensor(0.2624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:50 loss: 0.000128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:51 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:53 loss: 0.003981tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:54 loss: 0.010223tensor(0.4250, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:55 loss: 0.011785tensor(0.4144, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:56 loss: 0.008248tensor(0.4176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:57 loss: 0.000629tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:58 loss: 0.008900tensor(0.2379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:59 loss: 0.000259tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:60 loss: 0.010774tensor(0.4490, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:61 loss: 0.006552tensor(0.2676, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:63 loss: 0.001191tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:64 loss: 0.000850tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:65 loss: 0.012689tensor(0.2857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:66 loss: 0.000526tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:67 loss: 0.006079tensor(0.3719, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:68 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:70 loss: 0.001779tensor(0.2757, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:71 loss: 0.006263tensor(0.3936, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:72 loss: 0.009028tensor(0.3066, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:73 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:74 loss: 0.005692tensor(0.3846, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:75 loss: 0.001768tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:76 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:77 loss: 0.000891tensor(0.1875, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:78 loss: 0.055596tensor(0.2510, grad_fn=<DivBackward0>)\n",
      "Test Epoch:48 step:79 loss: 0.013696tensor(0.1246, grad_fn=<DivBackward0>)\n",
      "Epoch:49 step:0 loss: 0.007167\n",
      "Epoch:49 step:1 loss: 0.005159\n",
      "Epoch:49 step:2 loss: 0.000027\n",
      "Epoch:49 step:3 loss: 0.000005\n",
      "Epoch:49 step:4 loss: 0.026209\n",
      "Epoch:49 step:5 loss: 0.018273\n",
      "Epoch:49 step:6 loss: 0.000005\n",
      "Epoch:49 step:7 loss: 0.013934\n",
      "Epoch:49 step:8 loss: 0.000014\n",
      "Epoch:49 step:9 loss: 0.000232\n",
      "Epoch:49 step:10 loss: 0.001297\n",
      "Epoch:49 step:11 loss: 0.005777\n",
      "Epoch:49 step:12 loss: 0.008362\n",
      "Epoch:49 step:13 loss: 0.012549\n",
      "Epoch:49 step:14 loss: 0.000033\n",
      "Epoch:49 step:15 loss: 0.001423\n",
      "Epoch:49 step:16 loss: 0.000018\n",
      "Epoch:49 step:17 loss: 0.001694\n",
      "Epoch:49 step:18 loss: 0.005009\n",
      "Epoch:49 step:19 loss: 0.016237\n",
      "Epoch:49 step:20 loss: 0.000020\n",
      "Epoch:49 step:21 loss: 0.000022\n",
      "Epoch:49 step:22 loss: 0.021023\n",
      "Epoch:49 step:23 loss: 0.001030\n",
      "Epoch:49 step:24 loss: 0.013349\n",
      "Epoch:49 step:25 loss: 0.002491\n",
      "Epoch:49 step:26 loss: 0.009934\n",
      "Epoch:49 step:27 loss: 0.017784\n",
      "Epoch:49 step:28 loss: 0.000009\n",
      "Epoch:49 step:29 loss: 0.000003\n",
      "Epoch:49 step:30 loss: 0.000182\n",
      "Epoch:49 step:31 loss: 0.002158\n",
      "Epoch:49 step:32 loss: 0.000147\n",
      "Epoch:49 step:33 loss: 0.000003\n",
      "Epoch:49 step:34 loss: 0.009509\n",
      "Epoch:49 step:35 loss: 0.005961\n",
      "Epoch:49 step:36 loss: 0.000085\n",
      "Epoch:49 step:37 loss: 0.002326\n",
      "Epoch:49 step:38 loss: 0.000073\n",
      "Epoch:49 step:39 loss: 0.000488\n",
      "Epoch:49 step:40 loss: 0.026385\n",
      "Epoch:49 step:41 loss: 0.000048\n",
      "Epoch:49 step:42 loss: 0.000609\n",
      "Epoch:49 step:43 loss: 0.010508\n",
      "Epoch:49 step:44 loss: 0.001793\n",
      "Epoch:49 step:45 loss: 0.002257\n",
      "Epoch:49 step:46 loss: 0.005071\n",
      "Epoch:49 step:47 loss: 0.009514\n",
      "Epoch:49 step:48 loss: 0.003324\n",
      "Epoch:49 step:49 loss: 0.000016\n",
      "Epoch:49 step:50 loss: 0.000820\n",
      "Epoch:49 step:51 loss: 0.001200\n",
      "Epoch:49 step:52 loss: 0.000009\n",
      "Epoch:49 step:53 loss: 0.000100\n",
      "Epoch:49 step:54 loss: 0.016854\n",
      "Epoch:49 step:55 loss: 0.020973\n",
      "Epoch:49 step:56 loss: 0.008213\n",
      "Epoch:49 step:57 loss: 0.002615\n",
      "Epoch:49 step:58 loss: 0.041904\n",
      "Epoch:49 step:59 loss: 0.000105\n",
      "Epoch:49 step:60 loss: 0.014205\n",
      "Epoch:49 step:61 loss: 0.013896\n",
      "Epoch:49 step:62 loss: 0.000012\n",
      "Epoch:49 step:63 loss: 0.001726\n",
      "Epoch:49 step:64 loss: 0.001284\n",
      "Epoch:49 step:65 loss: 0.009893\n",
      "Epoch:49 step:66 loss: 0.000132\n",
      "Epoch:49 step:67 loss: 0.007442\n",
      "Epoch:49 step:68 loss: 0.000406\n",
      "Epoch:49 step:69 loss: 0.000651\n",
      "Epoch:49 step:70 loss: 0.002594\n",
      "Epoch:49 step:71 loss: 0.008445\n",
      "Epoch:49 step:72 loss: 0.008720\n",
      "Epoch:49 step:73 loss: 0.000321\n",
      "Epoch:49 step:74 loss: 0.004235\n",
      "Epoch:49 step:75 loss: 0.000625\n",
      "Epoch:49 step:76 loss: 0.000066\n",
      "Epoch:49 step:77 loss: 0.000704\n",
      "Epoch:49 step:78 loss: 0.019076\n",
      "Epoch:49 step:79 loss: 0.004276\n",
      "Test Epoch:49 step:0 loss: 0.004708tensor(0.2828, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:1 loss: 0.004484tensor(0.0465, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:2 loss: 0.000353tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:3 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:4 loss: 0.012537tensor(0.3544, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:5 loss: 0.006851tensor(0.3435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:7 loss: 0.008380tensor(0.3176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:8 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:9 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:10 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:11 loss: 0.004157tensor(0.3482, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:12 loss: 0.006730tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:13 loss: 0.000294tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:15 loss: 0.000396tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:16 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:17 loss: 0.000298tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:18 loss: 0.005627tensor(0.2758, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:19 loss: 0.014044tensor(0.3716, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:20 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:22 loss: 0.015077tensor(0.3958, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:23 loss: 0.000671tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:24 loss: 0.006649tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:25 loss: 0.001741tensor(0.0521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:26 loss: 0.006992tensor(0.3859, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:27 loss: 0.014869tensor(0.4430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:28 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:49 step:30 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:31 loss: 0.000161tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:32 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:34 loss: 0.005046tensor(0.2544, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:35 loss: 0.005101tensor(0.2481, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:36 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:37 loss: 0.004459tensor(0.1063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:38 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:39 loss: 0.000169tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:40 loss: 0.016695tensor(0.4404, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:41 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:42 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:43 loss: 0.008872tensor(0.4148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:44 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:45 loss: 0.001308tensor(0.3309, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:46 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:47 loss: 0.007314tensor(0.4143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:48 loss: 0.003074tensor(0.2434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:50 loss: 0.000194tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:51 loss: 0.000656tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:53 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:54 loss: 0.013238tensor(0.4070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:55 loss: 0.014463tensor(0.4042, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:56 loss: 0.006205tensor(0.4311, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:57 loss: 0.003625tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:58 loss: 0.011286tensor(0.1071, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:59 loss: 0.000290tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:60 loss: 0.013258tensor(0.4406, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:61 loss: 0.009124tensor(0.2545, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:63 loss: 0.001620tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:64 loss: 0.001950tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:65 loss: 0.003511tensor(0.4235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:66 loss: 0.000099tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:67 loss: 0.006935tensor(0.3676, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:70 loss: 0.002171tensor(0.2702, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:71 loss: 0.005270tensor(0.4087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:72 loss: 0.002482tensor(0.4061, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:73 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:74 loss: 0.003287tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:75 loss: 0.000474tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:76 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:77 loss: 0.001369tensor(0.0362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:78 loss: 0.010174tensor(0.4210, grad_fn=<DivBackward0>)\n",
      "Test Epoch:49 step:79 loss: 0.001778tensor(0.3989, grad_fn=<DivBackward0>)\n",
      "Epoch:50 step:0 loss: 0.004332\n",
      "Epoch:50 step:1 loss: 0.002767\n",
      "Epoch:50 step:2 loss: 0.000365\n",
      "Epoch:50 step:3 loss: 0.000001\n",
      "Epoch:50 step:4 loss: 0.009266\n",
      "Epoch:50 step:5 loss: 0.005162\n",
      "Epoch:50 step:6 loss: 0.000027\n",
      "Epoch:50 step:7 loss: 0.005332\n",
      "Epoch:50 step:8 loss: 0.000001\n",
      "Epoch:50 step:9 loss: 0.000051\n",
      "Epoch:50 step:10 loss: 0.000002\n",
      "Epoch:50 step:11 loss: 0.003825\n",
      "Epoch:50 step:12 loss: 0.005572\n",
      "Epoch:50 step:13 loss: 0.000040\n",
      "Epoch:50 step:14 loss: 0.000001\n",
      "Epoch:50 step:15 loss: 0.000090\n",
      "Epoch:50 step:16 loss: 0.000001\n",
      "Epoch:50 step:17 loss: 0.000065\n",
      "Epoch:50 step:18 loss: 0.005120\n",
      "Epoch:50 step:19 loss: 0.009676\n",
      "Epoch:50 step:20 loss: 0.000001\n",
      "Epoch:50 step:21 loss: 0.000000\n",
      "Epoch:50 step:22 loss: 0.014512\n",
      "Epoch:50 step:23 loss: 0.003292\n",
      "Epoch:50 step:24 loss: 0.005940\n",
      "Epoch:50 step:25 loss: 0.001946\n",
      "Epoch:50 step:26 loss: 0.008481\n",
      "Epoch:50 step:27 loss: 0.014076\n",
      "Epoch:50 step:28 loss: 0.000006\n",
      "Epoch:50 step:29 loss: 0.000001\n",
      "Epoch:50 step:30 loss: 0.000279\n",
      "Epoch:50 step:31 loss: 0.000070\n",
      "Epoch:50 step:32 loss: 0.000020\n",
      "Epoch:50 step:33 loss: 0.000000\n",
      "Epoch:50 step:34 loss: 0.004512\n",
      "Epoch:50 step:35 loss: 0.005098\n",
      "Epoch:50 step:36 loss: 0.000045\n",
      "Epoch:50 step:37 loss: 0.001486\n",
      "Epoch:50 step:38 loss: 0.000055\n",
      "Epoch:50 step:39 loss: 0.000156\n",
      "Epoch:50 step:40 loss: 0.014989\n",
      "Epoch:50 step:41 loss: 0.000003\n",
      "Epoch:50 step:42 loss: 0.000118\n",
      "Epoch:50 step:43 loss: 0.007771\n",
      "Epoch:50 step:44 loss: 0.000087\n",
      "Epoch:50 step:45 loss: 0.001673\n",
      "Epoch:50 step:46 loss: 0.000048\n",
      "Epoch:50 step:47 loss: 0.007142\n",
      "Epoch:50 step:48 loss: 0.002828\n",
      "Epoch:50 step:49 loss: 0.000008\n",
      "Epoch:50 step:50 loss: 0.000136\n",
      "Epoch:50 step:51 loss: 0.000109\n",
      "Epoch:50 step:52 loss: 0.000004\n",
      "Epoch:50 step:53 loss: 0.000025\n",
      "Epoch:50 step:54 loss: 0.009422\n",
      "Epoch:50 step:55 loss: 0.010515\n",
      "Epoch:50 step:56 loss: 0.005683\n",
      "Epoch:50 step:57 loss: 0.001516\n",
      "Epoch:50 step:58 loss: 0.005169\n",
      "Epoch:50 step:59 loss: 0.000344\n",
      "Epoch:50 step:60 loss: 0.011891\n",
      "Epoch:50 step:61 loss: 0.006467\n",
      "Epoch:50 step:62 loss: 0.000008\n",
      "Epoch:50 step:63 loss: 0.001200\n",
      "Epoch:50 step:64 loss: 0.002634\n",
      "Epoch:50 step:65 loss: 0.002882\n",
      "Epoch:50 step:66 loss: 0.000068\n",
      "Epoch:50 step:67 loss: 0.007209\n",
      "Epoch:50 step:68 loss: 0.000000\n",
      "Epoch:50 step:69 loss: 0.000000\n",
      "Epoch:50 step:70 loss: 0.002679\n",
      "Epoch:50 step:71 loss: 0.004574\n",
      "Epoch:50 step:72 loss: 0.001931\n",
      "Epoch:50 step:73 loss: 0.000002\n",
      "Epoch:50 step:74 loss: 0.003063\n",
      "Epoch:50 step:75 loss: 0.000105\n",
      "Epoch:50 step:76 loss: 0.000058\n",
      "Epoch:50 step:77 loss: 0.000827\n",
      "Epoch:50 step:78 loss: 0.010643\n",
      "Epoch:50 step:79 loss: 0.001706\n",
      "Test Epoch:50 step:0 loss: 0.004551tensor(0.3132, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:1 loss: 0.002265tensor(0.2151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:2 loss: 0.000220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:4 loss: 0.009320tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:5 loss: 0.004374tensor(0.4008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:7 loss: 0.004630tensor(0.3736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:8 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:9 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:10 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:11 loss: 0.004158tensor(0.3506, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:12 loss: 0.005272tensor(0.4565, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:13 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:15 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:17 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:18 loss: 0.003707tensor(0.3414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:19 loss: 0.009210tensor(0.4115, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:22 loss: 0.013988tensor(0.4102, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:23 loss: 0.000343tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:24 loss: 0.005259tensor(0.4176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:25 loss: 0.001912tensor(0.0253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:26 loss: 0.006363tensor(0.4099, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:50 step:27 loss: 0.011853tensor(0.4580, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:28 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:30 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:31 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:32 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:34 loss: 0.003076tensor(0.3533, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:35 loss: 0.003792tensor(0.3071, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:36 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:37 loss: 0.002031tensor(0.1341, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:38 loss: 0.000055tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:39 loss: 0.000146tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:40 loss: 0.016023tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:42 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:43 loss: 0.007723tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:44 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:45 loss: 0.001129tensor(0.3641, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:46 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:47 loss: 0.006231tensor(0.4261, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:48 loss: 0.002664tensor(0.2591, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:49 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:50 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:51 loss: 0.000119tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:53 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:54 loss: 0.008712tensor(0.4358, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:55 loss: 0.009526tensor(0.4274, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:56 loss: 0.005098tensor(0.4411, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:57 loss: 0.003092tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:58 loss: 0.005230tensor(0.2559, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:59 loss: 0.000434tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:60 loss: 0.010706tensor(0.4536, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:61 loss: 0.006778tensor(0.2956, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:62 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:63 loss: 0.001675tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:64 loss: 0.002943tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:65 loss: 0.003701tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:66 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:67 loss: 0.005469tensor(0.3909, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:70 loss: 0.002780tensor(0.2674, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:71 loss: 0.004205tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:72 loss: 0.002807tensor(0.4116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:73 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:74 loss: 0.003992tensor(0.4254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:75 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:76 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:77 loss: 0.000570tensor(0.2037, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:78 loss: 0.008682tensor(0.4424, grad_fn=<DivBackward0>)\n",
      "Test Epoch:50 step:79 loss: 0.001661tensor(0.4119, grad_fn=<DivBackward0>)\n",
      "Epoch:51 step:0 loss: 0.003834\n",
      "Epoch:51 step:1 loss: 0.002199\n",
      "Epoch:51 step:2 loss: 0.000121\n",
      "Epoch:51 step:3 loss: 0.000001\n",
      "Epoch:51 step:4 loss: 0.009291\n",
      "Epoch:51 step:5 loss: 0.007252\n",
      "Epoch:51 step:6 loss: 0.000053\n",
      "Epoch:51 step:7 loss: 0.004231\n",
      "Epoch:51 step:8 loss: 0.000003\n",
      "Epoch:51 step:9 loss: 0.000111\n",
      "Epoch:51 step:10 loss: 0.000033\n",
      "Epoch:51 step:11 loss: 0.004871\n",
      "Epoch:51 step:12 loss: 0.004693\n",
      "Epoch:51 step:13 loss: 0.000080\n",
      "Epoch:51 step:14 loss: 0.000001\n",
      "Epoch:51 step:15 loss: 0.000066\n",
      "Epoch:51 step:16 loss: 0.000000\n",
      "Epoch:51 step:17 loss: 0.000152\n",
      "Epoch:51 step:18 loss: 0.003512\n",
      "Epoch:51 step:19 loss: 0.009215\n",
      "Epoch:51 step:20 loss: 0.000002\n",
      "Epoch:51 step:21 loss: 0.000000\n",
      "Epoch:51 step:22 loss: 0.010714\n",
      "Epoch:51 step:23 loss: 0.001094\n",
      "Epoch:51 step:24 loss: 0.006374\n",
      "Epoch:51 step:25 loss: 0.001000\n",
      "Epoch:51 step:26 loss: 0.005151\n",
      "Epoch:51 step:27 loss: 0.013782\n",
      "Epoch:51 step:28 loss: 0.000037\n",
      "Epoch:51 step:29 loss: 0.000000\n",
      "Epoch:51 step:30 loss: 0.000330\n",
      "Epoch:51 step:31 loss: 0.000076\n",
      "Epoch:51 step:32 loss: 0.000007\n",
      "Epoch:51 step:33 loss: 0.000000\n",
      "Epoch:51 step:34 loss: 0.004272\n",
      "Epoch:51 step:35 loss: 0.004879\n",
      "Epoch:51 step:36 loss: 0.000066\n",
      "Epoch:51 step:37 loss: 0.002487\n",
      "Epoch:51 step:38 loss: 0.000027\n",
      "Epoch:51 step:39 loss: 0.000109\n",
      "Epoch:51 step:40 loss: 0.014339\n",
      "Epoch:51 step:41 loss: 0.000001\n",
      "Epoch:51 step:42 loss: 0.000049\n",
      "Epoch:51 step:43 loss: 0.007710\n",
      "Epoch:51 step:44 loss: 0.000039\n",
      "Epoch:51 step:45 loss: 0.001266\n",
      "Epoch:51 step:46 loss: 0.000014\n",
      "Epoch:51 step:47 loss: 0.006579\n",
      "Epoch:51 step:48 loss: 0.002315\n",
      "Epoch:51 step:49 loss: 0.000004\n",
      "Epoch:51 step:50 loss: 0.000058\n",
      "Epoch:51 step:51 loss: 0.000163\n",
      "Epoch:51 step:52 loss: 0.000003\n",
      "Epoch:51 step:53 loss: 0.000080\n",
      "Epoch:51 step:54 loss: 0.008486\n",
      "Epoch:51 step:55 loss: 0.009719\n",
      "Epoch:51 step:56 loss: 0.004882\n",
      "Epoch:51 step:57 loss: 0.003016\n",
      "Epoch:51 step:58 loss: 0.004199\n",
      "Epoch:51 step:59 loss: 0.000128\n",
      "Epoch:51 step:60 loss: 0.008770\n",
      "Epoch:51 step:61 loss: 0.006272\n",
      "Epoch:51 step:62 loss: 0.000006\n",
      "Epoch:51 step:63 loss: 0.000758\n",
      "Epoch:51 step:64 loss: 0.001998\n",
      "Epoch:51 step:65 loss: 0.002927\n",
      "Epoch:51 step:66 loss: 0.000058\n",
      "Epoch:51 step:67 loss: 0.004825\n",
      "Epoch:51 step:68 loss: 0.000001\n",
      "Epoch:51 step:69 loss: 0.000000\n",
      "Epoch:51 step:70 loss: 0.002059\n",
      "Epoch:51 step:71 loss: 0.003462\n",
      "Epoch:51 step:72 loss: 0.001698\n",
      "Epoch:51 step:73 loss: 0.000301\n",
      "Epoch:51 step:74 loss: 0.003346\n",
      "Epoch:51 step:75 loss: 0.000073\n",
      "Epoch:51 step:76 loss: 0.000007\n",
      "Epoch:51 step:77 loss: 0.000551\n",
      "Epoch:51 step:78 loss: 0.013142\n",
      "Epoch:51 step:79 loss: 0.001652\n",
      "Test Epoch:51 step:0 loss: 0.003796tensor(0.3253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:1 loss: 0.002121tensor(0.2340, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:2 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:4 loss: 0.010795tensor(0.3984, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:5 loss: 0.004737tensor(0.4089, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:7 loss: 0.005986tensor(0.3576, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:9 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:11 loss: 0.004139tensor(0.3513, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:12 loss: 0.005746tensor(0.4516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:13 loss: 0.000199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:15 loss: 0.000212tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:17 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:18 loss: 0.004750tensor(0.3268, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:19 loss: 0.009594tensor(0.4077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:22 loss: 0.013410tensor(0.4143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:23 loss: 0.000153tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:51 step:24 loss: 0.005228tensor(0.4199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:25 loss: 0.001055tensor(0.1120, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:26 loss: 0.005577tensor(0.4124, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:27 loss: 0.011338tensor(0.4573, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:28 loss: 0.001149tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:30 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:31 loss: 0.000188tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:32 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:34 loss: 0.004680tensor(0.3145, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:35 loss: 0.003117tensor(0.3234, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:36 loss: 0.000076tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:37 loss: 0.002103tensor(0.1624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:38 loss: 0.000605tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:39 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:40 loss: 0.018303tensor(0.4396, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:42 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:43 loss: 0.007711tensor(0.4279, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:44 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:45 loss: 0.001054tensor(0.3683, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:46 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:47 loss: 0.006774tensor(0.4238, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:48 loss: 0.002607tensor(0.2158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:50 loss: 0.000081tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:51 loss: 0.000444tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:53 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:54 loss: 0.010743tensor(0.4235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:55 loss: 0.009257tensor(0.4300, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:56 loss: 0.005268tensor(0.4419, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:57 loss: 0.000813tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:58 loss: 0.006776tensor(0.2324, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:59 loss: 0.001131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:60 loss: 0.021021tensor(0.4241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:61 loss: 0.005205tensor(0.3247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:63 loss: 0.001129tensor(0.0140, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:64 loss: 0.001380tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:65 loss: 0.003448tensor(0.4254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:66 loss: 0.000179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:67 loss: 0.015615tensor(0.3402, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:70 loss: 0.129728tensor(0.0152, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:71 loss: 0.046408tensor(0.2157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:72 loss: 0.008296tensor(0.2650, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:73 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:74 loss: 0.043181tensor(0.0506, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:75 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:77 loss: 0.002917tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:78 loss: 0.147917tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "Test Epoch:51 step:79 loss: 0.013112tensor(0.0539, grad_fn=<DivBackward0>)\n",
      "Epoch:52 step:0 loss: 0.014480\n",
      "Epoch:52 step:1 loss: 0.005840\n",
      "Epoch:52 step:2 loss: 0.002162\n",
      "Epoch:52 step:3 loss: 0.000998\n",
      "Epoch:52 step:4 loss: 0.029028\n",
      "Epoch:52 step:5 loss: 0.012715\n",
      "Epoch:52 step:6 loss: 0.006769\n",
      "Epoch:52 step:7 loss: 0.017667\n",
      "Epoch:52 step:8 loss: 0.000983\n",
      "Epoch:52 step:9 loss: 0.008687\n",
      "Epoch:52 step:10 loss: 0.013457\n",
      "Epoch:52 step:11 loss: 0.008100\n",
      "Epoch:52 step:12 loss: 0.052088\n",
      "Epoch:52 step:13 loss: 0.000078\n",
      "Epoch:52 step:14 loss: 0.000004\n",
      "Epoch:52 step:15 loss: 0.000614\n",
      "Epoch:52 step:16 loss: 0.000011\n",
      "Epoch:52 step:17 loss: 0.000214\n",
      "Epoch:52 step:18 loss: 0.015373\n",
      "Epoch:52 step:19 loss: 0.018788\n",
      "Epoch:52 step:20 loss: 0.000018\n",
      "Epoch:52 step:21 loss: 0.000035\n",
      "Epoch:52 step:22 loss: 0.073073\n",
      "Epoch:52 step:23 loss: 0.005305\n",
      "Epoch:52 step:24 loss: 0.014834\n",
      "Epoch:52 step:25 loss: 0.006386\n",
      "Epoch:52 step:26 loss: 0.035457\n",
      "Epoch:52 step:27 loss: 0.069982\n",
      "Epoch:52 step:28 loss: 0.000536\n",
      "Epoch:52 step:29 loss: 0.000279\n",
      "Epoch:52 step:30 loss: 0.008994\n",
      "Epoch:52 step:31 loss: 0.000841\n",
      "Epoch:52 step:32 loss: 0.000490\n",
      "Epoch:52 step:33 loss: 0.000763\n",
      "Epoch:52 step:34 loss: 0.030445\n",
      "Epoch:52 step:35 loss: 0.013889\n",
      "Epoch:52 step:36 loss: 0.003590\n",
      "Epoch:52 step:37 loss: 0.003064\n",
      "Epoch:52 step:38 loss: 0.000495\n",
      "Epoch:52 step:39 loss: 0.002979\n",
      "Epoch:52 step:40 loss: 0.055039\n",
      "Epoch:52 step:41 loss: 0.000346\n",
      "Epoch:52 step:42 loss: 0.000338\n",
      "Epoch:52 step:43 loss: 0.042124\n",
      "Epoch:52 step:44 loss: 0.000748\n",
      "Epoch:52 step:45 loss: 0.005200\n",
      "Epoch:52 step:46 loss: 0.000392\n",
      "Epoch:52 step:47 loss: 0.017966\n",
      "Epoch:52 step:48 loss: 0.005066\n",
      "Epoch:52 step:49 loss: 0.000248\n",
      "Epoch:52 step:50 loss: 0.001512\n",
      "Epoch:52 step:51 loss: 0.000611\n",
      "Epoch:52 step:52 loss: 0.000075\n",
      "Epoch:52 step:53 loss: 0.002294\n",
      "Epoch:52 step:54 loss: 0.054475\n",
      "Epoch:52 step:55 loss: 0.037702\n",
      "Epoch:52 step:56 loss: 0.016907\n",
      "Epoch:52 step:57 loss: 0.000005\n",
      "Epoch:52 step:58 loss: 0.016383\n",
      "Epoch:52 step:59 loss: 0.000016\n",
      "Epoch:52 step:60 loss: 0.099621\n",
      "Epoch:52 step:61 loss: 0.031672\n",
      "Epoch:52 step:62 loss: 0.000016\n",
      "Epoch:52 step:63 loss: 0.001745\n",
      "Epoch:52 step:64 loss: 0.003966\n",
      "Epoch:52 step:65 loss: 0.005006\n",
      "Epoch:52 step:66 loss: 0.001514\n",
      "Epoch:52 step:67 loss: 0.010709\n",
      "Epoch:52 step:68 loss: 0.000058\n",
      "Epoch:52 step:69 loss: 0.000089\n",
      "Epoch:52 step:70 loss: 0.010359\n",
      "Epoch:52 step:71 loss: 0.014004\n",
      "Epoch:52 step:72 loss: 0.011566\n",
      "Epoch:52 step:73 loss: 0.000802\n",
      "Epoch:52 step:74 loss: 0.007163\n",
      "Epoch:52 step:75 loss: 0.001476\n",
      "Epoch:52 step:76 loss: 0.000167\n",
      "Epoch:52 step:77 loss: 0.001119\n",
      "Epoch:52 step:78 loss: 0.029676\n",
      "Epoch:52 step:79 loss: 0.012406\n",
      "Test Epoch:52 step:0 loss: 0.011736tensor(0.0991, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:1 loss: 0.008883tensor(0.0090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:2 loss: 0.001262tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:3 loss: 0.000125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:4 loss: 0.011015tensor(0.3372, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:5 loss: 0.012548tensor(0.1982, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:6 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:7 loss: 0.014218tensor(0.1592, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:8 loss: 0.000391tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:9 loss: 0.000762tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:10 loss: 0.001583tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:11 loss: 0.008126tensor(0.2457, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:12 loss: 0.012657tensor(0.3818, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:13 loss: 0.002613tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:14 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:15 loss: 0.001593tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:16 loss: 0.000317tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:17 loss: 0.004442tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:18 loss: 0.008504tensor(0.1458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:19 loss: 0.019666tensor(0.3159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:20 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:52 step:21 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:22 loss: 0.039789tensor(0.2948, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:23 loss: 0.002596tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:24 loss: 0.008439tensor(0.3672, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:25 loss: 0.005933tensor(2.6199e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:26 loss: 0.012984tensor(0.3113, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:27 loss: 0.031559tensor(0.3760, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:28 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:29 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:30 loss: 0.000440tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:31 loss: 0.000945tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:32 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:33 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:34 loss: 0.022177tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:35 loss: 0.005140tensor(0.2234, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:36 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:37 loss: 0.004180tensor(0.0908, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:38 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:39 loss: 0.005416tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:40 loss: 0.034926tensor(0.3871, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:41 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:42 loss: 0.000308tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:43 loss: 0.010197tensor(0.3945, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:44 loss: 0.000496tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:45 loss: 0.001636tensor(0.2900, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:46 loss: 0.000760tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:47 loss: 0.010211tensor(0.3777, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:48 loss: 0.002384tensor(0.2199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:49 loss: 0.000170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:50 loss: 0.001299tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:51 loss: 0.001975tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:52 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:53 loss: 0.000668tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:54 loss: 0.029502tensor(0.3227, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:55 loss: 0.019930tensor(0.3610, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:56 loss: 0.016223tensor(0.3756, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:57 loss: 0.000919tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:58 loss: 0.015479tensor(0.0811, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:59 loss: 0.000121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:60 loss: 0.023645tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:61 loss: 0.010826tensor(0.1845, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:62 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:63 loss: 0.001945tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:64 loss: 0.001510tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:65 loss: 0.012514tensor(0.2212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:66 loss: 0.000452tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:67 loss: 0.005898tensor(0.3602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:68 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:69 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:70 loss: 0.002339tensor(0.2525, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:71 loss: 0.011238tensor(0.3245, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:72 loss: 0.005765tensor(0.3292, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:73 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:74 loss: 0.005773tensor(0.3623, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:75 loss: 0.000209tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:76 loss: 0.000933tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:77 loss: 0.001619tensor(0.1278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:78 loss: 0.013302tensor(0.3962, grad_fn=<DivBackward0>)\n",
      "Test Epoch:52 step:79 loss: 0.003586tensor(0.3243, grad_fn=<DivBackward0>)\n",
      "Epoch:53 step:0 loss: 0.005418\n",
      "Epoch:53 step:1 loss: 0.005006\n",
      "Epoch:53 step:2 loss: 0.000662\n",
      "Epoch:53 step:3 loss: 0.000004\n",
      "Epoch:53 step:4 loss: 0.009525\n",
      "Epoch:53 step:5 loss: 0.011805\n",
      "Epoch:53 step:6 loss: 0.000005\n",
      "Epoch:53 step:7 loss: 0.011372\n",
      "Epoch:53 step:8 loss: 0.000004\n",
      "Epoch:53 step:9 loss: 0.000353\n",
      "Epoch:53 step:10 loss: 0.000008\n",
      "Epoch:53 step:11 loss: 0.005785\n",
      "Epoch:53 step:12 loss: 0.007528\n",
      "Epoch:53 step:13 loss: 0.000710\n",
      "Epoch:53 step:14 loss: 0.000006\n",
      "Epoch:53 step:15 loss: 0.000287\n",
      "Epoch:53 step:16 loss: 0.000004\n",
      "Epoch:53 step:17 loss: 0.002003\n",
      "Epoch:53 step:18 loss: 0.005092\n",
      "Epoch:53 step:19 loss: 0.013654\n",
      "Epoch:53 step:20 loss: 0.000006\n",
      "Epoch:53 step:21 loss: 0.000005\n",
      "Epoch:53 step:22 loss: 0.027189\n",
      "Epoch:53 step:23 loss: 0.004820\n",
      "Epoch:53 step:24 loss: 0.005695\n",
      "Epoch:53 step:25 loss: 0.001870\n",
      "Epoch:53 step:26 loss: 0.009440\n",
      "Epoch:53 step:27 loss: 0.017564\n",
      "Epoch:53 step:28 loss: 0.000001\n",
      "Epoch:53 step:29 loss: 0.000002\n",
      "Epoch:53 step:30 loss: 0.000050\n",
      "Epoch:53 step:31 loss: 0.000257\n",
      "Epoch:53 step:32 loss: 0.000030\n",
      "Epoch:53 step:33 loss: 0.000001\n",
      "Epoch:53 step:34 loss: 0.015645\n",
      "Epoch:53 step:35 loss: 0.008441\n",
      "Epoch:53 step:36 loss: 0.000045\n",
      "Epoch:53 step:37 loss: 0.003150\n",
      "Epoch:53 step:38 loss: 0.000040\n",
      "Epoch:53 step:39 loss: 0.001553\n",
      "Epoch:53 step:40 loss: 0.034537\n",
      "Epoch:53 step:41 loss: 0.000005\n",
      "Epoch:53 step:42 loss: 0.000171\n",
      "Epoch:53 step:43 loss: 0.010546\n",
      "Epoch:53 step:44 loss: 0.000631\n",
      "Epoch:53 step:45 loss: 0.001740\n",
      "Epoch:53 step:46 loss: 0.001765\n",
      "Epoch:53 step:47 loss: 0.008542\n",
      "Epoch:53 step:48 loss: 0.005741\n",
      "Epoch:53 step:49 loss: 0.000009\n",
      "Epoch:53 step:50 loss: 0.000801\n",
      "Epoch:53 step:51 loss: 0.001537\n",
      "Epoch:53 step:52 loss: 0.000006\n",
      "Epoch:53 step:53 loss: 0.000078\n",
      "Epoch:53 step:54 loss: 0.017763\n",
      "Epoch:53 step:55 loss: 0.023407\n",
      "Epoch:53 step:56 loss: 0.008995\n",
      "Epoch:53 step:57 loss: 0.000938\n",
      "Epoch:53 step:58 loss: 0.005348\n",
      "Epoch:53 step:59 loss: 0.000057\n",
      "Epoch:53 step:60 loss: 0.016406\n",
      "Epoch:53 step:61 loss: 0.013213\n",
      "Epoch:53 step:62 loss: 0.000003\n",
      "Epoch:53 step:63 loss: 0.002632\n",
      "Epoch:53 step:64 loss: 0.001093\n",
      "Epoch:53 step:65 loss: 0.004124\n",
      "Epoch:53 step:66 loss: 0.000135\n",
      "Epoch:53 step:67 loss: 0.008312\n",
      "Epoch:53 step:68 loss: 0.000002\n",
      "Epoch:53 step:69 loss: 0.000001\n",
      "Epoch:53 step:70 loss: 0.003714\n",
      "Epoch:53 step:71 loss: 0.005625\n",
      "Epoch:53 step:72 loss: 0.003003\n",
      "Epoch:53 step:73 loss: 0.000019\n",
      "Epoch:53 step:74 loss: 0.003870\n",
      "Epoch:53 step:75 loss: 0.000062\n",
      "Epoch:53 step:76 loss: 0.000081\n",
      "Epoch:53 step:77 loss: 0.000809\n",
      "Epoch:53 step:78 loss: 0.011175\n",
      "Epoch:53 step:79 loss: 0.003009\n",
      "Test Epoch:53 step:0 loss: 0.004936tensor(0.2704, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:1 loss: 0.004817tensor(0.0741, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:2 loss: 0.002178tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:3 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:4 loss: 0.009675tensor(0.3666, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:5 loss: 0.006328tensor(0.3521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:7 loss: 0.008342tensor(0.3087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:8 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:9 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:10 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:11 loss: 0.004144tensor(0.3557, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:12 loss: 0.006664tensor(0.4414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:13 loss: 0.000249tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:15 loss: 0.000194tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:17 loss: 0.000115tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:53 step:18 loss: 0.004055tensor(0.2896, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:19 loss: 0.011251tensor(0.3873, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:22 loss: 0.022096tensor(0.3516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:23 loss: 0.000871tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:24 loss: 0.005775tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:25 loss: 0.002912tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:26 loss: 0.008136tensor(0.3692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:27 loss: 0.019145tensor(0.4214, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:28 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:30 loss: 0.000363tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:31 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:32 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:34 loss: 0.006749tensor(0.1953, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:35 loss: 0.005062tensor(0.2553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:36 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:37 loss: 0.002511tensor(0.1447, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:38 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:39 loss: 0.000165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:40 loss: 0.019296tensor(0.4270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:42 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:43 loss: 0.008161tensor(0.4184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:44 loss: 0.000101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:45 loss: 0.001651tensor(0.3001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:46 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:47 loss: 0.007921tensor(0.4094, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:48 loss: 0.003334tensor(0.2240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:49 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:50 loss: 0.000340tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:51 loss: 0.001228tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:52 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:53 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:54 loss: 0.015692tensor(0.3888, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:55 loss: 0.016773tensor(0.3863, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:56 loss: 0.006461tensor(0.4270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:57 loss: 0.002112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:58 loss: 0.005237tensor(0.2494, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:59 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:60 loss: 0.016692tensor(0.4250, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:61 loss: 0.007593tensor(0.2722, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:62 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:63 loss: 0.001608tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:64 loss: 0.002385tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:65 loss: 0.003458tensor(0.4183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:66 loss: 0.000061tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:67 loss: 0.006395tensor(0.3588, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:70 loss: 0.002757tensor(0.2848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:71 loss: 0.004791tensor(0.4126, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:72 loss: 0.002982tensor(0.3849, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:73 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:74 loss: 0.003559tensor(0.4210, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:75 loss: 0.000198tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:76 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:77 loss: 0.000870tensor(0.1057, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:78 loss: 0.010782tensor(0.4235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:53 step:79 loss: 0.002504tensor(0.3755, grad_fn=<DivBackward0>)\n",
      "Epoch:54 step:0 loss: 0.003989\n",
      "Epoch:54 step:1 loss: 0.002292\n",
      "Epoch:54 step:2 loss: 0.000216\n",
      "Epoch:54 step:3 loss: 0.000002\n",
      "Epoch:54 step:4 loss: 0.007665\n",
      "Epoch:54 step:5 loss: 0.005523\n",
      "Epoch:54 step:6 loss: 0.000021\n",
      "Epoch:54 step:7 loss: 0.007361\n",
      "Epoch:54 step:8 loss: 0.000002\n",
      "Epoch:54 step:9 loss: 0.000055\n",
      "Epoch:54 step:10 loss: 0.000002\n",
      "Epoch:54 step:11 loss: 0.005898\n",
      "Epoch:54 step:12 loss: 0.005702\n",
      "Epoch:54 step:13 loss: 0.000181\n",
      "Epoch:54 step:14 loss: 0.000001\n",
      "Epoch:54 step:15 loss: 0.000089\n",
      "Epoch:54 step:16 loss: 0.000001\n",
      "Epoch:54 step:17 loss: 0.000063\n",
      "Epoch:54 step:18 loss: 0.002934\n",
      "Epoch:54 step:19 loss: 0.015469\n",
      "Epoch:54 step:20 loss: 0.000002\n",
      "Epoch:54 step:21 loss: 0.000003\n",
      "Epoch:54 step:22 loss: 0.015813\n",
      "Epoch:54 step:23 loss: 0.003497\n",
      "Epoch:54 step:24 loss: 0.006852\n",
      "Epoch:54 step:25 loss: 0.000915\n",
      "Epoch:54 step:26 loss: 0.007506\n",
      "Epoch:54 step:27 loss: 0.016336\n",
      "Epoch:54 step:28 loss: 0.000153\n",
      "Epoch:54 step:29 loss: 0.000001\n",
      "Epoch:54 step:30 loss: 0.000512\n",
      "Epoch:54 step:31 loss: 0.000046\n",
      "Epoch:54 step:32 loss: 0.000009\n",
      "Epoch:54 step:33 loss: 0.000001\n",
      "Epoch:54 step:34 loss: 0.006981\n",
      "Epoch:54 step:35 loss: 0.005357\n",
      "Epoch:54 step:36 loss: 0.000011\n",
      "Epoch:54 step:37 loss: 0.001670\n",
      "Epoch:54 step:38 loss: 0.000056\n",
      "Epoch:54 step:39 loss: 0.000117\n",
      "Epoch:54 step:40 loss: 0.021598\n",
      "Epoch:54 step:41 loss: 0.000001\n",
      "Epoch:54 step:42 loss: 0.000020\n",
      "Epoch:54 step:43 loss: 0.007331\n",
      "Epoch:54 step:44 loss: 0.000044\n",
      "Epoch:54 step:45 loss: 0.002124\n",
      "Epoch:54 step:46 loss: 0.000040\n",
      "Epoch:54 step:47 loss: 0.007520\n",
      "Epoch:54 step:48 loss: 0.003204\n",
      "Epoch:54 step:49 loss: 0.000002\n",
      "Epoch:54 step:50 loss: 0.000168\n",
      "Epoch:54 step:51 loss: 0.001247\n",
      "Epoch:54 step:52 loss: 0.000002\n",
      "Epoch:54 step:53 loss: 0.000016\n",
      "Epoch:54 step:54 loss: 0.011496\n",
      "Epoch:54 step:55 loss: 0.014600\n",
      "Epoch:54 step:56 loss: 0.005711\n",
      "Epoch:54 step:57 loss: 0.002219\n",
      "Epoch:54 step:58 loss: 0.004838\n",
      "Epoch:54 step:59 loss: 0.000030\n",
      "Epoch:54 step:60 loss: 0.012494\n",
      "Epoch:54 step:61 loss: 0.006968\n",
      "Epoch:54 step:62 loss: 0.000014\n",
      "Epoch:54 step:63 loss: 0.001249\n",
      "Epoch:54 step:64 loss: 0.000485\n",
      "Epoch:54 step:65 loss: 0.003386\n",
      "Epoch:54 step:66 loss: 0.000051\n",
      "Epoch:54 step:67 loss: 0.004775\n",
      "Epoch:54 step:68 loss: 0.000001\n",
      "Epoch:54 step:69 loss: 0.000000\n",
      "Epoch:54 step:70 loss: 0.001810\n",
      "Epoch:54 step:71 loss: 0.004618\n",
      "Epoch:54 step:72 loss: 0.002149\n",
      "Epoch:54 step:73 loss: 0.000004\n",
      "Epoch:54 step:74 loss: 0.003456\n",
      "Epoch:54 step:75 loss: 0.000081\n",
      "Epoch:54 step:76 loss: 0.000005\n",
      "Epoch:54 step:77 loss: 0.000650\n",
      "Epoch:54 step:78 loss: 0.010280\n",
      "Epoch:54 step:79 loss: 0.002336\n",
      "Test Epoch:54 step:0 loss: 0.004612tensor(0.3095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:1 loss: 0.002113tensor(0.2304, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:2 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:4 loss: 0.008044tensor(0.3948, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:5 loss: 0.005254tensor(0.3833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:6 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:7 loss: 0.006638tensor(0.3330, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:9 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:11 loss: 0.003897tensor(0.3781, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:12 loss: 0.005056tensor(0.4563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:13 loss: 0.000319tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:54 step:15 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:17 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:18 loss: 0.002493tensor(0.3787, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:19 loss: 0.009194tensor(0.4107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:22 loss: 0.013313tensor(0.4077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:23 loss: 0.000719tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:24 loss: 0.004756tensor(0.4226, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:25 loss: 0.000956tensor(0.1386, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:26 loss: 0.006012tensor(0.4035, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:27 loss: 0.013504tensor(0.4441, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:28 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:30 loss: 0.000257tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:31 loss: 0.000237tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:32 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:34 loss: 0.003559tensor(0.3502, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:35 loss: 0.003457tensor(0.3279, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:36 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:37 loss: 0.003406tensor(0.1403, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:38 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:39 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:40 loss: 0.016046tensor(0.4451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:42 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:43 loss: 0.008915tensor(0.4221, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:44 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:45 loss: 0.001956tensor(0.2574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:47 loss: 0.006481tensor(0.4273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:48 loss: 0.002134tensor(0.2812, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:50 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:51 loss: 0.000450tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:53 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:54 loss: 0.008821tensor(0.4320, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:55 loss: 0.012270tensor(0.4157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:56 loss: 0.005247tensor(0.4402, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:57 loss: 0.000892tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:58 loss: 0.005016tensor(0.2792, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:59 loss: 0.000402tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:60 loss: 0.017679tensor(0.4295, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:61 loss: 0.006088tensor(0.3030, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:62 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:63 loss: 0.001092tensor(0.0178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:64 loss: 0.001174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:65 loss: 0.003298tensor(0.4260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:66 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:67 loss: 0.004909tensor(0.3881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:70 loss: 0.001803tensor(0.3278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:71 loss: 0.006329tensor(0.4026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:72 loss: 0.002303tensor(0.4082, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:73 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:74 loss: 0.003577tensor(0.4230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:75 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:76 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:77 loss: 0.000490tensor(0.2470, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:78 loss: 0.012737tensor(0.4207, grad_fn=<DivBackward0>)\n",
      "Test Epoch:54 step:79 loss: 0.002084tensor(0.3929, grad_fn=<DivBackward0>)\n",
      "Epoch:55 step:0 loss: 0.003884\n",
      "Epoch:55 step:1 loss: 0.002820\n",
      "Epoch:55 step:2 loss: 0.000033\n",
      "Epoch:55 step:3 loss: 0.000001\n",
      "Epoch:55 step:4 loss: 0.009333\n",
      "Epoch:55 step:5 loss: 0.004337\n",
      "Epoch:55 step:6 loss: 0.000006\n",
      "Epoch:55 step:7 loss: 0.004930\n",
      "Epoch:55 step:8 loss: 0.000001\n",
      "Epoch:55 step:9 loss: 0.000012\n",
      "Epoch:55 step:10 loss: 0.000001\n",
      "Epoch:55 step:11 loss: 0.003819\n",
      "Epoch:55 step:12 loss: 0.005003\n",
      "Epoch:55 step:13 loss: 0.000802\n",
      "Epoch:55 step:14 loss: 0.000000\n",
      "Epoch:55 step:15 loss: 0.000300\n",
      "Epoch:55 step:16 loss: 0.000000\n",
      "Epoch:55 step:17 loss: 0.000034\n",
      "Epoch:55 step:18 loss: 0.002535\n",
      "Epoch:55 step:19 loss: 0.009985\n",
      "Epoch:55 step:20 loss: 0.000001\n",
      "Epoch:55 step:21 loss: 0.000001\n",
      "Epoch:55 step:22 loss: 0.011536\n",
      "Epoch:55 step:23 loss: 0.000643\n",
      "Epoch:55 step:24 loss: 0.004968\n",
      "Epoch:55 step:25 loss: 0.000741\n",
      "Epoch:55 step:26 loss: 0.005642\n",
      "Epoch:55 step:27 loss: 0.014172\n",
      "Epoch:55 step:28 loss: 0.000000\n",
      "Epoch:55 step:29 loss: 0.000000\n",
      "Epoch:55 step:30 loss: 0.000172\n",
      "Epoch:55 step:31 loss: 0.000019\n",
      "Epoch:55 step:32 loss: 0.000003\n",
      "Epoch:55 step:33 loss: 0.000000\n",
      "Epoch:55 step:34 loss: 0.006960\n",
      "Epoch:55 step:35 loss: 0.003638\n",
      "Epoch:55 step:36 loss: 0.000006\n",
      "Epoch:55 step:37 loss: 0.001953\n",
      "Epoch:55 step:38 loss: 0.000030\n",
      "Epoch:55 step:39 loss: 0.000120\n",
      "Epoch:55 step:40 loss: 0.027068\n",
      "Epoch:55 step:41 loss: 0.000004\n",
      "Epoch:55 step:42 loss: 0.000003\n",
      "Epoch:55 step:43 loss: 0.007875\n",
      "Epoch:55 step:44 loss: 0.000052\n",
      "Epoch:55 step:45 loss: 0.002246\n",
      "Epoch:55 step:46 loss: 0.000022\n",
      "Epoch:55 step:47 loss: 0.006937\n",
      "Epoch:55 step:48 loss: 0.002670\n",
      "Epoch:55 step:49 loss: 0.000001\n",
      "Epoch:55 step:50 loss: 0.000355\n",
      "Epoch:55 step:51 loss: 0.000832\n",
      "Epoch:55 step:52 loss: 0.000001\n",
      "Epoch:55 step:53 loss: 0.000013\n",
      "Epoch:55 step:54 loss: 0.010797\n",
      "Epoch:55 step:55 loss: 0.011746\n",
      "Epoch:55 step:56 loss: 0.005339\n",
      "Epoch:55 step:57 loss: 0.002938\n",
      "Epoch:55 step:58 loss: 0.006025\n",
      "Epoch:55 step:59 loss: 0.000011\n",
      "Epoch:55 step:60 loss: 0.010916\n",
      "Epoch:55 step:61 loss: 0.009662\n",
      "Epoch:55 step:62 loss: 0.000080\n",
      "Epoch:55 step:63 loss: 0.001035\n",
      "Epoch:55 step:64 loss: 0.000242\n",
      "Epoch:55 step:65 loss: 0.003392\n",
      "Epoch:55 step:66 loss: 0.000043\n",
      "Epoch:55 step:67 loss: 0.004730\n",
      "Epoch:55 step:68 loss: 0.000000\n",
      "Epoch:55 step:69 loss: 0.000000\n",
      "Epoch:55 step:70 loss: 0.001264\n",
      "Epoch:55 step:71 loss: 0.005081\n",
      "Epoch:55 step:72 loss: 0.002950\n",
      "Epoch:55 step:73 loss: 0.000003\n",
      "Epoch:55 step:74 loss: 0.003095\n",
      "Epoch:55 step:75 loss: 0.000056\n",
      "Epoch:55 step:76 loss: 0.000003\n",
      "Epoch:55 step:77 loss: 0.000603\n",
      "Epoch:55 step:78 loss: 0.009131\n",
      "Epoch:55 step:79 loss: 0.002861\n",
      "Test Epoch:55 step:0 loss: 0.003672tensor(0.3361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:1 loss: 0.002668tensor(0.2493, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:2 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:4 loss: 0.008922tensor(0.3871, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:5 loss: 0.005238tensor(0.3827, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:7 loss: 0.005192tensor(0.3536, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:9 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:11 loss: 0.006254tensor(0.3557, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:55 step:12 loss: 0.004912tensor(0.4602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:13 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:15 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:17 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:18 loss: 0.005166tensor(0.2837, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:19 loss: 0.012011tensor(0.3951, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:22 loss: 0.012731tensor(0.4125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:23 loss: 0.002841tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:24 loss: 0.008020tensor(0.3969, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:25 loss: 0.001238tensor(0.0904, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:26 loss: 0.006173tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:27 loss: 0.015345tensor(0.4434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:28 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:30 loss: 0.000675tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:31 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:32 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:34 loss: 0.005520tensor(0.2814, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:35 loss: 0.008137tensor(0.1875, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:36 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:37 loss: 0.001081tensor(0.1708, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:38 loss: 0.000111tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:39 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:40 loss: 0.014993tensor(0.4433, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:41 loss: 0.000137tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:42 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:43 loss: 0.009296tensor(0.4170, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:44 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:45 loss: 0.001572tensor(0.2904, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:46 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:47 loss: 0.006364tensor(0.4244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:48 loss: 0.003434tensor(0.2352, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:50 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:51 loss: 0.000863tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:53 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:54 loss: 0.010649tensor(0.4258, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:55 loss: 0.012267tensor(0.4122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:56 loss: 0.005924tensor(0.4316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:57 loss: 0.004789tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:58 loss: 0.008762tensor(0.2359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:59 loss: 0.000142tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:60 loss: 0.013990tensor(0.4421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:61 loss: 0.004981tensor(0.3402, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:62 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:63 loss: 0.001557tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:64 loss: 0.000572tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:65 loss: 0.006285tensor(0.3823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:66 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:67 loss: 0.013079tensor(0.2918, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:70 loss: 0.003362tensor(0.2137, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:71 loss: 0.006715tensor(0.4054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:72 loss: 0.002804tensor(0.3925, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:73 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:74 loss: 0.003711tensor(0.4208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:75 loss: 0.000082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:76 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:77 loss: 0.000896tensor(0.1910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:78 loss: 0.014294tensor(0.4155, grad_fn=<DivBackward0>)\n",
      "Test Epoch:55 step:79 loss: 0.010685tensor(0.2825, grad_fn=<DivBackward0>)\n",
      "Epoch:56 step:0 loss: 0.005627\n",
      "Epoch:56 step:1 loss: 0.002832\n",
      "Epoch:56 step:2 loss: 0.000243\n",
      "Epoch:56 step:3 loss: 0.000001\n",
      "Epoch:56 step:4 loss: 0.010043\n",
      "Epoch:56 step:5 loss: 0.004943\n",
      "Epoch:56 step:6 loss: 0.000001\n",
      "Epoch:56 step:7 loss: 0.008851\n",
      "Epoch:56 step:8 loss: 0.000003\n",
      "Epoch:56 step:9 loss: 0.000031\n",
      "Epoch:56 step:10 loss: 0.000013\n",
      "Epoch:56 step:11 loss: 0.004519\n",
      "Epoch:56 step:12 loss: 0.005427\n",
      "Epoch:56 step:13 loss: 0.001143\n",
      "Epoch:56 step:14 loss: 0.000000\n",
      "Epoch:56 step:15 loss: 0.000210\n",
      "Epoch:56 step:16 loss: 0.000001\n",
      "Epoch:56 step:17 loss: 0.000040\n",
      "Epoch:56 step:18 loss: 0.002861\n",
      "Epoch:56 step:19 loss: 0.016419\n",
      "Epoch:56 step:20 loss: 0.000003\n",
      "Epoch:56 step:21 loss: 0.000003\n",
      "Epoch:56 step:22 loss: 0.019183\n",
      "Epoch:56 step:23 loss: 0.003691\n",
      "Epoch:56 step:24 loss: 0.007209\n",
      "Epoch:56 step:25 loss: 0.001810\n",
      "Epoch:56 step:26 loss: 0.009936\n",
      "Epoch:56 step:27 loss: 0.016431\n",
      "Epoch:56 step:28 loss: 0.000116\n",
      "Epoch:56 step:29 loss: 0.000001\n",
      "Epoch:56 step:30 loss: 0.000112\n",
      "Epoch:56 step:31 loss: 0.000354\n",
      "Epoch:56 step:32 loss: 0.000066\n",
      "Epoch:56 step:33 loss: 0.000000\n",
      "Epoch:56 step:34 loss: 0.011237\n",
      "Epoch:56 step:35 loss: 0.003717\n",
      "Epoch:56 step:36 loss: 0.000010\n",
      "Epoch:56 step:37 loss: 0.003167\n",
      "Epoch:56 step:38 loss: 0.000332\n",
      "Epoch:56 step:39 loss: 0.000285\n",
      "Epoch:56 step:40 loss: 0.016134\n",
      "Epoch:56 step:41 loss: 0.000026\n",
      "Epoch:56 step:42 loss: 0.000022\n",
      "Epoch:56 step:43 loss: 0.008462\n",
      "Epoch:56 step:44 loss: 0.000019\n",
      "Epoch:56 step:45 loss: 0.001126\n",
      "Epoch:56 step:46 loss: 0.000023\n",
      "Epoch:56 step:47 loss: 0.007641\n",
      "Epoch:56 step:48 loss: 0.002313\n",
      "Epoch:56 step:49 loss: 0.000002\n",
      "Epoch:56 step:50 loss: 0.000135\n",
      "Epoch:56 step:51 loss: 0.002473\n",
      "Epoch:56 step:52 loss: 0.000002\n",
      "Epoch:56 step:53 loss: 0.000042\n",
      "Epoch:56 step:54 loss: 0.009845\n",
      "Epoch:56 step:55 loss: 0.012181\n",
      "Epoch:56 step:56 loss: 0.005084\n",
      "Epoch:56 step:57 loss: 0.004973\n",
      "Epoch:56 step:58 loss: 0.013178\n",
      "Epoch:56 step:59 loss: 0.000018\n",
      "Epoch:56 step:60 loss: 0.013286\n",
      "Epoch:56 step:61 loss: 0.010552\n",
      "Epoch:56 step:62 loss: 0.000001\n",
      "Epoch:56 step:63 loss: 0.001453\n",
      "Epoch:56 step:64 loss: 0.000229\n",
      "Epoch:56 step:65 loss: 0.004415\n",
      "Epoch:56 step:66 loss: 0.000115\n",
      "Epoch:56 step:67 loss: 0.012688\n",
      "Epoch:56 step:68 loss: 0.000001\n",
      "Epoch:56 step:69 loss: 0.000000\n",
      "Epoch:56 step:70 loss: 0.001552\n",
      "Epoch:56 step:71 loss: 0.006625\n",
      "Epoch:56 step:72 loss: 0.001964\n",
      "Epoch:56 step:73 loss: 0.000011\n",
      "Epoch:56 step:74 loss: 0.005919\n",
      "Epoch:56 step:75 loss: 0.000416\n",
      "Epoch:56 step:76 loss: 0.000012\n",
      "Epoch:56 step:77 loss: 0.002171\n",
      "Epoch:56 step:78 loss: 0.009308\n",
      "Epoch:56 step:79 loss: 0.002090\n",
      "Test Epoch:56 step:0 loss: 0.005181tensor(0.2656, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:1 loss: 0.003000tensor(0.1801, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:2 loss: 0.000667tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:3 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:4 loss: 0.007582tensor(0.3916, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:5 loss: 0.006040tensor(0.3557, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:6 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:7 loss: 0.006161tensor(0.3360, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:8 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:56 step:9 loss: 0.002315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:11 loss: 0.010442tensor(0.3030, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:12 loss: 0.004676tensor(0.4558, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:13 loss: 0.000110tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:15 loss: 0.000163tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:17 loss: 0.000136tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:18 loss: 0.004002tensor(0.3122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:19 loss: 0.009162tensor(0.4059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:20 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:21 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:22 loss: 0.012792tensor(0.4087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:23 loss: 0.000188tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:24 loss: 0.004873tensor(0.4219, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:25 loss: 0.000728tensor(0.2283, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:26 loss: 0.005746tensor(0.4089, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:27 loss: 0.012810tensor(0.4466, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:28 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:30 loss: 0.000878tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:31 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:32 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:34 loss: 0.006774tensor(0.2190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:35 loss: 0.004315tensor(0.2849, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:36 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:37 loss: 0.002567tensor(0.1292, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:38 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:39 loss: 0.001088tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:40 loss: 0.016708tensor(0.4362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:41 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:42 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:43 loss: 0.008195tensor(0.4174, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:44 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:45 loss: 0.001517tensor(0.3099, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:46 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:47 loss: 0.006288tensor(0.4246, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:48 loss: 0.002922tensor(0.2040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:49 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:50 loss: 0.000057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:51 loss: 0.000150tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:53 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:54 loss: 0.010697tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:55 loss: 0.010853tensor(0.4182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:56 loss: 0.005578tensor(0.4349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:57 loss: 0.003807tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:58 loss: 0.004185tensor(0.2892, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:59 loss: 0.000137tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:60 loss: 0.010745tensor(0.4486, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:61 loss: 0.005418tensor(0.3194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:62 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:63 loss: 0.001198tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:64 loss: 0.001316tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:65 loss: 0.004125tensor(0.4114, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:66 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:67 loss: 0.005195tensor(0.3904, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:70 loss: 0.002242tensor(0.3015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:71 loss: 0.004697tensor(0.4287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:72 loss: 0.002152tensor(0.4185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:73 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:74 loss: 0.003409tensor(0.4276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:75 loss: 0.000147tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:76 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:77 loss: 0.000400tensor(0.2934, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:78 loss: 0.009834tensor(0.4310, grad_fn=<DivBackward0>)\n",
      "Test Epoch:56 step:79 loss: 0.001799tensor(0.4036, grad_fn=<DivBackward0>)\n",
      "Epoch:57 step:0 loss: 0.003746\n",
      "Epoch:57 step:1 loss: 0.002008\n",
      "Epoch:57 step:2 loss: 0.000084\n",
      "Epoch:57 step:3 loss: 0.000003\n",
      "Epoch:57 step:4 loss: 0.007893\n",
      "Epoch:57 step:5 loss: 0.005216\n",
      "Epoch:57 step:6 loss: 0.000001\n",
      "Epoch:57 step:7 loss: 0.005535\n",
      "Epoch:57 step:8 loss: 0.000001\n",
      "Epoch:57 step:9 loss: 0.000044\n",
      "Epoch:57 step:10 loss: 0.000005\n",
      "Epoch:57 step:11 loss: 0.003570\n",
      "Epoch:57 step:12 loss: 0.004488\n",
      "Epoch:57 step:13 loss: 0.000531\n",
      "Epoch:57 step:14 loss: 0.000001\n",
      "Epoch:57 step:15 loss: 0.000227\n",
      "Epoch:57 step:16 loss: 0.000000\n",
      "Epoch:57 step:17 loss: 0.000132\n",
      "Epoch:57 step:18 loss: 0.002110\n",
      "Epoch:57 step:19 loss: 0.008184\n",
      "Epoch:57 step:20 loss: 0.000001\n",
      "Epoch:57 step:21 loss: 0.000001\n",
      "Epoch:57 step:22 loss: 0.010503\n",
      "Epoch:57 step:23 loss: 0.000290\n",
      "Epoch:57 step:24 loss: 0.004791\n",
      "Epoch:57 step:25 loss: 0.000883\n",
      "Epoch:57 step:26 loss: 0.004837\n",
      "Epoch:57 step:27 loss: 0.012373\n",
      "Epoch:57 step:28 loss: 0.000003\n",
      "Epoch:57 step:29 loss: 0.000000\n",
      "Epoch:57 step:30 loss: 0.000124\n",
      "Epoch:57 step:31 loss: 0.000094\n",
      "Epoch:57 step:32 loss: 0.000093\n",
      "Epoch:57 step:33 loss: 0.000001\n",
      "Epoch:57 step:34 loss: 0.003443\n",
      "Epoch:57 step:35 loss: 0.003387\n",
      "Epoch:57 step:36 loss: 0.000066\n",
      "Epoch:57 step:37 loss: 0.001885\n",
      "Epoch:57 step:38 loss: 0.000037\n",
      "Epoch:57 step:39 loss: 0.000121\n",
      "Epoch:57 step:40 loss: 0.012886\n",
      "Epoch:57 step:41 loss: 0.000004\n",
      "Epoch:57 step:42 loss: 0.000003\n",
      "Epoch:57 step:43 loss: 0.009522\n",
      "Epoch:57 step:44 loss: 0.000010\n",
      "Epoch:57 step:45 loss: 0.001250\n",
      "Epoch:57 step:46 loss: 0.000002\n",
      "Epoch:57 step:47 loss: 0.005287\n",
      "Epoch:57 step:48 loss: 0.001849\n",
      "Epoch:57 step:49 loss: 0.000001\n",
      "Epoch:57 step:50 loss: 0.000021\n",
      "Epoch:57 step:51 loss: 0.000114\n",
      "Epoch:57 step:52 loss: 0.000001\n",
      "Epoch:57 step:53 loss: 0.000010\n",
      "Epoch:57 step:54 loss: 0.006767\n",
      "Epoch:57 step:55 loss: 0.008901\n",
      "Epoch:57 step:56 loss: 0.004712\n",
      "Epoch:57 step:57 loss: 0.002864\n",
      "Epoch:57 step:58 loss: 0.003838\n",
      "Epoch:57 step:59 loss: 0.000268\n",
      "Epoch:57 step:60 loss: 0.009310\n",
      "Epoch:57 step:61 loss: 0.005357\n",
      "Epoch:57 step:62 loss: 0.000004\n",
      "Epoch:57 step:63 loss: 0.000841\n",
      "Epoch:57 step:64 loss: 0.000294\n",
      "Epoch:57 step:65 loss: 0.002762\n",
      "Epoch:57 step:66 loss: 0.000019\n",
      "Epoch:57 step:67 loss: 0.004486\n",
      "Epoch:57 step:68 loss: 0.000000\n",
      "Epoch:57 step:69 loss: 0.000000\n",
      "Epoch:57 step:70 loss: 0.001200\n",
      "Epoch:57 step:71 loss: 0.004390\n",
      "Epoch:57 step:72 loss: 0.001631\n",
      "Epoch:57 step:73 loss: 0.000020\n",
      "Epoch:57 step:74 loss: 0.003060\n",
      "Epoch:57 step:75 loss: 0.000059\n",
      "Epoch:57 step:76 loss: 0.000001\n",
      "Epoch:57 step:77 loss: 0.000834\n",
      "Epoch:57 step:78 loss: 0.008208\n",
      "Epoch:57 step:79 loss: 0.002439\n",
      "Test Epoch:57 step:0 loss: 0.003629tensor(0.3450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:1 loss: 0.002244tensor(0.2318, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:2 loss: 0.000170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:3 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:4 loss: 0.006057tensor(0.4208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:5 loss: 0.003700tensor(0.4060, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:57 step:6 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:7 loss: 0.003972tensor(0.3842, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:8 loss: 0.000701tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:9 loss: 0.000082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:11 loss: 0.004148tensor(0.3754, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:12 loss: 0.004236tensor(0.4619, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:13 loss: 0.000308tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:15 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:17 loss: 0.000227tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:18 loss: 0.001736tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:19 loss: 0.007579tensor(0.4250, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:20 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:22 loss: 0.009990tensor(0.4319, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:23 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:24 loss: 0.005035tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:25 loss: 0.000928tensor(0.2618, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:26 loss: 0.004473tensor(0.4299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:27 loss: 0.010345tensor(0.4583, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:30 loss: 0.000240tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:31 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:32 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:34 loss: 0.006303tensor(0.2738, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:35 loss: 0.003857tensor(0.3265, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:36 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:37 loss: 0.001458tensor(0.1915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:38 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:39 loss: 0.000253tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:40 loss: 0.014080tensor(0.4477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:42 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:43 loss: 0.008661tensor(0.4200, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:44 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:45 loss: 0.002255tensor(0.3047, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:46 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:47 loss: 0.004792tensor(0.4388, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:48 loss: 0.002018tensor(0.2746, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:50 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:51 loss: 0.000172tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:53 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:54 loss: 0.009180tensor(0.4412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:55 loss: 0.008899tensor(0.4346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:56 loss: 0.005034tensor(0.4440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:57 loss: 0.001359tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:58 loss: 0.003738tensor(0.3095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:59 loss: 0.000166tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:60 loss: 0.012574tensor(0.4473, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:61 loss: 0.005521tensor(0.3329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:62 loss: 0.000267tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:63 loss: 0.000721tensor(0.0628, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:64 loss: 0.000630tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:65 loss: 0.003923tensor(0.4162, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:66 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:67 loss: 0.004906tensor(0.4114, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:70 loss: 0.001437tensor(0.3454, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:71 loss: 0.004519tensor(0.4363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:72 loss: 0.003192tensor(0.4059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:73 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:74 loss: 0.004533tensor(0.4197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:75 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:77 loss: 0.000506tensor(0.2599, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:78 loss: 0.007337tensor(0.4455, grad_fn=<DivBackward0>)\n",
      "Test Epoch:57 step:79 loss: 0.001887tensor(0.4039, grad_fn=<DivBackward0>)\n",
      "Epoch:58 step:0 loss: 0.003597\n",
      "Epoch:58 step:1 loss: 0.002177\n",
      "Epoch:58 step:2 loss: 0.000056\n",
      "Epoch:58 step:3 loss: 0.000001\n",
      "Epoch:58 step:4 loss: 0.005735\n",
      "Epoch:58 step:5 loss: 0.006082\n",
      "Epoch:58 step:6 loss: 0.000001\n",
      "Epoch:58 step:7 loss: 0.003881\n",
      "Epoch:58 step:8 loss: 0.000001\n",
      "Epoch:58 step:9 loss: 0.000052\n",
      "Epoch:58 step:10 loss: 0.000002\n",
      "Epoch:58 step:11 loss: 0.005136\n",
      "Epoch:58 step:12 loss: 0.004644\n",
      "Epoch:58 step:13 loss: 0.000317\n",
      "Epoch:58 step:14 loss: 0.000001\n",
      "Epoch:58 step:15 loss: 0.000076\n",
      "Epoch:58 step:16 loss: 0.000000\n",
      "Epoch:58 step:17 loss: 0.000023\n",
      "Epoch:58 step:18 loss: 0.001631\n",
      "Epoch:58 step:19 loss: 0.008806\n",
      "Epoch:58 step:20 loss: 0.000001\n",
      "Epoch:58 step:21 loss: 0.000000\n",
      "Epoch:58 step:22 loss: 0.010717\n",
      "Epoch:58 step:23 loss: 0.000204\n",
      "Epoch:58 step:24 loss: 0.004837\n",
      "Epoch:58 step:25 loss: 0.001005\n",
      "Epoch:58 step:26 loss: 0.008351\n",
      "Epoch:58 step:27 loss: 0.011895\n",
      "Epoch:58 step:28 loss: 0.000049\n",
      "Epoch:58 step:29 loss: 0.000000\n",
      "Epoch:58 step:30 loss: 0.000488\n",
      "Epoch:58 step:31 loss: 0.000049\n",
      "Epoch:58 step:32 loss: 0.000032\n",
      "Epoch:58 step:33 loss: 0.000000\n",
      "Epoch:58 step:34 loss: 0.003367\n",
      "Epoch:58 step:35 loss: 0.003314\n",
      "Epoch:58 step:36 loss: 0.000029\n",
      "Epoch:58 step:37 loss: 0.001260\n",
      "Epoch:58 step:38 loss: 0.000430\n",
      "Epoch:58 step:39 loss: 0.000134\n",
      "Epoch:58 step:40 loss: 0.015268\n",
      "Epoch:58 step:41 loss: 0.000002\n",
      "Epoch:58 step:42 loss: 0.000005\n",
      "Epoch:58 step:43 loss: 0.006812\n",
      "Epoch:58 step:44 loss: 0.000030\n",
      "Epoch:58 step:45 loss: 0.001128\n",
      "Epoch:58 step:46 loss: 0.000001\n",
      "Epoch:58 step:47 loss: 0.005896\n",
      "Epoch:58 step:48 loss: 0.002017\n",
      "Epoch:58 step:49 loss: 0.000001\n",
      "Epoch:58 step:50 loss: 0.000008\n",
      "Epoch:58 step:51 loss: 0.000014\n",
      "Epoch:58 step:52 loss: 0.000001\n",
      "Epoch:58 step:53 loss: 0.000012\n",
      "Epoch:58 step:54 loss: 0.007444\n",
      "Epoch:58 step:55 loss: 0.008973\n",
      "Epoch:58 step:56 loss: 0.004652\n",
      "Epoch:58 step:57 loss: 0.000504\n",
      "Epoch:58 step:58 loss: 0.003797\n",
      "Epoch:58 step:59 loss: 0.000158\n",
      "Epoch:58 step:60 loss: 0.010132\n",
      "Epoch:58 step:61 loss: 0.004924\n",
      "Epoch:58 step:62 loss: 0.000001\n",
      "Epoch:58 step:63 loss: 0.001151\n",
      "Epoch:58 step:64 loss: 0.000198\n",
      "Epoch:58 step:65 loss: 0.003446\n",
      "Epoch:58 step:66 loss: 0.000014\n",
      "Epoch:58 step:67 loss: 0.004112\n",
      "Epoch:58 step:68 loss: 0.000000\n",
      "Epoch:58 step:69 loss: 0.000000\n",
      "Epoch:58 step:70 loss: 0.001026\n",
      "Epoch:58 step:71 loss: 0.003672\n",
      "Epoch:58 step:72 loss: 0.001303\n",
      "Epoch:58 step:73 loss: 0.000001\n",
      "Epoch:58 step:74 loss: 0.003236\n",
      "Epoch:58 step:75 loss: 0.000020\n",
      "Epoch:58 step:76 loss: 0.000000\n",
      "Epoch:58 step:77 loss: 0.001247\n",
      "Epoch:58 step:78 loss: 0.010609\n",
      "Epoch:58 step:79 loss: 0.001609\n",
      "Test Epoch:58 step:0 loss: 0.003542tensor(0.3409, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:1 loss: 0.001933tensor(0.2737, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:2 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:58 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:4 loss: 0.006467tensor(0.4197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:5 loss: 0.003265tensor(0.4197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:7 loss: 0.004189tensor(0.3841, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:9 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:10 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:11 loss: 0.003182tensor(0.3974, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:12 loss: 0.003944tensor(0.4661, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:13 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:15 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:17 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:18 loss: 0.001959tensor(0.4010, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:19 loss: 0.007420tensor(0.4260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:22 loss: 0.009306tensor(0.4358, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:23 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:24 loss: 0.004764tensor(0.4357, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:25 loss: 0.000694tensor(0.2851, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:26 loss: 0.004434tensor(0.4308, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:27 loss: 0.012253tensor(0.4565, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:30 loss: 0.000243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:31 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:32 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:34 loss: 0.011133tensor(0.1695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:35 loss: 0.005589tensor(0.2783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:36 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:37 loss: 0.000585tensor(0.2853, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:38 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:39 loss: 0.000643tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:40 loss: 0.026179tensor(0.4216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:42 loss: 0.000066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:43 loss: 0.011262tensor(0.4079, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:44 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:45 loss: 0.007499tensor(0.1934, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:46 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:47 loss: 0.007184tensor(0.4216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:48 loss: 0.002459tensor(0.2723, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:50 loss: 0.000642tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:51 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:53 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:54 loss: 0.009787tensor(0.4349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:55 loss: 0.012187tensor(0.4212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:56 loss: 0.007106tensor(0.4343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:57 loss: 0.003360tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:58 loss: 0.010365tensor(0.1832, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:59 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:60 loss: 0.011083tensor(0.4506, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:61 loss: 0.008608tensor(0.3080, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:62 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:63 loss: 0.000807tensor(0.0469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:64 loss: 0.002664tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:65 loss: 0.004545tensor(0.3988, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:66 loss: 0.000172tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:67 loss: 0.004946tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:68 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:70 loss: 0.001626tensor(0.3176, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:71 loss: 0.005564tensor(0.4082, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:72 loss: 0.001926tensor(0.4226, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:73 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:74 loss: 0.005176tensor(0.4099, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:75 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:76 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:77 loss: 0.002626tensor(0.0693, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:78 loss: 0.013687tensor(0.4171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:58 step:79 loss: 0.003427tensor(0.3494, grad_fn=<DivBackward0>)\n",
      "Epoch:59 step:0 loss: 0.003476\n",
      "Epoch:59 step:1 loss: 0.004185\n",
      "Epoch:59 step:2 loss: 0.000100\n",
      "Epoch:59 step:3 loss: 0.000002\n",
      "Epoch:59 step:4 loss: 0.007809\n",
      "Epoch:59 step:5 loss: 0.004471\n",
      "Epoch:59 step:6 loss: 0.000000\n",
      "Epoch:59 step:7 loss: 0.006931\n",
      "Epoch:59 step:8 loss: 0.000007\n",
      "Epoch:59 step:9 loss: 0.000040\n",
      "Epoch:59 step:10 loss: 0.000004\n",
      "Epoch:59 step:11 loss: 0.007527\n",
      "Epoch:59 step:12 loss: 0.007583\n",
      "Epoch:59 step:13 loss: 0.000330\n",
      "Epoch:59 step:14 loss: 0.000001\n",
      "Epoch:59 step:15 loss: 0.000070\n",
      "Epoch:59 step:16 loss: 0.000000\n",
      "Epoch:59 step:17 loss: 0.000031\n",
      "Epoch:59 step:18 loss: 0.003239\n",
      "Epoch:59 step:19 loss: 0.039349\n",
      "Epoch:59 step:20 loss: 0.000006\n",
      "Epoch:59 step:21 loss: 0.000000\n",
      "Epoch:59 step:22 loss: 0.013116\n",
      "Epoch:59 step:23 loss: 0.004180\n",
      "Epoch:59 step:24 loss: 0.009651\n",
      "Epoch:59 step:25 loss: 0.001025\n",
      "Epoch:59 step:26 loss: 0.007405\n",
      "Epoch:59 step:27 loss: 0.014607\n",
      "Epoch:59 step:28 loss: 0.000360\n",
      "Epoch:59 step:29 loss: 0.000001\n",
      "Epoch:59 step:30 loss: 0.000754\n",
      "Epoch:59 step:31 loss: 0.000116\n",
      "Epoch:59 step:32 loss: 0.000042\n",
      "Epoch:59 step:33 loss: 0.000000\n",
      "Epoch:59 step:34 loss: 0.004790\n",
      "Epoch:59 step:35 loss: 0.003904\n",
      "Epoch:59 step:36 loss: 0.000047\n",
      "Epoch:59 step:37 loss: 0.001998\n",
      "Epoch:59 step:38 loss: 0.000009\n",
      "Epoch:59 step:39 loss: 0.000231\n",
      "Epoch:59 step:40 loss: 0.022446\n",
      "Epoch:59 step:41 loss: 0.000003\n",
      "Epoch:59 step:42 loss: 0.000021\n",
      "Epoch:59 step:43 loss: 0.009055\n",
      "Epoch:59 step:44 loss: 0.000049\n",
      "Epoch:59 step:45 loss: 0.003645\n",
      "Epoch:59 step:46 loss: 0.000025\n",
      "Epoch:59 step:47 loss: 0.007830\n",
      "Epoch:59 step:48 loss: 0.003075\n",
      "Epoch:59 step:49 loss: 0.000002\n",
      "Epoch:59 step:50 loss: 0.000461\n",
      "Epoch:59 step:51 loss: 0.000063\n",
      "Epoch:59 step:52 loss: 0.000001\n",
      "Epoch:59 step:53 loss: 0.000038\n",
      "Epoch:59 step:54 loss: 0.011747\n",
      "Epoch:59 step:55 loss: 0.013470\n",
      "Epoch:59 step:56 loss: 0.005954\n",
      "Epoch:59 step:57 loss: 0.001205\n",
      "Epoch:59 step:58 loss: 0.008283\n",
      "Epoch:59 step:59 loss: 0.000082\n",
      "Epoch:59 step:60 loss: 0.020275\n",
      "Epoch:59 step:61 loss: 0.008423\n",
      "Epoch:59 step:62 loss: 0.000001\n",
      "Epoch:59 step:63 loss: 0.001160\n",
      "Epoch:59 step:64 loss: 0.000092\n",
      "Epoch:59 step:65 loss: 0.005123\n",
      "Epoch:59 step:66 loss: 0.000068\n",
      "Epoch:59 step:67 loss: 0.006397\n",
      "Epoch:59 step:68 loss: 0.000004\n",
      "Epoch:59 step:69 loss: 0.000003\n",
      "Epoch:59 step:70 loss: 0.001648\n",
      "Epoch:59 step:71 loss: 0.005664\n",
      "Epoch:59 step:72 loss: 0.007290\n",
      "Epoch:59 step:73 loss: 0.000022\n",
      "Epoch:59 step:74 loss: 0.003481\n",
      "Epoch:59 step:75 loss: 0.000299\n",
      "Epoch:59 step:76 loss: 0.000010\n",
      "Epoch:59 step:77 loss: 0.000736\n",
      "Epoch:59 step:78 loss: 0.016314\n",
      "Epoch:59 step:79 loss: 0.004541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:59 step:0 loss: 0.004365tensor(0.3005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:1 loss: 0.004896tensor(0.0516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:2 loss: 0.000397tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:4 loss: 0.009843tensor(0.3694, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:5 loss: 0.005362tensor(0.3731, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:7 loss: 0.005088tensor(0.3500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:9 loss: 0.000165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:10 loss: 0.000075tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:11 loss: 0.006016tensor(0.3332, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:12 loss: 0.009736tensor(0.4220, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:13 loss: 0.000980tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:14 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:15 loss: 0.000640tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:17 loss: 0.000741tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:18 loss: 0.007172tensor(0.2736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:19 loss: 0.010819tensor(0.3984, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:20 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:22 loss: 0.014252tensor(0.4099, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:23 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:24 loss: 0.013368tensor(0.3648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:25 loss: 0.002258tensor(0.0190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:26 loss: 0.005735tensor(0.4094, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:27 loss: 0.018196tensor(0.4383, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:30 loss: 0.000120tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:31 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:32 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:34 loss: 0.011138tensor(0.1215, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:35 loss: 0.009056tensor(0.1699, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:36 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:37 loss: 0.000725tensor(0.2390, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:38 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:39 loss: 0.000626tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:40 loss: 0.017390tensor(0.4367, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:41 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:42 loss: 0.000142tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:43 loss: 0.007641tensor(0.4252, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:44 loss: 0.000367tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:45 loss: 0.002113tensor(0.2945, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:46 loss: 0.000279tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:47 loss: 0.006347tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:48 loss: 0.003659tensor(0.2345, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:49 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:50 loss: 0.000912tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:51 loss: 0.000114tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:52 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:53 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:54 loss: 0.008773tensor(0.4287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:55 loss: 0.012667tensor(0.4180, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:56 loss: 0.004854tensor(0.4421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:57 loss: 0.000545tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:58 loss: 0.011014tensor(0.1272, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:59 loss: 0.000128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:60 loss: 0.010727tensor(0.4508, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:61 loss: 0.006556tensor(0.3225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:63 loss: 0.001366tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:64 loss: 0.000315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:65 loss: 0.004114tensor(0.3998, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:66 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:67 loss: 0.006484tensor(0.3656, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:70 loss: 0.001322tensor(0.3469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:71 loss: 0.004629tensor(0.4186, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:72 loss: 0.002555tensor(0.4055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:73 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:74 loss: 0.003268tensor(0.4251, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:75 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:76 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:77 loss: 0.000476tensor(0.2960, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:78 loss: 0.009237tensor(0.4336, grad_fn=<DivBackward0>)\n",
      "Test Epoch:59 step:79 loss: 0.002115tensor(0.3841, grad_fn=<DivBackward0>)\n",
      "Epoch:60 step:0 loss: 0.003344\n",
      "Epoch:60 step:1 loss: 0.003319\n",
      "Epoch:60 step:2 loss: 0.000791\n",
      "Epoch:60 step:3 loss: 0.000001\n",
      "Epoch:60 step:4 loss: 0.008654\n",
      "Epoch:60 step:5 loss: 0.004822\n",
      "Epoch:60 step:6 loss: 0.000001\n",
      "Epoch:60 step:7 loss: 0.003918\n",
      "Epoch:60 step:8 loss: 0.000008\n",
      "Epoch:60 step:9 loss: 0.000112\n",
      "Epoch:60 step:10 loss: 0.000001\n",
      "Epoch:60 step:11 loss: 0.004225\n",
      "Epoch:60 step:12 loss: 0.004475\n",
      "Epoch:60 step:13 loss: 0.000272\n",
      "Epoch:60 step:14 loss: 0.000005\n",
      "Epoch:60 step:15 loss: 0.000092\n",
      "Epoch:60 step:16 loss: 0.000012\n",
      "Epoch:60 step:17 loss: 0.000145\n",
      "Epoch:60 step:18 loss: 0.002405\n",
      "Epoch:60 step:19 loss: 0.007927\n",
      "Epoch:60 step:20 loss: 0.000016\n",
      "Epoch:60 step:21 loss: 0.000007\n",
      "Epoch:60 step:22 loss: 0.010252\n",
      "Epoch:60 step:23 loss: 0.000019\n",
      "Epoch:60 step:24 loss: 0.004140\n",
      "Epoch:60 step:25 loss: 0.001113\n",
      "Epoch:60 step:26 loss: 0.005373\n",
      "Epoch:60 step:27 loss: 0.011351\n",
      "Epoch:60 step:28 loss: 0.000000\n",
      "Epoch:60 step:29 loss: 0.000001\n",
      "Epoch:60 step:30 loss: 0.000089\n",
      "Epoch:60 step:31 loss: 0.000015\n",
      "Epoch:60 step:32 loss: 0.000002\n",
      "Epoch:60 step:33 loss: 0.000002\n",
      "Epoch:60 step:34 loss: 0.003398\n",
      "Epoch:60 step:35 loss: 0.006455\n",
      "Epoch:60 step:36 loss: 0.000055\n",
      "Epoch:60 step:37 loss: 0.001006\n",
      "Epoch:60 step:38 loss: 0.000007\n",
      "Epoch:60 step:39 loss: 0.000093\n",
      "Epoch:60 step:40 loss: 0.010386\n",
      "Epoch:60 step:41 loss: 0.000001\n",
      "Epoch:60 step:42 loss: 0.000003\n",
      "Epoch:60 step:43 loss: 0.006326\n",
      "Epoch:60 step:44 loss: 0.000009\n",
      "Epoch:60 step:45 loss: 0.001335\n",
      "Epoch:60 step:46 loss: 0.000011\n",
      "Epoch:60 step:47 loss: 0.004971\n",
      "Epoch:60 step:48 loss: 0.002513\n",
      "Epoch:60 step:49 loss: 0.000002\n",
      "Epoch:60 step:50 loss: 0.000146\n",
      "Epoch:60 step:51 loss: 0.000175\n",
      "Epoch:60 step:52 loss: 0.000002\n",
      "Epoch:60 step:53 loss: 0.000020\n",
      "Epoch:60 step:54 loss: 0.006901\n",
      "Epoch:60 step:55 loss: 0.008670\n",
      "Epoch:60 step:56 loss: 0.004632\n",
      "Epoch:60 step:57 loss: 0.004820\n",
      "Epoch:60 step:58 loss: 0.005730\n",
      "Epoch:60 step:59 loss: 0.000159\n",
      "Epoch:60 step:60 loss: 0.008066\n",
      "Epoch:60 step:61 loss: 0.004689\n",
      "Epoch:60 step:62 loss: 0.000001\n",
      "Epoch:60 step:63 loss: 0.001548\n",
      "Epoch:60 step:64 loss: 0.000089\n",
      "Epoch:60 step:65 loss: 0.003795\n",
      "Epoch:60 step:66 loss: 0.000008\n",
      "Epoch:60 step:67 loss: 0.009304\n",
      "Epoch:60 step:68 loss: 0.000000\n",
      "Epoch:60 step:69 loss: 0.000000\n",
      "Epoch:60 step:70 loss: 0.001418\n",
      "Epoch:60 step:71 loss: 0.004566\n",
      "Epoch:60 step:72 loss: 0.003000\n",
      "Epoch:60 step:73 loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:60 step:74 loss: 0.003033\n",
      "Epoch:60 step:75 loss: 0.000036\n",
      "Epoch:60 step:76 loss: 0.000008\n",
      "Epoch:60 step:77 loss: 0.000721\n",
      "Epoch:60 step:78 loss: 0.007173\n",
      "Epoch:60 step:79 loss: 0.004400\n",
      "Test Epoch:60 step:0 loss: 0.003132tensor(0.3482, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:1 loss: 0.003010tensor(0.1616, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:2 loss: 0.000717tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:4 loss: 0.005597tensor(0.4221, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:5 loss: 0.003426tensor(0.4105, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:7 loss: 0.004217tensor(0.3750, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:8 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:9 loss: 0.000144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:11 loss: 0.006324tensor(0.3493, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:12 loss: 0.004538tensor(0.4591, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:13 loss: 0.000381tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:15 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:17 loss: 0.000292tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:18 loss: 0.001859tensor(0.4042, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:19 loss: 0.008829tensor(0.4105, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:20 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:22 loss: 0.008593tensor(0.4364, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:23 loss: 0.000306tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:24 loss: 0.003831tensor(0.4384, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:25 loss: 0.000897tensor(0.1999, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:26 loss: 0.005235tensor(0.4225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:27 loss: 0.013182tensor(0.4534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:28 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:30 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:31 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:32 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:34 loss: 0.005241tensor(0.2877, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:35 loss: 0.006617tensor(0.2430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:36 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:37 loss: 0.000929tensor(0.2458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:38 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:39 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:40 loss: 0.022073tensor(0.4305, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:42 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:43 loss: 0.005833tensor(0.4383, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:44 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:45 loss: 0.002791tensor(0.2905, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:46 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:47 loss: 0.005403tensor(0.4380, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:48 loss: 0.002311tensor(0.2718, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:50 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:51 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:53 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:54 loss: 0.009751tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:55 loss: 0.008938tensor(0.4360, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:56 loss: 0.005372tensor(0.4405, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:57 loss: 0.001568tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:58 loss: 0.010491tensor(0.1811, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:59 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:60 loss: 0.008277tensor(0.4605, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:61 loss: 0.005763tensor(0.3490, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:62 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:63 loss: 0.001028tensor(0.0192, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:64 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:65 loss: 0.004166tensor(0.4193, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:66 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:67 loss: 0.003961tensor(0.4063, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:70 loss: 0.001115tensor(0.3602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:71 loss: 0.004201tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:72 loss: 0.002215tensor(0.4240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:73 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:74 loss: 0.006092tensor(0.4048, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:75 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:77 loss: 0.001413tensor(0.1933, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:78 loss: 0.007853tensor(0.4408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:60 step:79 loss: 0.002638tensor(0.3858, grad_fn=<DivBackward0>)\n",
      "Epoch:61 step:0 loss: 0.003538\n",
      "Epoch:61 step:1 loss: 0.002341\n",
      "Epoch:61 step:2 loss: 0.000046\n",
      "Epoch:61 step:3 loss: 0.000000\n",
      "Epoch:61 step:4 loss: 0.006685\n",
      "Epoch:61 step:5 loss: 0.005314\n",
      "Epoch:61 step:6 loss: 0.000000\n",
      "Epoch:61 step:7 loss: 0.005105\n",
      "Epoch:61 step:8 loss: 0.000006\n",
      "Epoch:61 step:9 loss: 0.000044\n",
      "Epoch:61 step:10 loss: 0.000001\n",
      "Epoch:61 step:11 loss: 0.003019\n",
      "Epoch:61 step:12 loss: 0.004030\n",
      "Epoch:61 step:13 loss: 0.000235\n",
      "Epoch:61 step:14 loss: 0.000001\n",
      "Epoch:61 step:15 loss: 0.000146\n",
      "Epoch:61 step:16 loss: 0.000001\n",
      "Epoch:61 step:17 loss: 0.000081\n",
      "Epoch:61 step:18 loss: 0.002723\n",
      "Epoch:61 step:19 loss: 0.008807\n",
      "Epoch:61 step:20 loss: 0.000007\n",
      "Epoch:61 step:21 loss: 0.000000\n",
      "Epoch:61 step:22 loss: 0.008303\n",
      "Epoch:61 step:23 loss: 0.000329\n",
      "Epoch:61 step:24 loss: 0.003600\n",
      "Epoch:61 step:25 loss: 0.000623\n",
      "Epoch:61 step:26 loss: 0.004251\n",
      "Epoch:61 step:27 loss: 0.010099\n",
      "Epoch:61 step:28 loss: 0.000000\n",
      "Epoch:61 step:29 loss: 0.000000\n",
      "Epoch:61 step:30 loss: 0.000008\n",
      "Epoch:61 step:31 loss: 0.000013\n",
      "Epoch:61 step:32 loss: 0.000055\n",
      "Epoch:61 step:33 loss: 0.000000\n",
      "Epoch:61 step:34 loss: 0.006146\n",
      "Epoch:61 step:35 loss: 0.003178\n",
      "Epoch:61 step:36 loss: 0.000007\n",
      "Epoch:61 step:37 loss: 0.001179\n",
      "Epoch:61 step:38 loss: 0.000001\n",
      "Epoch:61 step:39 loss: 0.000443\n",
      "Epoch:61 step:40 loss: 0.011304\n",
      "Epoch:61 step:41 loss: 0.000023\n",
      "Epoch:61 step:42 loss: 0.000004\n",
      "Epoch:61 step:43 loss: 0.008423\n",
      "Epoch:61 step:44 loss: 0.000020\n",
      "Epoch:61 step:45 loss: 0.001223\n",
      "Epoch:61 step:46 loss: 0.000032\n",
      "Epoch:61 step:47 loss: 0.005845\n",
      "Epoch:61 step:48 loss: 0.002740\n",
      "Epoch:61 step:49 loss: 0.000001\n",
      "Epoch:61 step:50 loss: 0.000859\n",
      "Epoch:61 step:51 loss: 0.002797\n",
      "Epoch:61 step:52 loss: 0.000001\n",
      "Epoch:61 step:53 loss: 0.000560\n",
      "Epoch:61 step:54 loss: 0.012004\n",
      "Epoch:61 step:55 loss: 0.008704\n",
      "Epoch:61 step:56 loss: 0.005899\n",
      "Epoch:61 step:57 loss: 0.013836\n",
      "Epoch:61 step:58 loss: 0.011147\n",
      "Epoch:61 step:59 loss: 0.000297\n",
      "Epoch:61 step:60 loss: 0.009555\n",
      "Epoch:61 step:61 loss: 0.008819\n",
      "Epoch:61 step:62 loss: 0.000001\n",
      "Epoch:61 step:63 loss: 0.001427\n",
      "Epoch:61 step:64 loss: 0.000041\n",
      "Epoch:61 step:65 loss: 0.016512\n",
      "Epoch:61 step:66 loss: 0.000004\n",
      "Epoch:61 step:67 loss: 0.011173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:61 step:68 loss: 0.000000\n",
      "Epoch:61 step:69 loss: 0.000001\n",
      "Epoch:61 step:70 loss: 0.002069\n",
      "Epoch:61 step:71 loss: 0.006509\n",
      "Epoch:61 step:72 loss: 0.010927\n",
      "Epoch:61 step:73 loss: 0.000001\n",
      "Epoch:61 step:74 loss: 0.004586\n",
      "Epoch:61 step:75 loss: 0.000137\n",
      "Epoch:61 step:76 loss: 0.000027\n",
      "Epoch:61 step:77 loss: 0.004065\n",
      "Epoch:61 step:78 loss: 0.034452\n",
      "Epoch:61 step:79 loss: 0.015620\n",
      "Test Epoch:61 step:0 loss: 0.003834tensor(0.3237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:1 loss: 0.007534tensor(0.0082, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:2 loss: 0.000887tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:4 loss: 0.008796tensor(0.3881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:5 loss: 0.004856tensor(0.3879, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:7 loss: 0.011266tensor(0.2939, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:8 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:9 loss: 0.001042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:10 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:11 loss: 0.004855tensor(0.3348, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:12 loss: 0.007252tensor(0.4290, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:13 loss: 0.001989tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:14 loss: 0.000066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:15 loss: 0.002652tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:16 loss: 0.000065tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:17 loss: 0.001448tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:18 loss: 0.004817tensor(0.2972, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:19 loss: 0.017091tensor(0.3353, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:20 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:21 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:22 loss: 0.016756tensor(0.3843, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:23 loss: 0.000444tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:24 loss: 0.006676tensor(0.3935, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:25 loss: 0.000835tensor(0.1763, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:26 loss: 0.009285tensor(0.3684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:27 loss: 0.019671tensor(0.4272, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:28 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:30 loss: 0.000633tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:31 loss: 0.000143tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:32 loss: 0.000273tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:34 loss: 0.010027tensor(0.1475, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:35 loss: 0.006902tensor(0.2006, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:36 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:37 loss: 0.001369tensor(0.1436, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:38 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:39 loss: 0.001712tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:40 loss: 0.023998tensor(0.4132, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:41 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:42 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:43 loss: 0.006959tensor(0.4240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:44 loss: 0.000156tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:45 loss: 0.003326tensor(0.2351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:46 loss: 0.000154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:47 loss: 0.006848tensor(0.4150, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:48 loss: 0.003228tensor(0.1680, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:50 loss: 0.000509tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:51 loss: 0.000181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:53 loss: 0.000362tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:54 loss: 0.011989tensor(0.4142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:55 loss: 0.022758tensor(0.3818, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:56 loss: 0.006269tensor(0.4293, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:57 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:58 loss: 0.026229tensor(0.0230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:59 loss: 0.000178tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:60 loss: 0.041873tensor(0.3832, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:61 loss: 0.005489tensor(0.3084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:63 loss: 0.001142tensor(0.0325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:64 loss: 0.000418tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:65 loss: 0.018190tensor(0.2141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:66 loss: 0.000763tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:67 loss: 0.062666tensor(0.1613, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:68 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:70 loss: 0.029075tensor(0.0460, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:71 loss: 0.033020tensor(0.1954, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:72 loss: 0.007884tensor(0.2688, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:73 loss: 0.000304tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:74 loss: 0.031307tensor(0.0939, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:75 loss: 0.000342tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:76 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:77 loss: 0.002703tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:78 loss: 0.086200tensor(0.0447, grad_fn=<DivBackward0>)\n",
      "Test Epoch:61 step:79 loss: 0.041837tensor(0.0268, grad_fn=<DivBackward0>)\n",
      "Epoch:62 step:0 loss: 0.019776\n",
      "Epoch:62 step:1 loss: 0.006920\n",
      "Epoch:62 step:2 loss: 0.002281\n",
      "Epoch:62 step:3 loss: 0.000789\n",
      "Epoch:62 step:4 loss: 0.042979\n",
      "Epoch:62 step:5 loss: 0.018242\n",
      "Epoch:62 step:6 loss: 0.001980\n",
      "Epoch:62 step:7 loss: 0.014394\n",
      "Epoch:62 step:8 loss: 0.004726\n",
      "Epoch:62 step:9 loss: 0.006795\n",
      "Epoch:62 step:10 loss: 0.002417\n",
      "Epoch:62 step:11 loss: 0.015536\n",
      "Epoch:62 step:12 loss: 0.025664\n",
      "Epoch:62 step:13 loss: 0.002335\n",
      "Epoch:62 step:14 loss: 0.004882\n",
      "Epoch:62 step:15 loss: 0.000107\n",
      "Epoch:62 step:16 loss: 0.000940\n",
      "Epoch:62 step:17 loss: 0.000792\n",
      "Epoch:62 step:18 loss: 0.035980\n",
      "Epoch:62 step:19 loss: 0.040915\n",
      "Epoch:62 step:20 loss: 0.000003\n",
      "Epoch:62 step:21 loss: 0.000006\n",
      "Epoch:62 step:22 loss: 0.184822\n",
      "Epoch:62 step:23 loss: 0.046159\n",
      "Epoch:62 step:24 loss: 0.030940\n",
      "Epoch:62 step:25 loss: 0.013908\n",
      "Epoch:62 step:26 loss: 0.024150\n",
      "Epoch:62 step:27 loss: 0.075444\n",
      "Epoch:62 step:28 loss: 0.009801\n",
      "Epoch:62 step:29 loss: 0.004898\n",
      "Epoch:62 step:30 loss: 0.006182\n",
      "Epoch:62 step:31 loss: 0.006733\n",
      "Epoch:62 step:32 loss: 0.029116\n",
      "Epoch:62 step:33 loss: 0.003173\n",
      "Epoch:62 step:34 loss: 0.029741\n",
      "Epoch:62 step:35 loss: 0.015662\n",
      "Epoch:62 step:36 loss: 0.000196\n",
      "Epoch:62 step:37 loss: 0.003208\n",
      "Epoch:62 step:38 loss: 0.000188\n",
      "Epoch:62 step:39 loss: 0.000229\n",
      "Epoch:62 step:40 loss: 0.300114\n",
      "Epoch:62 step:41 loss: 0.000360\n",
      "Epoch:62 step:42 loss: 0.000764\n",
      "Epoch:62 step:43 loss: 0.077333\n",
      "Epoch:62 step:44 loss: 0.003160\n",
      "Epoch:62 step:45 loss: 0.007797\n",
      "Epoch:62 step:46 loss: 0.010224\n",
      "Epoch:62 step:47 loss: 0.054774\n",
      "Epoch:62 step:48 loss: 0.022191\n",
      "Epoch:62 step:49 loss: 0.045663\n",
      "Epoch:62 step:50 loss: 0.006095\n",
      "Epoch:62 step:51 loss: 0.001768\n",
      "Epoch:62 step:52 loss: 0.000495\n",
      "Epoch:62 step:53 loss: 0.000779\n",
      "Epoch:62 step:54 loss: 0.165829\n",
      "Epoch:62 step:55 loss: 0.114253\n",
      "Epoch:62 step:56 loss: 0.054443\n",
      "Epoch:62 step:57 loss: 0.001245\n",
      "Epoch:62 step:58 loss: 0.018368\n",
      "Epoch:62 step:59 loss: 0.008747\n",
      "Epoch:62 step:60 loss: 0.058733\n",
      "Epoch:62 step:61 loss: 0.016935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:62 step:62 loss: 0.036968\n",
      "Epoch:62 step:63 loss: 0.019921\n",
      "Epoch:62 step:64 loss: 0.006656\n",
      "Epoch:62 step:65 loss: 0.015484\n",
      "Epoch:62 step:66 loss: 0.000781\n",
      "Epoch:62 step:67 loss: 0.024405\n",
      "Epoch:62 step:68 loss: 0.011863\n",
      "Epoch:62 step:69 loss: 0.001703\n",
      "Epoch:62 step:70 loss: 0.007208\n",
      "Epoch:62 step:71 loss: 0.044875\n",
      "Epoch:62 step:72 loss: 0.014644\n",
      "Epoch:62 step:73 loss: 0.000605\n",
      "Epoch:62 step:74 loss: 0.041137\n",
      "Epoch:62 step:75 loss: 0.002139\n",
      "Epoch:62 step:76 loss: 0.000735\n",
      "Epoch:62 step:77 loss: 0.002792\n",
      "Epoch:62 step:78 loss: 0.043184\n",
      "Epoch:62 step:79 loss: 0.010707\n",
      "Test Epoch:62 step:0 loss: 0.029884tensor(0.0189, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:1 loss: 0.006623tensor(0.0267, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:2 loss: 0.004036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:3 loss: 0.001633tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:4 loss: 0.029915tensor(0.1199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:5 loss: 0.013928tensor(0.1584, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:6 loss: 0.002689tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:7 loss: 0.013161tensor(0.1381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:8 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:9 loss: 0.000709tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:10 loss: 0.000221tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:11 loss: 0.016335tensor(0.0755, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:12 loss: 0.026338tensor(0.2548, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:13 loss: 0.001740tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:14 loss: 0.009174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:15 loss: 0.002803tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:16 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:17 loss: 0.008567tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:18 loss: 0.010381tensor(0.0790, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:19 loss: 0.045290tensor(0.1317, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:22 loss: 0.126331tensor(0.0356, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:23 loss: 0.000972tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:24 loss: 0.017320tensor(0.2246, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:25 loss: 0.007078tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:26 loss: 0.019493tensor(0.1947, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:27 loss: 0.055652tensor(0.2518, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:28 loss: 0.001624tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:29 loss: 0.002846tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:30 loss: 0.005449tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:31 loss: 0.016906tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:32 loss: 0.020374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:33 loss: 0.002111tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:34 loss: 0.031409tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:35 loss: 0.016420tensor(0.0320, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:36 loss: 0.000602tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:37 loss: 0.002207tensor(0.0157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:38 loss: 0.000560tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:39 loss: 0.003983tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:40 loss: 0.092208tensor(0.2228, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:41 loss: 0.001572tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:42 loss: 0.000260tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:43 loss: 0.049861tensor(0.1476, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:44 loss: 0.028402tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:45 loss: 0.004977tensor(0.0434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:46 loss: 0.001709tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:47 loss: 0.026330tensor(0.2033, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:48 loss: 0.005017tensor(0.0355, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:49 loss: 0.005207tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:50 loss: 0.006777tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:51 loss: 0.002726tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:52 loss: 0.001392tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:53 loss: 0.005374tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:54 loss: 0.051523tensor(0.1181, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:55 loss: 0.058073tensor(0.1034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:56 loss: 0.025118tensor(0.1989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:57 loss: 0.000435tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:58 loss: 0.035393tensor(0.0319, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:59 loss: 0.000768tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:60 loss: 0.040477tensor(0.2888, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:61 loss: 0.028037tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:62 loss: 0.000753tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:63 loss: 0.003411tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:64 loss: 0.001121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:65 loss: 0.021256tensor(0.1268, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:66 loss: 0.000528tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:67 loss: 0.018577tensor(0.1431, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:68 loss: 0.000694tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:69 loss: 0.002704tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:70 loss: 0.005250tensor(0.0281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:71 loss: 0.014561tensor(0.2768, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:72 loss: 0.004988tensor(0.2942, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:73 loss: 0.000735tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:74 loss: 0.010863tensor(0.2634, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:75 loss: 0.001335tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:76 loss: 0.004355tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:77 loss: 0.001602tensor(0.0203, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:78 loss: 0.024456tensor(0.3079, grad_fn=<DivBackward0>)\n",
      "Test Epoch:62 step:79 loss: 0.010697tensor(0.1094, grad_fn=<DivBackward0>)\n",
      "Epoch:63 step:0 loss: 0.009901\n",
      "Epoch:63 step:1 loss: 0.010036\n",
      "Epoch:63 step:2 loss: 0.007229\n",
      "Epoch:63 step:3 loss: 0.000100\n",
      "Epoch:63 step:4 loss: 0.019219\n",
      "Epoch:63 step:5 loss: 0.012901\n",
      "Epoch:63 step:6 loss: 0.000083\n",
      "Epoch:63 step:7 loss: 0.016529\n",
      "Epoch:63 step:8 loss: 0.001055\n",
      "Epoch:63 step:9 loss: 0.000276\n",
      "Epoch:63 step:10 loss: 0.000309\n",
      "Epoch:63 step:11 loss: 0.009395\n",
      "Epoch:63 step:12 loss: 0.017194\n",
      "Epoch:63 step:13 loss: 0.000847\n",
      "Epoch:63 step:14 loss: 0.001169\n",
      "Epoch:63 step:15 loss: 0.000215\n",
      "Epoch:63 step:16 loss: 0.000151\n",
      "Epoch:63 step:17 loss: 0.002472\n",
      "Epoch:63 step:18 loss: 0.010833\n",
      "Epoch:63 step:19 loss: 0.025786\n",
      "Epoch:63 step:20 loss: 0.000193\n",
      "Epoch:63 step:21 loss: 0.000199\n",
      "Epoch:63 step:22 loss: 0.046114\n",
      "Epoch:63 step:23 loss: 0.005975\n",
      "Epoch:63 step:24 loss: 0.011299\n",
      "Epoch:63 step:25 loss: 0.007955\n",
      "Epoch:63 step:26 loss: 0.020549\n",
      "Epoch:63 step:27 loss: 0.030733\n",
      "Epoch:63 step:28 loss: 0.000329\n",
      "Epoch:63 step:29 loss: 0.000470\n",
      "Epoch:63 step:30 loss: 0.001288\n",
      "Epoch:63 step:31 loss: 0.003096\n",
      "Epoch:63 step:32 loss: 0.000859\n",
      "Epoch:63 step:33 loss: 0.000219\n",
      "Epoch:63 step:34 loss: 0.019929\n",
      "Epoch:63 step:35 loss: 0.005615\n",
      "Epoch:63 step:36 loss: 0.001730\n",
      "Epoch:63 step:37 loss: 0.001628\n",
      "Epoch:63 step:38 loss: 0.000035\n",
      "Epoch:63 step:39 loss: 0.001649\n",
      "Epoch:63 step:40 loss: 0.041233\n",
      "Epoch:63 step:41 loss: 0.000082\n",
      "Epoch:63 step:42 loss: 0.000090\n",
      "Epoch:63 step:43 loss: 0.030449\n",
      "Epoch:63 step:44 loss: 0.000634\n",
      "Epoch:63 step:45 loss: 0.002367\n",
      "Epoch:63 step:46 loss: 0.000407\n",
      "Epoch:63 step:47 loss: 0.014224\n",
      "Epoch:63 step:48 loss: 0.003538\n",
      "Epoch:63 step:49 loss: 0.000950\n",
      "Epoch:63 step:50 loss: 0.003460\n",
      "Epoch:63 step:51 loss: 0.002462\n",
      "Epoch:63 step:52 loss: 0.000999\n",
      "Epoch:63 step:53 loss: 0.026629\n",
      "Epoch:63 step:54 loss: 0.039527\n",
      "Epoch:63 step:55 loss: 0.026705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:63 step:56 loss: 0.012896\n",
      "Epoch:63 step:57 loss: 0.000382\n",
      "Epoch:63 step:58 loss: 0.035198\n",
      "Epoch:63 step:59 loss: 0.000154\n",
      "Epoch:63 step:60 loss: 0.032822\n",
      "Epoch:63 step:61 loss: 0.022539\n",
      "Epoch:63 step:62 loss: 0.000059\n",
      "Epoch:63 step:63 loss: 0.001415\n",
      "Epoch:63 step:64 loss: 0.000120\n",
      "Epoch:63 step:65 loss: 0.042387\n",
      "Epoch:63 step:66 loss: 0.000302\n",
      "Epoch:63 step:67 loss: 0.012704\n",
      "Epoch:63 step:68 loss: 0.000612\n",
      "Epoch:63 step:69 loss: 0.000407\n",
      "Epoch:63 step:70 loss: 0.002871\n",
      "Epoch:63 step:71 loss: 0.010729\n",
      "Epoch:63 step:72 loss: 0.004159\n",
      "Epoch:63 step:73 loss: 0.003586\n",
      "Epoch:63 step:74 loss: 0.009602\n",
      "Epoch:63 step:75 loss: 0.002253\n",
      "Epoch:63 step:76 loss: 0.001548\n",
      "Epoch:63 step:77 loss: 0.002097\n",
      "Epoch:63 step:78 loss: 0.015875\n",
      "Epoch:63 step:79 loss: 0.012386\n",
      "Test Epoch:63 step:0 loss: 0.007801tensor(0.1696, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:1 loss: 0.004774tensor(0.0976, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:2 loss: 0.004271tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:3 loss: 0.000114tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:4 loss: 0.013766tensor(0.3137, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:5 loss: 0.015764tensor(0.1554, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:6 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:7 loss: 0.021139tensor(0.0855, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:8 loss: 0.000559tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:9 loss: 0.000383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:10 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:11 loss: 0.008337tensor(0.2211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:12 loss: 0.011058tensor(0.3875, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:13 loss: 0.001118tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:14 loss: 0.002854tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:15 loss: 0.000659tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:16 loss: 0.000789tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:17 loss: 0.001314tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:18 loss: 0.008486tensor(0.1072, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:19 loss: 0.019208tensor(0.2964, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:20 loss: 0.000440tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:21 loss: 0.000512tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:22 loss: 0.029707tensor(0.3040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:23 loss: 0.008319tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:24 loss: 0.010168tensor(0.3299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:25 loss: 0.002352tensor(0.0159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:26 loss: 0.012398tensor(0.3134, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:27 loss: 0.025888tensor(0.4074, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:28 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:29 loss: 0.000125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:30 loss: 0.000193tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:31 loss: 0.001807tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:32 loss: 0.000253tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:33 loss: 0.000121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:34 loss: 0.021804tensor(0.0148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:35 loss: 0.010188tensor(0.0458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:36 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:37 loss: 0.001599tensor(0.0432, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:38 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:39 loss: 0.000479tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:40 loss: 0.055754tensor(0.3412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:41 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:42 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:43 loss: 0.025227tensor(0.2992, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:44 loss: 0.000554tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:45 loss: 0.002212tensor(0.2039, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:46 loss: 0.001082tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:47 loss: 0.009727tensor(0.3690, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:48 loss: 0.008365tensor(0.1411, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:49 loss: 0.001000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:50 loss: 0.003783tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:51 loss: 0.004687tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:52 loss: 0.000961tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:53 loss: 0.001189tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:54 loss: 0.030272tensor(0.3206, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:55 loss: 0.028072tensor(0.3185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:56 loss: 0.010730tensor(0.3720, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:57 loss: 0.000610tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:58 loss: 0.020162tensor(0.0329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:59 loss: 0.000232tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:60 loss: 0.022074tensor(0.3983, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:61 loss: 0.018304tensor(0.0331, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:62 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:63 loss: 0.001264tensor(0.0059, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:64 loss: 0.000223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:65 loss: 0.009197tensor(0.2954, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:66 loss: 0.000194tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:67 loss: 0.015468tensor(0.2165, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:68 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:69 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:70 loss: 0.003368tensor(0.0851, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:71 loss: 0.024311tensor(0.1826, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:72 loss: 0.003936tensor(0.3375, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:73 loss: 0.000629tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:74 loss: 0.008100tensor(0.3205, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:75 loss: 0.000318tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:76 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:77 loss: 0.003268tensor(0.0361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:78 loss: 0.013677tensor(0.3846, grad_fn=<DivBackward0>)\n",
      "Test Epoch:63 step:79 loss: 0.007138tensor(0.2098, grad_fn=<DivBackward0>)\n",
      "Epoch:64 step:0 loss: 0.006068\n",
      "Epoch:64 step:1 loss: 0.003277\n",
      "Epoch:64 step:2 loss: 0.004406\n",
      "Epoch:64 step:3 loss: 0.000013\n",
      "Epoch:64 step:4 loss: 0.011398\n",
      "Epoch:64 step:5 loss: 0.008599\n",
      "Epoch:64 step:6 loss: 0.000007\n",
      "Epoch:64 step:7 loss: 0.011309\n",
      "Epoch:64 step:8 loss: 0.000116\n",
      "Epoch:64 step:9 loss: 0.000992\n",
      "Epoch:64 step:10 loss: 0.000065\n",
      "Epoch:64 step:11 loss: 0.007067\n",
      "Epoch:64 step:12 loss: 0.008712\n",
      "Epoch:64 step:13 loss: 0.000501\n",
      "Epoch:64 step:14 loss: 0.000702\n",
      "Epoch:64 step:15 loss: 0.000276\n",
      "Epoch:64 step:16 loss: 0.000048\n",
      "Epoch:64 step:17 loss: 0.000158\n",
      "Epoch:64 step:18 loss: 0.007097\n",
      "Epoch:64 step:19 loss: 0.017389\n",
      "Epoch:64 step:20 loss: 0.000066\n",
      "Epoch:64 step:21 loss: 0.000104\n",
      "Epoch:64 step:22 loss: 0.021884\n",
      "Epoch:64 step:23 loss: 0.003660\n",
      "Epoch:64 step:24 loss: 0.006657\n",
      "Epoch:64 step:25 loss: 0.002572\n",
      "Epoch:64 step:26 loss: 0.014064\n",
      "Epoch:64 step:27 loss: 0.022913\n",
      "Epoch:64 step:28 loss: 0.000027\n",
      "Epoch:64 step:29 loss: 0.000005\n",
      "Epoch:64 step:30 loss: 0.001002\n",
      "Epoch:64 step:31 loss: 0.000172\n",
      "Epoch:64 step:32 loss: 0.000155\n",
      "Epoch:64 step:33 loss: 0.000007\n",
      "Epoch:64 step:34 loss: 0.016695\n",
      "Epoch:64 step:35 loss: 0.004630\n",
      "Epoch:64 step:36 loss: 0.000124\n",
      "Epoch:64 step:37 loss: 0.001307\n",
      "Epoch:64 step:38 loss: 0.000161\n",
      "Epoch:64 step:39 loss: 0.000561\n",
      "Epoch:64 step:40 loss: 0.028380\n",
      "Epoch:64 step:41 loss: 0.000027\n",
      "Epoch:64 step:42 loss: 0.000107\n",
      "Epoch:64 step:43 loss: 0.017021\n",
      "Epoch:64 step:44 loss: 0.000094\n",
      "Epoch:64 step:45 loss: 0.002620\n",
      "Epoch:64 step:46 loss: 0.000166\n",
      "Epoch:64 step:47 loss: 0.008446\n",
      "Epoch:64 step:48 loss: 0.002877\n",
      "Epoch:64 step:49 loss: 0.000605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:64 step:50 loss: 0.000736\n",
      "Epoch:64 step:51 loss: 0.001043\n",
      "Epoch:64 step:52 loss: 0.000628\n",
      "Epoch:64 step:53 loss: 0.000441\n",
      "Epoch:64 step:54 loss: 0.016277\n",
      "Epoch:64 step:55 loss: 0.016800\n",
      "Epoch:64 step:56 loss: 0.008437\n",
      "Epoch:64 step:57 loss: 0.002438\n",
      "Epoch:64 step:58 loss: 0.011711\n",
      "Epoch:64 step:59 loss: 0.001192\n",
      "Epoch:64 step:60 loss: 0.023350\n",
      "Epoch:64 step:61 loss: 0.006541\n",
      "Epoch:64 step:62 loss: 0.000062\n",
      "Epoch:64 step:63 loss: 0.001438\n",
      "Epoch:64 step:64 loss: 0.002045\n",
      "Epoch:64 step:65 loss: 0.004432\n",
      "Epoch:64 step:66 loss: 0.000374\n",
      "Epoch:64 step:67 loss: 0.010383\n",
      "Epoch:64 step:68 loss: 0.000001\n",
      "Epoch:64 step:69 loss: 0.000004\n",
      "Epoch:64 step:70 loss: 0.003499\n",
      "Epoch:64 step:71 loss: 0.010377\n",
      "Epoch:64 step:72 loss: 0.002492\n",
      "Epoch:64 step:73 loss: 0.000120\n",
      "Epoch:64 step:74 loss: 0.011097\n",
      "Epoch:64 step:75 loss: 0.000041\n",
      "Epoch:64 step:76 loss: 0.000011\n",
      "Epoch:64 step:77 loss: 0.002501\n",
      "Epoch:64 step:78 loss: 0.015654\n",
      "Epoch:64 step:79 loss: 0.005809\n",
      "Test Epoch:64 step:0 loss: 0.006116tensor(0.2030, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:1 loss: 0.003026tensor(0.1419, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:2 loss: 0.002208tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:3 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:4 loss: 0.009870tensor(0.3597, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:5 loss: 0.004903tensor(0.3650, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:6 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:7 loss: 0.007288tensor(0.2915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:8 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:9 loss: 0.001297tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:10 loss: 0.000218tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:11 loss: 0.014143tensor(0.2472, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:12 loss: 0.006572tensor(0.4397, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:13 loss: 0.000462tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:14 loss: 0.000642tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:15 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:16 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:17 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:18 loss: 0.008060tensor(0.1589, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:19 loss: 0.016371tensor(0.3427, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:20 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:21 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:22 loss: 0.029414tensor(0.3185, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:23 loss: 0.000855tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:24 loss: 0.006180tensor(0.4054, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:25 loss: 0.004293tensor(0.0035, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:26 loss: 0.012398tensor(0.3462, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:27 loss: 0.020026tensor(0.4212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:28 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:29 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:30 loss: 0.000859tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:31 loss: 0.000242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:32 loss: 0.000162tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:33 loss: 0.000509tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:34 loss: 0.009876tensor(0.1349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:35 loss: 0.003616tensor(0.2956, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:36 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:37 loss: 0.001419tensor(0.1082, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:38 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:39 loss: 0.000711tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:40 loss: 0.024180tensor(0.4027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:41 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:42 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:43 loss: 0.013476tensor(0.3916, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:44 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:45 loss: 0.002395tensor(0.2569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:46 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:47 loss: 0.007959tensor(0.3945, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:48 loss: 0.003215tensor(0.1599, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:49 loss: 0.000414tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:50 loss: 0.000157tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:51 loss: 0.000136tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:52 loss: 0.000401tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:53 loss: 0.000098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:54 loss: 0.015191tensor(0.3921, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:55 loss: 0.017830tensor(0.3648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:56 loss: 0.006732tensor(0.4151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:57 loss: 0.002306tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:58 loss: 0.008610tensor(0.1809, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:59 loss: 0.001181tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:60 loss: 0.017593tensor(0.4202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:61 loss: 0.006003tensor(0.2888, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:62 loss: 0.000467tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:63 loss: 0.004717tensor(0.0077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:64 loss: 0.004771tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:65 loss: 0.004229tensor(0.4022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:66 loss: 0.000228tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:67 loss: 0.007054tensor(0.3369, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:69 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:70 loss: 0.003002tensor(0.2202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:71 loss: 0.006190tensor(0.4046, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:72 loss: 0.003022tensor(0.3799, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:73 loss: 0.000249tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:74 loss: 0.011223tensor(0.2869, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:75 loss: 0.000093tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:76 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:77 loss: 0.002527tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:78 loss: 0.014148tensor(0.3957, grad_fn=<DivBackward0>)\n",
      "Test Epoch:64 step:79 loss: 0.005375tensor(0.2972, grad_fn=<DivBackward0>)\n",
      "Epoch:65 step:0 loss: 0.005177\n",
      "Epoch:65 step:1 loss: 0.002442\n",
      "Epoch:65 step:2 loss: 0.000614\n",
      "Epoch:65 step:3 loss: 0.000004\n",
      "Epoch:65 step:4 loss: 0.010641\n",
      "Epoch:65 step:5 loss: 0.004998\n",
      "Epoch:65 step:6 loss: 0.000009\n",
      "Epoch:65 step:7 loss: 0.006881\n",
      "Epoch:65 step:8 loss: 0.000011\n",
      "Epoch:65 step:9 loss: 0.000936\n",
      "Epoch:65 step:10 loss: 0.000062\n",
      "Epoch:65 step:11 loss: 0.005902\n",
      "Epoch:65 step:12 loss: 0.006379\n",
      "Epoch:65 step:13 loss: 0.000712\n",
      "Epoch:65 step:14 loss: 0.000571\n",
      "Epoch:65 step:15 loss: 0.000136\n",
      "Epoch:65 step:16 loss: 0.000004\n",
      "Epoch:65 step:17 loss: 0.000297\n",
      "Epoch:65 step:18 loss: 0.009428\n",
      "Epoch:65 step:19 loss: 0.011142\n",
      "Epoch:65 step:20 loss: 0.000013\n",
      "Epoch:65 step:21 loss: 0.000003\n",
      "Epoch:65 step:22 loss: 0.017089\n",
      "Epoch:65 step:23 loss: 0.001446\n",
      "Epoch:65 step:24 loss: 0.005711\n",
      "Epoch:65 step:25 loss: 0.001369\n",
      "Epoch:65 step:26 loss: 0.009366\n",
      "Epoch:65 step:27 loss: 0.016209\n",
      "Epoch:65 step:28 loss: 0.000005\n",
      "Epoch:65 step:29 loss: 0.000001\n",
      "Epoch:65 step:30 loss: 0.000189\n",
      "Epoch:65 step:31 loss: 0.000433\n",
      "Epoch:65 step:32 loss: 0.000140\n",
      "Epoch:65 step:33 loss: 0.000002\n",
      "Epoch:65 step:34 loss: 0.006529\n",
      "Epoch:65 step:35 loss: 0.003608\n",
      "Epoch:65 step:36 loss: 0.000031\n",
      "Epoch:65 step:37 loss: 0.001231\n",
      "Epoch:65 step:38 loss: 0.000044\n",
      "Epoch:65 step:39 loss: 0.000133\n",
      "Epoch:65 step:40 loss: 0.019047\n",
      "Epoch:65 step:41 loss: 0.000002\n",
      "Epoch:65 step:42 loss: 0.000010\n",
      "Epoch:65 step:43 loss: 0.011029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:65 step:44 loss: 0.000050\n",
      "Epoch:65 step:45 loss: 0.001984\n",
      "Epoch:65 step:46 loss: 0.000010\n",
      "Epoch:65 step:47 loss: 0.007046\n",
      "Epoch:65 step:48 loss: 0.002940\n",
      "Epoch:65 step:49 loss: 0.000157\n",
      "Epoch:65 step:50 loss: 0.000087\n",
      "Epoch:65 step:51 loss: 0.000094\n",
      "Epoch:65 step:52 loss: 0.000125\n",
      "Epoch:65 step:53 loss: 0.000171\n",
      "Epoch:65 step:54 loss: 0.011409\n",
      "Epoch:65 step:55 loss: 0.012230\n",
      "Epoch:65 step:56 loss: 0.006342\n",
      "Epoch:65 step:57 loss: 0.000834\n",
      "Epoch:65 step:58 loss: 0.006522\n",
      "Epoch:65 step:59 loss: 0.000942\n",
      "Epoch:65 step:60 loss: 0.013594\n",
      "Epoch:65 step:61 loss: 0.005540\n",
      "Epoch:65 step:62 loss: 0.000061\n",
      "Epoch:65 step:63 loss: 0.000733\n",
      "Epoch:65 step:64 loss: 0.001608\n",
      "Epoch:65 step:65 loss: 0.003803\n",
      "Epoch:65 step:66 loss: 0.000270\n",
      "Epoch:65 step:67 loss: 0.005821\n",
      "Epoch:65 step:68 loss: 0.000001\n",
      "Epoch:65 step:69 loss: 0.000002\n",
      "Epoch:65 step:70 loss: 0.002522\n",
      "Epoch:65 step:71 loss: 0.005716\n",
      "Epoch:65 step:72 loss: 0.001866\n",
      "Epoch:65 step:73 loss: 0.000159\n",
      "Epoch:65 step:74 loss: 0.004688\n",
      "Epoch:65 step:75 loss: 0.000064\n",
      "Epoch:65 step:76 loss: 0.000007\n",
      "Epoch:65 step:77 loss: 0.001460\n",
      "Epoch:65 step:78 loss: 0.010843\n",
      "Epoch:65 step:79 loss: 0.003902\n",
      "Test Epoch:65 step:0 loss: 0.004629tensor(0.2894, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:1 loss: 0.002353tensor(0.2068, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:2 loss: 0.000142tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:4 loss: 0.007880tensor(0.3896, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:5 loss: 0.008792tensor(0.3259, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:7 loss: 0.007189tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:8 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:9 loss: 0.000204tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:10 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:11 loss: 0.004597tensor(0.3534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:12 loss: 0.006428tensor(0.4394, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:13 loss: 0.000223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:14 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:15 loss: 0.000103tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:16 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:17 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:18 loss: 0.004761tensor(0.2979, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:19 loss: 0.011394tensor(0.3887, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:20 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:22 loss: 0.015019tensor(0.3908, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:23 loss: 0.003064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:24 loss: 0.005100tensor(0.4215, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:25 loss: 0.001131tensor(0.1783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:26 loss: 0.007198tensor(0.3857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:27 loss: 0.014393tensor(0.4404, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:28 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:30 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:31 loss: 0.000170tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:32 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:34 loss: 0.006486tensor(0.2371, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:35 loss: 0.006865tensor(0.2316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:36 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:37 loss: 0.001151tensor(0.1798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:38 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:39 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:40 loss: 0.016564tensor(0.4354, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:42 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:43 loss: 0.009691tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:44 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:45 loss: 0.001669tensor(0.2994, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:46 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:47 loss: 0.007166tensor(0.4116, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:48 loss: 0.002877tensor(0.1842, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:49 loss: 0.000152tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:50 loss: 0.000078tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:51 loss: 0.000529tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:52 loss: 0.000128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:53 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:54 loss: 0.011147tensor(0.4162, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:55 loss: 0.011178tensor(0.4119, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:56 loss: 0.005607tensor(0.4310, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:57 loss: 0.003514tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:58 loss: 0.004233tensor(0.2802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:59 loss: 0.001599tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:60 loss: 0.012852tensor(0.4401, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:61 loss: 0.005112tensor(0.3273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:62 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:63 loss: 0.001046tensor(0.0187, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:64 loss: 0.000549tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:65 loss: 0.003459tensor(0.4208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:66 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:67 loss: 0.006728tensor(0.3534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:70 loss: 0.002449tensor(0.2813, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:71 loss: 0.005594tensor(0.4052, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:72 loss: 0.001953tensor(0.4158, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:73 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:74 loss: 0.003629tensor(0.4160, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:75 loss: 0.000092tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:76 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:77 loss: 0.001543tensor(0.0214, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:78 loss: 0.009481tensor(0.4241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:65 step:79 loss: 0.003556tensor(0.3477, grad_fn=<DivBackward0>)\n",
      "Epoch:66 step:0 loss: 0.004521\n",
      "Epoch:66 step:1 loss: 0.002413\n",
      "Epoch:66 step:2 loss: 0.000081\n",
      "Epoch:66 step:3 loss: 0.000001\n",
      "Epoch:66 step:4 loss: 0.007128\n",
      "Epoch:66 step:5 loss: 0.006597\n",
      "Epoch:66 step:6 loss: 0.000001\n",
      "Epoch:66 step:7 loss: 0.006465\n",
      "Epoch:66 step:8 loss: 0.000005\n",
      "Epoch:66 step:9 loss: 0.000154\n",
      "Epoch:66 step:10 loss: 0.000025\n",
      "Epoch:66 step:11 loss: 0.004214\n",
      "Epoch:66 step:12 loss: 0.005670\n",
      "Epoch:66 step:13 loss: 0.000261\n",
      "Epoch:66 step:14 loss: 0.000014\n",
      "Epoch:66 step:15 loss: 0.000150\n",
      "Epoch:66 step:16 loss: 0.000001\n",
      "Epoch:66 step:17 loss: 0.000166\n",
      "Epoch:66 step:18 loss: 0.006224\n",
      "Epoch:66 step:19 loss: 0.010746\n",
      "Epoch:66 step:20 loss: 0.000016\n",
      "Epoch:66 step:21 loss: 0.000002\n",
      "Epoch:66 step:22 loss: 0.015103\n",
      "Epoch:66 step:23 loss: 0.002706\n",
      "Epoch:66 step:24 loss: 0.005098\n",
      "Epoch:66 step:25 loss: 0.000704\n",
      "Epoch:66 step:26 loss: 0.006496\n",
      "Epoch:66 step:27 loss: 0.013358\n",
      "Epoch:66 step:28 loss: 0.000013\n",
      "Epoch:66 step:29 loss: 0.000000\n",
      "Epoch:66 step:30 loss: 0.000293\n",
      "Epoch:66 step:31 loss: 0.000136\n",
      "Epoch:66 step:32 loss: 0.000014\n",
      "Epoch:66 step:33 loss: 0.000001\n",
      "Epoch:66 step:34 loss: 0.006955\n",
      "Epoch:66 step:35 loss: 0.007546\n",
      "Epoch:66 step:36 loss: 0.000026\n",
      "Epoch:66 step:37 loss: 0.000837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:66 step:38 loss: 0.000007\n",
      "Epoch:66 step:39 loss: 0.000092\n",
      "Epoch:66 step:40 loss: 0.017270\n",
      "Epoch:66 step:41 loss: 0.000000\n",
      "Epoch:66 step:42 loss: 0.000001\n",
      "Epoch:66 step:43 loss: 0.008463\n",
      "Epoch:66 step:44 loss: 0.000034\n",
      "Epoch:66 step:45 loss: 0.001828\n",
      "Epoch:66 step:46 loss: 0.000006\n",
      "Epoch:66 step:47 loss: 0.006431\n",
      "Epoch:66 step:48 loss: 0.002463\n",
      "Epoch:66 step:49 loss: 0.000246\n",
      "Epoch:66 step:50 loss: 0.000082\n",
      "Epoch:66 step:51 loss: 0.000029\n",
      "Epoch:66 step:52 loss: 0.000127\n",
      "Epoch:66 step:53 loss: 0.000104\n",
      "Epoch:66 step:54 loss: 0.010151\n",
      "Epoch:66 step:55 loss: 0.011185\n",
      "Epoch:66 step:56 loss: 0.005613\n",
      "Epoch:66 step:57 loss: 0.001202\n",
      "Epoch:66 step:58 loss: 0.005452\n",
      "Epoch:66 step:59 loss: 0.000868\n",
      "Epoch:66 step:60 loss: 0.012708\n",
      "Epoch:66 step:61 loss: 0.005736\n",
      "Epoch:66 step:62 loss: 0.000014\n",
      "Epoch:66 step:63 loss: 0.000952\n",
      "Epoch:66 step:64 loss: 0.000409\n",
      "Epoch:66 step:65 loss: 0.003918\n",
      "Epoch:66 step:66 loss: 0.000053\n",
      "Epoch:66 step:67 loss: 0.005094\n",
      "Epoch:66 step:68 loss: 0.000000\n",
      "Epoch:66 step:69 loss: 0.000000\n",
      "Epoch:66 step:70 loss: 0.002022\n",
      "Epoch:66 step:71 loss: 0.005314\n",
      "Epoch:66 step:72 loss: 0.001828\n",
      "Epoch:66 step:73 loss: 0.000444\n",
      "Epoch:66 step:74 loss: 0.003386\n",
      "Epoch:66 step:75 loss: 0.000139\n",
      "Epoch:66 step:76 loss: 0.000007\n",
      "Epoch:66 step:77 loss: 0.000716\n",
      "Epoch:66 step:78 loss: 0.008336\n",
      "Epoch:66 step:79 loss: 0.002310\n",
      "Test Epoch:66 step:0 loss: 0.004684tensor(0.2897, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:1 loss: 0.002174tensor(0.2229, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:2 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:4 loss: 0.006986tensor(0.4024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:5 loss: 0.005606tensor(0.3798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:7 loss: 0.005789tensor(0.3377, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:8 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:9 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:10 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:11 loss: 0.003269tensor(0.3819, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:12 loss: 0.005328tensor(0.4533, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:13 loss: 0.000178tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:14 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:15 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:17 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:18 loss: 0.003100tensor(0.3498, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:19 loss: 0.010537tensor(0.4008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:20 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:22 loss: 0.014374tensor(0.3989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:23 loss: 0.001488tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:24 loss: 0.004298tensor(0.4288, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:25 loss: 0.001724tensor(0.0302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:26 loss: 0.007676tensor(0.3903, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:27 loss: 0.012763tensor(0.4483, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:28 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:30 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:31 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:32 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:34 loss: 0.010280tensor(0.1443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:35 loss: 0.004195tensor(0.2983, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:36 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:37 loss: 0.000894tensor(0.2370, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:38 loss: 0.000616tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:39 loss: 0.000072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:40 loss: 0.015355tensor(0.4393, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:42 loss: 0.000349tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:43 loss: 0.008405tensor(0.4227, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:44 loss: 0.000065tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:45 loss: 0.002198tensor(0.2887, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:46 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:47 loss: 0.007386tensor(0.4141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:48 loss: 0.004236tensor(0.2294, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:49 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:50 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:51 loss: 0.001004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:52 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:53 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:54 loss: 0.009679tensor(0.4250, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:55 loss: 0.012039tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:56 loss: 0.005358tensor(0.4353, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:57 loss: 0.003441tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:58 loss: 0.004392tensor(0.2974, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:59 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:60 loss: 0.018374tensor(0.4298, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:61 loss: 0.005540tensor(0.3357, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:62 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:63 loss: 0.000578tensor(0.1092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:64 loss: 0.000640tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:65 loss: 0.003391tensor(0.4218, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:66 loss: 0.000287tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:67 loss: 0.004506tensor(0.3960, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:70 loss: 0.001480tensor(0.3400, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:71 loss: 0.004883tensor(0.4150, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:72 loss: 0.001621tensor(0.4340, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:73 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:74 loss: 0.003378tensor(0.4304, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:75 loss: 0.000186tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:76 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:77 loss: 0.000736tensor(0.1724, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:78 loss: 0.007218tensor(0.4429, grad_fn=<DivBackward0>)\n",
      "Test Epoch:66 step:79 loss: 0.002133tensor(0.3907, grad_fn=<DivBackward0>)\n",
      "Epoch:67 step:0 loss: 0.004741\n",
      "Epoch:67 step:1 loss: 0.002031\n",
      "Epoch:67 step:2 loss: 0.000032\n",
      "Epoch:67 step:3 loss: 0.000000\n",
      "Epoch:67 step:4 loss: 0.006370\n",
      "Epoch:67 step:5 loss: 0.006956\n",
      "Epoch:67 step:6 loss: 0.000000\n",
      "Epoch:67 step:7 loss: 0.006214\n",
      "Epoch:67 step:8 loss: 0.000005\n",
      "Epoch:67 step:9 loss: 0.000326\n",
      "Epoch:67 step:10 loss: 0.000120\n",
      "Epoch:67 step:11 loss: 0.003503\n",
      "Epoch:67 step:12 loss: 0.004815\n",
      "Epoch:67 step:13 loss: 0.000203\n",
      "Epoch:67 step:14 loss: 0.000053\n",
      "Epoch:67 step:15 loss: 0.000126\n",
      "Epoch:67 step:16 loss: 0.000002\n",
      "Epoch:67 step:17 loss: 0.000086\n",
      "Epoch:67 step:18 loss: 0.003130\n",
      "Epoch:67 step:19 loss: 0.009876\n",
      "Epoch:67 step:20 loss: 0.000014\n",
      "Epoch:67 step:21 loss: 0.000002\n",
      "Epoch:67 step:22 loss: 0.013663\n",
      "Epoch:67 step:23 loss: 0.001620\n",
      "Epoch:67 step:24 loss: 0.004118\n",
      "Epoch:67 step:25 loss: 0.000803\n",
      "Epoch:67 step:26 loss: 0.006953\n",
      "Epoch:67 step:27 loss: 0.013281\n",
      "Epoch:67 step:28 loss: 0.000001\n",
      "Epoch:67 step:29 loss: 0.000000\n",
      "Epoch:67 step:30 loss: 0.000026\n",
      "Epoch:67 step:31 loss: 0.000077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:67 step:32 loss: 0.000007\n",
      "Epoch:67 step:33 loss: 0.000002\n",
      "Epoch:67 step:34 loss: 0.005848\n",
      "Epoch:67 step:35 loss: 0.004878\n",
      "Epoch:67 step:36 loss: 0.000115\n",
      "Epoch:67 step:37 loss: 0.000930\n",
      "Epoch:67 step:38 loss: 0.000001\n",
      "Epoch:67 step:39 loss: 0.000120\n",
      "Epoch:67 step:40 loss: 0.012265\n",
      "Epoch:67 step:41 loss: 0.000000\n",
      "Epoch:67 step:42 loss: 0.000002\n",
      "Epoch:67 step:43 loss: 0.007739\n",
      "Epoch:67 step:44 loss: 0.000019\n",
      "Epoch:67 step:45 loss: 0.001274\n",
      "Epoch:67 step:46 loss: 0.000002\n",
      "Epoch:67 step:47 loss: 0.007090\n",
      "Epoch:67 step:48 loss: 0.003425\n",
      "Epoch:67 step:49 loss: 0.000008\n",
      "Epoch:67 step:50 loss: 0.000049\n",
      "Epoch:67 step:51 loss: 0.000032\n",
      "Epoch:67 step:52 loss: 0.000009\n",
      "Epoch:67 step:53 loss: 0.000067\n",
      "Epoch:67 step:54 loss: 0.011440\n",
      "Epoch:67 step:55 loss: 0.010068\n",
      "Epoch:67 step:56 loss: 0.005402\n",
      "Epoch:67 step:57 loss: 0.002059\n",
      "Epoch:67 step:58 loss: 0.007694\n",
      "Epoch:67 step:59 loss: 0.004786\n",
      "Epoch:67 step:60 loss: 0.012186\n",
      "Epoch:67 step:61 loss: 0.008970\n",
      "Epoch:67 step:62 loss: 0.000047\n",
      "Epoch:67 step:63 loss: 0.000586\n",
      "Epoch:67 step:64 loss: 0.000141\n",
      "Epoch:67 step:65 loss: 0.004034\n",
      "Epoch:67 step:66 loss: 0.000011\n",
      "Epoch:67 step:67 loss: 0.007080\n",
      "Epoch:67 step:68 loss: 0.000000\n",
      "Epoch:67 step:69 loss: 0.000000\n",
      "Epoch:67 step:70 loss: 0.002353\n",
      "Epoch:67 step:71 loss: 0.005003\n",
      "Epoch:67 step:72 loss: 0.001750\n",
      "Epoch:67 step:73 loss: 0.000002\n",
      "Epoch:67 step:74 loss: 0.003816\n",
      "Epoch:67 step:75 loss: 0.000039\n",
      "Epoch:67 step:76 loss: 0.000002\n",
      "Epoch:67 step:77 loss: 0.000687\n",
      "Epoch:67 step:78 loss: 0.006841\n",
      "Epoch:67 step:79 loss: 0.003305\n",
      "Test Epoch:67 step:0 loss: 0.004539tensor(0.2945, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:1 loss: 0.002021tensor(0.2400, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:2 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:4 loss: 0.006769tensor(0.4066, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:5 loss: 0.007182tensor(0.3602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:6 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:7 loss: 0.005993tensor(0.3406, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:8 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:9 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:11 loss: 0.003320tensor(0.3804, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:12 loss: 0.004720tensor(0.4569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:13 loss: 0.000883tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:14 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:15 loss: 0.000222tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:17 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:18 loss: 0.004450tensor(0.3199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:19 loss: 0.010321tensor(0.4033, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:20 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:22 loss: 0.011884tensor(0.4155, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:23 loss: 0.002485tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:24 loss: 0.003988tensor(0.4394, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:25 loss: 0.002310tensor(0.0442, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:26 loss: 0.006698tensor(0.4008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:27 loss: 0.013749tensor(0.4464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:30 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:31 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:32 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:34 loss: 0.009447tensor(0.2012, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:35 loss: 0.008377tensor(0.1990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:36 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:37 loss: 0.000931tensor(0.1639, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:38 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:39 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:40 loss: 0.018464tensor(0.4340, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:42 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:43 loss: 0.006920tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:44 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:45 loss: 0.003102tensor(0.2639, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:46 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:47 loss: 0.006003tensor(0.4244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:48 loss: 0.002895tensor(0.2178, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:49 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:50 loss: 0.000111tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:51 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:52 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:53 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:54 loss: 0.009676tensor(0.4289, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:55 loss: 0.010316tensor(0.4223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:56 loss: 0.005091tensor(0.4379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:57 loss: 0.000734tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:58 loss: 0.005177tensor(0.2627, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:59 loss: 0.000279tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:60 loss: 0.012031tensor(0.4446, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:61 loss: 0.005139tensor(0.3253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:62 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:63 loss: 0.000937tensor(0.0249, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:64 loss: 0.000410tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:65 loss: 0.004535tensor(0.4096, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:66 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:67 loss: 0.005035tensor(0.3816, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:68 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:70 loss: 0.002330tensor(0.3027, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:71 loss: 0.005053tensor(0.4110, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:72 loss: 0.001565tensor(0.4311, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:73 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:74 loss: 0.003879tensor(0.4208, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:75 loss: 0.000094tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:77 loss: 0.001050tensor(0.0839, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:78 loss: 0.008602tensor(0.4349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:67 step:79 loss: 0.002548tensor(0.3774, grad_fn=<DivBackward0>)\n",
      "Epoch:68 step:0 loss: 0.004236\n",
      "Epoch:68 step:1 loss: 0.003267\n",
      "Epoch:68 step:2 loss: 0.000128\n",
      "Epoch:68 step:3 loss: 0.000000\n",
      "Epoch:68 step:4 loss: 0.006964\n",
      "Epoch:68 step:5 loss: 0.005511\n",
      "Epoch:68 step:6 loss: 0.000001\n",
      "Epoch:68 step:7 loss: 0.005174\n",
      "Epoch:68 step:8 loss: 0.000006\n",
      "Epoch:68 step:9 loss: 0.000061\n",
      "Epoch:68 step:10 loss: 0.000003\n",
      "Epoch:68 step:11 loss: 0.003437\n",
      "Epoch:68 step:12 loss: 0.007766\n",
      "Epoch:68 step:13 loss: 0.000101\n",
      "Epoch:68 step:14 loss: 0.000010\n",
      "Epoch:68 step:15 loss: 0.000236\n",
      "Epoch:68 step:16 loss: 0.000001\n",
      "Epoch:68 step:17 loss: 0.000562\n",
      "Epoch:68 step:18 loss: 0.003685\n",
      "Epoch:68 step:19 loss: 0.011254\n",
      "Epoch:68 step:20 loss: 0.000026\n",
      "Epoch:68 step:21 loss: 0.000002\n",
      "Epoch:68 step:22 loss: 0.012201\n",
      "Epoch:68 step:23 loss: 0.001566\n",
      "Epoch:68 step:24 loss: 0.008801\n",
      "Epoch:68 step:25 loss: 0.000683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:68 step:26 loss: 0.006027\n",
      "Epoch:68 step:27 loss: 0.013244\n",
      "Epoch:68 step:28 loss: 0.000048\n",
      "Epoch:68 step:29 loss: 0.000000\n",
      "Epoch:68 step:30 loss: 0.000293\n",
      "Epoch:68 step:31 loss: 0.000198\n",
      "Epoch:68 step:32 loss: 0.000007\n",
      "Epoch:68 step:33 loss: 0.000015\n",
      "Epoch:68 step:34 loss: 0.008496\n",
      "Epoch:68 step:35 loss: 0.010197\n",
      "Epoch:68 step:36 loss: 0.000029\n",
      "Epoch:68 step:37 loss: 0.000865\n",
      "Epoch:68 step:38 loss: 0.000001\n",
      "Epoch:68 step:39 loss: 0.002180\n",
      "Epoch:68 step:40 loss: 0.014205\n",
      "Epoch:68 step:41 loss: 0.000000\n",
      "Epoch:68 step:42 loss: 0.000011\n",
      "Epoch:68 step:43 loss: 0.006577\n",
      "Epoch:68 step:44 loss: 0.000006\n",
      "Epoch:68 step:45 loss: 0.001478\n",
      "Epoch:68 step:46 loss: 0.000003\n",
      "Epoch:68 step:47 loss: 0.006478\n",
      "Epoch:68 step:48 loss: 0.003248\n",
      "Epoch:68 step:49 loss: 0.000051\n",
      "Epoch:68 step:50 loss: 0.000051\n",
      "Epoch:68 step:51 loss: 0.000032\n",
      "Epoch:68 step:52 loss: 0.000052\n",
      "Epoch:68 step:53 loss: 0.000071\n",
      "Epoch:68 step:54 loss: 0.008519\n",
      "Epoch:68 step:55 loss: 0.009900\n",
      "Epoch:68 step:56 loss: 0.007148\n",
      "Epoch:68 step:57 loss: 0.003146\n",
      "Epoch:68 step:58 loss: 0.005651\n",
      "Epoch:68 step:59 loss: 0.002657\n",
      "Epoch:68 step:60 loss: 0.010135\n",
      "Epoch:68 step:61 loss: 0.006501\n",
      "Epoch:68 step:62 loss: 0.000058\n",
      "Epoch:68 step:63 loss: 0.000824\n",
      "Epoch:68 step:64 loss: 0.000321\n",
      "Epoch:68 step:65 loss: 0.004189\n",
      "Epoch:68 step:66 loss: 0.000014\n",
      "Epoch:68 step:67 loss: 0.005773\n",
      "Epoch:68 step:68 loss: 0.000000\n",
      "Epoch:68 step:69 loss: 0.000001\n",
      "Epoch:68 step:70 loss: 0.001476\n",
      "Epoch:68 step:71 loss: 0.004639\n",
      "Epoch:68 step:72 loss: 0.001561\n",
      "Epoch:68 step:73 loss: 0.000005\n",
      "Epoch:68 step:74 loss: 0.003253\n",
      "Epoch:68 step:75 loss: 0.000078\n",
      "Epoch:68 step:76 loss: 0.000010\n",
      "Epoch:68 step:77 loss: 0.000637\n",
      "Epoch:68 step:78 loss: 0.006212\n",
      "Epoch:68 step:79 loss: 0.002303\n",
      "Test Epoch:68 step:0 loss: 0.004406tensor(0.3043, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:1 loss: 0.001925tensor(0.2468, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:2 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:4 loss: 0.006047tensor(0.4141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:5 loss: 0.008293tensor(0.3517, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:7 loss: 0.005366tensor(0.3543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:8 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:9 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:11 loss: 0.002999tensor(0.3882, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:12 loss: 0.005146tensor(0.4566, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:13 loss: 0.000706tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:14 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:15 loss: 0.000254tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:16 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:17 loss: 0.000281tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:18 loss: 0.003046tensor(0.3629, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:19 loss: 0.009095tensor(0.4113, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:20 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:22 loss: 0.011528tensor(0.4179, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:23 loss: 0.003604tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:24 loss: 0.004155tensor(0.4387, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:25 loss: 0.000812tensor(0.2542, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:26 loss: 0.006780tensor(0.4008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:27 loss: 0.011082tensor(0.4553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:29 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:30 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:31 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:32 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:34 loss: 0.006935tensor(0.2377, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:35 loss: 0.007309tensor(0.2287, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:36 loss: 0.000046tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:37 loss: 0.000840tensor(0.1885, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:38 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:39 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:40 loss: 0.012631tensor(0.4510, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:42 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:43 loss: 0.006744tensor(0.4325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:44 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:45 loss: 0.002456tensor(0.2885, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:46 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:47 loss: 0.005891tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:48 loss: 0.002311tensor(0.2081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:49 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:50 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:51 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:52 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:53 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:54 loss: 0.008190tensor(0.4374, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:55 loss: 0.009442tensor(0.4306, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:56 loss: 0.004851tensor(0.4410, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:57 loss: 0.001429tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:58 loss: 0.004281tensor(0.3040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:59 loss: 0.000531tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:60 loss: 0.012584tensor(0.4456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:61 loss: 0.009687tensor(0.2888, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:62 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:63 loss: 0.000699tensor(0.0787, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:64 loss: 0.000251tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:65 loss: 0.003575tensor(0.4283, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:66 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:67 loss: 0.005314tensor(0.3819, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:70 loss: 0.001604tensor(0.3314, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:71 loss: 0.004841tensor(0.4240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:72 loss: 0.002118tensor(0.4254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:73 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:74 loss: 0.004870tensor(0.4169, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:75 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:77 loss: 0.000509tensor(0.2509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:78 loss: 0.005920tensor(0.4505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:68 step:79 loss: 0.001833tensor(0.3994, grad_fn=<DivBackward0>)\n",
      "Epoch:69 step:0 loss: 0.004464\n",
      "Epoch:69 step:1 loss: 0.001873\n",
      "Epoch:69 step:2 loss: 0.000059\n",
      "Epoch:69 step:3 loss: 0.000000\n",
      "Epoch:69 step:4 loss: 0.005573\n",
      "Epoch:69 step:5 loss: 0.005693\n",
      "Epoch:69 step:6 loss: 0.000000\n",
      "Epoch:69 step:7 loss: 0.004459\n",
      "Epoch:69 step:8 loss: 0.000003\n",
      "Epoch:69 step:9 loss: 0.000031\n",
      "Epoch:69 step:10 loss: 0.000002\n",
      "Epoch:69 step:11 loss: 0.002887\n",
      "Epoch:69 step:12 loss: 0.004251\n",
      "Epoch:69 step:13 loss: 0.000150\n",
      "Epoch:69 step:14 loss: 0.000009\n",
      "Epoch:69 step:15 loss: 0.000163\n",
      "Epoch:69 step:16 loss: 0.000002\n",
      "Epoch:69 step:17 loss: 0.000081\n",
      "Epoch:69 step:18 loss: 0.002067\n",
      "Epoch:69 step:19 loss: 0.009187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:69 step:20 loss: 0.000009\n",
      "Epoch:69 step:21 loss: 0.000001\n",
      "Epoch:69 step:22 loss: 0.010558\n",
      "Epoch:69 step:23 loss: 0.001945\n",
      "Epoch:69 step:24 loss: 0.004904\n",
      "Epoch:69 step:25 loss: 0.000587\n",
      "Epoch:69 step:26 loss: 0.005864\n",
      "Epoch:69 step:27 loss: 0.010637\n",
      "Epoch:69 step:28 loss: 0.000001\n",
      "Epoch:69 step:29 loss: 0.000002\n",
      "Epoch:69 step:30 loss: 0.000039\n",
      "Epoch:69 step:31 loss: 0.000032\n",
      "Epoch:69 step:32 loss: 0.000004\n",
      "Epoch:69 step:33 loss: 0.000001\n",
      "Epoch:69 step:34 loss: 0.005521\n",
      "Epoch:69 step:35 loss: 0.006821\n",
      "Epoch:69 step:36 loss: 0.000061\n",
      "Epoch:69 step:37 loss: 0.000887\n",
      "Epoch:69 step:38 loss: 0.000009\n",
      "Epoch:69 step:39 loss: 0.000015\n",
      "Epoch:69 step:40 loss: 0.012336\n",
      "Epoch:69 step:41 loss: 0.000000\n",
      "Epoch:69 step:42 loss: 0.000001\n",
      "Epoch:69 step:43 loss: 0.006252\n",
      "Epoch:69 step:44 loss: 0.000007\n",
      "Epoch:69 step:45 loss: 0.001334\n",
      "Epoch:69 step:46 loss: 0.000001\n",
      "Epoch:69 step:47 loss: 0.005527\n",
      "Epoch:69 step:48 loss: 0.002702\n",
      "Epoch:69 step:49 loss: 0.000010\n",
      "Epoch:69 step:50 loss: 0.000015\n",
      "Epoch:69 step:51 loss: 0.000004\n",
      "Epoch:69 step:52 loss: 0.000012\n",
      "Epoch:69 step:53 loss: 0.000010\n",
      "Epoch:69 step:54 loss: 0.007185\n",
      "Epoch:69 step:55 loss: 0.008073\n",
      "Epoch:69 step:56 loss: 0.004871\n",
      "Epoch:69 step:57 loss: 0.000290\n",
      "Epoch:69 step:58 loss: 0.005641\n",
      "Epoch:69 step:59 loss: 0.000735\n",
      "Epoch:69 step:60 loss: 0.009528\n",
      "Epoch:69 step:61 loss: 0.008532\n",
      "Epoch:69 step:62 loss: 0.000056\n",
      "Epoch:69 step:63 loss: 0.001023\n",
      "Epoch:69 step:64 loss: 0.000403\n",
      "Epoch:69 step:65 loss: 0.004292\n",
      "Epoch:69 step:66 loss: 0.000040\n",
      "Epoch:69 step:67 loss: 0.004568\n",
      "Epoch:69 step:68 loss: 0.000000\n",
      "Epoch:69 step:69 loss: 0.000000\n",
      "Epoch:69 step:70 loss: 0.001329\n",
      "Epoch:69 step:71 loss: 0.004169\n",
      "Epoch:69 step:72 loss: 0.002580\n",
      "Epoch:69 step:73 loss: 0.000001\n",
      "Epoch:69 step:74 loss: 0.005542\n",
      "Epoch:69 step:75 loss: 0.000004\n",
      "Epoch:69 step:76 loss: 0.000001\n",
      "Epoch:69 step:77 loss: 0.000493\n",
      "Epoch:69 step:78 loss: 0.007539\n",
      "Epoch:69 step:79 loss: 0.002458\n",
      "Test Epoch:69 step:0 loss: 0.004406tensor(0.3188, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:1 loss: 0.002094tensor(0.2407, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:2 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:4 loss: 0.005558tensor(0.4239, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:5 loss: 0.005794tensor(0.3828, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:7 loss: 0.004819tensor(0.3645, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:8 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:9 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:11 loss: 0.002693tensor(0.4025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:12 loss: 0.004365tensor(0.4627, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:13 loss: 0.000141tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:14 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:15 loss: 0.000308tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:16 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:17 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:18 loss: 0.002147tensor(0.3876, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:19 loss: 0.009040tensor(0.4118, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:20 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:22 loss: 0.012146tensor(0.4192, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:23 loss: 0.002100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:24 loss: 0.004118tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:25 loss: 0.000638tensor(0.2362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:26 loss: 0.006130tensor(0.4081, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:27 loss: 0.009994tensor(0.4597, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:28 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:29 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:30 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:31 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:32 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:33 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:34 loss: 0.004751tensor(0.3047, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:35 loss: 0.006127tensor(0.2463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:36 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:37 loss: 0.000945tensor(0.1488, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:38 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:39 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:40 loss: 0.017459tensor(0.4411, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:42 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:43 loss: 0.006343tensor(0.4343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:44 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:45 loss: 0.002378tensor(0.2934, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:46 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:47 loss: 0.005693tensor(0.4329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:48 loss: 0.001936tensor(0.2473, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:49 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:50 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:51 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:52 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:53 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:54 loss: 0.007456tensor(0.4436, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:55 loss: 0.008339tensor(0.4412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:56 loss: 0.005194tensor(0.4414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:57 loss: 0.000136tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:58 loss: 0.003693tensor(0.3064, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:59 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:60 loss: 0.013418tensor(0.4470, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:61 loss: 0.005257tensor(0.3420, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:62 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:63 loss: 0.000706tensor(0.1034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:64 loss: 0.000643tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:65 loss: 0.004940tensor(0.4143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:66 loss: 0.000171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:67 loss: 0.004234tensor(0.4097, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:68 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:70 loss: 0.001172tensor(0.3574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:71 loss: 0.010421tensor(0.3737, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:72 loss: 0.002078tensor(0.4327, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:73 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:74 loss: 0.003384tensor(0.4274, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:75 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:77 loss: 0.000365tensor(0.3171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:78 loss: 0.014778tensor(0.4154, grad_fn=<DivBackward0>)\n",
      "Test Epoch:69 step:79 loss: 0.001953tensor(0.3942, grad_fn=<DivBackward0>)\n",
      "Epoch:70 step:0 loss: 0.004922\n",
      "Epoch:70 step:1 loss: 0.002494\n",
      "Epoch:70 step:2 loss: 0.000009\n",
      "Epoch:70 step:3 loss: 0.000000\n",
      "Epoch:70 step:4 loss: 0.006807\n",
      "Epoch:70 step:5 loss: 0.007365\n",
      "Epoch:70 step:6 loss: 0.000001\n",
      "Epoch:70 step:7 loss: 0.005022\n",
      "Epoch:70 step:8 loss: 0.000003\n",
      "Epoch:70 step:9 loss: 0.000044\n",
      "Epoch:70 step:10 loss: 0.000003\n",
      "Epoch:70 step:11 loss: 0.004140\n",
      "Epoch:70 step:12 loss: 0.003751\n",
      "Epoch:70 step:13 loss: 0.000074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:70 step:14 loss: 0.000076\n",
      "Epoch:70 step:15 loss: 0.000570\n",
      "Epoch:70 step:16 loss: 0.000009\n",
      "Epoch:70 step:17 loss: 0.000182\n",
      "Epoch:70 step:18 loss: 0.003540\n",
      "Epoch:70 step:19 loss: 0.008485\n",
      "Epoch:70 step:20 loss: 0.000017\n",
      "Epoch:70 step:21 loss: 0.000004\n",
      "Epoch:70 step:22 loss: 0.017317\n",
      "Epoch:70 step:23 loss: 0.000798\n",
      "Epoch:70 step:24 loss: 0.004760\n",
      "Epoch:70 step:25 loss: 0.000555\n",
      "Epoch:70 step:26 loss: 0.005076\n",
      "Epoch:70 step:27 loss: 0.011928\n",
      "Epoch:70 step:28 loss: 0.000004\n",
      "Epoch:70 step:29 loss: 0.000028\n",
      "Epoch:70 step:30 loss: 0.000332\n",
      "Epoch:70 step:31 loss: 0.000100\n",
      "Epoch:70 step:32 loss: 0.000002\n",
      "Epoch:70 step:33 loss: 0.000000\n",
      "Epoch:70 step:34 loss: 0.005589\n",
      "Epoch:70 step:35 loss: 0.007539\n",
      "Epoch:70 step:36 loss: 0.000021\n",
      "Epoch:70 step:37 loss: 0.000846\n",
      "Epoch:70 step:38 loss: 0.000020\n",
      "Epoch:70 step:39 loss: 0.000032\n",
      "Epoch:70 step:40 loss: 0.023764\n",
      "Epoch:70 step:41 loss: 0.000000\n",
      "Epoch:70 step:42 loss: 0.000004\n",
      "Epoch:70 step:43 loss: 0.006965\n",
      "Epoch:70 step:44 loss: 0.000015\n",
      "Epoch:70 step:45 loss: 0.002076\n",
      "Epoch:70 step:46 loss: 0.000002\n",
      "Epoch:70 step:47 loss: 0.005691\n",
      "Epoch:70 step:48 loss: 0.002451\n",
      "Epoch:70 step:49 loss: 0.000013\n",
      "Epoch:70 step:50 loss: 0.000013\n",
      "Epoch:70 step:51 loss: 0.000001\n",
      "Epoch:70 step:52 loss: 0.000012\n",
      "Epoch:70 step:53 loss: 0.000003\n",
      "Epoch:70 step:54 loss: 0.008469\n",
      "Epoch:70 step:55 loss: 0.012278\n",
      "Epoch:70 step:56 loss: 0.004598\n",
      "Epoch:70 step:57 loss: 0.000173\n",
      "Epoch:70 step:58 loss: 0.004293\n",
      "Epoch:70 step:59 loss: 0.000036\n",
      "Epoch:70 step:60 loss: 0.012807\n",
      "Epoch:70 step:61 loss: 0.006017\n",
      "Epoch:70 step:62 loss: 0.000068\n",
      "Epoch:70 step:63 loss: 0.001001\n",
      "Epoch:70 step:64 loss: 0.000677\n",
      "Epoch:70 step:65 loss: 0.004827\n",
      "Epoch:70 step:66 loss: 0.000087\n",
      "Epoch:70 step:67 loss: 0.004321\n",
      "Epoch:70 step:68 loss: 0.000009\n",
      "Epoch:70 step:69 loss: 0.000003\n",
      "Epoch:70 step:70 loss: 0.001183\n",
      "Epoch:70 step:71 loss: 0.005552\n",
      "Epoch:70 step:72 loss: 0.001381\n",
      "Epoch:70 step:73 loss: 0.000143\n",
      "Epoch:70 step:74 loss: 0.003171\n",
      "Epoch:70 step:75 loss: 0.000042\n",
      "Epoch:70 step:76 loss: 0.000001\n",
      "Epoch:70 step:77 loss: 0.000554\n",
      "Epoch:70 step:78 loss: 0.005227\n",
      "Epoch:70 step:79 loss: 0.001518\n",
      "Test Epoch:70 step:0 loss: 0.003662tensor(0.3344, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:1 loss: 0.001954tensor(0.2574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:2 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:4 loss: 0.007151tensor(0.4056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:5 loss: 0.012372tensor(0.3199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:7 loss: 0.004662tensor(0.3718, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:9 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:11 loss: 0.002628tensor(0.4038, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:12 loss: 0.003670tensor(0.4684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:13 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:14 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:15 loss: 0.000320tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:17 loss: 0.000136tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:18 loss: 0.002380tensor(0.3884, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:19 loss: 0.008509tensor(0.4151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:21 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:22 loss: 0.015876tensor(0.4040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:23 loss: 0.001824tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:24 loss: 0.004536tensor(0.4371, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:25 loss: 0.000813tensor(0.1998, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:26 loss: 0.009842tensor(0.3980, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:27 loss: 0.014408tensor(0.4485, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:28 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:30 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:31 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:32 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:33 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:34 loss: 0.004117tensor(0.3199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:35 loss: 0.009902tensor(0.1716, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:36 loss: 0.000126tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:37 loss: 0.001000tensor(0.1329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:38 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:39 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:40 loss: 0.017502tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:42 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:43 loss: 0.009003tensor(0.4171, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:44 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:45 loss: 0.001255tensor(0.3331, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:47 loss: 0.009372tensor(0.4070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:48 loss: 0.001959tensor(0.2715, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:49 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:50 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:51 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:52 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:53 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:54 loss: 0.015573tensor(0.4084, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:55 loss: 0.016460tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:56 loss: 0.007028tensor(0.4263, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:57 loss: 0.000755tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:58 loss: 0.018638tensor(0.1624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:59 loss: 0.001353tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:60 loss: 0.013010tensor(0.4485, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:61 loss: 0.007041tensor(0.3005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:62 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:63 loss: 0.001992tensor(0.0004, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:64 loss: 0.008521tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:65 loss: 0.007111tensor(0.3834, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:66 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:67 loss: 0.009902tensor(0.3469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:68 loss: 0.001589tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:69 loss: 0.000314tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:70 loss: 0.015025tensor(3.1020e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:71 loss: 0.014421tensor(0.3569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:72 loss: 0.001748tensor(0.4329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:73 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:74 loss: 0.007206tensor(0.3615, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:75 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:76 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:77 loss: 0.000538tensor(0.2505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:78 loss: 0.038392tensor(0.2920, grad_fn=<DivBackward0>)\n",
      "Test Epoch:70 step:79 loss: 0.004027tensor(0.3227, grad_fn=<DivBackward0>)\n",
      "Epoch:71 step:0 loss: 0.005376\n",
      "Epoch:71 step:1 loss: 0.009635\n",
      "Epoch:71 step:2 loss: 0.006000\n",
      "Epoch:71 step:3 loss: 0.000021\n",
      "Epoch:71 step:4 loss: 0.012391\n",
      "Epoch:71 step:5 loss: 0.004710\n",
      "Epoch:71 step:6 loss: 0.000060\n",
      "Epoch:71 step:7 loss: 0.006695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:71 step:8 loss: 0.000033\n",
      "Epoch:71 step:9 loss: 0.000488\n",
      "Epoch:71 step:10 loss: 0.009193\n",
      "Epoch:71 step:11 loss: 0.005965\n",
      "Epoch:71 step:12 loss: 0.007132\n",
      "Epoch:71 step:13 loss: 0.000890\n",
      "Epoch:71 step:14 loss: 0.002206\n",
      "Epoch:71 step:15 loss: 0.000469\n",
      "Epoch:71 step:16 loss: 0.000004\n",
      "Epoch:71 step:17 loss: 0.000258\n",
      "Epoch:71 step:18 loss: 0.013675\n",
      "Epoch:71 step:19 loss: 0.022852\n",
      "Epoch:71 step:20 loss: 0.000018\n",
      "Epoch:71 step:21 loss: 0.000045\n",
      "Epoch:71 step:22 loss: 0.055617\n",
      "Epoch:71 step:23 loss: 0.003897\n",
      "Epoch:71 step:24 loss: 0.009644\n",
      "Epoch:71 step:25 loss: 0.001290\n",
      "Epoch:71 step:26 loss: 0.014704\n",
      "Epoch:71 step:27 loss: 0.021106\n",
      "Epoch:71 step:28 loss: 0.000049\n",
      "Epoch:71 step:29 loss: 0.000024\n",
      "Epoch:71 step:30 loss: 0.004585\n",
      "Epoch:71 step:31 loss: 0.001760\n",
      "Epoch:71 step:32 loss: 0.000197\n",
      "Epoch:71 step:33 loss: 0.000007\n",
      "Epoch:71 step:34 loss: 0.033232\n",
      "Epoch:71 step:35 loss: 0.005488\n",
      "Epoch:71 step:36 loss: 0.000106\n",
      "Epoch:71 step:37 loss: 0.001301\n",
      "Epoch:71 step:38 loss: 0.000218\n",
      "Epoch:71 step:39 loss: 0.015244\n",
      "Epoch:71 step:40 loss: 0.063598\n",
      "Epoch:71 step:41 loss: 0.000811\n",
      "Epoch:71 step:42 loss: 0.000099\n",
      "Epoch:71 step:43 loss: 0.036886\n",
      "Epoch:71 step:44 loss: 0.000107\n",
      "Epoch:71 step:45 loss: 0.002959\n",
      "Epoch:71 step:46 loss: 0.000108\n",
      "Epoch:71 step:47 loss: 0.015842\n",
      "Epoch:71 step:48 loss: 0.004512\n",
      "Epoch:71 step:49 loss: 0.006395\n",
      "Epoch:71 step:50 loss: 0.000582\n",
      "Epoch:71 step:51 loss: 0.000467\n",
      "Epoch:71 step:52 loss: 0.000114\n",
      "Epoch:71 step:53 loss: 0.000552\n",
      "Epoch:71 step:54 loss: 0.035476\n",
      "Epoch:71 step:55 loss: 0.041031\n",
      "Epoch:71 step:56 loss: 0.012820\n",
      "Epoch:71 step:57 loss: 0.005523\n",
      "Epoch:71 step:58 loss: 0.049431\n",
      "Epoch:71 step:59 loss: 0.005696\n",
      "Epoch:71 step:60 loss: 0.029543\n",
      "Epoch:71 step:61 loss: 0.008429\n",
      "Epoch:71 step:62 loss: 0.000229\n",
      "Epoch:71 step:63 loss: 0.001188\n",
      "Epoch:71 step:64 loss: 0.002050\n",
      "Epoch:71 step:65 loss: 0.011394\n",
      "Epoch:71 step:66 loss: 0.000678\n",
      "Epoch:71 step:67 loss: 0.007502\n",
      "Epoch:71 step:68 loss: 0.000016\n",
      "Epoch:71 step:69 loss: 0.000016\n",
      "Epoch:71 step:70 loss: 0.002424\n",
      "Epoch:71 step:71 loss: 0.012650\n",
      "Epoch:71 step:72 loss: 0.003598\n",
      "Epoch:71 step:73 loss: 0.000324\n",
      "Epoch:71 step:74 loss: 0.006108\n",
      "Epoch:71 step:75 loss: 0.001428\n",
      "Epoch:71 step:76 loss: 0.000093\n",
      "Epoch:71 step:77 loss: 0.001167\n",
      "Epoch:71 step:78 loss: 0.011903\n",
      "Epoch:71 step:79 loss: 0.008380\n",
      "Test Epoch:71 step:0 loss: 0.006142tensor(0.2008, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:1 loss: 0.004665tensor(0.0488, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:2 loss: 0.000766tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:3 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:4 loss: 0.012146tensor(0.3463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:5 loss: 0.009150tensor(0.3040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:6 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:7 loss: 0.011546tensor(0.2520, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:8 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:9 loss: 0.000660tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:10 loss: 0.000366tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:11 loss: 0.004865tensor(0.3282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:12 loss: 0.007296tensor(0.4316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:13 loss: 0.000693tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:14 loss: 0.000296tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:15 loss: 0.001239tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:16 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:17 loss: 0.000644tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:18 loss: 0.006533tensor(0.2442, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:19 loss: 0.013231tensor(0.3600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:20 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:21 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:22 loss: 0.019219tensor(0.3744, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:23 loss: 0.002488tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:24 loss: 0.005949tensor(0.4075, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:25 loss: 0.000739tensor(0.2122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:26 loss: 0.011961tensor(0.3402, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:27 loss: 0.018237tensor(0.4328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:28 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:29 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:30 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:31 loss: 0.000394tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:32 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:34 loss: 0.016169tensor(0.0590, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:35 loss: 0.005968tensor(0.2143, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:36 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:37 loss: 0.001031tensor(0.1350, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:38 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:39 loss: 0.000372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:40 loss: 0.023624tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:41 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:42 loss: 0.000794tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:43 loss: 0.013587tensor(0.3856, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:44 loss: 0.000518tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:45 loss: 0.002604tensor(0.2500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:46 loss: 0.000803tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:47 loss: 0.007285tensor(0.4147, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:48 loss: 0.003396tensor(0.2122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:49 loss: 0.000218tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:50 loss: 0.002500tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:51 loss: 0.001658tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:52 loss: 0.000209tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:53 loss: 0.000535tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:54 loss: 0.027841tensor(0.3637, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:55 loss: 0.017878tensor(0.3848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:56 loss: 0.006626tensor(0.4241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:57 loss: 0.000149tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:58 loss: 0.022102tensor(0.0521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:59 loss: 0.000091tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:60 loss: 0.036531tensor(0.3798, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:61 loss: 0.008823tensor(0.2058, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:63 loss: 0.000665tensor(0.0744, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:64 loss: 0.001530tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:65 loss: 0.005067tensor(0.3702, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:66 loss: 0.000791tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:67 loss: 0.006689tensor(0.3532, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:68 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:69 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:70 loss: 0.002926tensor(0.2473, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:71 loss: 0.009370tensor(0.3451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:72 loss: 0.004442tensor(0.3351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:73 loss: 0.000248tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:74 loss: 0.004688tensor(0.3948, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:75 loss: 0.000732tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:76 loss: 0.000133tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:77 loss: 0.000691tensor(0.1528, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:78 loss: 0.015901tensor(0.3901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:71 step:79 loss: 0.002362tensor(0.3740, grad_fn=<DivBackward0>)\n",
      "Epoch:72 step:0 loss: 0.007269\n",
      "Epoch:72 step:1 loss: 0.002978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:72 step:2 loss: 0.000088\n",
      "Epoch:72 step:3 loss: 0.000000\n",
      "Epoch:72 step:4 loss: 0.010237\n",
      "Epoch:72 step:5 loss: 0.008268\n",
      "Epoch:72 step:6 loss: 0.000001\n",
      "Epoch:72 step:7 loss: 0.009138\n",
      "Epoch:72 step:8 loss: 0.000012\n",
      "Epoch:72 step:9 loss: 0.000166\n",
      "Epoch:72 step:10 loss: 0.000017\n",
      "Epoch:72 step:11 loss: 0.004520\n",
      "Epoch:72 step:12 loss: 0.009291\n",
      "Epoch:72 step:13 loss: 0.001064\n",
      "Epoch:72 step:14 loss: 0.000033\n",
      "Epoch:72 step:15 loss: 0.002202\n",
      "Epoch:72 step:16 loss: 0.000025\n",
      "Epoch:72 step:17 loss: 0.001289\n",
      "Epoch:72 step:18 loss: 0.007316\n",
      "Epoch:72 step:19 loss: 0.012204\n",
      "Epoch:72 step:20 loss: 0.000035\n",
      "Epoch:72 step:21 loss: 0.000016\n",
      "Epoch:72 step:22 loss: 0.018631\n",
      "Epoch:72 step:23 loss: 0.004399\n",
      "Epoch:72 step:24 loss: 0.004639\n",
      "Epoch:72 step:25 loss: 0.000864\n",
      "Epoch:72 step:26 loss: 0.007300\n",
      "Epoch:72 step:27 loss: 0.013485\n",
      "Epoch:72 step:28 loss: 0.000001\n",
      "Epoch:72 step:29 loss: 0.000001\n",
      "Epoch:72 step:30 loss: 0.000007\n",
      "Epoch:72 step:31 loss: 0.000238\n",
      "Epoch:72 step:32 loss: 0.000006\n",
      "Epoch:72 step:33 loss: 0.000000\n",
      "Epoch:72 step:34 loss: 0.007211\n",
      "Epoch:72 step:35 loss: 0.005616\n",
      "Epoch:72 step:36 loss: 0.000045\n",
      "Epoch:72 step:37 loss: 0.001090\n",
      "Epoch:72 step:38 loss: 0.000054\n",
      "Epoch:72 step:39 loss: 0.000037\n",
      "Epoch:72 step:40 loss: 0.017137\n",
      "Epoch:72 step:41 loss: 0.000000\n",
      "Epoch:72 step:42 loss: 0.000003\n",
      "Epoch:72 step:43 loss: 0.008997\n",
      "Epoch:72 step:44 loss: 0.000019\n",
      "Epoch:72 step:45 loss: 0.001321\n",
      "Epoch:72 step:46 loss: 0.000031\n",
      "Epoch:72 step:47 loss: 0.007859\n",
      "Epoch:72 step:48 loss: 0.002813\n",
      "Epoch:72 step:49 loss: 0.000021\n",
      "Epoch:72 step:50 loss: 0.000167\n",
      "Epoch:72 step:51 loss: 0.000602\n",
      "Epoch:72 step:52 loss: 0.000019\n",
      "Epoch:72 step:53 loss: 0.000040\n",
      "Epoch:72 step:54 loss: 0.013395\n",
      "Epoch:72 step:55 loss: 0.014493\n",
      "Epoch:72 step:56 loss: 0.004866\n",
      "Epoch:72 step:57 loss: 0.000729\n",
      "Epoch:72 step:58 loss: 0.008844\n",
      "Epoch:72 step:59 loss: 0.001497\n",
      "Epoch:72 step:60 loss: 0.013628\n",
      "Epoch:72 step:61 loss: 0.005419\n",
      "Epoch:72 step:62 loss: 0.000020\n",
      "Epoch:72 step:63 loss: 0.000648\n",
      "Epoch:72 step:64 loss: 0.000476\n",
      "Epoch:72 step:65 loss: 0.003854\n",
      "Epoch:72 step:66 loss: 0.000068\n",
      "Epoch:72 step:67 loss: 0.007553\n",
      "Epoch:72 step:68 loss: 0.000000\n",
      "Epoch:72 step:69 loss: 0.000000\n",
      "Epoch:72 step:70 loss: 0.001391\n",
      "Epoch:72 step:71 loss: 0.006842\n",
      "Epoch:72 step:72 loss: 0.002039\n",
      "Epoch:72 step:73 loss: 0.000019\n",
      "Epoch:72 step:74 loss: 0.003383\n",
      "Epoch:72 step:75 loss: 0.000099\n",
      "Epoch:72 step:76 loss: 0.000161\n",
      "Epoch:72 step:77 loss: 0.000823\n",
      "Epoch:72 step:78 loss: 0.007179\n",
      "Epoch:72 step:79 loss: 0.002031\n",
      "Test Epoch:72 step:0 loss: 0.004062tensor(0.3016, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:1 loss: 0.002387tensor(0.1975, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:2 loss: 0.000364tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:4 loss: 0.006860tensor(0.4012, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:5 loss: 0.006745tensor(0.3595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:6 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:7 loss: 0.006558tensor(0.3377, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:9 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:10 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:11 loss: 0.002766tensor(0.3918, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:12 loss: 0.004691tensor(0.4590, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:13 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:14 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:15 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:17 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:18 loss: 0.006455tensor(0.2464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:19 loss: 0.009610tensor(0.4011, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:21 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:22 loss: 0.011757tensor(0.4086, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:23 loss: 0.002789tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:24 loss: 0.005056tensor(0.4230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:25 loss: 0.000777tensor(0.2157, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:26 loss: 0.007027tensor(0.3873, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:27 loss: 0.014748tensor(0.4430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:28 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:30 loss: 0.000273tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:31 loss: 0.000163tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:32 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:34 loss: 0.007025tensor(0.2458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:35 loss: 0.004430tensor(0.2815, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:36 loss: 0.000112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:37 loss: 0.001132tensor(0.1277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:38 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:39 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:40 loss: 0.015044tensor(0.4458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:42 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:43 loss: 0.006314tensor(0.4337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:44 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:45 loss: 0.001636tensor(0.2927, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:47 loss: 0.006214tensor(0.4291, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:48 loss: 0.003116tensor(0.1587, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:49 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:50 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:51 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:53 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:54 loss: 0.009758tensor(0.4262, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:55 loss: 0.009366tensor(0.4269, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:56 loss: 0.004649tensor(0.4424, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:57 loss: 0.001984tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:58 loss: 0.004081tensor(0.2911, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:59 loss: 0.001148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:60 loss: 0.011569tensor(0.4494, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:61 loss: 0.008955tensor(0.2883, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:62 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:63 loss: 0.000395tensor(0.1879, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:64 loss: 0.000255tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:65 loss: 0.002961tensor(0.4322, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:66 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:67 loss: 0.008851tensor(0.3433, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:70 loss: 0.002078tensor(0.2915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:71 loss: 0.004231tensor(0.4294, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:72 loss: 0.001657tensor(0.4365, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:73 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:74 loss: 0.003013tensor(0.4355, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:75 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:76 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:77 loss: 0.000548tensor(0.2149, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:72 step:78 loss: 0.005998tensor(0.4494, grad_fn=<DivBackward0>)\n",
      "Test Epoch:72 step:79 loss: 0.002546tensor(0.3891, grad_fn=<DivBackward0>)\n",
      "Epoch:73 step:0 loss: 0.003987\n",
      "Epoch:73 step:1 loss: 0.001700\n",
      "Epoch:73 step:2 loss: 0.000035\n",
      "Epoch:73 step:3 loss: 0.000000\n",
      "Epoch:73 step:4 loss: 0.007124\n",
      "Epoch:73 step:5 loss: 0.005124\n",
      "Epoch:73 step:6 loss: 0.000000\n",
      "Epoch:73 step:7 loss: 0.004641\n",
      "Epoch:73 step:8 loss: 0.000001\n",
      "Epoch:73 step:9 loss: 0.000013\n",
      "Epoch:73 step:10 loss: 0.000006\n",
      "Epoch:73 step:11 loss: 0.002357\n",
      "Epoch:73 step:12 loss: 0.004897\n",
      "Epoch:73 step:13 loss: 0.000005\n",
      "Epoch:73 step:14 loss: 0.000000\n",
      "Epoch:73 step:15 loss: 0.000282\n",
      "Epoch:73 step:16 loss: 0.000001\n",
      "Epoch:73 step:17 loss: 0.000034\n",
      "Epoch:73 step:18 loss: 0.003109\n",
      "Epoch:73 step:19 loss: 0.008176\n",
      "Epoch:73 step:20 loss: 0.000001\n",
      "Epoch:73 step:21 loss: 0.000019\n",
      "Epoch:73 step:22 loss: 0.009685\n",
      "Epoch:73 step:23 loss: 0.000758\n",
      "Epoch:73 step:24 loss: 0.005428\n",
      "Epoch:73 step:25 loss: 0.000991\n",
      "Epoch:73 step:26 loss: 0.008007\n",
      "Epoch:73 step:27 loss: 0.012476\n",
      "Epoch:73 step:28 loss: 0.000002\n",
      "Epoch:73 step:29 loss: 0.000001\n",
      "Epoch:73 step:30 loss: 0.000547\n",
      "Epoch:73 step:31 loss: 0.000226\n",
      "Epoch:73 step:32 loss: 0.000006\n",
      "Epoch:73 step:33 loss: 0.000000\n",
      "Epoch:73 step:34 loss: 0.005220\n",
      "Epoch:73 step:35 loss: 0.002827\n",
      "Epoch:73 step:36 loss: 0.000084\n",
      "Epoch:73 step:37 loss: 0.000720\n",
      "Epoch:73 step:38 loss: 0.000355\n",
      "Epoch:73 step:39 loss: 0.000054\n",
      "Epoch:73 step:40 loss: 0.012852\n",
      "Epoch:73 step:41 loss: 0.000000\n",
      "Epoch:73 step:42 loss: 0.000004\n",
      "Epoch:73 step:43 loss: 0.006528\n",
      "Epoch:73 step:44 loss: 0.000014\n",
      "Epoch:73 step:45 loss: 0.001359\n",
      "Epoch:73 step:46 loss: 0.000001\n",
      "Epoch:73 step:47 loss: 0.005946\n",
      "Epoch:73 step:48 loss: 0.001982\n",
      "Epoch:73 step:49 loss: 0.000049\n",
      "Epoch:73 step:50 loss: 0.000019\n",
      "Epoch:73 step:51 loss: 0.000018\n",
      "Epoch:73 step:52 loss: 0.000021\n",
      "Epoch:73 step:53 loss: 0.000051\n",
      "Epoch:73 step:54 loss: 0.010494\n",
      "Epoch:73 step:55 loss: 0.010559\n",
      "Epoch:73 step:56 loss: 0.004794\n",
      "Epoch:73 step:57 loss: 0.000868\n",
      "Epoch:73 step:58 loss: 0.004312\n",
      "Epoch:73 step:59 loss: 0.000327\n",
      "Epoch:73 step:60 loss: 0.013003\n",
      "Epoch:73 step:61 loss: 0.004563\n",
      "Epoch:73 step:62 loss: 0.000119\n",
      "Epoch:73 step:63 loss: 0.000954\n",
      "Epoch:73 step:64 loss: 0.001371\n",
      "Epoch:73 step:65 loss: 0.004984\n",
      "Epoch:73 step:66 loss: 0.000036\n",
      "Epoch:73 step:67 loss: 0.004504\n",
      "Epoch:73 step:68 loss: 0.000000\n",
      "Epoch:73 step:69 loss: 0.000001\n",
      "Epoch:73 step:70 loss: 0.001605\n",
      "Epoch:73 step:71 loss: 0.004571\n",
      "Epoch:73 step:72 loss: 0.002360\n",
      "Epoch:73 step:73 loss: 0.000028\n",
      "Epoch:73 step:74 loss: 0.007075\n",
      "Epoch:73 step:75 loss: 0.000015\n",
      "Epoch:73 step:76 loss: 0.000002\n",
      "Epoch:73 step:77 loss: 0.000338\n",
      "Epoch:73 step:78 loss: 0.006090\n",
      "Epoch:73 step:79 loss: 0.001560\n",
      "Test Epoch:73 step:0 loss: 0.003510tensor(0.3313, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:1 loss: 0.001766tensor(0.3056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:2 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:4 loss: 0.005847tensor(0.4240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:5 loss: 0.005613tensor(0.3858, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:7 loss: 0.005680tensor(0.3620, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:9 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:10 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:11 loss: 0.002267tensor(0.4142, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:12 loss: 0.004805tensor(0.4607, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:13 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:15 loss: 0.000144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:16 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:17 loss: 0.000052tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:18 loss: 0.002065tensor(0.3848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:19 loss: 0.008899tensor(0.4141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:21 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:22 loss: 0.008807tensor(0.4323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:23 loss: 0.000567tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:24 loss: 0.004479tensor(0.4316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:25 loss: 0.000921tensor(0.2469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:26 loss: 0.006702tensor(0.4024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:27 loss: 0.010043tensor(0.4604, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:28 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:30 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:31 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:32 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:34 loss: 0.004380tensor(0.3441, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:35 loss: 0.002571tensor(0.3579, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:36 loss: 0.000098tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:37 loss: 0.000836tensor(0.2228, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:38 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:39 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:40 loss: 0.010949tensor(0.4576, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:43 loss: 0.006592tensor(0.4345, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:44 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:45 loss: 0.001455tensor(0.3359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:47 loss: 0.005940tensor(0.4323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:48 loss: 0.003011tensor(0.1775, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:50 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:51 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:53 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:54 loss: 0.009690tensor(0.4351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:55 loss: 0.008895tensor(0.4352, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:56 loss: 0.004826tensor(0.4423, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:57 loss: 0.001102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:58 loss: 0.003618tensor(0.3079, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:59 loss: 0.000521tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:60 loss: 0.009991tensor(0.4554, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:61 loss: 0.007338tensor(0.3037, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:62 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:63 loss: 0.000973tensor(0.1781, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:64 loss: 0.000315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:65 loss: 0.004495tensor(0.4197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:66 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:67 loss: 0.004193tensor(0.4137, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:69 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:70 loss: 0.001597tensor(0.3456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:71 loss: 0.005155tensor(0.4242, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:72 loss: 0.001634tensor(0.4415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:73 loss: 0.000220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:74 loss: 0.004574tensor(0.4224, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:73 step:75 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:77 loss: 0.000311tensor(0.3263, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:78 loss: 0.006875tensor(0.4475, grad_fn=<DivBackward0>)\n",
      "Test Epoch:73 step:79 loss: 0.001724tensor(0.4063, grad_fn=<DivBackward0>)\n",
      "Epoch:74 step:0 loss: 0.003545\n",
      "Epoch:74 step:1 loss: 0.001716\n",
      "Epoch:74 step:2 loss: 0.000003\n",
      "Epoch:74 step:3 loss: 0.000000\n",
      "Epoch:74 step:4 loss: 0.005866\n",
      "Epoch:74 step:5 loss: 0.005270\n",
      "Epoch:74 step:6 loss: 0.000000\n",
      "Epoch:74 step:7 loss: 0.004233\n",
      "Epoch:74 step:8 loss: 0.000001\n",
      "Epoch:74 step:9 loss: 0.000005\n",
      "Epoch:74 step:10 loss: 0.000005\n",
      "Epoch:74 step:11 loss: 0.002398\n",
      "Epoch:74 step:12 loss: 0.004098\n",
      "Epoch:74 step:13 loss: 0.000017\n",
      "Epoch:74 step:14 loss: 0.000001\n",
      "Epoch:74 step:15 loss: 0.000256\n",
      "Epoch:74 step:16 loss: 0.000034\n",
      "Epoch:74 step:17 loss: 0.000058\n",
      "Epoch:74 step:18 loss: 0.001865\n",
      "Epoch:74 step:19 loss: 0.008350\n",
      "Epoch:74 step:20 loss: 0.000004\n",
      "Epoch:74 step:21 loss: 0.000009\n",
      "Epoch:74 step:22 loss: 0.011907\n",
      "Epoch:74 step:23 loss: 0.000544\n",
      "Epoch:74 step:24 loss: 0.004004\n",
      "Epoch:74 step:25 loss: 0.000626\n",
      "Epoch:74 step:26 loss: 0.005985\n",
      "Epoch:74 step:27 loss: 0.010189\n",
      "Epoch:74 step:28 loss: 0.000001\n",
      "Epoch:74 step:29 loss: 0.000000\n",
      "Epoch:74 step:30 loss: 0.000080\n",
      "Epoch:74 step:31 loss: 0.000008\n",
      "Epoch:74 step:32 loss: 0.000002\n",
      "Epoch:74 step:33 loss: 0.000000\n",
      "Epoch:74 step:34 loss: 0.005387\n",
      "Epoch:74 step:35 loss: 0.003871\n",
      "Epoch:74 step:36 loss: 0.000030\n",
      "Epoch:74 step:37 loss: 0.000752\n",
      "Epoch:74 step:38 loss: 0.000059\n",
      "Epoch:74 step:39 loss: 0.000018\n",
      "Epoch:74 step:40 loss: 0.016271\n",
      "Epoch:74 step:41 loss: 0.000000\n",
      "Epoch:74 step:42 loss: 0.000000\n",
      "Epoch:74 step:43 loss: 0.006722\n",
      "Epoch:74 step:44 loss: 0.000012\n",
      "Epoch:74 step:45 loss: 0.002078\n",
      "Epoch:74 step:46 loss: 0.000000\n",
      "Epoch:74 step:47 loss: 0.005012\n",
      "Epoch:74 step:48 loss: 0.002312\n",
      "Epoch:74 step:49 loss: 0.000005\n",
      "Epoch:74 step:50 loss: 0.000006\n",
      "Epoch:74 step:51 loss: 0.000011\n",
      "Epoch:74 step:52 loss: 0.000005\n",
      "Epoch:74 step:53 loss: 0.000005\n",
      "Epoch:74 step:54 loss: 0.008282\n",
      "Epoch:74 step:55 loss: 0.008628\n",
      "Epoch:74 step:56 loss: 0.005167\n",
      "Epoch:74 step:57 loss: 0.000541\n",
      "Epoch:74 step:58 loss: 0.003676\n",
      "Epoch:74 step:59 loss: 0.000129\n",
      "Epoch:74 step:60 loss: 0.009220\n",
      "Epoch:74 step:61 loss: 0.004926\n",
      "Epoch:74 step:62 loss: 0.000090\n",
      "Epoch:74 step:63 loss: 0.000328\n",
      "Epoch:74 step:64 loss: 0.000436\n",
      "Epoch:74 step:65 loss: 0.005648\n",
      "Epoch:74 step:66 loss: 0.000032\n",
      "Epoch:74 step:67 loss: 0.004194\n",
      "Epoch:74 step:68 loss: 0.000001\n",
      "Epoch:74 step:69 loss: 0.000002\n",
      "Epoch:74 step:70 loss: 0.001176\n",
      "Epoch:74 step:71 loss: 0.004957\n",
      "Epoch:74 step:72 loss: 0.001494\n",
      "Epoch:74 step:73 loss: 0.000124\n",
      "Epoch:74 step:74 loss: 0.003699\n",
      "Epoch:74 step:75 loss: 0.000188\n",
      "Epoch:74 step:76 loss: 0.000002\n",
      "Epoch:74 step:77 loss: 0.000306\n",
      "Epoch:74 step:78 loss: 0.006778\n",
      "Epoch:74 step:79 loss: 0.001402\n",
      "Test Epoch:74 step:0 loss: 0.003609tensor(0.3225, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:1 loss: 0.001991tensor(0.2568, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:2 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:4 loss: 0.006471tensor(0.4159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:5 loss: 0.006531tensor(0.3767, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:7 loss: 0.004277tensor(0.3816, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:9 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:10 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:11 loss: 0.002381tensor(0.4125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:12 loss: 0.003910tensor(0.4657, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:13 loss: 0.000286tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:15 loss: 0.000379tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:17 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:18 loss: 0.002781tensor(0.3750, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:19 loss: 0.007518tensor(0.4241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:21 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:22 loss: 0.012449tensor(0.4194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:23 loss: 0.001125tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:24 loss: 0.003555tensor(0.4481, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:25 loss: 0.000658tensor(0.2666, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:26 loss: 0.004860tensor(0.4194, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:27 loss: 0.011388tensor(0.4588, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:30 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:31 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:32 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:34 loss: 0.005081tensor(0.3025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:35 loss: 0.005244tensor(0.2846, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:36 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:37 loss: 0.000713tensor(0.2366, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:38 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:39 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:40 loss: 0.010713tensor(0.4586, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:43 loss: 0.005539tensor(0.4423, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:44 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:45 loss: 0.001750tensor(0.3297, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:47 loss: 0.005116tensor(0.4403, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:48 loss: 0.001654tensor(0.2882, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:50 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:51 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:53 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:54 loss: 0.011360tensor(0.4328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:55 loss: 0.011027tensor(0.4289, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:56 loss: 0.003359tensor(0.4582, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:57 loss: 0.000967tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:58 loss: 0.004709tensor(0.2802, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:59 loss: 0.000410tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:60 loss: 0.010736tensor(0.4557, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:61 loss: 0.005743tensor(0.3396, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:62 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:63 loss: 0.000404tensor(0.2577, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:64 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:65 loss: 0.004234tensor(0.4270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:66 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:67 loss: 0.003537tensor(0.4183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:69 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:70 loss: 0.001178tensor(0.3818, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:71 loss: 0.005302tensor(0.4251, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:74 step:72 loss: 0.001487tensor(0.4453, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:73 loss: 0.000060tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:74 loss: 0.002927tensor(0.4415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:75 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:76 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:77 loss: 0.000407tensor(0.2947, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:78 loss: 0.007374tensor(0.4491, grad_fn=<DivBackward0>)\n",
      "Test Epoch:74 step:79 loss: 0.001493tensor(0.4173, grad_fn=<DivBackward0>)\n",
      "Epoch:75 step:0 loss: 0.002938\n",
      "Epoch:75 step:1 loss: 0.003287\n",
      "Epoch:75 step:2 loss: 0.000008\n",
      "Epoch:75 step:3 loss: 0.000000\n",
      "Epoch:75 step:4 loss: 0.008547\n",
      "Epoch:75 step:5 loss: 0.003731\n",
      "Epoch:75 step:6 loss: 0.000000\n",
      "Epoch:75 step:7 loss: 0.004381\n",
      "Epoch:75 step:8 loss: 0.000001\n",
      "Epoch:75 step:9 loss: 0.000002\n",
      "Epoch:75 step:10 loss: 0.000037\n",
      "Epoch:75 step:11 loss: 0.002633\n",
      "Epoch:75 step:12 loss: 0.004923\n",
      "Epoch:75 step:13 loss: 0.000010\n",
      "Epoch:75 step:14 loss: 0.000001\n",
      "Epoch:75 step:15 loss: 0.000127\n",
      "Epoch:75 step:16 loss: 0.000002\n",
      "Epoch:75 step:17 loss: 0.000142\n",
      "Epoch:75 step:18 loss: 0.003350\n",
      "Epoch:75 step:19 loss: 0.008941\n",
      "Epoch:75 step:20 loss: 0.000005\n",
      "Epoch:75 step:21 loss: 0.000013\n",
      "Epoch:75 step:22 loss: 0.011967\n",
      "Epoch:75 step:23 loss: 0.000302\n",
      "Epoch:75 step:24 loss: 0.003331\n",
      "Epoch:75 step:25 loss: 0.000558\n",
      "Epoch:75 step:26 loss: 0.005383\n",
      "Epoch:75 step:27 loss: 0.012116\n",
      "Epoch:75 step:28 loss: 0.000000\n",
      "Epoch:75 step:29 loss: 0.000000\n",
      "Epoch:75 step:30 loss: 0.000014\n",
      "Epoch:75 step:31 loss: 0.000017\n",
      "Epoch:75 step:32 loss: 0.000004\n",
      "Epoch:75 step:33 loss: 0.000000\n",
      "Epoch:75 step:34 loss: 0.004924\n",
      "Epoch:75 step:35 loss: 0.005474\n",
      "Epoch:75 step:36 loss: 0.000044\n",
      "Epoch:75 step:37 loss: 0.000804\n",
      "Epoch:75 step:38 loss: 0.000077\n",
      "Epoch:75 step:39 loss: 0.000014\n",
      "Epoch:75 step:40 loss: 0.012338\n",
      "Epoch:75 step:41 loss: 0.000000\n",
      "Epoch:75 step:42 loss: 0.000000\n",
      "Epoch:75 step:43 loss: 0.005441\n",
      "Epoch:75 step:44 loss: 0.000022\n",
      "Epoch:75 step:45 loss: 0.001716\n",
      "Epoch:75 step:46 loss: 0.000003\n",
      "Epoch:75 step:47 loss: 0.004896\n",
      "Epoch:75 step:48 loss: 0.002010\n",
      "Epoch:75 step:49 loss: 0.000000\n",
      "Epoch:75 step:50 loss: 0.000018\n",
      "Epoch:75 step:51 loss: 0.000004\n",
      "Epoch:75 step:52 loss: 0.000000\n",
      "Epoch:75 step:53 loss: 0.000003\n",
      "Epoch:75 step:54 loss: 0.006021\n",
      "Epoch:75 step:55 loss: 0.007469\n",
      "Epoch:75 step:56 loss: 0.003939\n",
      "Epoch:75 step:57 loss: 0.000079\n",
      "Epoch:75 step:58 loss: 0.006314\n",
      "Epoch:75 step:59 loss: 0.000161\n",
      "Epoch:75 step:60 loss: 0.010328\n",
      "Epoch:75 step:61 loss: 0.004351\n",
      "Epoch:75 step:62 loss: 0.000006\n",
      "Epoch:75 step:63 loss: 0.001005\n",
      "Epoch:75 step:64 loss: 0.000491\n",
      "Epoch:75 step:65 loss: 0.006129\n",
      "Epoch:75 step:66 loss: 0.000018\n",
      "Epoch:75 step:67 loss: 0.004912\n",
      "Epoch:75 step:68 loss: 0.000001\n",
      "Epoch:75 step:69 loss: 0.000000\n",
      "Epoch:75 step:70 loss: 0.001594\n",
      "Epoch:75 step:71 loss: 0.010206\n",
      "Epoch:75 step:72 loss: 0.002039\n",
      "Epoch:75 step:73 loss: 0.000301\n",
      "Epoch:75 step:74 loss: 0.003738\n",
      "Epoch:75 step:75 loss: 0.000054\n",
      "Epoch:75 step:76 loss: 0.000001\n",
      "Epoch:75 step:77 loss: 0.000295\n",
      "Epoch:75 step:78 loss: 0.007374\n",
      "Epoch:75 step:79 loss: 0.002363\n",
      "Test Epoch:75 step:0 loss: 0.003474tensor(0.3510, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:1 loss: 0.001905tensor(0.2547, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:2 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:4 loss: 0.008624tensor(0.3991, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:5 loss: 0.004602tensor(0.3914, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:7 loss: 0.004549tensor(0.3734, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:9 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:11 loss: 0.003746tensor(0.3820, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:12 loss: 0.004275tensor(0.4632, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:13 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:15 loss: 0.000113tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:17 loss: 0.000220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:18 loss: 0.003326tensor(0.3461, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:19 loss: 0.008502tensor(0.4228, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:21 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:22 loss: 0.011627tensor(0.4234, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:23 loss: 0.001476tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:24 loss: 0.004365tensor(0.4395, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:25 loss: 0.000604tensor(0.2854, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:26 loss: 0.004746tensor(0.4222, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:27 loss: 0.013187tensor(0.4573, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:30 loss: 0.000237tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:31 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:32 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:34 loss: 0.004889tensor(0.3021, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:35 loss: 0.004463tensor(0.3035, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:36 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:37 loss: 0.000871tensor(0.1786, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:38 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:39 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:40 loss: 0.013015tensor(0.4550, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:43 loss: 0.005744tensor(0.4409, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:44 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:45 loss: 0.001361tensor(0.3512, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:47 loss: 0.004657tensor(0.4433, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:48 loss: 0.001761tensor(0.3042, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:50 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:51 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:53 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:54 loss: 0.007506tensor(0.4472, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:55 loss: 0.008274tensor(0.4413, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:56 loss: 0.004957tensor(0.4483, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:57 loss: 0.000975tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:58 loss: 0.003557tensor(0.3153, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:59 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:60 loss: 0.010346tensor(0.4580, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:61 loss: 0.004442tensor(0.3532, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:62 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:63 loss: 0.000593tensor(0.1019, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:64 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:65 loss: 0.004098tensor(0.4273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:66 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:67 loss: 0.004079tensor(0.4092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:75 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:70 loss: 0.001021tensor(0.3897, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:71 loss: 0.005557tensor(0.4173, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:72 loss: 0.002020tensor(0.4346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:73 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:74 loss: 0.003237tensor(0.4361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:75 loss: 0.000165tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:77 loss: 0.000591tensor(0.3244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:78 loss: 0.005379tensor(0.4544, grad_fn=<DivBackward0>)\n",
      "Test Epoch:75 step:79 loss: 0.001860tensor(0.4097, grad_fn=<DivBackward0>)\n",
      "Epoch:76 step:0 loss: 0.003596\n",
      "Epoch:76 step:1 loss: 0.002134\n",
      "Epoch:76 step:2 loss: 0.000004\n",
      "Epoch:76 step:3 loss: 0.000000\n",
      "Epoch:76 step:4 loss: 0.007650\n",
      "Epoch:76 step:5 loss: 0.008428\n",
      "Epoch:76 step:6 loss: 0.000000\n",
      "Epoch:76 step:7 loss: 0.005465\n",
      "Epoch:76 step:8 loss: 0.000001\n",
      "Epoch:76 step:9 loss: 0.000003\n",
      "Epoch:76 step:10 loss: 0.000010\n",
      "Epoch:76 step:11 loss: 0.002420\n",
      "Epoch:76 step:12 loss: 0.004209\n",
      "Epoch:76 step:13 loss: 0.001009\n",
      "Epoch:76 step:14 loss: 0.000000\n",
      "Epoch:76 step:15 loss: 0.000378\n",
      "Epoch:76 step:16 loss: 0.000002\n",
      "Epoch:76 step:17 loss: 0.000195\n",
      "Epoch:76 step:18 loss: 0.008811\n",
      "Epoch:76 step:19 loss: 0.007679\n",
      "Epoch:76 step:20 loss: 0.000002\n",
      "Epoch:76 step:21 loss: 0.000016\n",
      "Epoch:76 step:22 loss: 0.012024\n",
      "Epoch:76 step:23 loss: 0.003166\n",
      "Epoch:76 step:24 loss: 0.002805\n",
      "Epoch:76 step:25 loss: 0.000584\n",
      "Epoch:76 step:26 loss: 0.004446\n",
      "Epoch:76 step:27 loss: 0.012543\n",
      "Epoch:76 step:28 loss: 0.000017\n",
      "Epoch:76 step:29 loss: 0.000000\n",
      "Epoch:76 step:30 loss: 0.000003\n",
      "Epoch:76 step:31 loss: 0.000116\n",
      "Epoch:76 step:32 loss: 0.000000\n",
      "Epoch:76 step:33 loss: 0.000000\n",
      "Epoch:76 step:34 loss: 0.006489\n",
      "Epoch:76 step:35 loss: 0.007841\n",
      "Epoch:76 step:36 loss: 0.000024\n",
      "Epoch:76 step:37 loss: 0.001202\n",
      "Epoch:76 step:38 loss: 0.000005\n",
      "Epoch:76 step:39 loss: 0.000002\n",
      "Epoch:76 step:40 loss: 0.012568\n",
      "Epoch:76 step:41 loss: 0.000000\n",
      "Epoch:76 step:42 loss: 0.000000\n",
      "Epoch:76 step:43 loss: 0.006977\n",
      "Epoch:76 step:44 loss: 0.000008\n",
      "Epoch:76 step:45 loss: 0.001225\n",
      "Epoch:76 step:46 loss: 0.000003\n",
      "Epoch:76 step:47 loss: 0.006894\n",
      "Epoch:76 step:48 loss: 0.001677\n",
      "Epoch:76 step:49 loss: 0.000000\n",
      "Epoch:76 step:50 loss: 0.000053\n",
      "Epoch:76 step:51 loss: 0.001540\n",
      "Epoch:76 step:52 loss: 0.000000\n",
      "Epoch:76 step:53 loss: 0.000111\n",
      "Epoch:76 step:54 loss: 0.010540\n",
      "Epoch:76 step:55 loss: 0.008491\n",
      "Epoch:76 step:56 loss: 0.004111\n",
      "Epoch:76 step:57 loss: 0.002324\n",
      "Epoch:76 step:58 loss: 0.006796\n",
      "Epoch:76 step:59 loss: 0.000591\n",
      "Epoch:76 step:60 loss: 0.009439\n",
      "Epoch:76 step:61 loss: 0.005387\n",
      "Epoch:76 step:62 loss: 0.000095\n",
      "Epoch:76 step:63 loss: 0.000345\n",
      "Epoch:76 step:64 loss: 0.000567\n",
      "Epoch:76 step:65 loss: 0.003547\n",
      "Epoch:76 step:66 loss: 0.000057\n",
      "Epoch:76 step:67 loss: 0.003662\n",
      "Epoch:76 step:68 loss: 0.000001\n",
      "Epoch:76 step:69 loss: 0.000001\n",
      "Epoch:76 step:70 loss: 0.001390\n",
      "Epoch:76 step:71 loss: 0.004566\n",
      "Epoch:76 step:72 loss: 0.002250\n",
      "Epoch:76 step:73 loss: 0.000002\n",
      "Epoch:76 step:74 loss: 0.003023\n",
      "Epoch:76 step:75 loss: 0.000001\n",
      "Epoch:76 step:76 loss: 0.000001\n",
      "Epoch:76 step:77 loss: 0.002681\n",
      "Epoch:76 step:78 loss: 0.005759\n",
      "Epoch:76 step:79 loss: 0.003225\n",
      "Test Epoch:76 step:0 loss: 0.002821tensor(0.3684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:1 loss: 0.002433tensor(0.2309, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:2 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:4 loss: 0.008367tensor(0.4030, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:5 loss: 0.004908tensor(0.3847, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:7 loss: 0.006355tensor(0.3634, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:9 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:11 loss: 0.003219tensor(0.3940, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:12 loss: 0.004156tensor(0.4621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:13 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:15 loss: 0.000080tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:17 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:18 loss: 0.002402tensor(0.3767, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:19 loss: 0.009380tensor(0.4187, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:20 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:21 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:22 loss: 0.011882tensor(0.4211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:23 loss: 0.001249tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:24 loss: 0.004667tensor(0.4323, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:25 loss: 0.000844tensor(0.2938, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:26 loss: 0.004937tensor(0.4224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:27 loss: 0.010907tensor(0.4621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:28 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:29 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:30 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:31 loss: 0.000240tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:32 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:34 loss: 0.005579tensor(0.3048, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:35 loss: 0.008703tensor(0.2240, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:36 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:37 loss: 0.001059tensor(0.1311, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:38 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:39 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:40 loss: 0.014056tensor(0.4553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:43 loss: 0.005536tensor(0.4401, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:44 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:45 loss: 0.001832tensor(0.3299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:47 loss: 0.005182tensor(0.4399, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:48 loss: 0.002636tensor(0.2730, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:50 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:51 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:52 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:53 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:54 loss: 0.006368tensor(0.4522, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:55 loss: 0.007396tensor(0.4468, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:56 loss: 0.006004tensor(0.4358, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:57 loss: 0.000133tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:58 loss: 0.003905tensor(0.2848, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:59 loss: 0.000122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:60 loss: 0.009517tensor(0.4594, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:61 loss: 0.007346tensor(0.3073, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:62 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:63 loss: 0.000680tensor(0.1662, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:64 loss: 0.000233tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:65 loss: 0.003346tensor(0.4312, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:76 step:66 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:67 loss: 0.003804tensor(0.4080, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:70 loss: 0.001234tensor(0.3608, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:71 loss: 0.005408tensor(0.4170, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:72 loss: 0.001515tensor(0.4400, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:73 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:74 loss: 0.003247tensor(0.4277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:75 loss: 0.000153tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:76 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:77 loss: 0.001642tensor(0.1961, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:78 loss: 0.005270tensor(0.4530, grad_fn=<DivBackward0>)\n",
      "Test Epoch:76 step:79 loss: 0.001548tensor(0.4168, grad_fn=<DivBackward0>)\n",
      "Epoch:77 step:0 loss: 0.002853\n",
      "Epoch:77 step:1 loss: 0.001698\n",
      "Epoch:77 step:2 loss: 0.000013\n",
      "Epoch:77 step:3 loss: 0.000000\n",
      "Epoch:77 step:4 loss: 0.008223\n",
      "Epoch:77 step:5 loss: 0.007743\n",
      "Epoch:77 step:6 loss: 0.000000\n",
      "Epoch:77 step:7 loss: 0.007009\n",
      "Epoch:77 step:8 loss: 0.000000\n",
      "Epoch:77 step:9 loss: 0.000003\n",
      "Epoch:77 step:10 loss: 0.000007\n",
      "Epoch:77 step:11 loss: 0.002858\n",
      "Epoch:77 step:12 loss: 0.003411\n",
      "Epoch:77 step:13 loss: 0.000002\n",
      "Epoch:77 step:14 loss: 0.000000\n",
      "Epoch:77 step:15 loss: 0.000016\n",
      "Epoch:77 step:16 loss: 0.000000\n",
      "Epoch:77 step:17 loss: 0.000100\n",
      "Epoch:77 step:18 loss: 0.002171\n",
      "Epoch:77 step:19 loss: 0.009680\n",
      "Epoch:77 step:20 loss: 0.000000\n",
      "Epoch:77 step:21 loss: 0.000000\n",
      "Epoch:77 step:22 loss: 0.010436\n",
      "Epoch:77 step:23 loss: 0.002757\n",
      "Epoch:77 step:24 loss: 0.005819\n",
      "Epoch:77 step:25 loss: 0.000520\n",
      "Epoch:77 step:26 loss: 0.005326\n",
      "Epoch:77 step:27 loss: 0.010736\n",
      "Epoch:77 step:28 loss: 0.000000\n",
      "Epoch:77 step:29 loss: 0.000000\n",
      "Epoch:77 step:30 loss: 0.000035\n",
      "Epoch:77 step:31 loss: 0.000012\n",
      "Epoch:77 step:32 loss: 0.000008\n",
      "Epoch:77 step:33 loss: 0.000000\n",
      "Epoch:77 step:34 loss: 0.004964\n",
      "Epoch:77 step:35 loss: 0.005120\n",
      "Epoch:77 step:36 loss: 0.000015\n",
      "Epoch:77 step:37 loss: 0.000779\n",
      "Epoch:77 step:38 loss: 0.000008\n",
      "Epoch:77 step:39 loss: 0.000024\n",
      "Epoch:77 step:40 loss: 0.010072\n",
      "Epoch:77 step:41 loss: 0.000000\n",
      "Epoch:77 step:42 loss: 0.000000\n",
      "Epoch:77 step:43 loss: 0.006608\n",
      "Epoch:77 step:44 loss: 0.000008\n",
      "Epoch:77 step:45 loss: 0.001086\n",
      "Epoch:77 step:46 loss: 0.000000\n",
      "Epoch:77 step:47 loss: 0.005021\n",
      "Epoch:77 step:48 loss: 0.001729\n",
      "Epoch:77 step:49 loss: 0.000003\n",
      "Epoch:77 step:50 loss: 0.000040\n",
      "Epoch:77 step:51 loss: 0.000010\n",
      "Epoch:77 step:52 loss: 0.000003\n",
      "Epoch:77 step:53 loss: 0.000006\n",
      "Epoch:77 step:54 loss: 0.005786\n",
      "Epoch:77 step:55 loss: 0.008552\n",
      "Epoch:77 step:56 loss: 0.003496\n",
      "Epoch:77 step:57 loss: 0.000398\n",
      "Epoch:77 step:58 loss: 0.005158\n",
      "Epoch:77 step:59 loss: 0.000141\n",
      "Epoch:77 step:60 loss: 0.009346\n",
      "Epoch:77 step:61 loss: 0.004350\n",
      "Epoch:77 step:62 loss: 0.000002\n",
      "Epoch:77 step:63 loss: 0.000530\n",
      "Epoch:77 step:64 loss: 0.000228\n",
      "Epoch:77 step:65 loss: 0.004283\n",
      "Epoch:77 step:66 loss: 0.000004\n",
      "Epoch:77 step:67 loss: 0.004744\n",
      "Epoch:77 step:68 loss: 0.000000\n",
      "Epoch:77 step:69 loss: 0.000000\n",
      "Epoch:77 step:70 loss: 0.001740\n",
      "Epoch:77 step:71 loss: 0.003669\n",
      "Epoch:77 step:72 loss: 0.001519\n",
      "Epoch:77 step:73 loss: 0.000057\n",
      "Epoch:77 step:74 loss: 0.003352\n",
      "Epoch:77 step:75 loss: 0.000052\n",
      "Epoch:77 step:76 loss: 0.000011\n",
      "Epoch:77 step:77 loss: 0.000498\n",
      "Epoch:77 step:78 loss: 0.004910\n",
      "Epoch:77 step:79 loss: 0.001671\n",
      "Test Epoch:77 step:0 loss: 0.003061tensor(0.3519, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:1 loss: 0.001790tensor(0.2823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:2 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:4 loss: 0.008636tensor(0.4005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:5 loss: 0.009676tensor(0.3232, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:7 loss: 0.004402tensor(0.3774, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:9 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:11 loss: 0.004305tensor(0.3617, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:12 loss: 0.004634tensor(0.4590, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:13 loss: 0.000034tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:15 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:17 loss: 0.000347tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:18 loss: 0.004233tensor(0.3571, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:19 loss: 0.009152tensor(0.4189, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:22 loss: 0.008976tensor(0.4349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:23 loss: 0.000353tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:24 loss: 0.003510tensor(0.4424, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:25 loss: 0.000645tensor(0.2991, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:26 loss: 0.006514tensor(0.4173, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:27 loss: 0.009828tensor(0.4650, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:30 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:31 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:32 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:34 loss: 0.005058tensor(0.3228, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:35 loss: 0.002712tensor(0.3449, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:36 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:37 loss: 0.000793tensor(0.2058, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:38 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:39 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:40 loss: 0.013037tensor(0.4588, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:43 loss: 0.006574tensor(0.4379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:44 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:45 loss: 0.001445tensor(0.3350, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:47 loss: 0.005059tensor(0.4428, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:48 loss: 0.001502tensor(0.3296, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:50 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:51 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:53 loss: 0.000192tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:54 loss: 0.006082tensor(0.4537, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:55 loss: 0.007024tensor(0.4476, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:56 loss: 0.004280tensor(0.4520, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:57 loss: 0.000483tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:58 loss: 0.003193tensor(0.3418, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:59 loss: 0.001235tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:60 loss: 0.007635tensor(0.4643, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:61 loss: 0.005051tensor(0.3472, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:62 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:77 step:63 loss: 0.000411tensor(0.1864, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:64 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:65 loss: 0.004203tensor(0.4164, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:66 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:67 loss: 0.004676tensor(0.4014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:70 loss: 0.000870tensor(0.4062, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:71 loss: 0.004843tensor(0.4188, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:72 loss: 0.001401tensor(0.4499, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:73 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:74 loss: 0.003974tensor(0.4256, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:75 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:76 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:77 loss: 0.001583tensor(0.2238, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:78 loss: 0.004615tensor(0.4600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:77 step:79 loss: 0.001457tensor(0.4233, grad_fn=<DivBackward0>)\n",
      "Epoch:78 step:0 loss: 0.002708\n",
      "Epoch:78 step:1 loss: 0.001941\n",
      "Epoch:78 step:2 loss: 0.000097\n",
      "Epoch:78 step:3 loss: 0.000000\n",
      "Epoch:78 step:4 loss: 0.008184\n",
      "Epoch:78 step:5 loss: 0.004507\n",
      "Epoch:78 step:6 loss: 0.000000\n",
      "Epoch:78 step:7 loss: 0.004116\n",
      "Epoch:78 step:8 loss: 0.000000\n",
      "Epoch:78 step:9 loss: 0.000002\n",
      "Epoch:78 step:10 loss: 0.000001\n",
      "Epoch:78 step:11 loss: 0.003600\n",
      "Epoch:78 step:12 loss: 0.004666\n",
      "Epoch:78 step:13 loss: 0.000001\n",
      "Epoch:78 step:14 loss: 0.000000\n",
      "Epoch:78 step:15 loss: 0.000007\n",
      "Epoch:78 step:16 loss: 0.000000\n",
      "Epoch:78 step:17 loss: 0.000052\n",
      "Epoch:78 step:18 loss: 0.002557\n",
      "Epoch:78 step:19 loss: 0.008837\n",
      "Epoch:78 step:20 loss: 0.000001\n",
      "Epoch:78 step:21 loss: 0.000007\n",
      "Epoch:78 step:22 loss: 0.010954\n",
      "Epoch:78 step:23 loss: 0.001103\n",
      "Epoch:78 step:24 loss: 0.007853\n",
      "Epoch:78 step:25 loss: 0.000866\n",
      "Epoch:78 step:26 loss: 0.006511\n",
      "Epoch:78 step:27 loss: 0.009673\n",
      "Epoch:78 step:28 loss: 0.000002\n",
      "Epoch:78 step:29 loss: 0.000000\n",
      "Epoch:78 step:30 loss: 0.000386\n",
      "Epoch:78 step:31 loss: 0.000036\n",
      "Epoch:78 step:32 loss: 0.000034\n",
      "Epoch:78 step:33 loss: 0.000000\n",
      "Epoch:78 step:34 loss: 0.003071\n",
      "Epoch:78 step:35 loss: 0.002946\n",
      "Epoch:78 step:36 loss: 0.000013\n",
      "Epoch:78 step:37 loss: 0.000703\n",
      "Epoch:78 step:38 loss: 0.000030\n",
      "Epoch:78 step:39 loss: 0.000014\n",
      "Epoch:78 step:40 loss: 0.008842\n",
      "Epoch:78 step:41 loss: 0.000001\n",
      "Epoch:78 step:42 loss: 0.000026\n",
      "Epoch:78 step:43 loss: 0.008299\n",
      "Epoch:78 step:44 loss: 0.000005\n",
      "Epoch:78 step:45 loss: 0.001604\n",
      "Epoch:78 step:46 loss: 0.000000\n",
      "Epoch:78 step:47 loss: 0.006995\n",
      "Epoch:78 step:48 loss: 0.001908\n",
      "Epoch:78 step:49 loss: 0.000000\n",
      "Epoch:78 step:50 loss: 0.000009\n",
      "Epoch:78 step:51 loss: 0.000024\n",
      "Epoch:78 step:52 loss: 0.000001\n",
      "Epoch:78 step:53 loss: 0.000015\n",
      "Epoch:78 step:54 loss: 0.010311\n",
      "Epoch:78 step:55 loss: 0.009375\n",
      "Epoch:78 step:56 loss: 0.005055\n",
      "Epoch:78 step:57 loss: 0.000325\n",
      "Epoch:78 step:58 loss: 0.015686\n",
      "Epoch:78 step:59 loss: 0.000845\n",
      "Epoch:78 step:60 loss: 0.014821\n",
      "Epoch:78 step:61 loss: 0.008736\n",
      "Epoch:78 step:62 loss: 0.000026\n",
      "Epoch:78 step:63 loss: 0.000568\n",
      "Epoch:78 step:64 loss: 0.000126\n",
      "Epoch:78 step:65 loss: 0.003611\n",
      "Epoch:78 step:66 loss: 0.000001\n",
      "Epoch:78 step:67 loss: 0.005520\n",
      "Epoch:78 step:68 loss: 0.000001\n",
      "Epoch:78 step:69 loss: 0.000001\n",
      "Epoch:78 step:70 loss: 0.002356\n",
      "Epoch:78 step:71 loss: 0.005792\n",
      "Epoch:78 step:72 loss: 0.001772\n",
      "Epoch:78 step:73 loss: 0.000001\n",
      "Epoch:78 step:74 loss: 0.004504\n",
      "Epoch:78 step:75 loss: 0.000157\n",
      "Epoch:78 step:76 loss: 0.000002\n",
      "Epoch:78 step:77 loss: 0.000548\n",
      "Epoch:78 step:78 loss: 0.009047\n",
      "Epoch:78 step:79 loss: 0.002950\n",
      "Test Epoch:78 step:0 loss: 0.003480tensor(0.3509, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:1 loss: 0.005915tensor(0.1917, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:2 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:4 loss: 0.013230tensor(0.3817, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:5 loss: 0.007638tensor(0.3422, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:7 loss: 0.006592tensor(0.3317, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:8 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:9 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:11 loss: 0.003100tensor(0.3891, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:12 loss: 0.005947tensor(0.4520, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:13 loss: 0.000129tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:14 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:15 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:16 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:17 loss: 0.000272tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:18 loss: 0.005899tensor(0.2573, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:19 loss: 0.010005tensor(0.4111, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:20 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:21 loss: 0.000120tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:22 loss: 0.011795tensor(0.4217, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:23 loss: 0.005028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:24 loss: 0.008141tensor(0.3922, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:25 loss: 0.000717tensor(0.2249, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:26 loss: 0.008391tensor(0.4000, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:27 loss: 0.010882tensor(0.4602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:28 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:29 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:30 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:31 loss: 0.000171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:32 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:34 loss: 0.004914tensor(0.3192, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:35 loss: 0.005986tensor(0.2569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:36 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:37 loss: 0.002389tensor(0.0110, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:38 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:39 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:40 loss: 0.020470tensor(0.4413, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:42 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:43 loss: 0.008522tensor(0.4269, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:44 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:45 loss: 0.001542tensor(0.3368, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:46 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:47 loss: 0.005238tensor(0.4363, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:48 loss: 0.002321tensor(0.2655, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:49 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:50 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:51 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:52 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:53 loss: 0.000852tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:54 loss: 0.012997tensor(0.4253, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:55 loss: 0.019318tensor(0.4218, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:56 loss: 0.006487tensor(0.4247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:57 loss: 0.000093tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:58 loss: 0.008317tensor(0.1709, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:59 loss: 0.003433tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:78 step:60 loss: 0.020896tensor(0.4270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:61 loss: 0.007850tensor(0.2768, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:62 loss: 0.000711tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:63 loss: 0.000876tensor(0.1707, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:64 loss: 0.003870tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:65 loss: 0.003558tensor(0.4212, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:66 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:67 loss: 0.004509tensor(0.3924, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:68 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:69 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:70 loss: 0.001531tensor(0.3216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:71 loss: 0.004420tensor(0.4202, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:72 loss: 0.002266tensor(0.4155, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:73 loss: 0.001072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:74 loss: 0.005668tensor(0.3912, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:75 loss: 0.000389tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:76 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:77 loss: 0.000476tensor(0.2695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:78 loss: 0.006932tensor(0.4374, grad_fn=<DivBackward0>)\n",
      "Test Epoch:78 step:79 loss: 0.003293tensor(0.3636, grad_fn=<DivBackward0>)\n",
      "Epoch:79 step:0 loss: 0.005854\n",
      "Epoch:79 step:1 loss: 0.004468\n",
      "Epoch:79 step:2 loss: 0.000025\n",
      "Epoch:79 step:3 loss: 0.000001\n",
      "Epoch:79 step:4 loss: 0.005690\n",
      "Epoch:79 step:5 loss: 0.006720\n",
      "Epoch:79 step:6 loss: 0.000001\n",
      "Epoch:79 step:7 loss: 0.006413\n",
      "Epoch:79 step:8 loss: 0.000005\n",
      "Epoch:79 step:9 loss: 0.000027\n",
      "Epoch:79 step:10 loss: 0.000007\n",
      "Epoch:79 step:11 loss: 0.005055\n",
      "Epoch:79 step:12 loss: 0.010492\n",
      "Epoch:79 step:13 loss: 0.000026\n",
      "Epoch:79 step:14 loss: 0.000002\n",
      "Epoch:79 step:15 loss: 0.000050\n",
      "Epoch:79 step:16 loss: 0.000002\n",
      "Epoch:79 step:17 loss: 0.000734\n",
      "Epoch:79 step:18 loss: 0.003187\n",
      "Epoch:79 step:19 loss: 0.008332\n",
      "Epoch:79 step:20 loss: 0.000010\n",
      "Epoch:79 step:21 loss: 0.000004\n",
      "Epoch:79 step:22 loss: 0.010168\n",
      "Epoch:79 step:23 loss: 0.004033\n",
      "Epoch:79 step:24 loss: 0.012167\n",
      "Epoch:79 step:25 loss: 0.002727\n",
      "Epoch:79 step:26 loss: 0.010261\n",
      "Epoch:79 step:27 loss: 0.012865\n",
      "Epoch:79 step:28 loss: 0.000348\n",
      "Epoch:79 step:29 loss: 0.000004\n",
      "Epoch:79 step:30 loss: 0.000110\n",
      "Epoch:79 step:31 loss: 0.000103\n",
      "Epoch:79 step:32 loss: 0.000016\n",
      "Epoch:79 step:33 loss: 0.000001\n",
      "Epoch:79 step:34 loss: 0.008682\n",
      "Epoch:79 step:35 loss: 0.007066\n",
      "Epoch:79 step:36 loss: 0.000003\n",
      "Epoch:79 step:37 loss: 0.001483\n",
      "Epoch:79 step:38 loss: 0.000000\n",
      "Epoch:79 step:39 loss: 0.000015\n",
      "Epoch:79 step:40 loss: 0.037969\n",
      "Epoch:79 step:41 loss: 0.000022\n",
      "Epoch:79 step:42 loss: 0.000000\n",
      "Epoch:79 step:43 loss: 0.010000\n",
      "Epoch:79 step:44 loss: 0.000065\n",
      "Epoch:79 step:45 loss: 0.003211\n",
      "Epoch:79 step:46 loss: 0.000123\n",
      "Epoch:79 step:47 loss: 0.011092\n",
      "Epoch:79 step:48 loss: 0.004148\n",
      "Epoch:79 step:49 loss: 0.000017\n",
      "Epoch:79 step:50 loss: 0.001113\n",
      "Epoch:79 step:51 loss: 0.000032\n",
      "Epoch:79 step:52 loss: 0.000027\n",
      "Epoch:79 step:53 loss: 0.001922\n",
      "Epoch:79 step:54 loss: 0.043306\n",
      "Epoch:79 step:55 loss: 0.015260\n",
      "Epoch:79 step:56 loss: 0.009434\n",
      "Epoch:79 step:57 loss: 0.001132\n",
      "Epoch:79 step:58 loss: 0.005891\n",
      "Epoch:79 step:59 loss: 0.001998\n",
      "Epoch:79 step:60 loss: 0.025725\n",
      "Epoch:79 step:61 loss: 0.005961\n",
      "Epoch:79 step:62 loss: 0.000034\n",
      "Epoch:79 step:63 loss: 0.001483\n",
      "Epoch:79 step:64 loss: 0.001327\n",
      "Epoch:79 step:65 loss: 0.012891\n",
      "Epoch:79 step:66 loss: 0.000099\n",
      "Epoch:79 step:67 loss: 0.004601\n",
      "Epoch:79 step:68 loss: 0.000009\n",
      "Epoch:79 step:69 loss: 0.000034\n",
      "Epoch:79 step:70 loss: 0.001798\n",
      "Epoch:79 step:71 loss: 0.012084\n",
      "Epoch:79 step:72 loss: 0.005629\n",
      "Epoch:79 step:73 loss: 0.000059\n",
      "Epoch:79 step:74 loss: 0.003373\n",
      "Epoch:79 step:75 loss: 0.000347\n",
      "Epoch:79 step:76 loss: 0.000010\n",
      "Epoch:79 step:77 loss: 0.001352\n",
      "Epoch:79 step:78 loss: 0.010790\n",
      "Epoch:79 step:79 loss: 0.006318\n",
      "Test Epoch:79 step:0 loss: 0.003900tensor(0.3058, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:1 loss: 0.001974tensor(0.2273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:2 loss: 0.000208tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:4 loss: 0.006769tensor(0.4031, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:5 loss: 0.003630tensor(0.3985, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:6 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:7 loss: 0.006503tensor(0.3106, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:8 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:9 loss: 0.000117tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:10 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:11 loss: 0.007576tensor(0.3469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:12 loss: 0.013954tensor(0.4244, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:13 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:14 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:15 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:16 loss: 0.000431tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:17 loss: 0.001596tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:18 loss: 0.002371tensor(0.3701, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:19 loss: 0.016448tensor(0.3792, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:20 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:21 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:22 loss: 0.017235tensor(0.3795, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:23 loss: 0.001505tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:24 loss: 0.006834tensor(0.4076, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:25 loss: 0.001283tensor(0.0907, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:26 loss: 0.012816tensor(0.3439, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:27 loss: 0.011989tensor(0.4480, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:28 loss: 0.000480tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:29 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:30 loss: 0.000421tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:31 loss: 0.004053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:32 loss: 0.000175tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:33 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:34 loss: 0.005346tensor(0.2763, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:35 loss: 0.007923tensor(0.1987, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:36 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:37 loss: 0.000900tensor(0.1605, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:38 loss: 0.000425tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:39 loss: 0.001727tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:40 loss: 0.023593tensor(0.4256, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:41 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:42 loss: 0.000109tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:43 loss: 0.007936tensor(0.4254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:44 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:45 loss: 0.001202tensor(0.3386, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:46 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:47 loss: 0.010177tensor(0.4118, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:48 loss: 0.002725tensor(0.2351, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:49 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:50 loss: 0.000273tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:51 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:52 loss: 0.000050tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:53 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:54 loss: 0.009880tensor(0.4169, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:55 loss: 0.015451tensor(0.3966, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:56 loss: 0.006760tensor(0.4239, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:79 step:57 loss: 0.004117tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:58 loss: 0.017976tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:59 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:60 loss: 0.014549tensor(0.4372, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:61 loss: 0.014085tensor(0.1390, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:63 loss: 0.001884tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:64 loss: 0.000116tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:65 loss: 0.007772tensor(0.3527, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:66 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:67 loss: 0.016946tensor(0.2741, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:69 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:70 loss: 0.001712tensor(0.3014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:71 loss: 0.008202tensor(0.3626, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:72 loss: 0.014898tensor(0.2412, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:73 loss: 0.000077tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:74 loss: 0.006640tensor(0.3843, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:75 loss: 0.000482tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:76 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:77 loss: 0.003836tensor(4.4724e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:78 loss: 0.037114tensor(0.3133, grad_fn=<DivBackward0>)\n",
      "Test Epoch:79 step:79 loss: 0.003346tensor(0.3488, grad_fn=<DivBackward0>)\n",
      "Epoch:80 step:0 loss: 0.006053\n",
      "Epoch:80 step:1 loss: 0.005555\n",
      "Epoch:80 step:2 loss: 0.000450\n",
      "Epoch:80 step:3 loss: 0.000056\n",
      "Epoch:80 step:4 loss: 0.011908\n",
      "Epoch:80 step:5 loss: 0.008081\n",
      "Epoch:80 step:6 loss: 0.000039\n",
      "Epoch:80 step:7 loss: 0.007691\n",
      "Epoch:80 step:8 loss: 0.000049\n",
      "Epoch:80 step:9 loss: 0.000675\n",
      "Epoch:80 step:10 loss: 0.000018\n",
      "Epoch:80 step:11 loss: 0.007194\n",
      "Epoch:80 step:12 loss: 0.005323\n",
      "Epoch:80 step:13 loss: 0.000263\n",
      "Epoch:80 step:14 loss: 0.000027\n",
      "Epoch:80 step:15 loss: 0.000241\n",
      "Epoch:80 step:16 loss: 0.000006\n",
      "Epoch:80 step:17 loss: 0.000074\n",
      "Epoch:80 step:18 loss: 0.008571\n",
      "Epoch:80 step:19 loss: 0.029114\n",
      "Epoch:80 step:20 loss: 0.000007\n",
      "Epoch:80 step:21 loss: 0.000010\n",
      "Epoch:80 step:22 loss: 0.019240\n",
      "Epoch:80 step:23 loss: 0.000177\n",
      "Epoch:80 step:24 loss: 0.006686\n",
      "Epoch:80 step:25 loss: 0.000939\n",
      "Epoch:80 step:26 loss: 0.016009\n",
      "Epoch:80 step:27 loss: 0.043152\n",
      "Epoch:80 step:28 loss: 0.000009\n",
      "Epoch:80 step:29 loss: 0.000282\n",
      "Epoch:80 step:30 loss: 0.000867\n",
      "Epoch:80 step:31 loss: 0.000023\n",
      "Epoch:80 step:32 loss: 0.000010\n",
      "Epoch:80 step:33 loss: 0.000001\n",
      "Epoch:80 step:34 loss: 0.016971\n",
      "Epoch:80 step:35 loss: 0.009988\n",
      "Epoch:80 step:36 loss: 0.000545\n",
      "Epoch:80 step:37 loss: 0.001181\n",
      "Epoch:80 step:38 loss: 0.000041\n",
      "Epoch:80 step:39 loss: 0.000069\n",
      "Epoch:80 step:40 loss: 0.040064\n",
      "Epoch:80 step:41 loss: 0.000002\n",
      "Epoch:80 step:42 loss: 0.000019\n",
      "Epoch:80 step:43 loss: 0.006723\n",
      "Epoch:80 step:44 loss: 0.000040\n",
      "Epoch:80 step:45 loss: 0.002111\n",
      "Epoch:80 step:46 loss: 0.000116\n",
      "Epoch:80 step:47 loss: 0.007013\n",
      "Epoch:80 step:48 loss: 0.002846\n",
      "Epoch:80 step:49 loss: 0.000005\n",
      "Epoch:80 step:50 loss: 0.000964\n",
      "Epoch:80 step:51 loss: 0.002052\n",
      "Epoch:80 step:52 loss: 0.000005\n",
      "Epoch:80 step:53 loss: 0.000166\n",
      "Epoch:80 step:54 loss: 0.015868\n",
      "Epoch:80 step:55 loss: 0.014498\n",
      "Epoch:80 step:56 loss: 0.004928\n",
      "Epoch:80 step:57 loss: 0.004002\n",
      "Epoch:80 step:58 loss: 0.039452\n",
      "Epoch:80 step:59 loss: 0.000284\n",
      "Epoch:80 step:60 loss: 0.011269\n",
      "Epoch:80 step:61 loss: 0.006406\n",
      "Epoch:80 step:62 loss: 0.000083\n",
      "Epoch:80 step:63 loss: 0.000789\n",
      "Epoch:80 step:64 loss: 0.003678\n",
      "Epoch:80 step:65 loss: 0.007048\n",
      "Epoch:80 step:66 loss: 0.000275\n",
      "Epoch:80 step:67 loss: 0.005137\n",
      "Epoch:80 step:68 loss: 0.000018\n",
      "Epoch:80 step:69 loss: 0.000761\n",
      "Epoch:80 step:70 loss: 0.004174\n",
      "Epoch:80 step:71 loss: 0.005172\n",
      "Epoch:80 step:72 loss: 0.001989\n",
      "Epoch:80 step:73 loss: 0.000044\n",
      "Epoch:80 step:74 loss: 0.006546\n",
      "Epoch:80 step:75 loss: 0.000226\n",
      "Epoch:80 step:76 loss: 0.000060\n",
      "Epoch:80 step:77 loss: 0.000668\n",
      "Epoch:80 step:78 loss: 0.016447\n",
      "Epoch:80 step:79 loss: 0.002996\n",
      "Test Epoch:80 step:0 loss: 0.006547tensor(0.2280, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:1 loss: 0.007678tensor(0.1218, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:2 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:3 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:4 loss: 0.009726tensor(0.3629, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:5 loss: 0.004588tensor(0.3757, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:6 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:7 loss: 0.008838tensor(0.2881, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:8 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:9 loss: 0.000433tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:10 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:11 loss: 0.005451tensor(0.3341, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:12 loss: 0.042074tensor(0.2385, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:13 loss: 0.000798tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:14 loss: 0.000183tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:15 loss: 0.000924tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:16 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:17 loss: 0.012826tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:18 loss: 0.007549tensor(0.2477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:19 loss: 0.019958tensor(0.3095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:20 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:21 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:22 loss: 0.026641tensor(0.3346, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:23 loss: 0.000857tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:24 loss: 0.006505tensor(0.3995, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:25 loss: 0.002629tensor(0.0489, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:26 loss: 0.009938tensor(0.3523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:27 loss: 0.020679tensor(0.4251, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:28 loss: 0.000647tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:29 loss: 0.000045tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:30 loss: 0.002738tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:31 loss: 0.011216tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:32 loss: 0.007309tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:33 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:34 loss: 0.011458tensor(0.1588, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:35 loss: 0.007027tensor(0.2630, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:36 loss: 0.000107tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:37 loss: 0.001302tensor(0.0780, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:38 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:39 loss: 0.001735tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:40 loss: 0.017386tensor(0.4297, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:42 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:43 loss: 0.027373tensor(0.3391, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:44 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:45 loss: 0.004397tensor(0.0474, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:46 loss: 0.000204tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:47 loss: 0.017471tensor(0.3753, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:48 loss: 0.011029tensor(0.0173, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:49 loss: 0.000809tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:50 loss: 0.000320tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:51 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:52 loss: 0.000841tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:53 loss: 0.002497tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:80 step:54 loss: 0.020938tensor(0.3445, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:55 loss: 0.022324tensor(0.3263, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:56 loss: 0.013305tensor(0.3704, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:57 loss: 0.000291tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:58 loss: 0.028003tensor(0.0904, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:59 loss: 0.006279tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:60 loss: 0.015292tensor(0.4254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:61 loss: 0.009274tensor(0.1902, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:62 loss: 0.000118tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:63 loss: 0.005420tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:64 loss: 0.000655tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:65 loss: 0.016566tensor(0.1663, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:66 loss: 0.000372tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:67 loss: 0.007521tensor(0.3380, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:68 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:69 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:70 loss: 0.003683tensor(0.0988, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:71 loss: 0.009985tensor(0.3398, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:72 loss: 0.002578tensor(0.3960, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:73 loss: 0.000066tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:74 loss: 0.004647tensor(0.4005, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:75 loss: 0.000119tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:76 loss: 0.000360tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:77 loss: 0.001793tensor(0.0134, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:78 loss: 0.021872tensor(0.3665, grad_fn=<DivBackward0>)\n",
      "Test Epoch:80 step:79 loss: 0.006967tensor(0.2591, grad_fn=<DivBackward0>)\n",
      "Epoch:81 step:0 loss: 0.009090\n",
      "Epoch:81 step:1 loss: 0.004749\n",
      "Epoch:81 step:2 loss: 0.002144\n",
      "Epoch:81 step:3 loss: 0.000003\n",
      "Epoch:81 step:4 loss: 0.018260\n",
      "Epoch:81 step:5 loss: 0.005663\n",
      "Epoch:81 step:6 loss: 0.000003\n",
      "Epoch:81 step:7 loss: 0.010859\n",
      "Epoch:81 step:8 loss: 0.000011\n",
      "Epoch:81 step:9 loss: 0.000029\n",
      "Epoch:81 step:10 loss: 0.000033\n",
      "Epoch:81 step:11 loss: 0.005034\n",
      "Epoch:81 step:12 loss: 0.008388\n",
      "Epoch:81 step:13 loss: 0.000385\n",
      "Epoch:81 step:14 loss: 0.000283\n",
      "Epoch:81 step:15 loss: 0.000120\n",
      "Epoch:81 step:16 loss: 0.000011\n",
      "Epoch:81 step:17 loss: 0.000230\n",
      "Epoch:81 step:18 loss: 0.005995\n",
      "Epoch:81 step:19 loss: 0.022683\n",
      "Epoch:81 step:20 loss: 0.000055\n",
      "Epoch:81 step:21 loss: 0.000012\n",
      "Epoch:81 step:22 loss: 0.021919\n",
      "Epoch:81 step:23 loss: 0.001114\n",
      "Epoch:81 step:24 loss: 0.005893\n",
      "Epoch:81 step:25 loss: 0.000903\n",
      "Epoch:81 step:26 loss: 0.011891\n",
      "Epoch:81 step:27 loss: 0.014668\n",
      "Epoch:81 step:28 loss: 0.000014\n",
      "Epoch:81 step:29 loss: 0.000052\n",
      "Epoch:81 step:30 loss: 0.001109\n",
      "Epoch:81 step:31 loss: 0.002349\n",
      "Epoch:81 step:32 loss: 0.002280\n",
      "Epoch:81 step:33 loss: 0.000011\n",
      "Epoch:81 step:34 loss: 0.005770\n",
      "Epoch:81 step:35 loss: 0.005224\n",
      "Epoch:81 step:36 loss: 0.000130\n",
      "Epoch:81 step:37 loss: 0.001872\n",
      "Epoch:81 step:38 loss: 0.000396\n",
      "Epoch:81 step:39 loss: 0.002671\n",
      "Epoch:81 step:40 loss: 0.020287\n",
      "Epoch:81 step:41 loss: 0.000004\n",
      "Epoch:81 step:42 loss: 0.000137\n",
      "Epoch:81 step:43 loss: 0.008510\n",
      "Epoch:81 step:44 loss: 0.000021\n",
      "Epoch:81 step:45 loss: 0.005934\n",
      "Epoch:81 step:46 loss: 0.000019\n",
      "Epoch:81 step:47 loss: 0.017350\n",
      "Epoch:81 step:48 loss: 0.008073\n",
      "Epoch:81 step:49 loss: 0.000038\n",
      "Epoch:81 step:50 loss: 0.001348\n",
      "Epoch:81 step:51 loss: 0.000057\n",
      "Epoch:81 step:52 loss: 0.000036\n",
      "Epoch:81 step:53 loss: 0.000167\n",
      "Epoch:81 step:54 loss: 0.023690\n",
      "Epoch:81 step:55 loss: 0.013350\n",
      "Epoch:81 step:56 loss: 0.012173\n",
      "Epoch:81 step:57 loss: 0.000045\n",
      "Epoch:81 step:58 loss: 0.004776\n",
      "Epoch:81 step:59 loss: 0.001615\n",
      "Epoch:81 step:60 loss: 0.014702\n",
      "Epoch:81 step:61 loss: 0.005964\n",
      "Epoch:81 step:62 loss: 0.000178\n",
      "Epoch:81 step:63 loss: 0.005411\n",
      "Epoch:81 step:64 loss: 0.006800\n",
      "Epoch:81 step:65 loss: 0.006496\n",
      "Epoch:81 step:66 loss: 0.000582\n",
      "Epoch:81 step:67 loss: 0.007661\n",
      "Epoch:81 step:68 loss: 0.000001\n",
      "Epoch:81 step:69 loss: 0.000003\n",
      "Epoch:81 step:70 loss: 0.002230\n",
      "Epoch:81 step:71 loss: 0.010211\n",
      "Epoch:81 step:72 loss: 0.006849\n",
      "Epoch:81 step:73 loss: 0.000120\n",
      "Epoch:81 step:74 loss: 0.024674\n",
      "Epoch:81 step:75 loss: 0.000044\n",
      "Epoch:81 step:76 loss: 0.000024\n",
      "Epoch:81 step:77 loss: 0.003399\n",
      "Epoch:81 step:78 loss: 0.008076\n",
      "Epoch:81 step:79 loss: 0.002492\n",
      "Test Epoch:81 step:0 loss: 0.005496tensor(0.2304, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:1 loss: 0.002871tensor(0.1711, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:2 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:3 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:4 loss: 0.010014tensor(0.3805, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:5 loss: 0.007088tensor(0.3468, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:6 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:7 loss: 0.006908tensor(0.3238, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:8 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:9 loss: 0.000463tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:10 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:11 loss: 0.003525tensor(0.3671, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:12 loss: 0.006922tensor(0.4414, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:13 loss: 0.000223tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:14 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:15 loss: 0.000331tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:16 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:17 loss: 0.000539tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:18 loss: 0.005945tensor(0.2616, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:19 loss: 0.010047tensor(0.3925, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:20 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:21 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:22 loss: 0.011449tensor(0.4127, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:23 loss: 0.001242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:24 loss: 0.004465tensor(0.4215, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:25 loss: 0.000694tensor(0.2713, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:26 loss: 0.009132tensor(0.3681, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:27 loss: 0.014027tensor(0.4461, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:28 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:29 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:30 loss: 0.000580tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:31 loss: 0.000761tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:32 loss: 0.000067tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:33 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:34 loss: 0.005066tensor(0.2883, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:35 loss: 0.003278tensor(0.3233, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:36 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:37 loss: 0.002088tensor(0.1718, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:38 loss: 0.000218tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:39 loss: 0.001782tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:40 loss: 0.011989tensor(0.4546, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:41 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:42 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:43 loss: 0.008930tensor(0.4224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:44 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:45 loss: 0.001548tensor(0.3061, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:46 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:47 loss: 0.007833tensor(0.4199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:48 loss: 0.003910tensor(0.1138, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:49 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:50 loss: 0.000292tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:81 step:51 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:52 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:53 loss: 0.000085tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:54 loss: 0.014061tensor(0.4108, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:55 loss: 0.008728tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:56 loss: 0.009808tensor(0.4097, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:57 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:58 loss: 0.007351tensor(0.2254, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:59 loss: 0.000312tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:60 loss: 0.008991tensor(0.4556, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:61 loss: 0.005090tensor(0.3325, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:62 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:63 loss: 0.001556tensor(0.1111, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:64 loss: 0.002716tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:65 loss: 0.004313tensor(0.4122, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:66 loss: 0.001505tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:67 loss: 0.007245tensor(0.3766, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:68 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:69 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:70 loss: 0.001539tensor(0.3383, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:71 loss: 0.006136tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:72 loss: 0.001650tensor(0.4332, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:73 loss: 0.000054tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:74 loss: 0.003117tensor(0.4260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:75 loss: 0.000310tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:76 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:77 loss: 0.000693tensor(0.1693, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:78 loss: 0.008457tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:81 step:79 loss: 0.001678tensor(0.4058, grad_fn=<DivBackward0>)\n",
      "Epoch:82 step:0 loss: 0.006752\n",
      "Epoch:82 step:1 loss: 0.002652\n",
      "Epoch:82 step:2 loss: 0.000007\n",
      "Epoch:82 step:3 loss: 0.000001\n",
      "Epoch:82 step:4 loss: 0.009576\n",
      "Epoch:82 step:5 loss: 0.007469\n",
      "Epoch:82 step:6 loss: 0.000001\n",
      "Epoch:82 step:7 loss: 0.006651\n",
      "Epoch:82 step:8 loss: 0.000004\n",
      "Epoch:82 step:9 loss: 0.000070\n",
      "Epoch:82 step:10 loss: 0.000012\n",
      "Epoch:82 step:11 loss: 0.002858\n",
      "Epoch:82 step:12 loss: 0.004275\n",
      "Epoch:82 step:13 loss: 0.000166\n",
      "Epoch:82 step:14 loss: 0.000007\n",
      "Epoch:82 step:15 loss: 0.000295\n",
      "Epoch:82 step:16 loss: 0.000008\n",
      "Epoch:82 step:17 loss: 0.000374\n",
      "Epoch:82 step:18 loss: 0.003374\n",
      "Epoch:82 step:19 loss: 0.008708\n",
      "Epoch:82 step:20 loss: 0.000037\n",
      "Epoch:82 step:21 loss: 0.000011\n",
      "Epoch:82 step:22 loss: 0.013642\n",
      "Epoch:82 step:23 loss: 0.000365\n",
      "Epoch:82 step:24 loss: 0.003500\n",
      "Epoch:82 step:25 loss: 0.000761\n",
      "Epoch:82 step:26 loss: 0.006628\n",
      "Epoch:82 step:27 loss: 0.010688\n",
      "Epoch:82 step:28 loss: 0.000002\n",
      "Epoch:82 step:29 loss: 0.000002\n",
      "Epoch:82 step:30 loss: 0.000041\n",
      "Epoch:82 step:31 loss: 0.000086\n",
      "Epoch:82 step:32 loss: 0.000074\n",
      "Epoch:82 step:33 loss: 0.000001\n",
      "Epoch:82 step:34 loss: 0.003387\n",
      "Epoch:82 step:35 loss: 0.004568\n",
      "Epoch:82 step:36 loss: 0.000011\n",
      "Epoch:82 step:37 loss: 0.001236\n",
      "Epoch:82 step:38 loss: 0.000279\n",
      "Epoch:82 step:39 loss: 0.000223\n",
      "Epoch:82 step:40 loss: 0.010950\n",
      "Epoch:82 step:41 loss: 0.000000\n",
      "Epoch:82 step:42 loss: 0.000002\n",
      "Epoch:82 step:43 loss: 0.006403\n",
      "Epoch:82 step:44 loss: 0.000019\n",
      "Epoch:82 step:45 loss: 0.001188\n",
      "Epoch:82 step:46 loss: 0.000009\n",
      "Epoch:82 step:47 loss: 0.005994\n",
      "Epoch:82 step:48 loss: 0.001827\n",
      "Epoch:82 step:49 loss: 0.000008\n",
      "Epoch:82 step:50 loss: 0.000029\n",
      "Epoch:82 step:51 loss: 0.000065\n",
      "Epoch:82 step:52 loss: 0.000007\n",
      "Epoch:82 step:53 loss: 0.000029\n",
      "Epoch:82 step:54 loss: 0.008037\n",
      "Epoch:82 step:55 loss: 0.008122\n",
      "Epoch:82 step:56 loss: 0.006341\n",
      "Epoch:82 step:57 loss: 0.000269\n",
      "Epoch:82 step:58 loss: 0.003871\n",
      "Epoch:82 step:59 loss: 0.000217\n",
      "Epoch:82 step:60 loss: 0.007777\n",
      "Epoch:82 step:61 loss: 0.004724\n",
      "Epoch:82 step:62 loss: 0.000022\n",
      "Epoch:82 step:63 loss: 0.000330\n",
      "Epoch:82 step:64 loss: 0.000271\n",
      "Epoch:82 step:65 loss: 0.003442\n",
      "Epoch:82 step:66 loss: 0.000189\n",
      "Epoch:82 step:67 loss: 0.004779\n",
      "Epoch:82 step:68 loss: 0.000000\n",
      "Epoch:82 step:69 loss: 0.000003\n",
      "Epoch:82 step:70 loss: 0.001193\n",
      "Epoch:82 step:71 loss: 0.005551\n",
      "Epoch:82 step:72 loss: 0.001727\n",
      "Epoch:82 step:73 loss: 0.000034\n",
      "Epoch:82 step:74 loss: 0.002865\n",
      "Epoch:82 step:75 loss: 0.000060\n",
      "Epoch:82 step:76 loss: 0.000004\n",
      "Epoch:82 step:77 loss: 0.000339\n",
      "Epoch:82 step:78 loss: 0.006427\n",
      "Epoch:82 step:79 loss: 0.001417\n",
      "Test Epoch:82 step:0 loss: 0.004146tensor(0.3274, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:1 loss: 0.002635tensor(0.2070, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:2 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:4 loss: 0.005887tensor(0.4247, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:5 loss: 0.003834tensor(0.4048, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:7 loss: 0.004074tensor(0.3844, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:8 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:9 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:10 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:11 loss: 0.002593tensor(0.4056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:12 loss: 0.004875tensor(0.4588, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:13 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:14 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:15 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:16 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:17 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:18 loss: 0.002779tensor(0.3629, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:19 loss: 0.007511tensor(0.4223, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:20 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:21 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:22 loss: 0.009560tensor(0.4315, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:23 loss: 0.000358tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:24 loss: 0.005350tensor(0.4216, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:25 loss: 0.000506tensor(0.3077, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:26 loss: 0.005960tensor(0.4056, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:27 loss: 0.009472tensor(0.4621, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:28 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:30 loss: 0.001220tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:31 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:32 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:34 loss: 0.002998tensor(0.3684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:35 loss: 0.002602tensor(0.3616, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:36 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:37 loss: 0.001306tensor(0.2349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:38 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:39 loss: 0.000324tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:40 loss: 0.009742tensor(0.4628, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:43 loss: 0.005589tensor(0.4430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:44 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:45 loss: 0.001282tensor(0.3677, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:47 loss: 0.005248tensor(0.4413, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:82 step:48 loss: 0.003098tensor(0.1793, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:50 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:51 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:53 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:54 loss: 0.007125tensor(0.4475, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:55 loss: 0.006986tensor(0.4444, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:56 loss: 0.005273tensor(0.4464, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:57 loss: 0.000031tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:58 loss: 0.002976tensor(0.3616, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:59 loss: 0.000092tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:60 loss: 0.007561tensor(0.4641, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:61 loss: 0.004220tensor(0.3515, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:62 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:63 loss: 0.000859tensor(0.1980, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:64 loss: 0.000452tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:65 loss: 0.003473tensor(0.4329, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:66 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:67 loss: 0.006604tensor(0.3969, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:69 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:70 loss: 0.001392tensor(0.3724, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:71 loss: 0.007708tensor(0.4009, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:72 loss: 0.001909tensor(0.4353, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:73 loss: 0.000089tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:74 loss: 0.003289tensor(0.4333, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:75 loss: 0.000117tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:76 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:77 loss: 0.000278tensor(0.3503, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:78 loss: 0.005810tensor(0.4517, grad_fn=<DivBackward0>)\n",
      "Test Epoch:82 step:79 loss: 0.001288tensor(0.4285, grad_fn=<DivBackward0>)\n",
      "Epoch:83 step:0 loss: 0.004320\n",
      "Epoch:83 step:1 loss: 0.002241\n",
      "Epoch:83 step:2 loss: 0.000001\n",
      "Epoch:83 step:3 loss: 0.000000\n",
      "Epoch:83 step:4 loss: 0.006782\n",
      "Epoch:83 step:5 loss: 0.005303\n",
      "Epoch:83 step:6 loss: 0.000000\n",
      "Epoch:83 step:7 loss: 0.004707\n",
      "Epoch:83 step:8 loss: 0.000001\n",
      "Epoch:83 step:9 loss: 0.000004\n",
      "Epoch:83 step:10 loss: 0.000001\n",
      "Epoch:83 step:11 loss: 0.002570\n",
      "Epoch:83 step:12 loss: 0.004665\n",
      "Epoch:83 step:13 loss: 0.000014\n",
      "Epoch:83 step:14 loss: 0.000001\n",
      "Epoch:83 step:15 loss: 0.000065\n",
      "Epoch:83 step:16 loss: 0.000017\n",
      "Epoch:83 step:17 loss: 0.000040\n",
      "Epoch:83 step:18 loss: 0.001960\n",
      "Epoch:83 step:19 loss: 0.007216\n",
      "Epoch:83 step:20 loss: 0.000018\n",
      "Epoch:83 step:21 loss: 0.000003\n",
      "Epoch:83 step:22 loss: 0.009539\n",
      "Epoch:83 step:23 loss: 0.000221\n",
      "Epoch:83 step:24 loss: 0.004296\n",
      "Epoch:83 step:25 loss: 0.000705\n",
      "Epoch:83 step:26 loss: 0.005185\n",
      "Epoch:83 step:27 loss: 0.008740\n",
      "Epoch:83 step:28 loss: 0.000000\n",
      "Epoch:83 step:29 loss: 0.000000\n",
      "Epoch:83 step:30 loss: 0.000212\n",
      "Epoch:83 step:31 loss: 0.000024\n",
      "Epoch:83 step:32 loss: 0.000023\n",
      "Epoch:83 step:33 loss: 0.000001\n",
      "Epoch:83 step:34 loss: 0.002607\n",
      "Epoch:83 step:35 loss: 0.002327\n",
      "Epoch:83 step:36 loss: 0.000014\n",
      "Epoch:83 step:37 loss: 0.001642\n",
      "Epoch:83 step:38 loss: 0.000302\n",
      "Epoch:83 step:39 loss: 0.000060\n",
      "Epoch:83 step:40 loss: 0.009266\n",
      "Epoch:83 step:41 loss: 0.000000\n",
      "Epoch:83 step:42 loss: 0.000000\n",
      "Epoch:83 step:43 loss: 0.005357\n",
      "Epoch:83 step:44 loss: 0.000003\n",
      "Epoch:83 step:45 loss: 0.001099\n",
      "Epoch:83 step:46 loss: 0.000001\n",
      "Epoch:83 step:47 loss: 0.005167\n",
      "Epoch:83 step:48 loss: 0.002534\n",
      "Epoch:83 step:49 loss: 0.000001\n",
      "Epoch:83 step:50 loss: 0.000005\n",
      "Epoch:83 step:51 loss: 0.000007\n",
      "Epoch:83 step:52 loss: 0.000001\n",
      "Epoch:83 step:53 loss: 0.000008\n",
      "Epoch:83 step:54 loss: 0.006549\n",
      "Epoch:83 step:55 loss: 0.006579\n",
      "Epoch:83 step:56 loss: 0.004571\n",
      "Epoch:83 step:57 loss: 0.000131\n",
      "Epoch:83 step:58 loss: 0.002742\n",
      "Epoch:83 step:59 loss: 0.000104\n",
      "Epoch:83 step:60 loss: 0.007312\n",
      "Epoch:83 step:61 loss: 0.004185\n",
      "Epoch:83 step:62 loss: 0.000015\n",
      "Epoch:83 step:63 loss: 0.000329\n",
      "Epoch:83 step:64 loss: 0.000212\n",
      "Epoch:83 step:65 loss: 0.002444\n",
      "Epoch:83 step:66 loss: 0.000070\n",
      "Epoch:83 step:67 loss: 0.004714\n",
      "Epoch:83 step:68 loss: 0.000000\n",
      "Epoch:83 step:69 loss: 0.000005\n",
      "Epoch:83 step:70 loss: 0.001189\n",
      "Epoch:83 step:71 loss: 0.006145\n",
      "Epoch:83 step:72 loss: 0.002012\n",
      "Epoch:83 step:73 loss: 0.000088\n",
      "Epoch:83 step:74 loss: 0.003534\n",
      "Epoch:83 step:75 loss: 0.000118\n",
      "Epoch:83 step:76 loss: 0.000005\n",
      "Epoch:83 step:77 loss: 0.000472\n",
      "Epoch:83 step:78 loss: 0.004834\n",
      "Epoch:83 step:79 loss: 0.001399\n",
      "Test Epoch:83 step:0 loss: 0.003071tensor(0.3671, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:1 loss: 0.002301tensor(0.2427, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:2 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:4 loss: 0.006899tensor(0.4219, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:5 loss: 0.004340tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:7 loss: 0.003733tensor(0.3975, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:9 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:11 loss: 0.003200tensor(0.3988, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:12 loss: 0.005090tensor(0.4586, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:13 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:15 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:16 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:17 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:18 loss: 0.001785tensor(0.4126, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:19 loss: 0.007026tensor(0.4340, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:20 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:21 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:22 loss: 0.010398tensor(0.4334, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:23 loss: 0.000214tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:24 loss: 0.004803tensor(0.4304, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:25 loss: 0.000561tensor(0.3245, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:26 loss: 0.004590tensor(0.4289, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:27 loss: 0.008568tensor(0.4672, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:30 loss: 0.000501tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:31 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:32 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:34 loss: 0.002416tensor(0.3803, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:35 loss: 0.002376tensor(0.3701, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:36 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:37 loss: 0.000930tensor(0.2548, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:38 loss: 0.000242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:39 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:40 loss: 0.008641tensor(0.4669, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:43 loss: 0.005410tensor(0.4423, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:44 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:83 step:45 loss: 0.001033tensor(0.3783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:46 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:47 loss: 0.004809tensor(0.4443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:48 loss: 0.001970tensor(0.2706, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:50 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:51 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:53 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:54 loss: 0.006666tensor(0.4534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:55 loss: 0.006549tensor(0.4499, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:56 loss: 0.004464tensor(0.4513, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:57 loss: 0.000573tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:58 loss: 0.002468tensor(0.3711, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:59 loss: 0.000144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:60 loss: 0.007157tensor(0.4668, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:61 loss: 0.004021tensor(0.3624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:62 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:63 loss: 0.000739tensor(0.2305, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:64 loss: 0.000204tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:65 loss: 0.002387tensor(0.4466, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:66 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:67 loss: 0.005242tensor(0.4133, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:69 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:70 loss: 0.001733tensor(0.3528, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:71 loss: 0.005590tensor(0.4211, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:72 loss: 0.001543tensor(0.4468, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:73 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:74 loss: 0.002836tensor(0.4416, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:75 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:76 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:77 loss: 0.000286tensor(0.3693, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:78 loss: 0.004967tensor(0.4571, grad_fn=<DivBackward0>)\n",
      "Test Epoch:83 step:79 loss: 0.001333tensor(0.4313, grad_fn=<DivBackward0>)\n",
      "Epoch:84 step:0 loss: 0.002766\n",
      "Epoch:84 step:1 loss: 0.001964\n",
      "Epoch:84 step:2 loss: 0.000001\n",
      "Epoch:84 step:3 loss: 0.000000\n",
      "Epoch:84 step:4 loss: 0.006658\n",
      "Epoch:84 step:5 loss: 0.005461\n",
      "Epoch:84 step:6 loss: 0.000000\n",
      "Epoch:84 step:7 loss: 0.004658\n",
      "Epoch:84 step:8 loss: 0.000000\n",
      "Epoch:84 step:9 loss: 0.000001\n",
      "Epoch:84 step:10 loss: 0.000001\n",
      "Epoch:84 step:11 loss: 0.003791\n",
      "Epoch:84 step:12 loss: 0.005396\n",
      "Epoch:84 step:13 loss: 0.000002\n",
      "Epoch:84 step:14 loss: 0.000001\n",
      "Epoch:84 step:15 loss: 0.000009\n",
      "Epoch:84 step:16 loss: 0.000001\n",
      "Epoch:84 step:17 loss: 0.000032\n",
      "Epoch:84 step:18 loss: 0.001352\n",
      "Epoch:84 step:19 loss: 0.007407\n",
      "Epoch:84 step:20 loss: 0.000001\n",
      "Epoch:84 step:21 loss: 0.000001\n",
      "Epoch:84 step:22 loss: 0.008615\n",
      "Epoch:84 step:23 loss: 0.000208\n",
      "Epoch:84 step:24 loss: 0.004536\n",
      "Epoch:84 step:25 loss: 0.000574\n",
      "Epoch:84 step:26 loss: 0.004417\n",
      "Epoch:84 step:27 loss: 0.008558\n",
      "Epoch:84 step:28 loss: 0.000000\n",
      "Epoch:84 step:29 loss: 0.000000\n",
      "Epoch:84 step:30 loss: 0.000116\n",
      "Epoch:84 step:31 loss: 0.000026\n",
      "Epoch:84 step:32 loss: 0.000021\n",
      "Epoch:84 step:33 loss: 0.000000\n",
      "Epoch:84 step:34 loss: 0.002332\n",
      "Epoch:84 step:35 loss: 0.002593\n",
      "Epoch:84 step:36 loss: 0.000007\n",
      "Epoch:84 step:37 loss: 0.001024\n",
      "Epoch:84 step:38 loss: 0.000165\n",
      "Epoch:84 step:39 loss: 0.000035\n",
      "Epoch:84 step:40 loss: 0.009083\n",
      "Epoch:84 step:41 loss: 0.000001\n",
      "Epoch:84 step:42 loss: 0.000000\n",
      "Epoch:84 step:43 loss: 0.005623\n",
      "Epoch:84 step:44 loss: 0.000002\n",
      "Epoch:84 step:45 loss: 0.000795\n",
      "Epoch:84 step:46 loss: 0.000001\n",
      "Epoch:84 step:47 loss: 0.004723\n",
      "Epoch:84 step:48 loss: 0.002087\n",
      "Epoch:84 step:49 loss: 0.000000\n",
      "Epoch:84 step:50 loss: 0.000001\n",
      "Epoch:84 step:51 loss: 0.000004\n",
      "Epoch:84 step:52 loss: 0.000000\n",
      "Epoch:84 step:53 loss: 0.000002\n",
      "Epoch:84 step:54 loss: 0.005364\n",
      "Epoch:84 step:55 loss: 0.006035\n",
      "Epoch:84 step:56 loss: 0.003644\n",
      "Epoch:84 step:57 loss: 0.000154\n",
      "Epoch:84 step:58 loss: 0.002533\n",
      "Epoch:84 step:59 loss: 0.000152\n",
      "Epoch:84 step:60 loss: 0.007378\n",
      "Epoch:84 step:61 loss: 0.004221\n",
      "Epoch:84 step:62 loss: 0.000004\n",
      "Epoch:84 step:63 loss: 0.000354\n",
      "Epoch:84 step:64 loss: 0.000257\n",
      "Epoch:84 step:65 loss: 0.003008\n",
      "Epoch:84 step:66 loss: 0.000070\n",
      "Epoch:84 step:67 loss: 0.004503\n",
      "Epoch:84 step:68 loss: 0.000001\n",
      "Epoch:84 step:69 loss: 0.000001\n",
      "Epoch:84 step:70 loss: 0.000939\n",
      "Epoch:84 step:71 loss: 0.005011\n",
      "Epoch:84 step:72 loss: 0.001703\n",
      "Epoch:84 step:73 loss: 0.000120\n",
      "Epoch:84 step:74 loss: 0.002740\n",
      "Epoch:84 step:75 loss: 0.000078\n",
      "Epoch:84 step:76 loss: 0.000014\n",
      "Epoch:84 step:77 loss: 0.000355\n",
      "Epoch:84 step:78 loss: 0.004711\n",
      "Epoch:84 step:79 loss: 0.001277\n",
      "Test Epoch:84 step:0 loss: 0.002639tensor(0.3769, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:1 loss: 0.002062tensor(0.2807, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:2 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:4 loss: 0.004527tensor(0.4426, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:5 loss: 0.002539tensor(0.4221, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:7 loss: 0.003247tensor(0.4020, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:9 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:11 loss: 0.003770tensor(0.3889, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:12 loss: 0.006246tensor(0.4536, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:13 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:14 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:15 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:17 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:18 loss: 0.004149tensor(0.3585, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:19 loss: 0.006080tensor(0.4388, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:22 loss: 0.006826tensor(0.4491, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:23 loss: 0.000137tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:24 loss: 0.007034tensor(0.4191, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:25 loss: 0.000469tensor(0.3159, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:26 loss: 0.004498tensor(0.4322, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:27 loss: 0.012323tensor(0.4600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:30 loss: 0.001773tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:31 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:32 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:34 loss: 0.002689tensor(0.3910, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:35 loss: 0.004088tensor(0.3480, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:36 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:37 loss: 0.000918tensor(0.2613, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:38 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:39 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:40 loss: 0.011992tensor(0.4617, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:84 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:43 loss: 0.005380tensor(0.4430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:44 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:45 loss: 0.001409tensor(0.3569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:47 loss: 0.005905tensor(0.4397, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:48 loss: 0.002378tensor(0.2534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:50 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:51 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:53 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:54 loss: 0.006466tensor(0.4555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:55 loss: 0.006722tensor(0.4516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:56 loss: 0.004060tensor(0.4542, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:57 loss: 0.000894tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:58 loss: 0.003221tensor(0.3578, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:59 loss: 0.000196tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:60 loss: 0.007404tensor(0.4666, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:61 loss: 0.005133tensor(0.3493, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:62 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:63 loss: 0.000938tensor(0.1998, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:64 loss: 0.000292tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:65 loss: 0.002361tensor(0.4463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:66 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:67 loss: 0.004491tensor(0.4183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:70 loss: 0.001373tensor(0.3528, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:71 loss: 0.003942tensor(0.4337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:72 loss: 0.001083tensor(0.4533, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:73 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:74 loss: 0.002916tensor(0.4405, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:75 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:76 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:77 loss: 0.000245tensor(0.3771, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:78 loss: 0.006073tensor(0.4521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:84 step:79 loss: 0.001593tensor(0.4248, grad_fn=<DivBackward0>)\n",
      "Epoch:85 step:0 loss: 0.002611\n",
      "Epoch:85 step:1 loss: 0.003553\n",
      "Epoch:85 step:2 loss: 0.000001\n",
      "Epoch:85 step:3 loss: 0.000000\n",
      "Epoch:85 step:4 loss: 0.006207\n",
      "Epoch:85 step:5 loss: 0.005918\n",
      "Epoch:85 step:6 loss: 0.000000\n",
      "Epoch:85 step:7 loss: 0.005106\n",
      "Epoch:85 step:8 loss: 0.000000\n",
      "Epoch:85 step:9 loss: 0.000001\n",
      "Epoch:85 step:10 loss: 0.000001\n",
      "Epoch:85 step:11 loss: 0.005936\n",
      "Epoch:85 step:12 loss: 0.007096\n",
      "Epoch:85 step:13 loss: 0.000002\n",
      "Epoch:85 step:14 loss: 0.000001\n",
      "Epoch:85 step:15 loss: 0.000012\n",
      "Epoch:85 step:16 loss: 0.000001\n",
      "Epoch:85 step:17 loss: 0.000041\n",
      "Epoch:85 step:18 loss: 0.001179\n",
      "Epoch:85 step:19 loss: 0.008679\n",
      "Epoch:85 step:20 loss: 0.000002\n",
      "Epoch:85 step:21 loss: 0.000002\n",
      "Epoch:85 step:22 loss: 0.008719\n",
      "Epoch:85 step:23 loss: 0.000460\n",
      "Epoch:85 step:24 loss: 0.003533\n",
      "Epoch:85 step:25 loss: 0.000563\n",
      "Epoch:85 step:26 loss: 0.004582\n",
      "Epoch:85 step:27 loss: 0.008820\n",
      "Epoch:85 step:28 loss: 0.000000\n",
      "Epoch:85 step:29 loss: 0.000000\n",
      "Epoch:85 step:30 loss: 0.000083\n",
      "Epoch:85 step:31 loss: 0.000635\n",
      "Epoch:85 step:32 loss: 0.000038\n",
      "Epoch:85 step:33 loss: 0.000001\n",
      "Epoch:85 step:34 loss: 0.003408\n",
      "Epoch:85 step:35 loss: 0.002410\n",
      "Epoch:85 step:36 loss: 0.000011\n",
      "Epoch:85 step:37 loss: 0.000661\n",
      "Epoch:85 step:38 loss: 0.000004\n",
      "Epoch:85 step:39 loss: 0.000237\n",
      "Epoch:85 step:40 loss: 0.008256\n",
      "Epoch:85 step:41 loss: 0.000001\n",
      "Epoch:85 step:42 loss: 0.000000\n",
      "Epoch:85 step:43 loss: 0.006204\n",
      "Epoch:85 step:44 loss: 0.000001\n",
      "Epoch:85 step:45 loss: 0.000873\n",
      "Epoch:85 step:46 loss: 0.000000\n",
      "Epoch:85 step:47 loss: 0.006074\n",
      "Epoch:85 step:48 loss: 0.002752\n",
      "Epoch:85 step:49 loss: 0.000002\n",
      "Epoch:85 step:50 loss: 0.000005\n",
      "Epoch:85 step:51 loss: 0.000000\n",
      "Epoch:85 step:52 loss: 0.000002\n",
      "Epoch:85 step:53 loss: 0.000013\n",
      "Epoch:85 step:54 loss: 0.005540\n",
      "Epoch:85 step:55 loss: 0.006019\n",
      "Epoch:85 step:56 loss: 0.003382\n",
      "Epoch:85 step:57 loss: 0.000004\n",
      "Epoch:85 step:58 loss: 0.003783\n",
      "Epoch:85 step:59 loss: 0.000182\n",
      "Epoch:85 step:60 loss: 0.006723\n",
      "Epoch:85 step:61 loss: 0.009631\n",
      "Epoch:85 step:62 loss: 0.000010\n",
      "Epoch:85 step:63 loss: 0.000244\n",
      "Epoch:85 step:64 loss: 0.000243\n",
      "Epoch:85 step:65 loss: 0.002599\n",
      "Epoch:85 step:66 loss: 0.000133\n",
      "Epoch:85 step:67 loss: 0.004528\n",
      "Epoch:85 step:68 loss: 0.000000\n",
      "Epoch:85 step:69 loss: 0.000003\n",
      "Epoch:85 step:70 loss: 0.000756\n",
      "Epoch:85 step:71 loss: 0.005152\n",
      "Epoch:85 step:72 loss: 0.003933\n",
      "Epoch:85 step:73 loss: 0.000074\n",
      "Epoch:85 step:74 loss: 0.003108\n",
      "Epoch:85 step:75 loss: 0.000970\n",
      "Epoch:85 step:76 loss: 0.000008\n",
      "Epoch:85 step:77 loss: 0.000490\n",
      "Epoch:85 step:78 loss: 0.008797\n",
      "Epoch:85 step:79 loss: 0.001300\n",
      "Test Epoch:85 step:0 loss: 0.002431tensor(0.3768, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:1 loss: 0.001888tensor(0.2872, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:2 loss: 0.000149tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:4 loss: 0.005311tensor(0.4369, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:5 loss: 0.002640tensor(0.4271, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:7 loss: 0.004333tensor(0.3850, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:9 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:11 loss: 0.004444tensor(0.3670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:12 loss: 0.005286tensor(0.4563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:13 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:15 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:17 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:18 loss: 0.006479tensor(0.2695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:19 loss: 0.008067tensor(0.4222, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:22 loss: 0.008621tensor(0.4387, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:23 loss: 0.000274tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:24 loss: 0.009141tensor(0.3965, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:25 loss: 0.000487tensor(0.3197, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:26 loss: 0.004462tensor(0.4285, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:27 loss: 0.010104tensor(0.4623, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:30 loss: 0.001538tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:31 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:32 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:34 loss: 0.002774tensor(0.3781, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:35 loss: 0.005401tensor(0.2995, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:36 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:37 loss: 0.003990tensor(0.1332, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:38 loss: 0.000155tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:85 step:39 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:40 loss: 0.010167tensor(0.4649, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:43 loss: 0.006056tensor(0.4392, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:44 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:45 loss: 0.002877tensor(0.2535, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:46 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:47 loss: 0.006114tensor(0.4326, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:48 loss: 0.009391tensor(0.0182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:50 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:51 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:53 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:54 loss: 0.013878tensor(0.4310, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:55 loss: 0.012884tensor(0.4246, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:56 loss: 0.006812tensor(0.4328, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:57 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:58 loss: 0.002574tensor(0.3595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:59 loss: 0.000139tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:60 loss: 0.016293tensor(0.4481, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:61 loss: 0.006622tensor(0.3210, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:62 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:63 loss: 0.001457tensor(0.1594, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:64 loss: 0.000174tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:65 loss: 0.003217tensor(0.4362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:66 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:67 loss: 0.005237tensor(0.4034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:69 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:70 loss: 0.001260tensor(0.3705, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:71 loss: 0.009536tensor(0.3917, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:72 loss: 0.001676tensor(0.4458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:73 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:74 loss: 0.002354tensor(0.4456, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:75 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:76 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:77 loss: 0.001414tensor(0.0523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:78 loss: 0.005251tensor(0.4576, grad_fn=<DivBackward0>)\n",
      "Test Epoch:85 step:79 loss: 0.002576tensor(0.3993, grad_fn=<DivBackward0>)\n",
      "Epoch:86 step:0 loss: 0.002774\n",
      "Epoch:86 step:1 loss: 0.002938\n",
      "Epoch:86 step:2 loss: 0.000118\n",
      "Epoch:86 step:3 loss: 0.000001\n",
      "Epoch:86 step:4 loss: 0.005709\n",
      "Epoch:86 step:5 loss: 0.005363\n",
      "Epoch:86 step:6 loss: 0.000000\n",
      "Epoch:86 step:7 loss: 0.003219\n",
      "Epoch:86 step:8 loss: 0.000000\n",
      "Epoch:86 step:9 loss: 0.000028\n",
      "Epoch:86 step:10 loss: 0.000005\n",
      "Epoch:86 step:11 loss: 0.002538\n",
      "Epoch:86 step:12 loss: 0.003755\n",
      "Epoch:86 step:13 loss: 0.000029\n",
      "Epoch:86 step:14 loss: 0.000001\n",
      "Epoch:86 step:15 loss: 0.000011\n",
      "Epoch:86 step:16 loss: 0.000001\n",
      "Epoch:86 step:17 loss: 0.000046\n",
      "Epoch:86 step:18 loss: 0.001823\n",
      "Epoch:86 step:19 loss: 0.007378\n",
      "Epoch:86 step:20 loss: 0.000001\n",
      "Epoch:86 step:21 loss: 0.000003\n",
      "Epoch:86 step:22 loss: 0.008128\n",
      "Epoch:86 step:23 loss: 0.000035\n",
      "Epoch:86 step:24 loss: 0.004120\n",
      "Epoch:86 step:25 loss: 0.000526\n",
      "Epoch:86 step:26 loss: 0.005009\n",
      "Epoch:86 step:27 loss: 0.009171\n",
      "Epoch:86 step:28 loss: 0.000003\n",
      "Epoch:86 step:29 loss: 0.000000\n",
      "Epoch:86 step:30 loss: 0.000348\n",
      "Epoch:86 step:31 loss: 0.000072\n",
      "Epoch:86 step:32 loss: 0.000068\n",
      "Epoch:86 step:33 loss: 0.000003\n",
      "Epoch:86 step:34 loss: 0.003289\n",
      "Epoch:86 step:35 loss: 0.002730\n",
      "Epoch:86 step:36 loss: 0.000091\n",
      "Epoch:86 step:37 loss: 0.002499\n",
      "Epoch:86 step:38 loss: 0.000017\n",
      "Epoch:86 step:39 loss: 0.000097\n",
      "Epoch:86 step:40 loss: 0.013452\n",
      "Epoch:86 step:41 loss: 0.000000\n",
      "Epoch:86 step:42 loss: 0.000000\n",
      "Epoch:86 step:43 loss: 0.005735\n",
      "Epoch:86 step:44 loss: 0.000003\n",
      "Epoch:86 step:45 loss: 0.001479\n",
      "Epoch:86 step:46 loss: 0.000000\n",
      "Epoch:86 step:47 loss: 0.007355\n",
      "Epoch:86 step:48 loss: 0.006048\n",
      "Epoch:86 step:49 loss: 0.000001\n",
      "Epoch:86 step:50 loss: 0.000014\n",
      "Epoch:86 step:51 loss: 0.000001\n",
      "Epoch:86 step:52 loss: 0.000001\n",
      "Epoch:86 step:53 loss: 0.000005\n",
      "Epoch:86 step:54 loss: 0.016521\n",
      "Epoch:86 step:55 loss: 0.024709\n",
      "Epoch:86 step:56 loss: 0.007440\n",
      "Epoch:86 step:57 loss: 0.000031\n",
      "Epoch:86 step:58 loss: 0.005757\n",
      "Epoch:86 step:59 loss: 0.000138\n",
      "Epoch:86 step:60 loss: 0.008658\n",
      "Epoch:86 step:61 loss: 0.004637\n",
      "Epoch:86 step:62 loss: 0.000980\n",
      "Epoch:86 step:63 loss: 0.001118\n",
      "Epoch:86 step:64 loss: 0.000358\n",
      "Epoch:86 step:65 loss: 0.002742\n",
      "Epoch:86 step:66 loss: 0.000223\n",
      "Epoch:86 step:67 loss: 0.005456\n",
      "Epoch:86 step:68 loss: 0.002725\n",
      "Epoch:86 step:69 loss: 0.004744\n",
      "Epoch:86 step:70 loss: 0.080717\n",
      "Epoch:86 step:71 loss: 0.131190\n",
      "Epoch:86 step:72 loss: 0.003068\n",
      "Epoch:86 step:73 loss: 0.000030\n",
      "Epoch:86 step:74 loss: 0.029452\n",
      "Epoch:86 step:75 loss: 0.000002\n",
      "Epoch:86 step:76 loss: 0.000001\n",
      "Epoch:86 step:77 loss: 0.003418\n",
      "Epoch:86 step:78 loss: 0.125460\n",
      "Epoch:86 step:79 loss: 0.004522\n",
      "Test Epoch:86 step:0 loss: 0.023896tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:1 loss: 0.010631tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:2 loss: 0.000322tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:3 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:4 loss: 0.044441tensor(0.0640, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:5 loss: 0.008897tensor(0.2778, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:6 loss: 0.001555tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:7 loss: 0.021469tensor(0.1825, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:8 loss: 0.000200tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:9 loss: 0.059769tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:10 loss: 0.006072tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:11 loss: 0.012663tensor(0.1463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:12 loss: 0.044794tensor(0.1995, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:13 loss: 0.000890tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:14 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:15 loss: 0.000416tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:16 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:17 loss: 0.001177tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:18 loss: 0.013129tensor(0.0388, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:19 loss: 0.051918tensor(0.0761, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:20 loss: 0.000163tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:21 loss: 0.000120tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:22 loss: 0.130383tensor(0.0251, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:23 loss: 0.004563tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:24 loss: 0.019075tensor(0.1694, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:25 loss: 0.004490tensor(0.0248, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:26 loss: 0.026688tensor(0.1344, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:27 loss: 0.259415tensor(0.0653, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:28 loss: 0.003812tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:29 loss: 0.019154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:30 loss: 0.060122tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:31 loss: 0.020383tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:32 loss: 0.005366tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:33 loss: 0.001790tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:34 loss: 0.026001tensor(0.0126, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:35 loss: 0.011104tensor(0.0459, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:86 step:36 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:37 loss: 0.002232tensor(0.0112, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:38 loss: 0.001338tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:39 loss: 0.000489tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:40 loss: 0.164341tensor(0.0626, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:41 loss: 0.000230tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:42 loss: 0.002048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:43 loss: 0.038553tensor(0.1300, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:44 loss: 0.000277tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:45 loss: 0.005643tensor(0.0198, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:46 loss: 0.007517tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:47 loss: 0.029059tensor(0.1406, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:48 loss: 0.004509tensor(0.0666, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:49 loss: 0.008315tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:50 loss: 0.002544tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:51 loss: 0.004494tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:52 loss: 0.006171tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:53 loss: 0.004128tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:54 loss: 0.042817tensor(0.1633, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:55 loss: 0.041705tensor(0.1783, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:56 loss: 0.029940tensor(0.1712, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:57 loss: 0.001756tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:58 loss: 0.027407tensor(0.0130, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:59 loss: 0.003924tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:60 loss: 0.051594tensor(0.2360, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:61 loss: 0.014127tensor(0.1014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:62 loss: 0.000338tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:63 loss: 0.008234tensor(2.5772e-05, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:64 loss: 0.007147tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:65 loss: 0.031859tensor(0.0503, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:66 loss: 0.002691tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:67 loss: 0.010411tensor(0.2566, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:68 loss: 0.000051tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:69 loss: 0.000157tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:70 loss: 0.003974tensor(0.1025, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:71 loss: 0.017093tensor(0.2321, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:72 loss: 0.007334tensor(0.2691, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:73 loss: 0.006560tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:74 loss: 0.007060tensor(0.3308, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:75 loss: 0.002511tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:76 loss: 0.000732tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:77 loss: 0.001748tensor(0.0302, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:78 loss: 0.027714tensor(0.2959, grad_fn=<DivBackward0>)\n",
      "Test Epoch:86 step:79 loss: 0.008758tensor(0.1677, grad_fn=<DivBackward0>)\n",
      "Epoch:87 step:0 loss: 0.010140\n",
      "Epoch:87 step:1 loss: 0.008466\n",
      "Epoch:87 step:2 loss: 0.004031\n",
      "Epoch:87 step:3 loss: 0.000033\n",
      "Epoch:87 step:4 loss: 0.017387\n",
      "Epoch:87 step:5 loss: 0.009598\n",
      "Epoch:87 step:6 loss: 0.000214\n",
      "Epoch:87 step:7 loss: 0.010296\n",
      "Epoch:87 step:8 loss: 0.000008\n",
      "Epoch:87 step:9 loss: 0.000344\n",
      "Epoch:87 step:10 loss: 0.000148\n",
      "Epoch:87 step:11 loss: 0.009786\n",
      "Epoch:87 step:12 loss: 0.010430\n",
      "Epoch:87 step:13 loss: 0.000905\n",
      "Epoch:87 step:14 loss: 0.000072\n",
      "Epoch:87 step:15 loss: 0.000402\n",
      "Epoch:87 step:16 loss: 0.000022\n",
      "Epoch:87 step:17 loss: 0.001945\n",
      "Epoch:87 step:18 loss: 0.006675\n",
      "Epoch:87 step:19 loss: 0.021554\n",
      "Epoch:87 step:20 loss: 0.000009\n",
      "Epoch:87 step:21 loss: 0.000176\n",
      "Epoch:87 step:22 loss: 0.050005\n",
      "Epoch:87 step:23 loss: 0.001601\n",
      "Epoch:87 step:24 loss: 0.007970\n",
      "Epoch:87 step:25 loss: 0.001894\n",
      "Epoch:87 step:26 loss: 0.014967\n",
      "Epoch:87 step:27 loss: 0.034411\n",
      "Epoch:87 step:28 loss: 0.000013\n",
      "Epoch:87 step:29 loss: 0.000028\n",
      "Epoch:87 step:30 loss: 0.001976\n",
      "Epoch:87 step:31 loss: 0.001143\n",
      "Epoch:87 step:32 loss: 0.000470\n",
      "Epoch:87 step:33 loss: 0.000001\n",
      "Epoch:87 step:34 loss: 0.007179\n",
      "Epoch:87 step:35 loss: 0.006388\n",
      "Epoch:87 step:36 loss: 0.000395\n",
      "Epoch:87 step:37 loss: 0.001697\n",
      "Epoch:87 step:38 loss: 0.001475\n",
      "Epoch:87 step:39 loss: 0.011831\n",
      "Epoch:87 step:40 loss: 0.025021\n",
      "Epoch:87 step:41 loss: 0.000056\n",
      "Epoch:87 step:42 loss: 0.000069\n",
      "Epoch:87 step:43 loss: 0.010306\n",
      "Epoch:87 step:44 loss: 0.000201\n",
      "Epoch:87 step:45 loss: 0.002803\n",
      "Epoch:87 step:46 loss: 0.000331\n",
      "Epoch:87 step:47 loss: 0.008953\n",
      "Epoch:87 step:48 loss: 0.004831\n",
      "Epoch:87 step:49 loss: 0.000048\n",
      "Epoch:87 step:50 loss: 0.000418\n",
      "Epoch:87 step:51 loss: 0.000349\n",
      "Epoch:87 step:52 loss: 0.000044\n",
      "Epoch:87 step:53 loss: 0.000082\n",
      "Epoch:87 step:54 loss: 0.027321\n",
      "Epoch:87 step:55 loss: 0.018884\n",
      "Epoch:87 step:56 loss: 0.010914\n",
      "Epoch:87 step:57 loss: 0.000123\n",
      "Epoch:87 step:58 loss: 0.011022\n",
      "Epoch:87 step:59 loss: 0.000675\n",
      "Epoch:87 step:60 loss: 0.023523\n",
      "Epoch:87 step:61 loss: 0.007888\n",
      "Epoch:87 step:62 loss: 0.000260\n",
      "Epoch:87 step:63 loss: 0.000804\n",
      "Epoch:87 step:64 loss: 0.001584\n",
      "Epoch:87 step:65 loss: 0.005979\n",
      "Epoch:87 step:66 loss: 0.002880\n",
      "Epoch:87 step:67 loss: 0.007101\n",
      "Epoch:87 step:68 loss: 0.000003\n",
      "Epoch:87 step:69 loss: 0.000015\n",
      "Epoch:87 step:70 loss: 0.001673\n",
      "Epoch:87 step:71 loss: 0.009121\n",
      "Epoch:87 step:72 loss: 0.002668\n",
      "Epoch:87 step:73 loss: 0.000170\n",
      "Epoch:87 step:74 loss: 0.004689\n",
      "Epoch:87 step:75 loss: 0.000668\n",
      "Epoch:87 step:76 loss: 0.000059\n",
      "Epoch:87 step:77 loss: 0.002001\n",
      "Epoch:87 step:78 loss: 0.014142\n",
      "Epoch:87 step:79 loss: 0.005004\n",
      "Test Epoch:87 step:0 loss: 0.007723tensor(0.2237, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:1 loss: 0.004020tensor(0.0778, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:2 loss: 0.000280tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:3 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:4 loss: 0.012812tensor(0.3555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:5 loss: 0.005823tensor(0.3421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:6 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:7 loss: 0.006018tensor(0.3101, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:8 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:9 loss: 0.000186tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:10 loss: 0.000187tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:11 loss: 0.004267tensor(0.3500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:12 loss: 0.005733tensor(0.4446, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:13 loss: 0.000229tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:14 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:15 loss: 0.000243tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:16 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:17 loss: 0.001250tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:18 loss: 0.004764tensor(0.2724, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:19 loss: 0.010241tensor(0.3867, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:20 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:21 loss: 0.000074tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:22 loss: 0.025349tensor(0.3451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:23 loss: 0.000580tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:24 loss: 0.005787tensor(0.4095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:25 loss: 0.001246tensor(0.0750, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:26 loss: 0.012506tensor(0.3055, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:27 loss: 0.018363tensor(0.4245, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:28 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:29 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:30 loss: 0.000539tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:31 loss: 0.000343tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:32 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:87 step:33 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:34 loss: 0.006008tensor(0.2320, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:35 loss: 0.003583tensor(0.2902, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:36 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:37 loss: 0.001683tensor(0.1276, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:38 loss: 0.000076tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:39 loss: 0.000806tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:40 loss: 0.018271tensor(0.4259, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:41 loss: 0.000359tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:42 loss: 0.000346tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:43 loss: 0.008507tensor(0.4129, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:44 loss: 0.000057tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:45 loss: 0.001422tensor(0.3121, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:46 loss: 0.000040tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:47 loss: 0.007555tensor(0.4112, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:48 loss: 0.002397tensor(0.2418, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:49 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:50 loss: 0.001316tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:51 loss: 0.000273tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:52 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:53 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:54 loss: 0.023954tensor(0.3546, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:55 loss: 0.016231tensor(0.3800, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:56 loss: 0.011718tensor(0.3915, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:57 loss: 0.000101tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:58 loss: 0.008958tensor(0.1824, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:59 loss: 0.000144tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:60 loss: 0.016087tensor(0.4369, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:61 loss: 0.006065tensor(0.3512, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:62 loss: 0.011263tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:63 loss: 0.000541tensor(0.1496, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:64 loss: 0.000285tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:65 loss: 0.005239tensor(0.4177, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:66 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:67 loss: 0.005673tensor(0.3807, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:68 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:69 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:70 loss: 0.001466tensor(0.3039, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:71 loss: 0.007030tensor(0.3857, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:72 loss: 0.002863tensor(0.3954, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:73 loss: 0.000102tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:74 loss: 0.005335tensor(0.4024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:75 loss: 0.000809tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:76 loss: 0.000073tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:77 loss: 0.000582tensor(0.2499, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:78 loss: 0.009478tensor(0.4241, grad_fn=<DivBackward0>)\n",
      "Test Epoch:87 step:79 loss: 0.002315tensor(0.3722, grad_fn=<DivBackward0>)\n",
      "Epoch:88 step:0 loss: 0.007472\n",
      "Epoch:88 step:1 loss: 0.004414\n",
      "Epoch:88 step:2 loss: 0.000180\n",
      "Epoch:88 step:3 loss: 0.000009\n",
      "Epoch:88 step:4 loss: 0.008295\n",
      "Epoch:88 step:5 loss: 0.003884\n",
      "Epoch:88 step:6 loss: 0.000031\n",
      "Epoch:88 step:7 loss: 0.005632\n",
      "Epoch:88 step:8 loss: 0.000138\n",
      "Epoch:88 step:9 loss: 0.000194\n",
      "Epoch:88 step:10 loss: 0.000010\n",
      "Epoch:88 step:11 loss: 0.003917\n",
      "Epoch:88 step:12 loss: 0.005584\n",
      "Epoch:88 step:13 loss: 0.000035\n",
      "Epoch:88 step:14 loss: 0.000015\n",
      "Epoch:88 step:15 loss: 0.000070\n",
      "Epoch:88 step:16 loss: 0.000008\n",
      "Epoch:88 step:17 loss: 0.000113\n",
      "Epoch:88 step:18 loss: 0.004286\n",
      "Epoch:88 step:19 loss: 0.008361\n",
      "Epoch:88 step:20 loss: 0.000075\n",
      "Epoch:88 step:21 loss: 0.000049\n",
      "Epoch:88 step:22 loss: 0.019467\n",
      "Epoch:88 step:23 loss: 0.000978\n",
      "Epoch:88 step:24 loss: 0.004400\n",
      "Epoch:88 step:25 loss: 0.000917\n",
      "Epoch:88 step:26 loss: 0.009087\n",
      "Epoch:88 step:27 loss: 0.017804\n",
      "Epoch:88 step:28 loss: 0.000006\n",
      "Epoch:88 step:29 loss: 0.000003\n",
      "Epoch:88 step:30 loss: 0.000628\n",
      "Epoch:88 step:31 loss: 0.000253\n",
      "Epoch:88 step:32 loss: 0.000025\n",
      "Epoch:88 step:33 loss: 0.000006\n",
      "Epoch:88 step:34 loss: 0.004243\n",
      "Epoch:88 step:35 loss: 0.002524\n",
      "Epoch:88 step:36 loss: 0.000043\n",
      "Epoch:88 step:37 loss: 0.001963\n",
      "Epoch:88 step:38 loss: 0.000841\n",
      "Epoch:88 step:39 loss: 0.000560\n",
      "Epoch:88 step:40 loss: 0.014956\n",
      "Epoch:88 step:41 loss: 0.000001\n",
      "Epoch:88 step:42 loss: 0.000004\n",
      "Epoch:88 step:43 loss: 0.006504\n",
      "Epoch:88 step:44 loss: 0.000007\n",
      "Epoch:88 step:45 loss: 0.001032\n",
      "Epoch:88 step:46 loss: 0.000001\n",
      "Epoch:88 step:47 loss: 0.006569\n",
      "Epoch:88 step:48 loss: 0.004070\n",
      "Epoch:88 step:49 loss: 0.000008\n",
      "Epoch:88 step:50 loss: 0.000036\n",
      "Epoch:88 step:51 loss: 0.000012\n",
      "Epoch:88 step:52 loss: 0.000010\n",
      "Epoch:88 step:53 loss: 0.000058\n",
      "Epoch:88 step:54 loss: 0.023215\n",
      "Epoch:88 step:55 loss: 0.014878\n",
      "Epoch:88 step:56 loss: 0.006899\n",
      "Epoch:88 step:57 loss: 0.000137\n",
      "Epoch:88 step:58 loss: 0.006379\n",
      "Epoch:88 step:59 loss: 0.000092\n",
      "Epoch:88 step:60 loss: 0.016723\n",
      "Epoch:88 step:61 loss: 0.007044\n",
      "Epoch:88 step:62 loss: 0.000001\n",
      "Epoch:88 step:63 loss: 0.000732\n",
      "Epoch:88 step:64 loss: 0.000758\n",
      "Epoch:88 step:65 loss: 0.003290\n",
      "Epoch:88 step:66 loss: 0.000247\n",
      "Epoch:88 step:67 loss: 0.004717\n",
      "Epoch:88 step:68 loss: 0.000000\n",
      "Epoch:88 step:69 loss: 0.000000\n",
      "Epoch:88 step:70 loss: 0.001842\n",
      "Epoch:88 step:71 loss: 0.006175\n",
      "Epoch:88 step:72 loss: 0.002512\n",
      "Epoch:88 step:73 loss: 0.000098\n",
      "Epoch:88 step:74 loss: 0.003647\n",
      "Epoch:88 step:75 loss: 0.000407\n",
      "Epoch:88 step:76 loss: 0.000063\n",
      "Epoch:88 step:77 loss: 0.000530\n",
      "Epoch:88 step:78 loss: 0.010141\n",
      "Epoch:88 step:79 loss: 0.001788\n",
      "Test Epoch:88 step:0 loss: 0.005414tensor(0.2797, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:1 loss: 0.003713tensor(0.1031, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:2 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:3 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:4 loss: 0.007543tensor(0.4014, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:5 loss: 0.003766tensor(0.4032, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:6 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:7 loss: 0.004073tensor(0.3664, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:8 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:9 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:10 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:11 loss: 0.002995tensor(0.3917, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:12 loss: 0.005282tensor(0.4531, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:13 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:14 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:15 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:16 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:17 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:18 loss: 0.002944tensor(0.3569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:19 loss: 0.007453tensor(0.4151, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:20 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:21 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:22 loss: 0.016405tensor(0.3856, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:23 loss: 0.001502tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:24 loss: 0.004122tensor(0.4321, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:25 loss: 0.000943tensor(0.2472, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:26 loss: 0.008982tensor(0.3565, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:27 loss: 0.016797tensor(0.4300, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:28 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:29 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:88 step:30 loss: 0.001023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:31 loss: 0.000444tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:32 loss: 0.000053tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:33 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:34 loss: 0.003187tensor(0.3458, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:35 loss: 0.002396tensor(0.3570, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:36 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:37 loss: 0.001763tensor(0.1424, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:38 loss: 0.000216tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:39 loss: 0.000242tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:40 loss: 0.012924tensor(0.4505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:43 loss: 0.006059tensor(0.4359, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:44 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:45 loss: 0.000832tensor(0.3824, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:46 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:47 loss: 0.005881tensor(0.4293, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:48 loss: 0.001742tensor(0.2878, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:49 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:50 loss: 0.000070tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:51 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:52 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:53 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:54 loss: 0.015150tensor(0.4090, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:55 loss: 0.012670tensor(0.4125, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:56 loss: 0.004259tensor(0.4522, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:57 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:58 loss: 0.004153tensor(0.3023, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:59 loss: 0.000071tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:60 loss: 0.013105tensor(0.4441, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:61 loss: 0.005529tensor(0.3424, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:62 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:63 loss: 0.000454tensor(0.1575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:64 loss: 0.001008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:65 loss: 0.003091tensor(0.4343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:66 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:67 loss: 0.004066tensor(0.4087, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:70 loss: 0.001021tensor(0.3736, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:71 loss: 0.004918tensor(0.4224, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:72 loss: 0.001798tensor(0.4347, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:73 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:74 loss: 0.003011tensor(0.4331, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:75 loss: 0.000158tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:76 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:77 loss: 0.000413tensor(0.2985, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:78 loss: 0.008528tensor(0.4386, grad_fn=<DivBackward0>)\n",
      "Test Epoch:88 step:79 loss: 0.001520tensor(0.4186, grad_fn=<DivBackward0>)\n",
      "Epoch:89 step:0 loss: 0.004077\n",
      "Epoch:89 step:1 loss: 0.003631\n",
      "Epoch:89 step:2 loss: 0.000011\n",
      "Epoch:89 step:3 loss: 0.000000\n",
      "Epoch:89 step:4 loss: 0.005862\n",
      "Epoch:89 step:5 loss: 0.003172\n",
      "Epoch:89 step:6 loss: 0.000000\n",
      "Epoch:89 step:7 loss: 0.003790\n",
      "Epoch:89 step:8 loss: 0.000003\n",
      "Epoch:89 step:9 loss: 0.000002\n",
      "Epoch:89 step:10 loss: 0.000001\n",
      "Epoch:89 step:11 loss: 0.002318\n",
      "Epoch:89 step:12 loss: 0.004638\n",
      "Epoch:89 step:13 loss: 0.000007\n",
      "Epoch:89 step:14 loss: 0.000005\n",
      "Epoch:89 step:15 loss: 0.000021\n",
      "Epoch:89 step:16 loss: 0.000000\n",
      "Epoch:89 step:17 loss: 0.000087\n",
      "Epoch:89 step:18 loss: 0.001693\n",
      "Epoch:89 step:19 loss: 0.006616\n",
      "Epoch:89 step:20 loss: 0.000005\n",
      "Epoch:89 step:21 loss: 0.000032\n",
      "Epoch:89 step:22 loss: 0.010410\n",
      "Epoch:89 step:23 loss: 0.000375\n",
      "Epoch:89 step:24 loss: 0.003968\n",
      "Epoch:89 step:25 loss: 0.000645\n",
      "Epoch:89 step:26 loss: 0.006335\n",
      "Epoch:89 step:27 loss: 0.014402\n",
      "Epoch:89 step:28 loss: 0.000001\n",
      "Epoch:89 step:29 loss: 0.000000\n",
      "Epoch:89 step:30 loss: 0.001134\n",
      "Epoch:89 step:31 loss: 0.000077\n",
      "Epoch:89 step:32 loss: 0.000011\n",
      "Epoch:89 step:33 loss: 0.000001\n",
      "Epoch:89 step:34 loss: 0.002985\n",
      "Epoch:89 step:35 loss: 0.002389\n",
      "Epoch:89 step:36 loss: 0.000019\n",
      "Epoch:89 step:37 loss: 0.001812\n",
      "Epoch:89 step:38 loss: 0.000003\n",
      "Epoch:89 step:39 loss: 0.000207\n",
      "Epoch:89 step:40 loss: 0.011479\n",
      "Epoch:89 step:41 loss: 0.000001\n",
      "Epoch:89 step:42 loss: 0.000000\n",
      "Epoch:89 step:43 loss: 0.005275\n",
      "Epoch:89 step:44 loss: 0.000010\n",
      "Epoch:89 step:45 loss: 0.000883\n",
      "Epoch:89 step:46 loss: 0.000001\n",
      "Epoch:89 step:47 loss: 0.005567\n",
      "Epoch:89 step:48 loss: 0.001956\n",
      "Epoch:89 step:49 loss: 0.000006\n",
      "Epoch:89 step:50 loss: 0.000005\n",
      "Epoch:89 step:51 loss: 0.000012\n",
      "Epoch:89 step:52 loss: 0.000006\n",
      "Epoch:89 step:53 loss: 0.000007\n",
      "Epoch:89 step:54 loss: 0.011024\n",
      "Epoch:89 step:55 loss: 0.009483\n",
      "Epoch:89 step:56 loss: 0.004327\n",
      "Epoch:89 step:57 loss: 0.000641\n",
      "Epoch:89 step:58 loss: 0.003518\n",
      "Epoch:89 step:59 loss: 0.000069\n",
      "Epoch:89 step:60 loss: 0.014382\n",
      "Epoch:89 step:61 loss: 0.004998\n",
      "Epoch:89 step:62 loss: 0.000000\n",
      "Epoch:89 step:63 loss: 0.000304\n",
      "Epoch:89 step:64 loss: 0.000095\n",
      "Epoch:89 step:65 loss: 0.002914\n",
      "Epoch:89 step:66 loss: 0.000017\n",
      "Epoch:89 step:67 loss: 0.003741\n",
      "Epoch:89 step:68 loss: 0.000000\n",
      "Epoch:89 step:69 loss: 0.000000\n",
      "Epoch:89 step:70 loss: 0.000790\n",
      "Epoch:89 step:71 loss: 0.003515\n",
      "Epoch:89 step:72 loss: 0.001159\n",
      "Epoch:89 step:73 loss: 0.000012\n",
      "Epoch:89 step:74 loss: 0.002921\n",
      "Epoch:89 step:75 loss: 0.000028\n",
      "Epoch:89 step:76 loss: 0.000014\n",
      "Epoch:89 step:77 loss: 0.000523\n",
      "Epoch:89 step:78 loss: 0.005901\n",
      "Epoch:89 step:79 loss: 0.001373\n",
      "Test Epoch:89 step:0 loss: 0.003030tensor(0.3692, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:1 loss: 0.003016tensor(0.2078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:2 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:4 loss: 0.008054tensor(0.4078, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:5 loss: 0.002909tensor(0.4256, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:7 loss: 0.003755tensor(0.3908, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:9 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:11 loss: 0.003028tensor(0.4095, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:12 loss: 0.003526tensor(0.4704, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:13 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:14 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:15 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:17 loss: 0.000032tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:18 loss: 0.002135tensor(0.3981, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:19 loss: 0.006430tensor(0.4338, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:22 loss: 0.009238tensor(0.4312, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:23 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:24 loss: 0.003513tensor(0.4429, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:25 loss: 0.000726tensor(0.2916, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:26 loss: 0.006168tensor(0.4127, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:89 step:27 loss: 0.014730tensor(0.4477, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:28 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:30 loss: 0.001294tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:31 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:32 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:34 loss: 0.002149tensor(0.3922, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:35 loss: 0.002187tensor(0.3807, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:36 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:37 loss: 0.001111tensor(0.2062, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:39 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:40 loss: 0.011643tensor(0.4603, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:43 loss: 0.005525tensor(0.4440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:44 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:45 loss: 0.000790tensor(0.4107, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:47 loss: 0.004863tensor(0.4443, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:48 loss: 0.001894tensor(0.3024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:49 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:50 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:51 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:52 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:53 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:54 loss: 0.008414tensor(0.4440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:55 loss: 0.008701tensor(0.4335, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:56 loss: 0.004277tensor(0.4550, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:57 loss: 0.000041tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:58 loss: 0.002915tensor(0.3534, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:59 loss: 0.000121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:60 loss: 0.010087tensor(0.4577, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:61 loss: 0.004816tensor(0.3523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:62 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:63 loss: 0.000397tensor(0.2695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:64 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:65 loss: 0.002508tensor(0.4439, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:66 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:67 loss: 0.003668tensor(0.4220, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:70 loss: 0.000692tensor(0.4199, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:71 loss: 0.002985tensor(0.4521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:72 loss: 0.001027tensor(0.4569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:73 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:74 loss: 0.002442tensor(0.4501, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:75 loss: 0.000056tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:76 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:77 loss: 0.000246tensor(0.3636, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:78 loss: 0.005575tensor(0.4589, grad_fn=<DivBackward0>)\n",
      "Test Epoch:89 step:79 loss: 0.001526tensor(0.4358, grad_fn=<DivBackward0>)\n",
      "Epoch:90 step:0 loss: 0.003435\n",
      "Epoch:90 step:1 loss: 0.002211\n",
      "Epoch:90 step:2 loss: 0.000012\n",
      "Epoch:90 step:3 loss: 0.000000\n",
      "Epoch:90 step:4 loss: 0.006376\n",
      "Epoch:90 step:5 loss: 0.002328\n",
      "Epoch:90 step:6 loss: 0.000000\n",
      "Epoch:90 step:7 loss: 0.003237\n",
      "Epoch:90 step:8 loss: 0.000000\n",
      "Epoch:90 step:9 loss: 0.000000\n",
      "Epoch:90 step:10 loss: 0.000001\n",
      "Epoch:90 step:11 loss: 0.002070\n",
      "Epoch:90 step:12 loss: 0.004522\n",
      "Epoch:90 step:13 loss: 0.000009\n",
      "Epoch:90 step:14 loss: 0.000016\n",
      "Epoch:90 step:15 loss: 0.000009\n",
      "Epoch:90 step:16 loss: 0.000000\n",
      "Epoch:90 step:17 loss: 0.000031\n",
      "Epoch:90 step:18 loss: 0.001152\n",
      "Epoch:90 step:19 loss: 0.006289\n",
      "Epoch:90 step:20 loss: 0.000001\n",
      "Epoch:90 step:21 loss: 0.000001\n",
      "Epoch:90 step:22 loss: 0.007869\n",
      "Epoch:90 step:23 loss: 0.000037\n",
      "Epoch:90 step:24 loss: 0.003034\n",
      "Epoch:90 step:25 loss: 0.002842\n",
      "Epoch:90 step:26 loss: 0.005256\n",
      "Epoch:90 step:27 loss: 0.012171\n",
      "Epoch:90 step:28 loss: 0.000009\n",
      "Epoch:90 step:29 loss: 0.000000\n",
      "Epoch:90 step:30 loss: 0.000267\n",
      "Epoch:90 step:31 loss: 0.000042\n",
      "Epoch:90 step:32 loss: 0.000024\n",
      "Epoch:90 step:33 loss: 0.000001\n",
      "Epoch:90 step:34 loss: 0.002133\n",
      "Epoch:90 step:35 loss: 0.002613\n",
      "Epoch:90 step:36 loss: 0.000063\n",
      "Epoch:90 step:37 loss: 0.001211\n",
      "Epoch:90 step:38 loss: 0.001727\n",
      "Epoch:90 step:39 loss: 0.000083\n",
      "Epoch:90 step:40 loss: 0.010291\n",
      "Epoch:90 step:41 loss: 0.000000\n",
      "Epoch:90 step:42 loss: 0.000196\n",
      "Epoch:90 step:43 loss: 0.005491\n",
      "Epoch:90 step:44 loss: 0.000012\n",
      "Epoch:90 step:45 loss: 0.000679\n",
      "Epoch:90 step:46 loss: 0.000000\n",
      "Epoch:90 step:47 loss: 0.004256\n",
      "Epoch:90 step:48 loss: 0.002889\n",
      "Epoch:90 step:49 loss: 0.000046\n",
      "Epoch:90 step:50 loss: 0.000010\n",
      "Epoch:90 step:51 loss: 0.000011\n",
      "Epoch:90 step:52 loss: 0.000054\n",
      "Epoch:90 step:53 loss: 0.000025\n",
      "Epoch:90 step:54 loss: 0.008008\n",
      "Epoch:90 step:55 loss: 0.012081\n",
      "Epoch:90 step:56 loss: 0.003021\n",
      "Epoch:90 step:57 loss: 0.000243\n",
      "Epoch:90 step:58 loss: 0.002686\n",
      "Epoch:90 step:59 loss: 0.000204\n",
      "Epoch:90 step:60 loss: 0.019524\n",
      "Epoch:90 step:61 loss: 0.004781\n",
      "Epoch:90 step:62 loss: 0.000013\n",
      "Epoch:90 step:63 loss: 0.000302\n",
      "Epoch:90 step:64 loss: 0.000582\n",
      "Epoch:90 step:65 loss: 0.002513\n",
      "Epoch:90 step:66 loss: 0.000027\n",
      "Epoch:90 step:67 loss: 0.003962\n",
      "Epoch:90 step:68 loss: 0.000000\n",
      "Epoch:90 step:69 loss: 0.000001\n",
      "Epoch:90 step:70 loss: 0.000821\n",
      "Epoch:90 step:71 loss: 0.004195\n",
      "Epoch:90 step:72 loss: 0.001070\n",
      "Epoch:90 step:73 loss: 0.000074\n",
      "Epoch:90 step:74 loss: 0.002285\n",
      "Epoch:90 step:75 loss: 0.000087\n",
      "Epoch:90 step:76 loss: 0.000011\n",
      "Epoch:90 step:77 loss: 0.000472\n",
      "Epoch:90 step:78 loss: 0.006753\n",
      "Epoch:90 step:79 loss: 0.001574\n",
      "Test Epoch:90 step:0 loss: 0.003445tensor(0.3339, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:1 loss: 0.002205tensor(0.2640, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:2 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:4 loss: 0.005652tensor(0.4334, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:5 loss: 0.002563tensor(0.4260, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:7 loss: 0.003102tensor(0.3994, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:9 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:11 loss: 0.003117tensor(0.3951, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:12 loss: 0.004171tensor(0.4642, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:13 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:14 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:15 loss: 0.000024tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:17 loss: 0.000084tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:18 loss: 0.001105tensor(0.4370, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:19 loss: 0.005401tensor(0.4425, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:22 loss: 0.008294tensor(0.4408, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:23 loss: 0.000314tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:90 step:24 loss: 0.002980tensor(0.4500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:25 loss: 0.001835tensor(0.2337, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:26 loss: 0.004525tensor(0.4297, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:27 loss: 0.009210tensor(0.4635, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:28 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:30 loss: 0.000112tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:31 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:32 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:34 loss: 0.005844tensor(0.2604, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:35 loss: 0.003534tensor(0.3395, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:36 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:37 loss: 0.000671tensor(0.2496, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:39 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:40 loss: 0.014423tensor(0.4521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:42 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:43 loss: 0.008995tensor(0.4256, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:44 loss: 0.000167tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:45 loss: 0.002285tensor(0.3093, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:46 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:47 loss: 0.004033tensor(0.4498, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:48 loss: 0.003945tensor(0.2606, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:49 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:50 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:51 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:53 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:54 loss: 0.012847tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:55 loss: 0.009027tensor(0.4290, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:56 loss: 0.005190tensor(0.4501, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:57 loss: 0.000740tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:58 loss: 0.003151tensor(0.3376, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:59 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:60 loss: 0.015132tensor(0.4435, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:61 loss: 0.004412tensor(0.3654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:62 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:63 loss: 0.000267tensor(0.2711, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:64 loss: 0.000106tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:65 loss: 0.002664tensor(0.4362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:66 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:67 loss: 0.002998tensor(0.4232, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:70 loss: 0.000655tensor(0.4045, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:71 loss: 0.002976tensor(0.4440, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:72 loss: 0.001245tensor(0.4492, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:73 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:74 loss: 0.002299tensor(0.4471, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:75 loss: 0.000100tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:76 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:77 loss: 0.001090tensor(0.2330, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:78 loss: 0.005092tensor(0.4582, grad_fn=<DivBackward0>)\n",
      "Test Epoch:90 step:79 loss: 0.001813tensor(0.4178, grad_fn=<DivBackward0>)\n",
      "Epoch:91 step:0 loss: 0.002763\n",
      "Epoch:91 step:1 loss: 0.002383\n",
      "Epoch:91 step:2 loss: 0.000014\n",
      "Epoch:91 step:3 loss: 0.000000\n",
      "Epoch:91 step:4 loss: 0.005440\n",
      "Epoch:91 step:5 loss: 0.003306\n",
      "Epoch:91 step:6 loss: 0.000000\n",
      "Epoch:91 step:7 loss: 0.004570\n",
      "Epoch:91 step:8 loss: 0.000000\n",
      "Epoch:91 step:9 loss: 0.000000\n",
      "Epoch:91 step:10 loss: 0.000001\n",
      "Epoch:91 step:11 loss: 0.002945\n",
      "Epoch:91 step:12 loss: 0.003618\n",
      "Epoch:91 step:13 loss: 0.000014\n",
      "Epoch:91 step:14 loss: 0.000001\n",
      "Epoch:91 step:15 loss: 0.000015\n",
      "Epoch:91 step:16 loss: 0.000000\n",
      "Epoch:91 step:17 loss: 0.000016\n",
      "Epoch:91 step:18 loss: 0.001064\n",
      "Epoch:91 step:19 loss: 0.006049\n",
      "Epoch:91 step:20 loss: 0.000000\n",
      "Epoch:91 step:21 loss: 0.000000\n",
      "Epoch:91 step:22 loss: 0.007141\n",
      "Epoch:91 step:23 loss: 0.000569\n",
      "Epoch:91 step:24 loss: 0.003170\n",
      "Epoch:91 step:25 loss: 0.000784\n",
      "Epoch:91 step:26 loss: 0.004389\n",
      "Epoch:91 step:27 loss: 0.011894\n",
      "Epoch:91 step:28 loss: 0.000003\n",
      "Epoch:91 step:29 loss: 0.000000\n",
      "Epoch:91 step:30 loss: 0.000452\n",
      "Epoch:91 step:31 loss: 0.000163\n",
      "Epoch:91 step:32 loss: 0.000006\n",
      "Epoch:91 step:33 loss: 0.000000\n",
      "Epoch:91 step:34 loss: 0.004217\n",
      "Epoch:91 step:35 loss: 0.002286\n",
      "Epoch:91 step:36 loss: 0.000011\n",
      "Epoch:91 step:37 loss: 0.000911\n",
      "Epoch:91 step:38 loss: 0.000000\n",
      "Epoch:91 step:39 loss: 0.000064\n",
      "Epoch:91 step:40 loss: 0.010392\n",
      "Epoch:91 step:41 loss: 0.000000\n",
      "Epoch:91 step:42 loss: 0.000001\n",
      "Epoch:91 step:43 loss: 0.007530\n",
      "Epoch:91 step:44 loss: 0.000002\n",
      "Epoch:91 step:45 loss: 0.000954\n",
      "Epoch:91 step:46 loss: 0.000000\n",
      "Epoch:91 step:47 loss: 0.004628\n",
      "Epoch:91 step:48 loss: 0.001771\n",
      "Epoch:91 step:49 loss: 0.000001\n",
      "Epoch:91 step:50 loss: 0.000007\n",
      "Epoch:91 step:51 loss: 0.000017\n",
      "Epoch:91 step:52 loss: 0.000001\n",
      "Epoch:91 step:53 loss: 0.000022\n",
      "Epoch:91 step:54 loss: 0.005184\n",
      "Epoch:91 step:55 loss: 0.008184\n",
      "Epoch:91 step:56 loss: 0.002974\n",
      "Epoch:91 step:57 loss: 0.000173\n",
      "Epoch:91 step:58 loss: 0.004106\n",
      "Epoch:91 step:59 loss: 0.000077\n",
      "Epoch:91 step:60 loss: 0.009401\n",
      "Epoch:91 step:61 loss: 0.004000\n",
      "Epoch:91 step:62 loss: 0.000004\n",
      "Epoch:91 step:63 loss: 0.000191\n",
      "Epoch:91 step:64 loss: 0.000059\n",
      "Epoch:91 step:65 loss: 0.002633\n",
      "Epoch:91 step:66 loss: 0.000008\n",
      "Epoch:91 step:67 loss: 0.002937\n",
      "Epoch:91 step:68 loss: 0.000000\n",
      "Epoch:91 step:69 loss: 0.000000\n",
      "Epoch:91 step:70 loss: 0.000762\n",
      "Epoch:91 step:71 loss: 0.003260\n",
      "Epoch:91 step:72 loss: 0.001412\n",
      "Epoch:91 step:73 loss: 0.000037\n",
      "Epoch:91 step:74 loss: 0.002502\n",
      "Epoch:91 step:75 loss: 0.000173\n",
      "Epoch:91 step:76 loss: 0.000004\n",
      "Epoch:91 step:77 loss: 0.000333\n",
      "Epoch:91 step:78 loss: 0.009912\n",
      "Epoch:91 step:79 loss: 0.001871\n",
      "Test Epoch:91 step:0 loss: 0.003130tensor(0.3566, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:1 loss: 0.002003tensor(0.2928, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:2 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:4 loss: 0.006184tensor(0.4343, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:5 loss: 0.002978tensor(0.4266, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:7 loss: 0.003392tensor(0.3942, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:9 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:11 loss: 0.003022tensor(0.4024, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:12 loss: 0.004951tensor(0.4636, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:13 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:14 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:15 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:17 loss: 0.000020tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:18 loss: 0.001961tensor(0.3989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:19 loss: 0.005874tensor(0.4362, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:91 step:21 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:22 loss: 0.007072tensor(0.4447, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:23 loss: 0.000305tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:24 loss: 0.005506tensor(0.4273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:25 loss: 0.000835tensor(0.2990, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:26 loss: 0.004534tensor(0.4317, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:27 loss: 0.009328tensor(0.4641, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:30 loss: 0.000086tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:31 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:32 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:34 loss: 0.014222tensor(0.1686, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:35 loss: 0.002366tensor(0.3721, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:36 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:37 loss: 0.000636tensor(0.2600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:39 loss: 0.000392tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:40 loss: 0.010364tensor(0.4614, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:42 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:43 loss: 0.006938tensor(0.4334, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:44 loss: 0.000344tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:45 loss: 0.002345tensor(0.3121, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:46 loss: 0.000206tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:47 loss: 0.004832tensor(0.4379, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:48 loss: 0.003402tensor(0.2633, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:50 loss: 0.000179tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:51 loss: 0.000870tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:53 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:54 loss: 0.012698tensor(0.4279, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:55 loss: 0.008607tensor(0.4316, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:56 loss: 0.009196tensor(0.4204, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:57 loss: 0.003707tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:58 loss: 0.003541tensor(0.3182, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:59 loss: 0.000065tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:60 loss: 0.010882tensor(0.4555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:61 loss: 0.005028tensor(0.3403, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:62 loss: 0.000017tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:63 loss: 0.000356tensor(0.2131, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:64 loss: 0.002655tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:65 loss: 0.002870tensor(0.4301, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:66 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:67 loss: 0.004046tensor(0.4092, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:70 loss: 0.000953tensor(0.3684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:71 loss: 0.003325tensor(0.4415, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:72 loss: 0.001329tensor(0.4471, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:73 loss: 0.000134tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:74 loss: 0.002880tensor(0.4396, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:75 loss: 0.000176tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:76 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:77 loss: 0.000429tensor(0.2768, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:78 loss: 0.008706tensor(0.4459, grad_fn=<DivBackward0>)\n",
      "Test Epoch:91 step:79 loss: 0.003314tensor(0.3829, grad_fn=<DivBackward0>)\n",
      "Epoch:92 step:0 loss: 0.003456\n",
      "Epoch:92 step:1 loss: 0.002677\n",
      "Epoch:92 step:2 loss: 0.000118\n",
      "Epoch:92 step:3 loss: 0.000000\n",
      "Epoch:92 step:4 loss: 0.006657\n",
      "Epoch:92 step:5 loss: 0.005410\n",
      "Epoch:92 step:6 loss: 0.000000\n",
      "Epoch:92 step:7 loss: 0.004281\n",
      "Epoch:92 step:8 loss: 0.000000\n",
      "Epoch:92 step:9 loss: 0.000245\n",
      "Epoch:92 step:10 loss: 0.000004\n",
      "Epoch:92 step:11 loss: 0.004042\n",
      "Epoch:92 step:12 loss: 0.003390\n",
      "Epoch:92 step:13 loss: 0.000092\n",
      "Epoch:92 step:14 loss: 0.000017\n",
      "Epoch:92 step:15 loss: 0.000028\n",
      "Epoch:92 step:16 loss: 0.000000\n",
      "Epoch:92 step:17 loss: 0.000187\n",
      "Epoch:92 step:18 loss: 0.001377\n",
      "Epoch:92 step:19 loss: 0.005734\n",
      "Epoch:92 step:20 loss: 0.000001\n",
      "Epoch:92 step:21 loss: 0.000001\n",
      "Epoch:92 step:22 loss: 0.008270\n",
      "Epoch:92 step:23 loss: 0.000347\n",
      "Epoch:92 step:24 loss: 0.002743\n",
      "Epoch:92 step:25 loss: 0.000486\n",
      "Epoch:92 step:26 loss: 0.004661\n",
      "Epoch:92 step:27 loss: 0.011515\n",
      "Epoch:92 step:28 loss: 0.001623\n",
      "Epoch:92 step:29 loss: 0.000000\n",
      "Epoch:92 step:30 loss: 0.000337\n",
      "Epoch:92 step:31 loss: 0.000602\n",
      "Epoch:92 step:32 loss: 0.000034\n",
      "Epoch:92 step:33 loss: 0.000000\n",
      "Epoch:92 step:34 loss: 0.003940\n",
      "Epoch:92 step:35 loss: 0.001713\n",
      "Epoch:92 step:36 loss: 0.000004\n",
      "Epoch:92 step:37 loss: 0.000974\n",
      "Epoch:92 step:38 loss: 0.000000\n",
      "Epoch:92 step:39 loss: 0.000065\n",
      "Epoch:92 step:40 loss: 0.009458\n",
      "Epoch:92 step:41 loss: 0.000000\n",
      "Epoch:92 step:42 loss: 0.000003\n",
      "Epoch:92 step:43 loss: 0.006342\n",
      "Epoch:92 step:44 loss: 0.000003\n",
      "Epoch:92 step:45 loss: 0.001048\n",
      "Epoch:92 step:46 loss: 0.000000\n",
      "Epoch:92 step:47 loss: 0.005230\n",
      "Epoch:92 step:48 loss: 0.002209\n",
      "Epoch:92 step:49 loss: 0.000003\n",
      "Epoch:92 step:50 loss: 0.000005\n",
      "Epoch:92 step:51 loss: 0.000040\n",
      "Epoch:92 step:52 loss: 0.000003\n",
      "Epoch:92 step:53 loss: 0.000085\n",
      "Epoch:92 step:54 loss: 0.009955\n",
      "Epoch:92 step:55 loss: 0.008978\n",
      "Epoch:92 step:56 loss: 0.003196\n",
      "Epoch:92 step:57 loss: 0.000209\n",
      "Epoch:92 step:58 loss: 0.004551\n",
      "Epoch:92 step:59 loss: 0.000037\n",
      "Epoch:92 step:60 loss: 0.015862\n",
      "Epoch:92 step:61 loss: 0.003656\n",
      "Epoch:92 step:62 loss: 0.000009\n",
      "Epoch:92 step:63 loss: 0.000251\n",
      "Epoch:92 step:64 loss: 0.001150\n",
      "Epoch:92 step:65 loss: 0.003536\n",
      "Epoch:92 step:66 loss: 0.000027\n",
      "Epoch:92 step:67 loss: 0.003291\n",
      "Epoch:92 step:68 loss: 0.000000\n",
      "Epoch:92 step:69 loss: 0.000000\n",
      "Epoch:92 step:70 loss: 0.001094\n",
      "Epoch:92 step:71 loss: 0.004399\n",
      "Epoch:92 step:72 loss: 0.002005\n",
      "Epoch:92 step:73 loss: 0.000056\n",
      "Epoch:92 step:74 loss: 0.002518\n",
      "Epoch:92 step:75 loss: 0.000126\n",
      "Epoch:92 step:76 loss: 0.000012\n",
      "Epoch:92 step:77 loss: 0.001059\n",
      "Epoch:92 step:78 loss: 0.008933\n",
      "Epoch:92 step:79 loss: 0.001630\n",
      "Test Epoch:92 step:0 loss: 0.002799tensor(0.3557, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:1 loss: 0.003295tensor(0.2281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:2 loss: 0.000096tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:4 loss: 0.004963tensor(0.4374, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:5 loss: 0.002645tensor(0.4306, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:7 loss: 0.003782tensor(0.3870, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:9 loss: 0.000049tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:11 loss: 0.002852tensor(0.4123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:12 loss: 0.003253tensor(0.4728, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:13 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:14 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:15 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:17 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:92 step:18 loss: 0.001349tensor(0.4238, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:19 loss: 0.006471tensor(0.4385, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:21 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:22 loss: 0.008032tensor(0.4389, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:23 loss: 0.000225tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:24 loss: 0.002921tensor(0.4527, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:25 loss: 0.000473tensor(0.3252, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:26 loss: 0.005668tensor(0.4136, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:27 loss: 0.012128tensor(0.4572, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:30 loss: 0.000559tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:31 loss: 0.000030tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:32 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:34 loss: 0.003033tensor(0.3476, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:35 loss: 0.002641tensor(0.3590, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:36 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:37 loss: 0.000703tensor(0.2735, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:39 loss: 0.000132tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:40 loss: 0.015586tensor(0.4505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:42 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:43 loss: 0.005786tensor(0.4427, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:44 loss: 0.000068tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:45 loss: 0.001510tensor(0.3430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:47 loss: 0.003820tensor(0.4514, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:48 loss: 0.001518tensor(0.3163, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:50 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:51 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:53 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:54 loss: 0.007503tensor(0.4491, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:55 loss: 0.008255tensor(0.4361, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:56 loss: 0.003029tensor(0.4639, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:57 loss: 0.000145tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:58 loss: 0.002635tensor(0.3647, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:59 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:60 loss: 0.008359tensor(0.4637, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:61 loss: 0.004177tensor(0.3672, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:62 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:63 loss: 0.000285tensor(0.2854, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:64 loss: 0.000108tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:65 loss: 0.001873tensor(0.4529, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:66 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:67 loss: 0.003138tensor(0.4263, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:70 loss: 0.000687tensor(0.4190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:71 loss: 0.002170tensor(0.4585, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:72 loss: 0.001394tensor(0.4523, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:73 loss: 0.000044tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:74 loss: 0.002159tensor(0.4502, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:75 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:76 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:77 loss: 0.000416tensor(0.3034, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:78 loss: 0.004650tensor(0.4644, grad_fn=<DivBackward0>)\n",
      "Test Epoch:92 step:79 loss: 0.001171tensor(0.4379, grad_fn=<DivBackward0>)\n",
      "Epoch:93 step:0 loss: 0.002808\n",
      "Epoch:93 step:1 loss: 0.004387\n",
      "Epoch:93 step:2 loss: 0.000014\n",
      "Epoch:93 step:3 loss: 0.000000\n",
      "Epoch:93 step:4 loss: 0.004077\n",
      "Epoch:93 step:5 loss: 0.001971\n",
      "Epoch:93 step:6 loss: 0.000000\n",
      "Epoch:93 step:7 loss: 0.002534\n",
      "Epoch:93 step:8 loss: 0.000000\n",
      "Epoch:93 step:9 loss: 0.000000\n",
      "Epoch:93 step:10 loss: 0.000000\n",
      "Epoch:93 step:11 loss: 0.001765\n",
      "Epoch:93 step:12 loss: 0.003862\n",
      "Epoch:93 step:13 loss: 0.000001\n",
      "Epoch:93 step:14 loss: 0.000001\n",
      "Epoch:93 step:15 loss: 0.000007\n",
      "Epoch:93 step:16 loss: 0.000000\n",
      "Epoch:93 step:17 loss: 0.000009\n",
      "Epoch:93 step:18 loss: 0.001508\n",
      "Epoch:93 step:19 loss: 0.005106\n",
      "Epoch:93 step:20 loss: 0.000000\n",
      "Epoch:93 step:21 loss: 0.000001\n",
      "Epoch:93 step:22 loss: 0.007592\n",
      "Epoch:93 step:23 loss: 0.000178\n",
      "Epoch:93 step:24 loss: 0.003223\n",
      "Epoch:93 step:25 loss: 0.000533\n",
      "Epoch:93 step:26 loss: 0.004328\n",
      "Epoch:93 step:27 loss: 0.010199\n",
      "Epoch:93 step:28 loss: 0.000000\n",
      "Epoch:93 step:29 loss: 0.000000\n",
      "Epoch:93 step:30 loss: 0.000598\n",
      "Epoch:93 step:31 loss: 0.000030\n",
      "Epoch:93 step:32 loss: 0.000001\n",
      "Epoch:93 step:33 loss: 0.000000\n",
      "Epoch:93 step:34 loss: 0.002044\n",
      "Epoch:93 step:35 loss: 0.002319\n",
      "Epoch:93 step:36 loss: 0.000005\n",
      "Epoch:93 step:37 loss: 0.000826\n",
      "Epoch:93 step:38 loss: 0.000000\n",
      "Epoch:93 step:39 loss: 0.000051\n",
      "Epoch:93 step:40 loss: 0.009484\n",
      "Epoch:93 step:41 loss: 0.000000\n",
      "Epoch:93 step:42 loss: 0.000001\n",
      "Epoch:93 step:43 loss: 0.007728\n",
      "Epoch:93 step:44 loss: 0.000000\n",
      "Epoch:93 step:45 loss: 0.002205\n",
      "Epoch:93 step:46 loss: 0.000000\n",
      "Epoch:93 step:47 loss: 0.004058\n",
      "Epoch:93 step:48 loss: 0.001532\n",
      "Epoch:93 step:49 loss: 0.000000\n",
      "Epoch:93 step:50 loss: 0.000001\n",
      "Epoch:93 step:51 loss: 0.000003\n",
      "Epoch:93 step:52 loss: 0.000000\n",
      "Epoch:93 step:53 loss: 0.000004\n",
      "Epoch:93 step:54 loss: 0.007616\n",
      "Epoch:93 step:55 loss: 0.007912\n",
      "Epoch:93 step:56 loss: 0.003573\n",
      "Epoch:93 step:57 loss: 0.000297\n",
      "Epoch:93 step:58 loss: 0.002453\n",
      "Epoch:93 step:59 loss: 0.000082\n",
      "Epoch:93 step:60 loss: 0.007997\n",
      "Epoch:93 step:61 loss: 0.004283\n",
      "Epoch:93 step:62 loss: 0.000007\n",
      "Epoch:93 step:63 loss: 0.000435\n",
      "Epoch:93 step:64 loss: 0.000083\n",
      "Epoch:93 step:65 loss: 0.002071\n",
      "Epoch:93 step:66 loss: 0.000004\n",
      "Epoch:93 step:67 loss: 0.002881\n",
      "Epoch:93 step:68 loss: 0.000000\n",
      "Epoch:93 step:69 loss: 0.000000\n",
      "Epoch:93 step:70 loss: 0.000509\n",
      "Epoch:93 step:71 loss: 0.002250\n",
      "Epoch:93 step:72 loss: 0.000827\n",
      "Epoch:93 step:73 loss: 0.000019\n",
      "Epoch:93 step:74 loss: 0.002309\n",
      "Epoch:93 step:75 loss: 0.000055\n",
      "Epoch:93 step:76 loss: 0.000001\n",
      "Epoch:93 step:77 loss: 0.001009\n",
      "Epoch:93 step:78 loss: 0.005064\n",
      "Epoch:93 step:79 loss: 0.000968\n",
      "Test Epoch:93 step:0 loss: 0.002901tensor(0.3724, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:1 loss: 0.002408tensor(0.2719, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:2 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:4 loss: 0.003806tensor(0.4498, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:5 loss: 0.002517tensor(0.4270, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:7 loss: 0.002429tensor(0.4190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:9 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:11 loss: 0.001500tensor(0.4479, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:12 loss: 0.003056tensor(0.4740, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:13 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:14 loss: 0.000015tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:93 step:15 loss: 0.000011tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:17 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:18 loss: 0.000829tensor(0.4527, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:19 loss: 0.004861tensor(0.4505, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:22 loss: 0.005438tensor(0.4598, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:23 loss: 0.000062tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:24 loss: 0.001901tensor(0.4674, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:25 loss: 0.000492tensor(0.3001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:26 loss: 0.002568tensor(0.4580, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:27 loss: 0.008240tensor(0.4695, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:30 loss: 0.000069tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:31 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:32 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:34 loss: 0.002885tensor(0.3792, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:35 loss: 0.002527tensor(0.3973, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:36 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:37 loss: 0.001363tensor(0.2405, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:39 loss: 0.000019tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:40 loss: 0.006932tensor(0.4733, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:43 loss: 0.004809tensor(0.4521, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:44 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:45 loss: 0.000983tensor(0.4020, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:47 loss: 0.008055tensor(0.4301, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:48 loss: 0.004309tensor(0.1790, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:50 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:51 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:53 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:54 loss: 0.007238tensor(0.4548, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:55 loss: 0.010350tensor(0.4353, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:56 loss: 0.003266tensor(0.4616, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:57 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:58 loss: 0.003413tensor(0.3407, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:59 loss: 0.000206tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:60 loss: 0.018060tensor(0.4448, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:61 loss: 0.003783tensor(0.3543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:62 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:63 loss: 0.000472tensor(0.2745, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:64 loss: 0.000408tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:65 loss: 0.002181tensor(0.4463, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:66 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:67 loss: 0.005599tensor(0.3989, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:70 loss: 0.000828tensor(0.4022, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:71 loss: 0.002652tensor(0.4522, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:72 loss: 0.001076tensor(0.4543, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:73 loss: 0.000037tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:74 loss: 0.001950tensor(0.4544, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:75 loss: 0.000095tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:76 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:77 loss: 0.000711tensor(0.2804, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:78 loss: 0.004653tensor(0.4589, grad_fn=<DivBackward0>)\n",
      "Test Epoch:93 step:79 loss: 0.001765tensor(0.4156, grad_fn=<DivBackward0>)\n",
      "Epoch:94 step:0 loss: 0.002732\n",
      "Epoch:94 step:1 loss: 0.002123\n",
      "Epoch:94 step:2 loss: 0.000013\n",
      "Epoch:94 step:3 loss: 0.000000\n",
      "Epoch:94 step:4 loss: 0.004588\n",
      "Epoch:94 step:5 loss: 0.002196\n",
      "Epoch:94 step:6 loss: 0.000000\n",
      "Epoch:94 step:7 loss: 0.002803\n",
      "Epoch:94 step:8 loss: 0.000001\n",
      "Epoch:94 step:9 loss: 0.000378\n",
      "Epoch:94 step:10 loss: 0.000000\n",
      "Epoch:94 step:11 loss: 0.001754\n",
      "Epoch:94 step:12 loss: 0.002266\n",
      "Epoch:94 step:13 loss: 0.000001\n",
      "Epoch:94 step:14 loss: 0.000008\n",
      "Epoch:94 step:15 loss: 0.000029\n",
      "Epoch:94 step:16 loss: 0.000000\n",
      "Epoch:94 step:17 loss: 0.000030\n",
      "Epoch:94 step:18 loss: 0.001331\n",
      "Epoch:94 step:19 loss: 0.005128\n",
      "Epoch:94 step:20 loss: 0.000000\n",
      "Epoch:94 step:21 loss: 0.000000\n",
      "Epoch:94 step:22 loss: 0.006724\n",
      "Epoch:94 step:23 loss: 0.000424\n",
      "Epoch:94 step:24 loss: 0.002097\n",
      "Epoch:94 step:25 loss: 0.000552\n",
      "Epoch:94 step:26 loss: 0.003592\n",
      "Epoch:94 step:27 loss: 0.007904\n",
      "Epoch:94 step:28 loss: 0.000000\n",
      "Epoch:94 step:29 loss: 0.000000\n",
      "Epoch:94 step:30 loss: 0.000598\n",
      "Epoch:94 step:31 loss: 0.000012\n",
      "Epoch:94 step:32 loss: 0.000045\n",
      "Epoch:94 step:33 loss: 0.000000\n",
      "Epoch:94 step:34 loss: 0.003440\n",
      "Epoch:94 step:35 loss: 0.002286\n",
      "Epoch:94 step:36 loss: 0.000003\n",
      "Epoch:94 step:37 loss: 0.000720\n",
      "Epoch:94 step:38 loss: 0.000004\n",
      "Epoch:94 step:39 loss: 0.000038\n",
      "Epoch:94 step:40 loss: 0.008019\n",
      "Epoch:94 step:41 loss: 0.000000\n",
      "Epoch:94 step:42 loss: 0.000019\n",
      "Epoch:94 step:43 loss: 0.007047\n",
      "Epoch:94 step:44 loss: 0.000049\n",
      "Epoch:94 step:45 loss: 0.000963\n",
      "Epoch:94 step:46 loss: 0.000000\n",
      "Epoch:94 step:47 loss: 0.003388\n",
      "Epoch:94 step:48 loss: 0.001516\n",
      "Epoch:94 step:49 loss: 0.000001\n",
      "Epoch:94 step:50 loss: 0.000000\n",
      "Epoch:94 step:51 loss: 0.000001\n",
      "Epoch:94 step:52 loss: 0.000001\n",
      "Epoch:94 step:53 loss: 0.000004\n",
      "Epoch:94 step:54 loss: 0.009081\n",
      "Epoch:94 step:55 loss: 0.007506\n",
      "Epoch:94 step:56 loss: 0.004832\n",
      "Epoch:94 step:57 loss: 0.000156\n",
      "Epoch:94 step:58 loss: 0.002177\n",
      "Epoch:94 step:59 loss: 0.000024\n",
      "Epoch:94 step:60 loss: 0.011491\n",
      "Epoch:94 step:61 loss: 0.003271\n",
      "Epoch:94 step:62 loss: 0.000001\n",
      "Epoch:94 step:63 loss: 0.000509\n",
      "Epoch:94 step:64 loss: 0.000242\n",
      "Epoch:94 step:65 loss: 0.002362\n",
      "Epoch:94 step:66 loss: 0.000014\n",
      "Epoch:94 step:67 loss: 0.002563\n",
      "Epoch:94 step:68 loss: 0.000000\n",
      "Epoch:94 step:69 loss: 0.000000\n",
      "Epoch:94 step:70 loss: 0.000540\n",
      "Epoch:94 step:71 loss: 0.003630\n",
      "Epoch:94 step:72 loss: 0.001105\n",
      "Epoch:94 step:73 loss: 0.000006\n",
      "Epoch:94 step:74 loss: 0.001785\n",
      "Epoch:94 step:75 loss: 0.000168\n",
      "Epoch:94 step:76 loss: 0.000002\n",
      "Epoch:94 step:77 loss: 0.000309\n",
      "Epoch:94 step:78 loss: 0.004466\n",
      "Epoch:94 step:79 loss: 0.001632\n",
      "Test Epoch:94 step:0 loss: 0.003144tensor(0.3700, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:1 loss: 0.001606tensor(0.3195, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:2 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:4 loss: 0.003852tensor(0.4460, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:5 loss: 0.002466tensor(0.4317, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:7 loss: 0.004374tensor(0.3926, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:9 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:11 loss: 0.001584tensor(0.4441, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:94 step:12 loss: 0.003085tensor(0.4766, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:13 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:15 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:17 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:18 loss: 0.001303tensor(0.4450, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:19 loss: 0.004695tensor(0.4533, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:22 loss: 0.006231tensor(0.4547, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:23 loss: 0.000889tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:24 loss: 0.002580tensor(0.4630, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:25 loss: 0.000583tensor(0.3174, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:26 loss: 0.003016tensor(0.4555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:27 loss: 0.009563tensor(0.4641, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:30 loss: 0.000267tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:31 loss: 0.001293tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:32 loss: 0.000127tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:34 loss: 0.002801tensor(0.3930, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:35 loss: 0.002096tensor(0.4141, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:36 loss: 0.000025tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:37 loss: 0.000661tensor(0.2833, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:39 loss: 0.000079tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:40 loss: 0.009931tensor(0.4685, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:42 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:43 loss: 0.007225tensor(0.4430, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:44 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:45 loss: 0.001313tensor(0.3741, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:47 loss: 0.003791tensor(0.4572, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:48 loss: 0.001307tensor(0.3397, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:49 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:50 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:51 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:53 loss: 0.000005tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:54 loss: 0.004108tensor(0.4691, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:55 loss: 0.007509tensor(0.4442, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:56 loss: 0.004360tensor(0.4600, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:57 loss: 0.000131tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:58 loss: 0.002121tensor(0.3826, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:59 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:60 loss: 0.007424tensor(0.4680, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:61 loss: 0.003374tensor(0.3823, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:63 loss: 0.001097tensor(0.2231, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:64 loss: 0.000149tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:65 loss: 0.002534tensor(0.4488, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:66 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:67 loss: 0.002929tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:70 loss: 0.000501tensor(0.4483, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:71 loss: 0.003111tensor(0.4533, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:72 loss: 0.001102tensor(0.4583, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:73 loss: 0.000124tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:74 loss: 0.001840tensor(0.4580, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:75 loss: 0.000145tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:76 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:77 loss: 0.000163tensor(0.4017, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:78 loss: 0.007209tensor(0.4522, grad_fn=<DivBackward0>)\n",
      "Test Epoch:94 step:79 loss: 0.001867tensor(0.4200, grad_fn=<DivBackward0>)\n",
      "Epoch:95 step:0 loss: 0.002589\n",
      "Epoch:95 step:1 loss: 0.001773\n",
      "Epoch:95 step:2 loss: 0.000002\n",
      "Epoch:95 step:3 loss: 0.000000\n",
      "Epoch:95 step:4 loss: 0.004219\n",
      "Epoch:95 step:5 loss: 0.002225\n",
      "Epoch:95 step:6 loss: 0.000000\n",
      "Epoch:95 step:7 loss: 0.003002\n",
      "Epoch:95 step:8 loss: 0.000000\n",
      "Epoch:95 step:9 loss: 0.000000\n",
      "Epoch:95 step:10 loss: 0.000000\n",
      "Epoch:95 step:11 loss: 0.001884\n",
      "Epoch:95 step:12 loss: 0.002972\n",
      "Epoch:95 step:13 loss: 0.000001\n",
      "Epoch:95 step:14 loss: 0.000002\n",
      "Epoch:95 step:15 loss: 0.000008\n",
      "Epoch:95 step:16 loss: 0.000000\n",
      "Epoch:95 step:17 loss: 0.000018\n",
      "Epoch:95 step:18 loss: 0.001046\n",
      "Epoch:95 step:19 loss: 0.005564\n",
      "Epoch:95 step:20 loss: 0.000000\n",
      "Epoch:95 step:21 loss: 0.000000\n",
      "Epoch:95 step:22 loss: 0.005078\n",
      "Epoch:95 step:23 loss: 0.000020\n",
      "Epoch:95 step:24 loss: 0.002917\n",
      "Epoch:95 step:25 loss: 0.000444\n",
      "Epoch:95 step:26 loss: 0.003599\n",
      "Epoch:95 step:27 loss: 0.007379\n",
      "Epoch:95 step:28 loss: 0.000000\n",
      "Epoch:95 step:29 loss: 0.000000\n",
      "Epoch:95 step:30 loss: 0.000132\n",
      "Epoch:95 step:31 loss: 0.000019\n",
      "Epoch:95 step:32 loss: 0.000003\n",
      "Epoch:95 step:33 loss: 0.000000\n",
      "Epoch:95 step:34 loss: 0.004465\n",
      "Epoch:95 step:35 loss: 0.001981\n",
      "Epoch:95 step:36 loss: 0.000004\n",
      "Epoch:95 step:37 loss: 0.000502\n",
      "Epoch:95 step:38 loss: 0.000000\n",
      "Epoch:95 step:39 loss: 0.000015\n",
      "Epoch:95 step:40 loss: 0.008065\n",
      "Epoch:95 step:41 loss: 0.000000\n",
      "Epoch:95 step:42 loss: 0.000003\n",
      "Epoch:95 step:43 loss: 0.006579\n",
      "Epoch:95 step:44 loss: 0.000016\n",
      "Epoch:95 step:45 loss: 0.000846\n",
      "Epoch:95 step:46 loss: 0.000000\n",
      "Epoch:95 step:47 loss: 0.003130\n",
      "Epoch:95 step:48 loss: 0.001525\n",
      "Epoch:95 step:49 loss: 0.000000\n",
      "Epoch:95 step:50 loss: 0.000004\n",
      "Epoch:95 step:51 loss: 0.000001\n",
      "Epoch:95 step:52 loss: 0.000000\n",
      "Epoch:95 step:53 loss: 0.000001\n",
      "Epoch:95 step:54 loss: 0.008516\n",
      "Epoch:95 step:55 loss: 0.006779\n",
      "Epoch:95 step:56 loss: 0.004222\n",
      "Epoch:95 step:57 loss: 0.000509\n",
      "Epoch:95 step:58 loss: 0.002582\n",
      "Epoch:95 step:59 loss: 0.000004\n",
      "Epoch:95 step:60 loss: 0.008045\n",
      "Epoch:95 step:61 loss: 0.003181\n",
      "Epoch:95 step:62 loss: 0.000002\n",
      "Epoch:95 step:63 loss: 0.000175\n",
      "Epoch:95 step:64 loss: 0.000049\n",
      "Epoch:95 step:65 loss: 0.002456\n",
      "Epoch:95 step:66 loss: 0.000037\n",
      "Epoch:95 step:67 loss: 0.003313\n",
      "Epoch:95 step:68 loss: 0.000000\n",
      "Epoch:95 step:69 loss: 0.000000\n",
      "Epoch:95 step:70 loss: 0.000511\n",
      "Epoch:95 step:71 loss: 0.002250\n",
      "Epoch:95 step:72 loss: 0.000924\n",
      "Epoch:95 step:73 loss: 0.000010\n",
      "Epoch:95 step:74 loss: 0.001858\n",
      "Epoch:95 step:75 loss: 0.000048\n",
      "Epoch:95 step:76 loss: 0.000001\n",
      "Epoch:95 step:77 loss: 0.000441\n",
      "Epoch:95 step:78 loss: 0.004480\n",
      "Epoch:95 step:79 loss: 0.000917\n",
      "Test Epoch:95 step:0 loss: 0.002180tensor(0.3976, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:1 loss: 0.001752tensor(0.3058, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:2 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:4 loss: 0.003987tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:5 loss: 0.002533tensor(0.4299, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:7 loss: 0.002488tensor(0.4209, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:95 step:9 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:11 loss: 0.002302tensor(0.4277, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:12 loss: 0.002276tensor(0.4803, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:13 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:14 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:15 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:17 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:18 loss: 0.000604tensor(0.4652, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:19 loss: 0.004231tensor(0.4569, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:22 loss: 0.004859tensor(0.4648, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:23 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:24 loss: 0.002168tensor(0.4670, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:25 loss: 0.000509tensor(0.3148, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:26 loss: 0.002595tensor(0.4614, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:27 loss: 0.008789tensor(0.4687, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:30 loss: 0.000099tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:31 loss: 0.000042tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:32 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:34 loss: 0.002590tensor(0.3999, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:35 loss: 0.001976tensor(0.4130, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:36 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:37 loss: 0.001273tensor(0.2448, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:39 loss: 0.000029tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:40 loss: 0.006656tensor(0.4746, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:42 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:43 loss: 0.004890tensor(0.4553, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:44 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:45 loss: 0.000523tensor(0.4311, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:47 loss: 0.003625tensor(0.4604, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:48 loss: 0.001839tensor(0.3189, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:50 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:51 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:53 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:54 loss: 0.006328tensor(0.4602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:55 loss: 0.007146tensor(0.4512, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:56 loss: 0.002995tensor(0.4673, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:57 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:58 loss: 0.003023tensor(0.3717, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:59 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:60 loss: 0.013595tensor(0.4566, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:61 loss: 0.004829tensor(0.3516, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:63 loss: 0.000220tensor(0.3190, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:64 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:65 loss: 0.002890tensor(0.4404, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:66 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:67 loss: 0.002412tensor(0.4439, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:70 loss: 0.000357tensor(0.4468, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:71 loss: 0.006433tensor(0.4255, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:72 loss: 0.003933tensor(0.4123, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:73 loss: 0.000105tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:74 loss: 0.002747tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:75 loss: 0.001103tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:76 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:77 loss: 0.000477tensor(0.3342, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:78 loss: 0.011601tensor(0.4273, grad_fn=<DivBackward0>)\n",
      "Test Epoch:95 step:79 loss: 0.001048tensor(0.4434, grad_fn=<DivBackward0>)\n",
      "Epoch:96 step:0 loss: 0.002219\n",
      "Epoch:96 step:1 loss: 0.001947\n",
      "Epoch:96 step:2 loss: 0.000262\n",
      "Epoch:96 step:3 loss: 0.000000\n",
      "Epoch:96 step:4 loss: 0.004095\n",
      "Epoch:96 step:5 loss: 0.003135\n",
      "Epoch:96 step:6 loss: 0.000000\n",
      "Epoch:96 step:7 loss: 0.003358\n",
      "Epoch:96 step:8 loss: 0.000001\n",
      "Epoch:96 step:9 loss: 0.000003\n",
      "Epoch:96 step:10 loss: 0.000000\n",
      "Epoch:96 step:11 loss: 0.003525\n",
      "Epoch:96 step:12 loss: 0.003481\n",
      "Epoch:96 step:13 loss: 0.000001\n",
      "Epoch:96 step:14 loss: 0.000008\n",
      "Epoch:96 step:15 loss: 0.000030\n",
      "Epoch:96 step:16 loss: 0.000000\n",
      "Epoch:96 step:17 loss: 0.000053\n",
      "Epoch:96 step:18 loss: 0.001739\n",
      "Epoch:96 step:19 loss: 0.006401\n",
      "Epoch:96 step:20 loss: 0.000000\n",
      "Epoch:96 step:21 loss: 0.000017\n",
      "Epoch:96 step:22 loss: 0.006376\n",
      "Epoch:96 step:23 loss: 0.000080\n",
      "Epoch:96 step:24 loss: 0.004467\n",
      "Epoch:96 step:25 loss: 0.000470\n",
      "Epoch:96 step:26 loss: 0.003534\n",
      "Epoch:96 step:27 loss: 0.008268\n",
      "Epoch:96 step:28 loss: 0.000000\n",
      "Epoch:96 step:29 loss: 0.000000\n",
      "Epoch:96 step:30 loss: 0.000173\n",
      "Epoch:96 step:31 loss: 0.000013\n",
      "Epoch:96 step:32 loss: 0.000006\n",
      "Epoch:96 step:33 loss: 0.000000\n",
      "Epoch:96 step:34 loss: 0.004993\n",
      "Epoch:96 step:35 loss: 0.001873\n",
      "Epoch:96 step:36 loss: 0.000004\n",
      "Epoch:96 step:37 loss: 0.000391\n",
      "Epoch:96 step:38 loss: 0.000000\n",
      "Epoch:96 step:39 loss: 0.000022\n",
      "Epoch:96 step:40 loss: 0.010324\n",
      "Epoch:96 step:41 loss: 0.000000\n",
      "Epoch:96 step:42 loss: 0.000030\n",
      "Epoch:96 step:43 loss: 0.005316\n",
      "Epoch:96 step:44 loss: 0.000051\n",
      "Epoch:96 step:45 loss: 0.000817\n",
      "Epoch:96 step:46 loss: 0.000013\n",
      "Epoch:96 step:47 loss: 0.003393\n",
      "Epoch:96 step:48 loss: 0.002632\n",
      "Epoch:96 step:49 loss: 0.000001\n",
      "Epoch:96 step:50 loss: 0.000002\n",
      "Epoch:96 step:51 loss: 0.000008\n",
      "Epoch:96 step:52 loss: 0.000001\n",
      "Epoch:96 step:53 loss: 0.000011\n",
      "Epoch:96 step:54 loss: 0.007785\n",
      "Epoch:96 step:55 loss: 0.007057\n",
      "Epoch:96 step:56 loss: 0.004572\n",
      "Epoch:96 step:57 loss: 0.000148\n",
      "Epoch:96 step:58 loss: 0.003701\n",
      "Epoch:96 step:59 loss: 0.000004\n",
      "Epoch:96 step:60 loss: 0.009746\n",
      "Epoch:96 step:61 loss: 0.003013\n",
      "Epoch:96 step:62 loss: 0.000001\n",
      "Epoch:96 step:63 loss: 0.000219\n",
      "Epoch:96 step:64 loss: 0.000003\n",
      "Epoch:96 step:65 loss: 0.001670\n",
      "Epoch:96 step:66 loss: 0.000004\n",
      "Epoch:96 step:67 loss: 0.003354\n",
      "Epoch:96 step:68 loss: 0.000000\n",
      "Epoch:96 step:69 loss: 0.000000\n",
      "Epoch:96 step:70 loss: 0.000615\n",
      "Epoch:96 step:71 loss: 0.002308\n",
      "Epoch:96 step:72 loss: 0.001161\n",
      "Epoch:96 step:73 loss: 0.000025\n",
      "Epoch:96 step:74 loss: 0.002496\n",
      "Epoch:96 step:75 loss: 0.000075\n",
      "Epoch:96 step:76 loss: 0.000001\n",
      "Epoch:96 step:77 loss: 0.000281\n",
      "Epoch:96 step:78 loss: 0.015560\n",
      "Epoch:96 step:79 loss: 0.000764\n",
      "Test Epoch:96 step:0 loss: 0.002916tensor(0.3688, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:1 loss: 0.002712tensor(0.1941, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:2 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:4 loss: 0.011548tensor(0.3901, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:5 loss: 0.008402tensor(0.3661, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:96 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:7 loss: 0.004495tensor(0.3713, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:9 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:11 loss: 0.003255tensor(0.4040, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:12 loss: 0.002863tensor(0.4745, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:13 loss: 0.000460tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:15 loss: 0.000228tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:17 loss: 0.000121tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:18 loss: 0.002870tensor(0.3911, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:19 loss: 0.006826tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:20 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:22 loss: 0.009949tensor(0.4381, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:23 loss: 0.000036tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:24 loss: 0.004035tensor(0.4473, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:25 loss: 0.000669tensor(0.2167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:26 loss: 0.009579tensor(0.4051, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:27 loss: 0.011910tensor(0.4520, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:30 loss: 0.000207tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:31 loss: 0.000168tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:32 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:34 loss: 0.002790tensor(0.3680, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:35 loss: 0.002536tensor(0.3578, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:36 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:37 loss: 0.000964tensor(0.2388, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:38 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:39 loss: 0.005569tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:40 loss: 0.009616tensor(0.4654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:41 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:42 loss: 0.000325tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:43 loss: 0.009407tensor(0.4281, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:44 loss: 0.000026tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:45 loss: 0.000724tensor(0.3971, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:46 loss: 0.000063tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:47 loss: 0.004231tensor(0.4508, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:48 loss: 0.001666tensor(0.3091, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:49 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:50 loss: 0.000090tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:51 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:52 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:53 loss: 0.000217tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:54 loss: 0.013938tensor(0.4230, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:55 loss: 0.016689tensor(0.4028, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:56 loss: 0.017365tensor(0.3816, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:57 loss: 0.001154tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:58 loss: 0.003104tensor(0.3280, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:59 loss: 0.000322tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:60 loss: 0.016114tensor(0.4357, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:61 loss: 0.005208tensor(0.3229, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:62 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:63 loss: 0.002070tensor(0.0820, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:64 loss: 0.012506tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:65 loss: 0.002428tensor(0.4421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:66 loss: 0.000151tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:67 loss: 0.007126tensor(0.3552, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:69 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:70 loss: 0.004366tensor(0.1677, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:71 loss: 0.005685tensor(0.4035, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:72 loss: 0.001373tensor(0.4367, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:73 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:74 loss: 0.002995tensor(0.4286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:75 loss: 0.001268tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:76 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:77 loss: 0.003382tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:78 loss: 0.005929tensor(0.4441, grad_fn=<DivBackward0>)\n",
      "Test Epoch:96 step:79 loss: 0.003443tensor(0.3990, grad_fn=<DivBackward0>)\n",
      "Epoch:97 step:0 loss: 0.005498\n",
      "Epoch:97 step:1 loss: 0.002899\n",
      "Epoch:97 step:2 loss: 0.001320\n",
      "Epoch:97 step:3 loss: 0.000001\n",
      "Epoch:97 step:4 loss: 0.006493\n",
      "Epoch:97 step:5 loss: 0.002590\n",
      "Epoch:97 step:6 loss: 0.000002\n",
      "Epoch:97 step:7 loss: 0.004693\n",
      "Epoch:97 step:8 loss: 0.000018\n",
      "Epoch:97 step:9 loss: 0.000015\n",
      "Epoch:97 step:10 loss: 0.000003\n",
      "Epoch:97 step:11 loss: 0.005352\n",
      "Epoch:97 step:12 loss: 0.005334\n",
      "Epoch:97 step:13 loss: 0.003048\n",
      "Epoch:97 step:14 loss: 0.000002\n",
      "Epoch:97 step:15 loss: 0.000070\n",
      "Epoch:97 step:16 loss: 0.000001\n",
      "Epoch:97 step:17 loss: 0.000441\n",
      "Epoch:97 step:18 loss: 0.006799\n",
      "Epoch:97 step:19 loss: 0.012132\n",
      "Epoch:97 step:20 loss: 0.000004\n",
      "Epoch:97 step:21 loss: 0.000004\n",
      "Epoch:97 step:22 loss: 0.017437\n",
      "Epoch:97 step:23 loss: 0.001282\n",
      "Epoch:97 step:24 loss: 0.008651\n",
      "Epoch:97 step:25 loss: 0.001016\n",
      "Epoch:97 step:26 loss: 0.006150\n",
      "Epoch:97 step:27 loss: 0.010356\n",
      "Epoch:97 step:28 loss: 0.000002\n",
      "Epoch:97 step:29 loss: 0.000609\n",
      "Epoch:97 step:30 loss: 0.001223\n",
      "Epoch:97 step:31 loss: 0.003041\n",
      "Epoch:97 step:32 loss: 0.000606\n",
      "Epoch:97 step:33 loss: 0.000001\n",
      "Epoch:97 step:34 loss: 0.002795\n",
      "Epoch:97 step:35 loss: 0.002292\n",
      "Epoch:97 step:36 loss: 0.000010\n",
      "Epoch:97 step:37 loss: 0.001133\n",
      "Epoch:97 step:38 loss: 0.000000\n",
      "Epoch:97 step:39 loss: 0.000066\n",
      "Epoch:97 step:40 loss: 0.010264\n",
      "Epoch:97 step:41 loss: 0.000000\n",
      "Epoch:97 step:42 loss: 0.000001\n",
      "Epoch:97 step:43 loss: 0.006641\n",
      "Epoch:97 step:44 loss: 0.000001\n",
      "Epoch:97 step:45 loss: 0.001339\n",
      "Epoch:97 step:46 loss: 0.000000\n",
      "Epoch:97 step:47 loss: 0.005335\n",
      "Epoch:97 step:48 loss: 0.001446\n",
      "Epoch:97 step:49 loss: 0.000000\n",
      "Epoch:97 step:50 loss: 0.000014\n",
      "Epoch:97 step:51 loss: 0.000045\n",
      "Epoch:97 step:52 loss: 0.000000\n",
      "Epoch:97 step:53 loss: 0.000076\n",
      "Epoch:97 step:54 loss: 0.006520\n",
      "Epoch:97 step:55 loss: 0.009942\n",
      "Epoch:97 step:56 loss: 0.003146\n",
      "Epoch:97 step:57 loss: 0.000009\n",
      "Epoch:97 step:58 loss: 0.003503\n",
      "Epoch:97 step:59 loss: 0.000825\n",
      "Epoch:97 step:60 loss: 0.008765\n",
      "Epoch:97 step:61 loss: 0.003097\n",
      "Epoch:97 step:62 loss: 0.000003\n",
      "Epoch:97 step:63 loss: 0.000355\n",
      "Epoch:97 step:64 loss: 0.000755\n",
      "Epoch:97 step:65 loss: 0.002482\n",
      "Epoch:97 step:66 loss: 0.000080\n",
      "Epoch:97 step:67 loss: 0.004489\n",
      "Epoch:97 step:68 loss: 0.000000\n",
      "Epoch:97 step:69 loss: 0.000000\n",
      "Epoch:97 step:70 loss: 0.002269\n",
      "Epoch:97 step:71 loss: 0.002956\n",
      "Epoch:97 step:72 loss: 0.001320\n",
      "Epoch:97 step:73 loss: 0.000010\n",
      "Epoch:97 step:74 loss: 0.002540\n",
      "Epoch:97 step:75 loss: 0.000039\n",
      "Epoch:97 step:76 loss: 0.000008\n",
      "Epoch:97 step:77 loss: 0.000288\n",
      "Epoch:97 step:78 loss: 0.007970\n",
      "Epoch:97 step:79 loss: 0.001492\n",
      "Test Epoch:97 step:0 loss: 0.002588tensor(0.3645, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:1 loss: 0.002993tensor(0.2602, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:2 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:97 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:4 loss: 0.004783tensor(0.4400, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:5 loss: 0.006955tensor(0.3869, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:7 loss: 0.003140tensor(0.3999, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:8 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:9 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:10 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:11 loss: 0.004182tensor(0.3894, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:12 loss: 0.002753tensor(0.4720, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:13 loss: 0.000035tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:14 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:15 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:17 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:18 loss: 0.001974tensor(0.4067, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:19 loss: 0.009534tensor(0.4113, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:22 loss: 0.007205tensor(0.4453, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:23 loss: 0.006661tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:24 loss: 0.004411tensor(0.4368, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:25 loss: 0.000946tensor(0.1836, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:26 loss: 0.004574tensor(0.4391, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:27 loss: 0.007378tensor(0.4679, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:30 loss: 0.000233tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:31 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:32 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:34 loss: 0.002802tensor(0.3612, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:35 loss: 0.003415tensor(0.3434, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:36 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:37 loss: 0.002300tensor(0.1663, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:39 loss: 0.000043tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:40 loss: 0.007796tensor(0.4709, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:42 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:43 loss: 0.004448tensor(0.4532, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:44 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:45 loss: 0.000506tensor(0.4168, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:47 loss: 0.003340tensor(0.4581, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:48 loss: 0.002034tensor(0.2449, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:49 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:50 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:51 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:52 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:53 loss: 0.000008tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:54 loss: 0.004169tensor(0.4659, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:55 loss: 0.007040tensor(0.4425, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:56 loss: 0.002492tensor(0.4688, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:57 loss: 0.000064tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:58 loss: 0.003003tensor(0.3462, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:59 loss: 0.000087tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:60 loss: 0.006525tensor(0.4688, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:61 loss: 0.003590tensor(0.3690, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:62 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:63 loss: 0.000175tensor(0.3615, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:64 loss: 0.000104tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:65 loss: 0.001781tensor(0.4547, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:66 loss: 0.000059tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:67 loss: 0.003298tensor(0.4278, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:70 loss: 0.000641tensor(0.4206, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:71 loss: 0.002318tensor(0.4574, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:72 loss: 0.001505tensor(0.4445, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:73 loss: 0.000021tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:74 loss: 0.001841tensor(0.4573, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:75 loss: 0.000039tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:76 loss: 0.000012tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:77 loss: 0.000494tensor(0.3449, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:78 loss: 0.004753tensor(0.4609, grad_fn=<DivBackward0>)\n",
      "Test Epoch:97 step:79 loss: 0.002533tensor(0.4013, grad_fn=<DivBackward0>)\n",
      "Epoch:98 step:0 loss: 0.002257\n",
      "Epoch:98 step:1 loss: 0.001804\n",
      "Epoch:98 step:2 loss: 0.000014\n",
      "Epoch:98 step:3 loss: 0.000000\n",
      "Epoch:98 step:4 loss: 0.003798\n",
      "Epoch:98 step:5 loss: 0.001786\n",
      "Epoch:98 step:6 loss: 0.000000\n",
      "Epoch:98 step:7 loss: 0.002539\n",
      "Epoch:98 step:8 loss: 0.000000\n",
      "Epoch:98 step:9 loss: 0.000013\n",
      "Epoch:98 step:10 loss: 0.000000\n",
      "Epoch:98 step:11 loss: 0.002082\n",
      "Epoch:98 step:12 loss: 0.002368\n",
      "Epoch:98 step:13 loss: 0.000001\n",
      "Epoch:98 step:14 loss: 0.000002\n",
      "Epoch:98 step:15 loss: 0.000009\n",
      "Epoch:98 step:16 loss: 0.000000\n",
      "Epoch:98 step:17 loss: 0.000012\n",
      "Epoch:98 step:18 loss: 0.001013\n",
      "Epoch:98 step:19 loss: 0.005078\n",
      "Epoch:98 step:20 loss: 0.000000\n",
      "Epoch:98 step:21 loss: 0.000000\n",
      "Epoch:98 step:22 loss: 0.004730\n",
      "Epoch:98 step:23 loss: 0.000033\n",
      "Epoch:98 step:24 loss: 0.002540\n",
      "Epoch:98 step:25 loss: 0.000531\n",
      "Epoch:98 step:26 loss: 0.003618\n",
      "Epoch:98 step:27 loss: 0.007089\n",
      "Epoch:98 step:28 loss: 0.000000\n",
      "Epoch:98 step:29 loss: 0.000000\n",
      "Epoch:98 step:30 loss: 0.000202\n",
      "Epoch:98 step:31 loss: 0.000008\n",
      "Epoch:98 step:32 loss: 0.000004\n",
      "Epoch:98 step:33 loss: 0.000000\n",
      "Epoch:98 step:34 loss: 0.001986\n",
      "Epoch:98 step:35 loss: 0.002102\n",
      "Epoch:98 step:36 loss: 0.000020\n",
      "Epoch:98 step:37 loss: 0.000455\n",
      "Epoch:98 step:38 loss: 0.000003\n",
      "Epoch:98 step:39 loss: 0.000026\n",
      "Epoch:98 step:40 loss: 0.006772\n",
      "Epoch:98 step:41 loss: 0.000000\n",
      "Epoch:98 step:42 loss: 0.000003\n",
      "Epoch:98 step:43 loss: 0.005096\n",
      "Epoch:98 step:44 loss: 0.000000\n",
      "Epoch:98 step:45 loss: 0.000686\n",
      "Epoch:98 step:46 loss: 0.000000\n",
      "Epoch:98 step:47 loss: 0.003235\n",
      "Epoch:98 step:48 loss: 0.001232\n",
      "Epoch:98 step:49 loss: 0.000001\n",
      "Epoch:98 step:50 loss: 0.000000\n",
      "Epoch:98 step:51 loss: 0.000000\n",
      "Epoch:98 step:52 loss: 0.000001\n",
      "Epoch:98 step:53 loss: 0.000000\n",
      "Epoch:98 step:54 loss: 0.004589\n",
      "Epoch:98 step:55 loss: 0.005907\n",
      "Epoch:98 step:56 loss: 0.003976\n",
      "Epoch:98 step:57 loss: 0.000005\n",
      "Epoch:98 step:58 loss: 0.005060\n",
      "Epoch:98 step:59 loss: 0.000019\n",
      "Epoch:98 step:60 loss: 0.006965\n",
      "Epoch:98 step:61 loss: 0.003257\n",
      "Epoch:98 step:62 loss: 0.000003\n",
      "Epoch:98 step:63 loss: 0.000243\n",
      "Epoch:98 step:64 loss: 0.000044\n",
      "Epoch:98 step:65 loss: 0.002349\n",
      "Epoch:98 step:66 loss: 0.000028\n",
      "Epoch:98 step:67 loss: 0.005466\n",
      "Epoch:98 step:68 loss: 0.000000\n",
      "Epoch:98 step:69 loss: 0.000000\n",
      "Epoch:98 step:70 loss: 0.000643\n",
      "Epoch:98 step:71 loss: 0.002707\n",
      "Epoch:98 step:72 loss: 0.001048\n",
      "Epoch:98 step:73 loss: 0.000011\n",
      "Epoch:98 step:74 loss: 0.002312\n",
      "Epoch:98 step:75 loss: 0.000067\n",
      "Epoch:98 step:76 loss: 0.000001\n",
      "Epoch:98 step:77 loss: 0.000181\n",
      "Epoch:98 step:78 loss: 0.004297\n",
      "Epoch:98 step:79 loss: 0.001152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:98 step:0 loss: 0.002479tensor(0.3866, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:1 loss: 0.003338tensor(0.2847, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:2 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:4 loss: 0.003803tensor(0.4500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:5 loss: 0.001829tensor(0.4421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:7 loss: 0.002448tensor(0.4232, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:9 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:11 loss: 0.002066tensor(0.4324, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:12 loss: 0.002596tensor(0.4769, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:13 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:14 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:15 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:17 loss: 0.000014tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:18 loss: 0.007433tensor(0.2681, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:19 loss: 0.004958tensor(0.4498, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:22 loss: 0.007124tensor(0.4490, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:23 loss: 0.000023tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:24 loss: 0.003789tensor(0.4511, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:25 loss: 0.000834tensor(0.3045, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:26 loss: 0.003637tensor(0.4527, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:27 loss: 0.008987tensor(0.4669, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:30 loss: 0.003602tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:31 loss: 0.000048tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:32 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:34 loss: 0.001820tensor(0.4184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:35 loss: 0.003091tensor(0.3750, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:36 loss: 0.000013tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:37 loss: 0.000329tensor(0.3624, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:38 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:39 loss: 0.000058tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:40 loss: 0.009214tensor(0.4687, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:43 loss: 0.011329tensor(0.4183, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:44 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:45 loss: 0.000528tensor(0.4184, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:47 loss: 0.005394tensor(0.4451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:48 loss: 0.001739tensor(0.3349, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:49 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:50 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:51 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:52 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:53 loss: 0.000083tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:54 loss: 0.004679tensor(0.4654, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:55 loss: 0.006632tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:56 loss: 0.003739tensor(0.4572, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:57 loss: 0.000047tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:58 loss: 0.004302tensor(0.3146, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:59 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:60 loss: 0.008718tensor(0.4639, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:61 loss: 0.004084tensor(0.3563, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:62 loss: 0.000009tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:63 loss: 0.000215tensor(0.3392, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:64 loss: 0.000199tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:65 loss: 0.003475tensor(0.4294, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:66 loss: 0.000022tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:67 loss: 0.003188tensor(0.4246, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:70 loss: 0.000496tensor(0.4296, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:71 loss: 0.006142tensor(0.4261, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:72 loss: 0.001609tensor(0.4500, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:73 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:74 loss: 0.002264tensor(0.4491, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:75 loss: 0.000393tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:76 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:77 loss: 0.000221tensor(0.3891, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:78 loss: 0.008499tensor(0.4413, grad_fn=<DivBackward0>)\n",
      "Test Epoch:98 step:79 loss: 0.001123tensor(0.4419, grad_fn=<DivBackward0>)\n",
      "Epoch:99 step:0 loss: 0.002125\n",
      "Epoch:99 step:1 loss: 0.001463\n",
      "Epoch:99 step:2 loss: 0.000019\n",
      "Epoch:99 step:3 loss: 0.000000\n",
      "Epoch:99 step:4 loss: 0.003827\n",
      "Epoch:99 step:5 loss: 0.002299\n",
      "Epoch:99 step:6 loss: 0.000000\n",
      "Epoch:99 step:7 loss: 0.002157\n",
      "Epoch:99 step:8 loss: 0.000001\n",
      "Epoch:99 step:9 loss: 0.000001\n",
      "Epoch:99 step:10 loss: 0.000000\n",
      "Epoch:99 step:11 loss: 0.001713\n",
      "Epoch:99 step:12 loss: 0.003079\n",
      "Epoch:99 step:13 loss: 0.000002\n",
      "Epoch:99 step:14 loss: 0.000001\n",
      "Epoch:99 step:15 loss: 0.000016\n",
      "Epoch:99 step:16 loss: 0.000000\n",
      "Epoch:99 step:17 loss: 0.000006\n",
      "Epoch:99 step:18 loss: 0.001039\n",
      "Epoch:99 step:19 loss: 0.006329\n",
      "Epoch:99 step:20 loss: 0.000000\n",
      "Epoch:99 step:21 loss: 0.000000\n",
      "Epoch:99 step:22 loss: 0.005238\n",
      "Epoch:99 step:23 loss: 0.000006\n",
      "Epoch:99 step:24 loss: 0.002106\n",
      "Epoch:99 step:25 loss: 0.000380\n",
      "Epoch:99 step:26 loss: 0.002441\n",
      "Epoch:99 step:27 loss: 0.006812\n",
      "Epoch:99 step:28 loss: 0.000000\n",
      "Epoch:99 step:29 loss: 0.000000\n",
      "Epoch:99 step:30 loss: 0.000103\n",
      "Epoch:99 step:31 loss: 0.000012\n",
      "Epoch:99 step:32 loss: 0.000010\n",
      "Epoch:99 step:33 loss: 0.000000\n",
      "Epoch:99 step:34 loss: 0.001554\n",
      "Epoch:99 step:35 loss: 0.002122\n",
      "Epoch:99 step:36 loss: 0.000010\n",
      "Epoch:99 step:37 loss: 0.000804\n",
      "Epoch:99 step:38 loss: 0.000001\n",
      "Epoch:99 step:39 loss: 0.000011\n",
      "Epoch:99 step:40 loss: 0.007447\n",
      "Epoch:99 step:41 loss: 0.000000\n",
      "Epoch:99 step:42 loss: 0.000003\n",
      "Epoch:99 step:43 loss: 0.004275\n",
      "Epoch:99 step:44 loss: 0.000000\n",
      "Epoch:99 step:45 loss: 0.001111\n",
      "Epoch:99 step:46 loss: 0.000000\n",
      "Epoch:99 step:47 loss: 0.003785\n",
      "Epoch:99 step:48 loss: 0.001271\n",
      "Epoch:99 step:49 loss: 0.000000\n",
      "Epoch:99 step:50 loss: 0.000000\n",
      "Epoch:99 step:51 loss: 0.000001\n",
      "Epoch:99 step:52 loss: 0.000000\n",
      "Epoch:99 step:53 loss: 0.000001\n",
      "Epoch:99 step:54 loss: 0.004111\n",
      "Epoch:99 step:55 loss: 0.005831\n",
      "Epoch:99 step:56 loss: 0.003051\n",
      "Epoch:99 step:57 loss: 0.000006\n",
      "Epoch:99 step:58 loss: 0.005002\n",
      "Epoch:99 step:59 loss: 0.000011\n",
      "Epoch:99 step:60 loss: 0.005737\n",
      "Epoch:99 step:61 loss: 0.002877\n",
      "Epoch:99 step:62 loss: 0.000017\n",
      "Epoch:99 step:63 loss: 0.000182\n",
      "Epoch:99 step:64 loss: 0.000012\n",
      "Epoch:99 step:65 loss: 0.001568\n",
      "Epoch:99 step:66 loss: 0.000009\n",
      "Epoch:99 step:67 loss: 0.002400\n",
      "Epoch:99 step:68 loss: 0.000000\n",
      "Epoch:99 step:69 loss: 0.000000\n",
      "Epoch:99 step:70 loss: 0.000511\n",
      "Epoch:99 step:71 loss: 0.002209\n",
      "Epoch:99 step:72 loss: 0.000989\n",
      "Epoch:99 step:73 loss: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99 step:74 loss: 0.001948\n",
      "Epoch:99 step:75 loss: 0.000028\n",
      "Epoch:99 step:76 loss: 0.000001\n",
      "Epoch:99 step:77 loss: 0.000200\n",
      "Epoch:99 step:78 loss: 0.005922\n",
      "Epoch:99 step:79 loss: 0.001038\n",
      "Test Epoch:99 step:0 loss: 0.002275tensor(0.3995, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:1 loss: 0.001500tensor(0.3339, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:2 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:3 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:4 loss: 0.004609tensor(0.4423, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:5 loss: 0.003292tensor(0.4167, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:6 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:7 loss: 0.002815tensor(0.4117, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:8 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:9 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:10 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:11 loss: 0.001474tensor(0.4452, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:12 loss: 0.002642tensor(0.4776, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:13 loss: 0.000033tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:14 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:15 loss: 0.000018tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:16 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:17 loss: 0.000003tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:18 loss: 0.000949tensor(0.4524, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:19 loss: 0.006327tensor(0.4451, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:20 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:21 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:22 loss: 0.004491tensor(0.4675, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:23 loss: 0.000010tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:24 loss: 0.001584tensor(0.4745, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:25 loss: 0.000490tensor(0.3558, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:26 loss: 0.002417tensor(0.4659, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:27 loss: 0.007618tensor(0.4727, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:28 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:29 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:30 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:31 loss: 0.000007tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:32 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:33 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:34 loss: 0.001541tensor(0.4327, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:35 loss: 0.002431tensor(0.3911, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:36 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:37 loss: 0.000400tensor(0.3546, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:38 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:39 loss: 0.000038tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:40 loss: 0.010471tensor(0.4707, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:41 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:42 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:43 loss: 0.004458tensor(0.4558, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:44 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:45 loss: 0.000491tensor(0.4327, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:46 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:47 loss: 0.005540tensor(0.4466, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:48 loss: 0.001235tensor(0.3467, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:49 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:50 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:51 loss: 0.000076tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:52 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:53 loss: 0.000016tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:54 loss: 0.006166tensor(0.4611, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:55 loss: 0.005666tensor(0.4575, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:56 loss: 0.004021tensor(0.4595, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:57 loss: 0.000027tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:58 loss: 0.004067tensor(0.3286, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:59 loss: 0.000148tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:60 loss: 0.004906tensor(0.4767, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:61 loss: 0.002783tensor(0.3980, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:62 loss: 0.000006tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:63 loss: 0.000268tensor(0.3578, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:64 loss: 0.000028tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:65 loss: 0.001800tensor(0.4555, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:66 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:67 loss: 0.002238tensor(0.4421, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:68 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:69 loss: 0.000000tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:70 loss: 0.000544tensor(0.4517, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:71 loss: 0.001648tensor(0.4684, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:72 loss: 0.000779tensor(0.4672, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:73 loss: 0.000001tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:74 loss: 0.001828tensor(0.4568, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:75 loss: 0.000004tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:76 loss: 0.000002tensor(0., grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:77 loss: 0.000233tensor(0.3725, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:78 loss: 0.002986tensor(0.4703, grad_fn=<DivBackward0>)\n",
      "Test Epoch:99 step:79 loss: 0.001429tensor(0.4470, grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 处理源图像与标记数据\n",
    "    trainDataLoader = trainData()\n",
    "    # 这个函数目的其实是为了检查一下标记和数据有没有对上\n",
    "    # trainDataLoader.test_show()\n",
    "\n",
    "    im_channel = 5\n",
    "    x, y = trainDataLoader.get_train_data(number=100,batch_size=1,channel=im_channel,im_size=(128,128))\n",
    "    # 运行unet\n",
    "\n",
    "    model = Unet(in_ch=im_channel,out_ch=1)\n",
    "    print(model)\n",
    "    \n",
    "    train_model(model,x,y,100,0.05)\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
